{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Version to run on MARCC\n",
    "\n",
    "This notebook is assummed to be launched from the top level of the AutomaticLP github repo (where the notebook file is)\n",
    "\n",
    "This also assummes that you've already cloed the tensorflow object detection project\n",
    "https://github.com/tensorflow/models (since you need to do this to add the python path to  the bashrc file which has to be done before launching jupyter lab\n",
    "\n",
    "Run with the LPproject kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup / Installations\n",
    "\n",
    "Add\n",
    "<code>\n",
    "export PYTHONPATH=$PYTHONPATH:`pwd`\n",
    "export PYTHONPATH=$PYTHONPATH:`pwd`/slim\n",
    "\n",
    "to your ~/.bashrc file where pwd is the full path to the models/research directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests that Tensorflow GPU is installed & this notebook can see the GPU \n",
    "\n",
    "These don't need to be run everytime but are here as a sanity / debugging check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test that tensorflow can access a GPU\n",
    "import tensorflow as tf\n",
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "cd models/research\n",
    "FILE=protobuf.zip\n",
    "if [ ! -f \"$FILE\" ]; then\n",
    "    wget -O protobuf.zip https://github.com/google/protobuf/releases/download/v3.0.0/protoc-3.0.0-linux-x86_64.zip\n",
    "    unzip protobuf.zip\n",
    "fi\n",
    "./bin/protoc object_detection/protos/*.proto --python_out=.\n",
    "pip install --user ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ml cuda/9.0\n",
    "!export CUDA_VISIBLE_DEVICES=1\n",
    "!echo ${CUDA_VISIBLE_DEVICES}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ScriptForBashFile generates both the training and test data and TFRecords from the image files\n",
    "\n",
    "(For now hard coded to 100 images - TODO: switch back to user input, note then this won't be able to run with a bash script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the total number of samples (60% is training, 40% is testing):  10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingImages_2020-04-12_09-38\n",
      "Number of Instance of Each Character:\n",
      "0 2\n",
      "1 4\n",
      "2 4\n",
      "3 2\n",
      "4 2\n",
      "5 3\n",
      "6 3\n",
      "7 5\n",
      "8 3\n",
      "9 2\n",
      "A 0\n",
      "B 3\n",
      "C 0\n",
      "D 0\n",
      "E 1\n",
      "F 0\n",
      "G 2\n",
      "H 0\n",
      "J 1\n",
      "K 0\n",
      "L 0\n",
      "M 2\n",
      "N 0\n",
      "P 1\n",
      "R 0\n",
      "S 0\n",
      "T 0\n",
      "V 0\n",
      "W 0\n",
      "X 0\n",
      "Y 1\n",
      "Z 1\n",
      "6  Training Images Generated\n",
      "TestImages_2020-04-12_09-38\n",
      "Number of Instance of Each Character:\n",
      "0 4\n",
      "1 6\n",
      "2 8\n",
      "3 5\n",
      "4 3\n",
      "5 4\n",
      "6 3\n",
      "7 6\n",
      "8 6\n",
      "9 5\n",
      "A 0\n",
      "B 4\n",
      "C 0\n",
      "D 0\n",
      "E 1\n",
      "F 0\n",
      "G 3\n",
      "H 0\n",
      "J 1\n",
      "K 0\n",
      "L 0\n",
      "M 2\n",
      "N 0\n",
      "P 2\n",
      "R 0\n",
      "S 1\n",
      "T 0\n",
      "V 0\n",
      "W 1\n",
      "X 1\n",
      "Y 2\n",
      "Z 2\n",
      "4  Test Images Generated\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/TFRecordConverter.py:86: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run ScriptForBashFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If training output directory dosen't exist create it\n",
    "!mkdir -p trainingOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/legacy/train.py:56: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/legacy/train.py:56: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/legacy/train.py:185: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/anaconda3/lib/python3.7/site-packages/absl/app.py:250: main (from __main__) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use object_detection/model_main.py.\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/legacy/train.py:91: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/legacy/train.py:96: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/legacy/trainer.py:267: create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.create_global_step\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/builders/dataset_builder.py:71: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
      "\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.parallel_interleave(...)`.\n",
      "WARNING:tensorflow:From /home/christina/.local/lib/python3.7/site-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/builders/dataset_builder.py:43: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/builders/dataset_builder.py:44: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/builders/dataset_builder.py:44: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/core/preprocessor.py:627: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/core/preprocessor.py:197: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/core/box_list_ops.py:206: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/core/batcher.py:101: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
      "WARNING:tensorflow:From /home/christina/.local/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:752: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/christina/.local/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:752: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/core/prefetcher.py:51: The name tf.PaddingFIFOQueue is deprecated. Please use tf.queue.PaddingFIFOQueue instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/core/prefetcher.py:58: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/legacy/trainer.py:286: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/slim/deployment/model_deploy.py:192: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/slim/deployment/model_deploy.py:192: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/core/preprocessor.py:2937: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/.local/lib/python3.7/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/core/losses.py:79: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/legacy/trainer.py:209: The name tf.losses.add_loss is deprecated. Please use tf.compat.v1.losses.add_loss instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/builders/optimizer_builder.py:157: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/utils/learning_schedules.py:66: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/builders/optimizer_builder.py:47: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/legacy/trainer.py:323: The name tf.check_numerics is deprecated. Please use tf.debugging.check_numerics instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/.local/lib/python3.7/site-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/christina/.local/lib/python3.7/site-packages/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/legacy/trainer.py:354: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/legacy/trainer.py:356: The name tf.losses.get_losses is deprecated. Please use tf.compat.v1.losses.get_losses instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/legacy/trainer.py:360: The name tf.losses.get_total_loss is deprecated. Please use tf.compat.v1.losses.get_total_loss instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/legacy/trainer.py:369: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/legacy/trainer.py:372: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/legacy/trainer.py:377: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/.local/lib/python3.7/site-packages/tensorflow_core/contrib/slim/python/slim/learning.py:742: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.MonitoredTrainingSession\n",
      "INFO:tensorflow:Restoring parameters from ../../FromScratch/ssd_mobilenet_v1_coco_2018_01_28/model.ckpt\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Starting Session.\n",
      "INFO:tensorflow:Saving checkpoint to path ../../trainingOutput/model.ckpt\n",
      "INFO:tensorflow:Starting Queues.\n",
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:Recording summary at step 0.\n",
      "INFO:tensorflow:global step 1: loss = 137.9314 (18.280 sec/step)\n",
      "INFO:tensorflow:global step 2: loss = 115.2412 (0.746 sec/step)\n",
      "INFO:tensorflow:global step 3: loss = 104.3407 (0.760 sec/step)\n",
      "INFO:tensorflow:global step 4: loss = 96.5293 (0.789 sec/step)\n",
      "INFO:tensorflow:global step 5: loss = 87.3902 (0.741 sec/step)\n",
      "INFO:tensorflow:global step 6: loss = 78.3884 (0.782 sec/step)\n",
      "INFO:tensorflow:global step 7: loss = 70.2592 (0.776 sec/step)\n",
      "INFO:tensorflow:global step 8: loss = 61.7219 (0.782 sec/step)\n"
     ]
    }
   ],
   "source": [
    "# This makes the output of the next cell write to the file\n",
    "# https://stackoverflow.com/questions/45200375/stdout-redirect-from-jupyter-notebook-is-landing-in-the-terminal\n",
    "import sys\n",
    "old_stdout = sys.stdout\n",
    "sys.stdout = open('trainingLog.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0412 09:39:16.520738 140345440180032 deprecation.py:323] From /home/christina/anaconda3/lib/python3.7/site-packages/absl/app.py:250: main (from __main__) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use object_detection/model_main.py.\n",
      "W0412 09:39:16.523317 140345440180032 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/legacy/train.py:91: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n",
      "W0412 09:39:16.531312 140345440180032 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/legacy/train.py:96: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.\n",
      "\n",
      "W0412 09:39:16.538436 140345440180032 deprecation.py:323] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/legacy/trainer.py:267: create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.create_global_step\n",
      "W0412 09:39:16.546613 140345440180032 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "W0412 09:39:16.549052 140345440180032 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
      "\n",
      "W0412 09:39:16.596649 140345440180032 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
      "\n",
      "W0412 09:39:16.599498 140345440180032 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/builders/dataset_builder.py:71: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
      "\n",
      "W0412 09:39:16.600937 140345440180032 dataset_builder.py:72] num_readers has been reduced to 1 to match input file shards.\n",
      "W0412 09:39:16.609690 140345440180032 deprecation.py:323] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.parallel_interleave(...)`.\n",
      "W0412 09:39:16.610887 140345440180032 deprecation.py:323] From /home/christina/.local/lib/python3.7/site-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "W0412 09:39:16.656268 140345440180032 deprecation.py:323] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0412 09:39:17.266446 140345440180032 deprecation.py:323] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/builders/dataset_builder.py:43: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
      "W0412 09:39:17.275932 140345440180032 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/builders/dataset_builder.py:44: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "W0412 09:39:17.277419 140345440180032 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/builders/dataset_builder.py:44: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "W0412 09:39:17.288634 140345440180032 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/core/preprocessor.py:627: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0412 09:39:17.356817 140345440180032 deprecation.py:323] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/core/preprocessor.py:197: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "W0412 09:39:17.370915 140345440180032 deprecation.py:323] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/core/box_list_ops.py:206: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0412 09:39:18.084327 140345440180032 deprecation.py:323] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/core/batcher.py:101: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
      "W0412 09:39:18.091735 140345440180032 deprecation.py:323] From /home/christina/.local/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:752: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0412 09:39:18.095773 140345440180032 deprecation.py:323] From /home/christina/.local/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:752: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0412 09:39:18.106395 140345440180032 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/core/prefetcher.py:51: The name tf.PaddingFIFOQueue is deprecated. Please use tf.queue.PaddingFIFOQueue instead.\n",
      "\n",
      "W0412 09:39:18.113529 140345440180032 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/core/prefetcher.py:58: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "W0412 09:39:18.121453 140345440180032 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/legacy/trainer.py:286: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "W0412 09:39:18.124122 140345440180032 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/slim/deployment/model_deploy.py:192: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0412 09:39:18.126205 140345440180032 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/slim/deployment/model_deploy.py:192: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "W0412 09:39:18.995675 140345440180032 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/core/preprocessor.py:2937: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "W0412 09:39:19.302121 140345440180032 deprecation.py:323] From /home/christina/.local/lib/python3.7/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "W0412 09:39:21.152137 140345440180032 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
      "\n",
      "W0412 09:39:21.177883 140345440180032 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "I0412 09:39:21.179489 140345440180032 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "I0412 09:39:21.222196 140345440180032 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "I0412 09:39:21.266563 140345440180032 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "I0412 09:39:21.311898 140345440180032 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "I0412 09:39:21.353975 140345440180032 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "I0412 09:39:21.393690 140345440180032 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "W0412 09:39:21.563134 140345440180032 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0412 09:39:25.200702 140345440180032 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/core/losses.py:79: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
      "\n",
      "W0412 09:39:25.204357 140345440180032 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
      "\n",
      "W0412 09:39:25.212004 140345440180032 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
      "\n",
      "W0412 09:39:25.847522 140345440180032 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/legacy/trainer.py:209: The name tf.losses.add_loss is deprecated. Please use tf.compat.v1.losses.add_loss instead.\n",
      "\n",
      "W0412 09:39:25.852381 140345440180032 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/builders/optimizer_builder.py:157: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "W0412 09:39:25.854080 140345440180032 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/utils/learning_schedules.py:66: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n",
      "W0412 09:39:25.870524 140345440180032 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/builders/optimizer_builder.py:47: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "W0412 09:39:27.943825 140345440180032 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/legacy/trainer.py:323: The name tf.check_numerics is deprecated. Please use tf.debugging.check_numerics instead.\n",
      "\n",
      "W0412 09:39:27.947369 140345440180032 deprecation.py:506] From /home/christina/.local/lib/python3.7/site-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0412 09:39:29.201997 140345440180032 deprecation.py:323] From /home/christina/.local/lib/python3.7/site-packages/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W0412 09:39:31.577726 140345440180032 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/legacy/trainer.py:354: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\n",
      "W0412 09:39:31.759191 140345440180032 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/legacy/trainer.py:356: The name tf.losses.get_losses is deprecated. Please use tf.compat.v1.losses.get_losses instead.\n",
      "\n",
      "W0412 09:39:31.764672 140345440180032 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/legacy/trainer.py:360: The name tf.losses.get_total_loss is deprecated. Please use tf.compat.v1.losses.get_total_loss instead.\n",
      "\n",
      "W0412 09:39:31.774021 140345440180032 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/legacy/trainer.py:369: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n",
      "W0412 09:39:31.786783 140345440180032 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/legacy/trainer.py:372: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0412 09:39:31.789455 140345440180032 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/legacy/trainer.py:377: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "W0412 09:39:32.366397 140345440180032 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "W0412 09:39:32.370743 140345440180032 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
      "\n",
      "W0412 09:39:32.384187 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.387926 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.388517 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.389054 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.389581 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.390597 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.391191 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_0/weights/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.391864 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_0/weights/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.392481 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_0/weights/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.393127 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.393712 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.394256 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.394791 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.395373 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.395918 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.396480 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.397032 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.397643 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.398192 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.398766 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.399342 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.399897 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.400619 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.403410 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.404065 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.404884 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/weights/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.405617 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.408967 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.409974 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.410910 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.411774 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.412690 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.413446 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.414412 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.416360 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.417285 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.418162 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.419229 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.420387 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.421767 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.423783 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.424633 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.425302 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.426070 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/weights/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.426759 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.427520 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.428181 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.429027 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.430870 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.433322 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.434307 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.435037 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.437223 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.438611 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.439818 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.440690 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.441527 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.442472 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.443226 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.444200 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.444983 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.445960 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/weights/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.447620 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.448605 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.449527 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.451514 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.453415 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.454868 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.455757 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.456532 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.457312 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.458057 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.458887 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.459573 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.460411 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.461326 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.462224 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.462934 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.463822 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.464548 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/weights/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.465437 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.466156 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.467064 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.472872 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.473655 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.474480 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.475573 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.476332 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/weights/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.477130 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/weights/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.477924 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/weights/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.479545 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.480437 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.481144 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.482055 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.482795 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.483652 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.484417 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/weights/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.485305 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/weights/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.487269 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/weights/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.488224 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.488926 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.489823 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.490546 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.491462 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.492229 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.493084 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/weights/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.493996 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/weights/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.494915 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/weights/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.495605 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.496574 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.497442 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.498388 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.499317 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.500083 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.500861 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/weights/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.501780 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/weights/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.504357 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/weights/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.505226 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.505887 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.506619 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.507425 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.508255 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.515065 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.516018 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/weights/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.518130 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/weights/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.520259 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/weights/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.521120 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.521904 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.523226 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.523910 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.524645 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.525361 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.526220 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/weights/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.527750 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/weights/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.528785 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/weights/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.529536 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.530364 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.531075 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.532287 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.534328 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.536424 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.537483 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/weights/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.538184 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/weights/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.539079 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/weights/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.539904 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.540738 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.541491 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.542391 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.543131 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.544079 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.544890 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/weights/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.545872 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/weights/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.546607 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/weights/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.547400 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.548153 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.549030 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.549709 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.550524 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.551367 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.556036 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.556792 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.557586 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.558642 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.559511 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.560622 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.561561 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.562465 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.563341 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.565366 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.566289 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/weights/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.567215 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.567956 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.569159 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.569928 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.570604 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.572434 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.573549 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.574288 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.575326 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.575896 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.576551 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.577176 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.578177 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.578844 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.579659 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.580247 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.581047 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.581588 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/weights/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.582233 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.582758 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.583310 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.583897 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.584457 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.584988 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.586695 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.588042 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.588695 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.589285 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.590023 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.590516 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.591097 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.591950 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.592472 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.593004 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.593517 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.594013 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/weights/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.594529 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.595049 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.595561 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.596068 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.596573 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.597142 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.597609 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.598133 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.598700 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.599371 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.599875 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.600578 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.601156 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.601620 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.602199 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.603461 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.604055 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.604664 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/weights/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.605167 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.606922 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.607614 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.608143 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.610166 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.611004 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.611673 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.612416 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.613000 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.613631 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.614195 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.614734 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.615307 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.615817 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.616422 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.616954 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.617531 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.618087 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/weights/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.618602 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.622991 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.623598 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.624283 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.624875 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.626310 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.626839 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.627390 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.628029 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.628578 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.629177 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.629760 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.630308 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.630941 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.632656 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.633234 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.634075 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.637495 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/weights/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.639148 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.639851 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.640515 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.641108 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.641701 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.642425 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.642992 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.643552 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.645211 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.645755 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.646428 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.647098 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.647725 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.648243 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.648931 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.649523 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.650110 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.650728 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/weights/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.651284 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.654139 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.655222 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.655893 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.656505 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.657240 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.658064 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.658787 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.659354 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.659802 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.660485 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.660959 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.661559 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.662312 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.662866 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.663365 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.665243 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.665817 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/weights/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.666629 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.667302 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.667928 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.668544 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.669323 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.671773 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.672627 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.673222 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.673807 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.674560 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.675233 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.675792 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.676505 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.677229 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.677963 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.678580 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:32.679314 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
      "W0412 09:39:32.679855 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/weights/RMSProp] is not available in checkpoint\n",
      "W0412 09:39:32.680694 140345440180032 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
      "W0412 09:39:33.389016 140345440180032 deprecation.py:323] From /home/christina/.local/lib/python3.7/site-packages/tensorflow_core/contrib/slim/python/slim/learning.py:742: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.MonitoredTrainingSession\n",
      "I0412 09:39:37.855362 140345440180032 saver.py:1284] Restoring parameters from ../../FromScratch/ssd_mobilenet_v1_coco_2018_01_28/model.ckpt\n",
      "I0412 09:39:38.523702 140345440180032 session_manager.py:500] Running local_init_op.\n",
      "I0412 09:39:39.087282 140345440180032 session_manager.py:502] Done running local_init_op.\n",
      "I0412 09:39:47.308347 140345440180032 learning.py:754] Starting Session.\n",
      "I0412 09:39:47.713313 140342435223296 supervisor.py:1117] Saving checkpoint to path ../../trainingOutput/model.ckpt\n",
      "I0412 09:39:47.732236 140345440180032 learning.py:768] Starting Queues.\n",
      "I0412 09:39:55.490235 140342485546752 supervisor.py:1099] global_step/sec: 0\n",
      "I0412 09:40:05.188638 140342460401408 supervisor.py:1050] Recording summary at step 0.\n",
      "I0412 09:40:06.433425 140345440180032 learning.py:507] global step 1: loss = 137.9314 (18.280 sec/step)\n",
      "I0412 09:40:07.588350 140345440180032 learning.py:507] global step 2: loss = 115.2412 (0.746 sec/step)\n",
      "I0412 09:40:08.350106 140345440180032 learning.py:507] global step 3: loss = 104.3407 (0.760 sec/step)\n",
      "I0412 09:40:09.141212 140345440180032 learning.py:507] global step 4: loss = 96.5293 (0.789 sec/step)\n",
      "I0412 09:40:09.884562 140345440180032 learning.py:507] global step 5: loss = 87.3902 (0.741 sec/step)\n",
      "I0412 09:40:10.668417 140345440180032 learning.py:507] global step 6: loss = 78.3884 (0.782 sec/step)\n",
      "I0412 09:40:11.447103 140345440180032 learning.py:507] global step 7: loss = 70.2592 (0.776 sec/step)\n",
      "I0412 09:40:12.231103 140345440180032 learning.py:507] global step 8: loss = 61.7219 (0.782 sec/step)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/Thesis/AutomaticLP/models/research/object_detection/legacy/train.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mmain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags_parser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_parse_flags_tolerate_undef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/absl/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv, flags_parser)\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m       \u001b[0m_run_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mUsageError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m       \u001b[0musage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshorthelp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetailed_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexitcode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexitcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/absl/app.py\u001b[0m in \u001b[0;36m_run_main\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Thesis/AutomaticLP/models/research/object_detection/legacy/train.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(_)\u001b[0m\n\u001b[1;32m    179\u001b[0m       \u001b[0mis_chief\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m       \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m       graph_hook_fn=graph_rewriter_fn)\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Thesis/AutomaticLP/models/research/object_detection/legacy/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(create_tensor_dict_fn, create_model_fn, train_config, master, task, num_clones, worker_replicas, clone_on_cpu, ps_tasks, worker_job_name, is_chief, train_dir, graph_hook_fn)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0msave_summaries_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0msync_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msync_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m         saver=saver)\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/contrib/slim/python/slim/learning.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_op, logdir, train_step_fn, train_step_kwargs, log_every_n_steps, graph, master, is_chief, global_step, number_of_steps, init_op, init_feed_dict, local_init_op, init_fn, ready_op, summary_op, save_summaries_secs, summary_writer, startup_delay_steps, saver, save_interval_secs, sync_optimizer, session_config, session_wrapper, trace_every_n_steps, ignore_live_threads)\u001b[0m\n\u001b[1;32m    773\u001b[0m           \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m             total_loss, should_stop = train_step_fn(sess, train_op, global_step,\n\u001b[0;32m--> 775\u001b[0;31m                                                     train_step_kwargs)\n\u001b[0m\u001b[1;32m    776\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m               \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Stopping Training.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/contrib/slim/python/slim/learning.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(sess, train_op, global_step, train_step_kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m   total_loss, np_global_step = sess.run([train_op, global_step],\n\u001b[1;32m    489\u001b[0m                                         \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrace_run_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m                                         run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    491\u001b[0m   \u001b[0mtime_elapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%cd models/research\n",
    "%run object_detection/legacy/train.py --logtostderr --train_dir=../../trainingOutput/ --pipeline_config_path=../../FromScratch/models/model/ssd_mobilenet_v1_coco.config \n",
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the cell output back to normal\n",
    "sys.stdout = old_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%run viewTraining.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/christina/Documents/Thesis/AutomaticLP/trainingOutput\n",
      "/home/christina/Documents/Thesis/AutomaticLP\n"
     ]
    }
   ],
   "source": [
    "# We want to run Evaluation on the latest checkpoint \n",
    "# this code extracts the step number of the most recent checkpoint saved\n",
    "\n",
    "from os import listdir\n",
    "import re\n",
    "\n",
    "%cd trainingOutput\n",
    "checkpointList = listdir()\n",
    "%cd ..\n",
    "\n",
    "numbers = []\n",
    "for filename in checkpointList:\n",
    "    match = re.search(\"^model.ckpt-\", filename)\n",
    "    if not match is None:\n",
    "        filename = filename.split(\".\")\n",
    "        filename = filename[1].split(\"-\")\n",
    "        numbers.append(filename[1])\n",
    "\n",
    "lastCheckpoint = max(numbers)\n",
    "\n",
    "CHECKPOINT_PREFIX = \"../../trainingOutput/model.ckpt-\"+str(lastCheckpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/christina/Documents/Thesis/AutomaticLP/models/research\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From object_detection/export_inference_graph.py:162: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0412 10:10:19.764824 139810515842880 module_wrapper.py:139] From object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/exporter.py:402: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n",
      "W0412 10:10:19.769852 139810515842880 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/exporter.py:402: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/exporter.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0412 10:10:19.770179 139810515842880 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/exporter.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/core/preprocessor.py:2937: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "W0412 10:10:19.798660 139810515842880 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/core/preprocessor.py:2937: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/meta_architectures/ssd_meta_arch.py:589: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "W0412 10:10:19.824487 139810515842880 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/meta_architectures/ssd_meta_arch.py:589: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0412 10:10:19.824766 139810515842880 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/.local/lib/python3.7/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "W0412 10:10:19.826163 139810515842880 deprecation.py:323] From /home/christina/.local/lib/python3.7/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
      "\n",
      "W0412 10:10:21.406611 139810515842880 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W0412 10:10:21.417128 139810515842880 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0412 10:10:21.417371 139810515842880 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0412 10:10:21.460889 139810515842880 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0412 10:10:21.500457 139810515842880 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0412 10:10:21.540359 139810515842880 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0412 10:10:21.582629 139810515842880 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0412 10:10:21.629194 139810515842880 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/core/post_processing.py:581: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0412 10:10:21.884455 139810515842880 deprecation.py:323] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/core/post_processing.py:581: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/exporter.py:278: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "W0412 10:10:23.330706 139810515842880 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/exporter.py:278: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/exporter.py:383: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n",
      "W0412 10:10:23.330981 139810515842880 deprecation.py:323] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/exporter.py:383: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/exporter.py:415: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0412 10:10:23.334207 139810515842880 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/exporter.py:415: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/exporter.py:539: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
      "Instructions for updating:\n",
      "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
      "W0412 10:10:23.334439 139810515842880 deprecation.py:323] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/exporter.py:539: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
      "Instructions for updating:\n",
      "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
      "WARNING:tensorflow:From /home/christina/.local/lib/python3.7/site-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "W0412 10:10:23.335674 139810515842880 deprecation.py:323] From /home/christina/.local/lib/python3.7/site-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "170 ops no flops stats due to incomplete shapes.\n",
      "Parsing Inputs...\n",
      "Incomplete shape.\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              0\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   name\n",
      "-account_type_regexes       _trainable_variables\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          .*BatchNorm.*\n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     params\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "Incomplete shape.\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "param: Number of parameters (in the Variable).\n",
      "\n",
      "Profile:\n",
      "node name | # parameters\n",
      "_TFProfRoot (--/5.95m params)\n",
      "  BoxPredictor_0 (--/56.94k params)\n",
      "    BoxPredictor_0/BoxEncodingPredictor (--/6.16k params)\n",
      "      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n",
      "      BoxPredictor_0/BoxEncodingPredictor/weights (1x1x512x12, 6.14k/6.14k params)\n",
      "    BoxPredictor_0/ClassPredictor (--/50.79k params)\n",
      "      BoxPredictor_0/ClassPredictor/biases (99, 99/99 params)\n",
      "      BoxPredictor_0/ClassPredictor/weights (1x1x512x99, 50.69k/50.69k params)\n",
      "  BoxPredictor_1 (--/227.55k params)\n",
      "    BoxPredictor_1/BoxEncodingPredictor (--/24.60k params)\n",
      "      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n",
      "      BoxPredictor_1/BoxEncodingPredictor/weights (1x1x1024x24, 24.58k/24.58k params)\n",
      "    BoxPredictor_1/ClassPredictor (--/202.95k params)\n",
      "      BoxPredictor_1/ClassPredictor/biases (198, 198/198 params)\n",
      "      BoxPredictor_1/ClassPredictor/weights (1x1x1024x198, 202.75k/202.75k params)\n",
      "  BoxPredictor_2 (--/113.89k params)\n",
      "    BoxPredictor_2/BoxEncodingPredictor (--/12.31k params)\n",
      "      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n",
      "      BoxPredictor_2/BoxEncodingPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
      "    BoxPredictor_2/ClassPredictor (--/101.57k params)\n",
      "      BoxPredictor_2/ClassPredictor/biases (198, 198/198 params)\n",
      "      BoxPredictor_2/ClassPredictor/weights (1x1x512x198, 101.38k/101.38k params)\n",
      "  BoxPredictor_3 (--/57.05k params)\n",
      "    BoxPredictor_3/BoxEncodingPredictor (--/6.17k params)\n",
      "      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n",
      "      BoxPredictor_3/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
      "    BoxPredictor_3/ClassPredictor (--/50.89k params)\n",
      "      BoxPredictor_3/ClassPredictor/biases (198, 198/198 params)\n",
      "      BoxPredictor_3/ClassPredictor/weights (1x1x256x198, 50.69k/50.69k params)\n",
      "  BoxPredictor_4 (--/57.05k params)\n",
      "    BoxPredictor_4/BoxEncodingPredictor (--/6.17k params)\n",
      "      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n",
      "      BoxPredictor_4/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
      "    BoxPredictor_4/ClassPredictor (--/50.89k params)\n",
      "      BoxPredictor_4/ClassPredictor/biases (198, 198/198 params)\n",
      "      BoxPredictor_4/ClassPredictor/weights (1x1x256x198, 50.69k/50.69k params)\n",
      "  BoxPredictor_5 (--/28.64k params)\n",
      "    BoxPredictor_5/BoxEncodingPredictor (--/3.10k params)\n",
      "      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n",
      "      BoxPredictor_5/BoxEncodingPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n",
      "    BoxPredictor_5/ClassPredictor (--/25.54k params)\n",
      "      BoxPredictor_5/ClassPredictor/biases (198, 198/198 params)\n",
      "      BoxPredictor_5/ClassPredictor/weights (1x1x128x198, 25.34k/25.34k params)\n",
      "  FeatureExtractor (--/5.41m params)\n",
      "    FeatureExtractor/MobilenetV1 (--/5.41m params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_0 (--/864 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_0/weights (3x3x3x32, 864/864 params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_10_depthwise (--/4.61k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_10_pointwise (--/262.14k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_11_depthwise (--/4.61k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_11_pointwise (--/262.14k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_12_depthwise (--/4.61k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_12_pointwise (--/524.29k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/weights (1x1x512x1024, 524.29k/524.29k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_13_depthwise (--/9.22k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/depthwise_weights (3x3x1024x1, 9.22k/9.22k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise (--/1.05m params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/weights (1x1x1024x1024, 1.05m/1.05m params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256 (--/262.14k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128 (--/65.54k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128 (--/32.77k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64 (--/16.38k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512 (--/1.18m params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/weights (3x3x256x512, 1.18m/1.18m params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256 (--/294.91k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256 (--/294.91k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128 (--/73.73k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/weights (3x3x64x128, 73.73k/73.73k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_1_depthwise (--/288 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/depthwise_weights (3x3x32x1, 288/288 params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_1_pointwise (--/2.05k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/weights (1x1x32x64, 2.05k/2.05k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_2_depthwise (--/576 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/depthwise_weights (3x3x64x1, 576/576 params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_2_pointwise (--/8.19k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/weights (1x1x64x128, 8.19k/8.19k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_3_depthwise (--/1.15k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_3_pointwise (--/16.38k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/weights (1x1x128x128, 16.38k/16.38k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_4_depthwise (--/1.15k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_4_pointwise (--/32.77k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/weights (1x1x128x256, 32.77k/32.77k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_5_depthwise (--/2.30k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_5_pointwise (--/65.54k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/weights (1x1x256x256, 65.54k/65.54k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_6_depthwise (--/2.30k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_6_pointwise (--/131.07k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/weights (1x1x256x512, 131.07k/131.07k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_7_depthwise (--/4.61k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_7_pointwise (--/262.14k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_8_depthwise (--/4.61k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_8_pointwise (--/262.14k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_9_depthwise (--/4.61k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_9_pointwise (--/262.14k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
      "\n",
      "======================End of Report==========================\n",
      "170 ops no flops stats due to incomplete shapes.\n",
      "Parsing Inputs...\n",
      "Incomplete shape.\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "Incomplete shape.\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.55k flops)\n",
      "  MultipleGridAnchorGenerator/mul_20 (192/192 flops)\n",
      "  MultipleGridAnchorGenerator/sub (192/192 flops)\n",
      "  MultipleGridAnchorGenerator/mul_19 (192/192 flops)\n",
      "  MultipleGridAnchorGenerator/mul_28 (96/96 flops)\n",
      "  MultipleGridAnchorGenerator/mul_21 (96/96 flops)\n",
      "  MultipleGridAnchorGenerator/sub_1 (96/96 flops)\n",
      "  MultipleGridAnchorGenerator/mul_27 (96/96 flops)\n",
      "  MultipleGridAnchorGenerator/mul_29 (48/48 flops)\n",
      "  MultipleGridAnchorGenerator/mul_35 (24/24 flops)\n",
      "  MultipleGridAnchorGenerator/mul_36 (24/24 flops)\n",
      "  MultipleGridAnchorGenerator/sub_2 (24/24 flops)\n",
      "  MultipleGridAnchorGenerator/mul_37 (12/12 flops)\n",
      "  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n",
      "  MultipleGridAnchorGenerator/sub_3 (12/12 flops)\n",
      "  MultipleGridAnchorGenerator/sub_4 (12/12 flops)\n",
      "  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n",
      "  MultipleGridAnchorGenerator/mul_52 (12/12 flops)\n",
      "  MultipleGridAnchorGenerator/mul_51 (12/12 flops)\n",
      "  MultipleGridAnchorGenerator/mul_43 (12/12 flops)\n",
      "  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n",
      "  MultipleGridAnchorGenerator/mul_44 (12/12 flops)\n",
      "  MultipleGridAnchorGenerator/mul_18 (8/8 flops)\n",
      "  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_45 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_53 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_26 (4/4 flops)\n",
      "  MultipleGridAnchorGenerator/mul_17 (4/4 flops)\n",
      "  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/mul_25 (2/2 flops)\n",
      "  MultipleGridAnchorGenerator/mul_34 (2/2 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_42 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_47 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_41 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_40 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_43 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_44 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_45 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_46 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_31 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_48 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_49 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_5 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_50 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_51 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_52 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_53 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_54 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_55 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_56 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_29 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_18 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_19 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_2 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_20 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_21 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_22 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_23 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_24 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_25 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_26 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_27 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_28 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_4 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_3 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_30 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_32 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_33 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_34 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_35 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_36 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_37 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_38 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_39 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
      "  Preprocessor/map/while/Less (1/1 flops)\n",
      "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_58 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_59 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_6 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_60 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_61 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_62 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_63 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_7 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_8 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_9 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_57 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_24 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_33 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_41 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_42 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_49 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_50 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_3 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_30 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_31 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_32 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_4 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_5 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_6 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_7 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_8 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_9 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_29 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_10 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_11 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_12 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_13 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_14 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_15 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_16 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_19 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_10 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_11 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_12 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_13 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_14 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_15 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_16 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_17 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_18 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_17 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_2 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_20 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_21 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_22 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_23 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_25 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_26 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_27 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_28 (1/1 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/exporter.py:432: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "W0412 10:10:24.846167 139810515842880 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/exporter.py:432: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/exporter.py:342: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0412 10:10:25.726134 139810515842880 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/exporter.py:342: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2020-04-12 10:10:25.726633: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2020-04-12 10:10:25.726658: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2020-04-12 10:10:25.726679: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (marvin-computer): /proc/driver/nvidia/version does not exist\n",
      "2020-04-12 10:10:25.726932: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-04-12 10:10:25.772430: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2394365000 Hz\n",
      "2020-04-12 10:10:25.773006: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558eb4b10d40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-04-12 10:10:25.773149: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "INFO:tensorflow:Restoring parameters from ../../trainingOutput/model.ckpt-60219\n",
      "I0412 10:10:25.779924 139810515842880 saver.py:1284] Restoring parameters from ../../trainingOutput/model.ckpt-60219\n",
      "WARNING:tensorflow:From /home/christina/.local/lib/python3.7/site-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "W0412 10:10:27.037518 139810515842880 deprecation.py:323] From /home/christina/.local/lib/python3.7/site-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ../../trainingOutput/model.ckpt-60219\n",
      "I0412 10:10:27.784671 139810515842880 saver.py:1284] Restoring parameters from ../../trainingOutput/model.ckpt-60219\n",
      "WARNING:tensorflow:From /home/christina/.local/lib/python3.7/site-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "W0412 10:10:28.524739 139810515842880 deprecation.py:323] From /home/christina/.local/lib/python3.7/site-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From /home/christina/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "W0412 10:10:28.524998 139810515842880 deprecation.py:323] From /home/christina/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 199 variables.\n",
      "I0412 10:10:28.960612 139810515842880 graph_util_impl.py:334] Froze 199 variables.\n",
      "INFO:tensorflow:Converted 199 variables to const ops.\n",
      "I0412 10:10:29.091361 139810515842880 graph_util_impl.py:394] Converted 199 variables to const ops.\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/exporter.py:306: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
      "\n",
      "W0412 10:10:29.960252 139810515842880 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/exporter.py:306: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/exporter.py:309: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "W0412 10:10:29.960602 139810515842880 deprecation.py:323] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/exporter.py:309: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/exporter.py:315: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
      "\n",
      "W0412 10:10:29.960958 139810515842880 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/exporter.py:315: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/exporter.py:318: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
      "\n",
      "W0412 10:10:29.961085 139810515842880 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/exporter.py:318: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/exporter.py:323: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
      "\n",
      "W0412 10:10:29.961288 139810515842880 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/exporter.py:323: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/exporter.py:325: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
      "\n",
      "W0412 10:10:29.961392 139810515842880 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/exporter.py:325: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
      "\n",
      "INFO:tensorflow:No assets to save.\n",
      "I0412 10:10:29.961606 139810515842880 builder_impl.py:640] No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "I0412 10:10:29.961678 139810515842880 builder_impl.py:460] No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: ../../inference_graph/saved_model/saved_model.pb\n",
      "I0412 10:10:30.332299 139810515842880 builder_impl.py:425] SavedModel written to: ../../inference_graph/saved_model/saved_model.pb\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/utils/config_util.py:188: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0412 10:10:30.359568 139810515842880 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/utils/config_util.py:188: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "INFO:tensorflow:Writing pipeline config file to ../../inference_graph/pipeline.config\n",
      "I0412 10:10:30.359761 139810515842880 config_util.py:190] Writing pipeline config file to ../../inference_graph/pipeline.config\n",
      "/home/christina/Documents/Thesis/AutomaticLP\n"
     ]
    }
   ],
   "source": [
    "%cd models/research\n",
    "!python object_detection/export_inference_graph.py --input_type image_tensor --pipeline_config_path ../../FromScratch/models/model/ssd_mobilenet_v1_coco.config --trained_checkpoint_prefix $CHECKPOINT_PREFIX --output_directory ../../inference_graph\n",
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Test Image Directory Name:  TestImages_2020-04-12_09-38\n",
      "Enter Threshold (0-1) for object detection:  .5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Show another image (y/n)?  y\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Show another image (y/n)?  y\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Show another image (y/n)?  n\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as plt\n",
    "%run customEvaluation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/christina/Documents/Thesis/AutomaticLP/models/research\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/inference/infer_detections.py:96: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/inference/infer_detections.py:57: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0412 10:12:40.835751 140170411185984 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/inference/infer_detections.py:57: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/inference/infer_detections.py:57: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0412 10:12:40.837383 140170411185984 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/inference/infer_detections.py:57: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/inference/infer_detections.py:68: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0412 10:12:40.844712 140170411185984 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/inference/infer_detections.py:68: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading input from 1 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:40.847105 140170411185984 infer_detections.py:68] Reading input from 1 files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/inference/detection_inference.py:35: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0412 10:12:40.852351 140170411185984 deprecation.py:323] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/inference/detection_inference.py:35: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/christina/.local/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:277: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0412 10:12:40.864382 140170411185984 deprecation.py:323] From /home/christina/.local/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:277: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/christina/.local/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:189: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0412 10:12:40.867541 140170411185984 deprecation.py:323] From /home/christina/.local/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:189: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/christina/.local/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:112: RefVariable.count_up_to (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Dataset.range instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0412 10:12:40.876903 140170411185984 deprecation.py:323] From /home/christina/.local/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:112: RefVariable.count_up_to (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Dataset.range instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/christina/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py:2522: count_up_to (from tensorflow.python.ops.state_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Dataset.range instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0412 10:12:40.878207 140170411185984 deprecation.py:323] From /home/christina/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py:2522: count_up_to (from tensorflow.python.ops.state_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Dataset.range instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/christina/.local/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:198: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0412 10:12:40.883497 140170411185984 deprecation.py:323] From /home/christina/.local/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:198: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/christina/.local/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:198: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0412 10:12:40.886656 140170411185984 deprecation.py:323] From /home/christina/.local/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:198: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/inference/detection_inference.py:37: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0412 10:12:40.898021 140170411185984 deprecation.py:323] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/inference/detection_inference.py:37: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/inference/detection_inference.py:39: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0412 10:12:40.904893 140170411185984 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/inference/detection_inference.py:39: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/inference/detection_inference.py:43: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0412 10:12:40.906293 140170411185984 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/inference/detection_inference.py:43: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading graph and building model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:40.993808 140170411185984 infer_detections.py:71] Reading graph and building model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/inference/detection_inference.py:68: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0412 10:12:40.995092 140170411185984 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/inference/detection_inference.py:68: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/inference/detection_inference.py:76: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0412 10:12:41.631952 140170411185984 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/inference/detection_inference.py:76: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running inference and writing output to ../../TFExamples.tfrecord\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:41.653893 140170411185984 infer_detections.py:77] Running inference and writing output to ../../TFExamples.tfrecord\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/inference/infer_detections.py:78: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0412 10:12:41.655469 140170411185984 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/inference/infer_detections.py:78: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/inference/infer_detections.py:79: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0412 10:12:41.884680 140170411185984 deprecation.py:323] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/inference/infer_detections.py:79: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/inference/infer_detections.py:80: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0412 10:12:41.886916 140170411185984 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/inference/infer_detections.py:80: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/inference/infer_detections.py:84: The name tf.logging.log_every_n is deprecated. Please use tf.compat.v1.logging.log_every_n instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0412 10:12:41.889204 140170411185984 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/inference/infer_detections.py:84: The name tf.logging.log_every_n is deprecated. Please use tf.compat.v1.logging.log_every_n instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 0 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:41.891201 140170411185984 infer_detections.py:85] Processed 0 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/inference/detection_inference.py:117: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0412 10:12:41.896439 140170411185984 module_wrapper.py:139] From /home/christina/Documents/Thesis/AutomaticLP/models/research/object_detection/inference/detection_inference.py:117: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 10 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:43.414918 140170411185984 infer_detections.py:85] Processed 10 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 20 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:43.577867 140170411185984 infer_detections.py:85] Processed 20 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 30 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:43.735945 140170411185984 infer_detections.py:85] Processed 30 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 40 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:43.883389 140170411185984 infer_detections.py:85] Processed 40 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 50 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:44.028267 140170411185984 infer_detections.py:85] Processed 50 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 60 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:44.173435 140170411185984 infer_detections.py:85] Processed 60 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 70 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:44.318427 140170411185984 infer_detections.py:85] Processed 70 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 80 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:44.466376 140170411185984 infer_detections.py:85] Processed 80 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 90 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:44.614171 140170411185984 infer_detections.py:85] Processed 90 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 100 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:44.776874 140170411185984 infer_detections.py:85] Processed 100 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 110 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:44.969347 140170411185984 infer_detections.py:85] Processed 110 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 120 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:45.190865 140170411185984 infer_detections.py:85] Processed 120 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 130 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:45.385627 140170411185984 infer_detections.py:85] Processed 130 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 140 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:45.550786 140170411185984 infer_detections.py:85] Processed 140 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 150 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:45.700446 140170411185984 infer_detections.py:85] Processed 150 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 160 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:45.845252 140170411185984 infer_detections.py:85] Processed 160 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 170 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:46.010568 140170411185984 infer_detections.py:85] Processed 170 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 180 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:46.158884 140170411185984 infer_detections.py:85] Processed 180 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 190 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:46.308883 140170411185984 infer_detections.py:85] Processed 190 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 200 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:46.452860 140170411185984 infer_detections.py:85] Processed 200 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 210 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:46.609319 140170411185984 infer_detections.py:85] Processed 210 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 220 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:46.760728 140170411185984 infer_detections.py:85] Processed 220 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 230 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:46.907529 140170411185984 infer_detections.py:85] Processed 230 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 240 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:47.050233 140170411185984 infer_detections.py:85] Processed 240 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 250 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:47.190233 140170411185984 infer_detections.py:85] Processed 250 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 260 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:47.333374 140170411185984 infer_detections.py:85] Processed 260 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 270 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:47.492174 140170411185984 infer_detections.py:85] Processed 270 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 280 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:47.647537 140170411185984 infer_detections.py:85] Processed 280 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 290 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:47.790305 140170411185984 infer_detections.py:85] Processed 290 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 300 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:47.940460 140170411185984 infer_detections.py:85] Processed 300 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 310 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:48.084107 140170411185984 infer_detections.py:85] Processed 310 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 320 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:48.234987 140170411185984 infer_detections.py:85] Processed 320 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 330 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:48.384220 140170411185984 infer_detections.py:85] Processed 330 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 340 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:48.531171 140170411185984 infer_detections.py:85] Processed 340 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 350 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:48.680133 140170411185984 infer_detections.py:85] Processed 350 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 360 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:48.831896 140170411185984 infer_detections.py:85] Processed 360 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 370 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:48.986715 140170411185984 infer_detections.py:85] Processed 370 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 380 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:49.144022 140170411185984 infer_detections.py:85] Processed 380 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 390 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:49.291254 140170411185984 infer_detections.py:85] Processed 390 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 400 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:49.447196 140170411185984 infer_detections.py:85] Processed 400 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 410 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:49.609775 140170411185984 infer_detections.py:85] Processed 410 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 420 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:49.772073 140170411185984 infer_detections.py:85] Processed 420 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 430 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:49.921497 140170411185984 infer_detections.py:85] Processed 430 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 440 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:50.070009 140170411185984 infer_detections.py:85] Processed 440 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 450 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:50.218936 140170411185984 infer_detections.py:85] Processed 450 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 460 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:50.365046 140170411185984 infer_detections.py:85] Processed 460 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 470 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:50.517109 140170411185984 infer_detections.py:85] Processed 470 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 480 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:50.664065 140170411185984 infer_detections.py:85] Processed 480 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 490 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:50.829671 140170411185984 infer_detections.py:85] Processed 490 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 500 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:50.984399 140170411185984 infer_detections.py:85] Processed 500 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 510 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:51.139102 140170411185984 infer_detections.py:85] Processed 510 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 520 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:51.300402 140170411185984 infer_detections.py:85] Processed 520 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 530 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:51.445480 140170411185984 infer_detections.py:85] Processed 530 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 540 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:51.586282 140170411185984 infer_detections.py:85] Processed 540 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 550 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:51.729413 140170411185984 infer_detections.py:85] Processed 550 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 560 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:51.879426 140170411185984 infer_detections.py:85] Processed 560 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 570 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:52.027168 140170411185984 infer_detections.py:85] Processed 570 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 580 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:52.172460 140170411185984 infer_detections.py:85] Processed 580 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 590 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:52.318874 140170411185984 infer_detections.py:85] Processed 590 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 600 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:52.466280 140170411185984 infer_detections.py:85] Processed 600 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 610 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:52.616256 140170411185984 infer_detections.py:85] Processed 610 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 620 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:52.771561 140170411185984 infer_detections.py:85] Processed 620 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 630 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:52.915265 140170411185984 infer_detections.py:85] Processed 630 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 640 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:53.059682 140170411185984 infer_detections.py:85] Processed 640 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 650 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:53.205002 140170411185984 infer_detections.py:85] Processed 650 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 660 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:53.348604 140170411185984 infer_detections.py:85] Processed 660 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 670 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:53.495478 140170411185984 infer_detections.py:85] Processed 670 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 680 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:53.643646 140170411185984 infer_detections.py:85] Processed 680 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 690 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:53.787504 140170411185984 infer_detections.py:85] Processed 690 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 700 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:53.954043 140170411185984 infer_detections.py:85] Processed 700 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 710 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:54.112202 140170411185984 infer_detections.py:85] Processed 710 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 720 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:54.264961 140170411185984 infer_detections.py:85] Processed 720 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 730 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:54.414909 140170411185984 infer_detections.py:85] Processed 730 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 740 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:54.572339 140170411185984 infer_detections.py:85] Processed 740 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 750 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:54.718799 140170411185984 infer_detections.py:85] Processed 750 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 760 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:54.869521 140170411185984 infer_detections.py:85] Processed 760 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 770 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:55.062144 140170411185984 infer_detections.py:85] Processed 770 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 780 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:55.225057 140170411185984 infer_detections.py:85] Processed 780 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 790 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:55.375856 140170411185984 infer_detections.py:85] Processed 790 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 800 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:55.520614 140170411185984 infer_detections.py:85] Processed 800 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 810 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:55.666053 140170411185984 infer_detections.py:85] Processed 810 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 820 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:55.809489 140170411185984 infer_detections.py:85] Processed 820 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 830 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:55.973998 140170411185984 infer_detections.py:85] Processed 830 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 840 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:56.119377 140170411185984 infer_detections.py:85] Processed 840 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 850 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:56.287668 140170411185984 infer_detections.py:85] Processed 850 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 860 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:56.446376 140170411185984 infer_detections.py:85] Processed 860 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 870 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:56.602864 140170411185984 infer_detections.py:85] Processed 870 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 880 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:56.758676 140170411185984 infer_detections.py:85] Processed 880 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 890 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:56.912335 140170411185984 infer_detections.py:85] Processed 890 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 900 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:57.073373 140170411185984 infer_detections.py:85] Processed 900 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 910 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:57.225478 140170411185984 infer_detections.py:85] Processed 910 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 920 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:57.383265 140170411185984 infer_detections.py:85] Processed 920 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 930 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:57.539009 140170411185984 infer_detections.py:85] Processed 930 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 940 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:57.698987 140170411185984 infer_detections.py:85] Processed 940 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 950 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:57.843396 140170411185984 infer_detections.py:85] Processed 950 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 960 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:57.992594 140170411185984 infer_detections.py:85] Processed 960 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 970 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:58.143646 140170411185984 infer_detections.py:85] Processed 970 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 980 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:58.297204 140170411185984 infer_detections.py:85] Processed 980 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 990 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:58.450851 140170411185984 infer_detections.py:85] Processed 990 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1000 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:58.598098 140170411185984 infer_detections.py:85] Processed 1000 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1010 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:58.745087 140170411185984 infer_detections.py:85] Processed 1010 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1020 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:58.890746 140170411185984 infer_detections.py:85] Processed 1020 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1030 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:59.035562 140170411185984 infer_detections.py:85] Processed 1030 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1040 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:59.182723 140170411185984 infer_detections.py:85] Processed 1040 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1050 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:59.327862 140170411185984 infer_detections.py:85] Processed 1050 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1060 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:59.472771 140170411185984 infer_detections.py:85] Processed 1060 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1070 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:59.621233 140170411185984 infer_detections.py:85] Processed 1070 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1080 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:59.766092 140170411185984 infer_detections.py:85] Processed 1080 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1090 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:12:59.913763 140170411185984 infer_detections.py:85] Processed 1090 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1100 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:00.061795 140170411185984 infer_detections.py:85] Processed 1100 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1110 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:00.204561 140170411185984 infer_detections.py:85] Processed 1110 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1120 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:00.347679 140170411185984 infer_detections.py:85] Processed 1120 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1130 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:00.497028 140170411185984 infer_detections.py:85] Processed 1130 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1140 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:00.642504 140170411185984 infer_detections.py:85] Processed 1140 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1150 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:00.786561 140170411185984 infer_detections.py:85] Processed 1150 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1160 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:00.928861 140170411185984 infer_detections.py:85] Processed 1160 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1170 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:01.077476 140170411185984 infer_detections.py:85] Processed 1170 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1180 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:01.232880 140170411185984 infer_detections.py:85] Processed 1180 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1190 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:01.374813 140170411185984 infer_detections.py:85] Processed 1190 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1200 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:01.522408 140170411185984 infer_detections.py:85] Processed 1200 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1210 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:01.666203 140170411185984 infer_detections.py:85] Processed 1210 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1220 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:01.813312 140170411185984 infer_detections.py:85] Processed 1220 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1230 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:01.959698 140170411185984 infer_detections.py:85] Processed 1230 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1240 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:02.119833 140170411185984 infer_detections.py:85] Processed 1240 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1250 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:02.273853 140170411185984 infer_detections.py:85] Processed 1250 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1260 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:02.431931 140170411185984 infer_detections.py:85] Processed 1260 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1270 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:02.579072 140170411185984 infer_detections.py:85] Processed 1270 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1280 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:02.751575 140170411185984 infer_detections.py:85] Processed 1280 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1290 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:02.918761 140170411185984 infer_detections.py:85] Processed 1290 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1300 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:03.071294 140170411185984 infer_detections.py:85] Processed 1300 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1310 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:03.217928 140170411185984 infer_detections.py:85] Processed 1310 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1320 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:03.362206 140170411185984 infer_detections.py:85] Processed 1320 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1330 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:03.510241 140170411185984 infer_detections.py:85] Processed 1330 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1340 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:03.671361 140170411185984 infer_detections.py:85] Processed 1340 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1350 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:03.824337 140170411185984 infer_detections.py:85] Processed 1350 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1360 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:03.986495 140170411185984 infer_detections.py:85] Processed 1360 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1370 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:04.139793 140170411185984 infer_detections.py:85] Processed 1370 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1380 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:04.304900 140170411185984 infer_detections.py:85] Processed 1380 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1390 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:04.460753 140170411185984 infer_detections.py:85] Processed 1390 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1400 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:04.610474 140170411185984 infer_detections.py:85] Processed 1400 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1410 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:04.774515 140170411185984 infer_detections.py:85] Processed 1410 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1420 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:04.933703 140170411185984 infer_detections.py:85] Processed 1420 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1430 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:05.084372 140170411185984 infer_detections.py:85] Processed 1430 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1440 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:05.251767 140170411185984 infer_detections.py:85] Processed 1440 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1450 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:05.403872 140170411185984 infer_detections.py:85] Processed 1450 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1460 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:05.579147 140170411185984 infer_detections.py:85] Processed 1460 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1470 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:05.747843 140170411185984 infer_detections.py:85] Processed 1470 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1480 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:05.896036 140170411185984 infer_detections.py:85] Processed 1480 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1490 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:06.056552 140170411185984 infer_detections.py:85] Processed 1490 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1500 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:06.207193 140170411185984 infer_detections.py:85] Processed 1500 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1510 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:06.384183 140170411185984 infer_detections.py:85] Processed 1510 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1520 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:06.544238 140170411185984 infer_detections.py:85] Processed 1520 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1530 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:06.696560 140170411185984 infer_detections.py:85] Processed 1530 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1540 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:06.838703 140170411185984 infer_detections.py:85] Processed 1540 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1550 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:06.994085 140170411185984 infer_detections.py:85] Processed 1550 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1560 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:07.153740 140170411185984 infer_detections.py:85] Processed 1560 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1570 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:07.307940 140170411185984 infer_detections.py:85] Processed 1570 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1580 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:07.477743 140170411185984 infer_detections.py:85] Processed 1580 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1590 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:07.627094 140170411185984 infer_detections.py:85] Processed 1590 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1600 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:07.792649 140170411185984 infer_detections.py:85] Processed 1600 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1610 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:07.950153 140170411185984 infer_detections.py:85] Processed 1610 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1620 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:08.106486 140170411185984 infer_detections.py:85] Processed 1620 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1630 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:08.271892 140170411185984 infer_detections.py:85] Processed 1630 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1640 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:08.430002 140170411185984 infer_detections.py:85] Processed 1640 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1650 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:08.591479 140170411185984 infer_detections.py:85] Processed 1650 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1660 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:08.751689 140170411185984 infer_detections.py:85] Processed 1660 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1670 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:08.925288 140170411185984 infer_detections.py:85] Processed 1670 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1680 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:09.083231 140170411185984 infer_detections.py:85] Processed 1680 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1690 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:09.264111 140170411185984 infer_detections.py:85] Processed 1690 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1700 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:09.417495 140170411185984 infer_detections.py:85] Processed 1700 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1710 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:09.572639 140170411185984 infer_detections.py:85] Processed 1710 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1720 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:09.726819 140170411185984 infer_detections.py:85] Processed 1720 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1730 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:09.873447 140170411185984 infer_detections.py:85] Processed 1730 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1740 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:10.019442 140170411185984 infer_detections.py:85] Processed 1740 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1750 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:10.165305 140170411185984 infer_detections.py:85] Processed 1750 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1760 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:10.311527 140170411185984 infer_detections.py:85] Processed 1760 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1770 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:10.457482 140170411185984 infer_detections.py:85] Processed 1770 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1780 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:10.600458 140170411185984 infer_detections.py:85] Processed 1780 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1790 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:10.752206 140170411185984 infer_detections.py:85] Processed 1790 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1800 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:10.897126 140170411185984 infer_detections.py:85] Processed 1800 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1810 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:11.036410 140170411185984 infer_detections.py:85] Processed 1810 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1820 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:11.198425 140170411185984 infer_detections.py:85] Processed 1820 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1830 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:11.349136 140170411185984 infer_detections.py:85] Processed 1830 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1840 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:11.504166 140170411185984 infer_detections.py:85] Processed 1840 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1850 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:11.666412 140170411185984 infer_detections.py:85] Processed 1850 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1860 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:11.817292 140170411185984 infer_detections.py:85] Processed 1860 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1870 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:11.968049 140170411185984 infer_detections.py:85] Processed 1870 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1880 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:12.115187 140170411185984 infer_detections.py:85] Processed 1880 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1890 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:12.259504 140170411185984 infer_detections.py:85] Processed 1890 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1900 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:12.400946 140170411185984 infer_detections.py:85] Processed 1900 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1910 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:12.546594 140170411185984 infer_detections.py:85] Processed 1910 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1920 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:12.714901 140170411185984 infer_detections.py:85] Processed 1920 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1930 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:12.866836 140170411185984 infer_detections.py:85] Processed 1930 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1940 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:13.016261 140170411185984 infer_detections.py:85] Processed 1940 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1950 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:13.171141 140170411185984 infer_detections.py:85] Processed 1950 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1960 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:13.323978 140170411185984 infer_detections.py:85] Processed 1960 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1970 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:13.475168 140170411185984 infer_detections.py:85] Processed 1970 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1980 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:13.626681 140170411185984 infer_detections.py:85] Processed 1980 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 1990 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:13.799518 140170411185984 infer_detections.py:85] Processed 1990 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2000 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:13.953797 140170411185984 infer_detections.py:85] Processed 2000 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2010 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:14.106352 140170411185984 infer_detections.py:85] Processed 2010 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2020 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:14.266029 140170411185984 infer_detections.py:85] Processed 2020 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2030 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:14.422738 140170411185984 infer_detections.py:85] Processed 2030 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2040 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:14.579568 140170411185984 infer_detections.py:85] Processed 2040 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2050 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:14.737379 140170411185984 infer_detections.py:85] Processed 2050 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2060 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:14.895743 140170411185984 infer_detections.py:85] Processed 2060 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2070 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:15.052932 140170411185984 infer_detections.py:85] Processed 2070 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2080 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:15.208952 140170411185984 infer_detections.py:85] Processed 2080 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2090 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:15.356162 140170411185984 infer_detections.py:85] Processed 2090 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2100 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:15.507959 140170411185984 infer_detections.py:85] Processed 2100 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2110 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:15.652203 140170411185984 infer_detections.py:85] Processed 2110 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2120 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:15.800142 140170411185984 infer_detections.py:85] Processed 2120 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2130 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:15.952430 140170411185984 infer_detections.py:85] Processed 2130 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2140 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:16.122089 140170411185984 infer_detections.py:85] Processed 2140 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2150 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:16.271208 140170411185984 infer_detections.py:85] Processed 2150 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2160 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:16.416723 140170411185984 infer_detections.py:85] Processed 2160 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2170 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:16.567646 140170411185984 infer_detections.py:85] Processed 2170 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2180 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:16.725975 140170411185984 infer_detections.py:85] Processed 2180 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2190 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:16.887458 140170411185984 infer_detections.py:85] Processed 2190 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2200 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:17.040448 140170411185984 infer_detections.py:85] Processed 2200 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2210 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:17.188091 140170411185984 infer_detections.py:85] Processed 2210 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2220 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:17.332212 140170411185984 infer_detections.py:85] Processed 2220 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2230 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:17.481374 140170411185984 infer_detections.py:85] Processed 2230 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2240 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:17.627593 140170411185984 infer_detections.py:85] Processed 2240 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2250 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:17.771162 140170411185984 infer_detections.py:85] Processed 2250 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2260 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:17.913597 140170411185984 infer_detections.py:85] Processed 2260 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2270 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:18.066844 140170411185984 infer_detections.py:85] Processed 2270 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2280 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:18.210033 140170411185984 infer_detections.py:85] Processed 2280 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2290 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:18.361412 140170411185984 infer_detections.py:85] Processed 2290 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2300 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:18.528706 140170411185984 infer_detections.py:85] Processed 2300 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2310 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:18.688934 140170411185984 infer_detections.py:85] Processed 2310 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2320 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:18.847207 140170411185984 infer_detections.py:85] Processed 2320 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2330 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:19.003567 140170411185984 infer_detections.py:85] Processed 2330 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2340 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:19.157445 140170411185984 infer_detections.py:85] Processed 2340 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2350 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:19.317825 140170411185984 infer_detections.py:85] Processed 2350 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2360 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:19.474436 140170411185984 infer_detections.py:85] Processed 2360 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2370 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:19.622705 140170411185984 infer_detections.py:85] Processed 2370 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2380 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:19.780697 140170411185984 infer_detections.py:85] Processed 2380 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2390 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:19.929107 140170411185984 infer_detections.py:85] Processed 2390 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2400 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:20.070227 140170411185984 infer_detections.py:85] Processed 2400 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2410 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:20.213755 140170411185984 infer_detections.py:85] Processed 2410 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2420 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:20.365741 140170411185984 infer_detections.py:85] Processed 2420 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2430 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:20.524314 140170411185984 infer_detections.py:85] Processed 2430 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2440 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:20.679981 140170411185984 infer_detections.py:85] Processed 2440 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2450 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:20.843656 140170411185984 infer_detections.py:85] Processed 2450 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2460 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:20.995779 140170411185984 infer_detections.py:85] Processed 2460 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2470 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:21.145917 140170411185984 infer_detections.py:85] Processed 2470 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2480 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:21.316065 140170411185984 infer_detections.py:85] Processed 2480 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2490 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:21.462659 140170411185984 infer_detections.py:85] Processed 2490 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2500 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:21.603886 140170411185984 infer_detections.py:85] Processed 2500 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2510 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:21.750876 140170411185984 infer_detections.py:85] Processed 2510 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2520 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:21.892841 140170411185984 infer_detections.py:85] Processed 2520 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2530 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:22.042541 140170411185984 infer_detections.py:85] Processed 2530 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2540 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:22.186662 140170411185984 infer_detections.py:85] Processed 2540 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2550 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:22.333086 140170411185984 infer_detections.py:85] Processed 2550 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2560 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:22.477862 140170411185984 infer_detections.py:85] Processed 2560 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2570 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:22.622216 140170411185984 infer_detections.py:85] Processed 2570 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2580 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:22.772941 140170411185984 infer_detections.py:85] Processed 2580 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2590 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:22.921398 140170411185984 infer_detections.py:85] Processed 2590 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2600 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:23.069853 140170411185984 infer_detections.py:85] Processed 2600 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2610 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:23.215682 140170411185984 infer_detections.py:85] Processed 2610 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2620 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:23.357888 140170411185984 infer_detections.py:85] Processed 2620 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2630 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:23.502619 140170411185984 infer_detections.py:85] Processed 2630 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2640 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:23.644206 140170411185984 infer_detections.py:85] Processed 2640 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2650 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:23.789180 140170411185984 infer_detections.py:85] Processed 2650 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2660 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:23.942032 140170411185984 infer_detections.py:85] Processed 2660 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2670 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:24.117285 140170411185984 infer_detections.py:85] Processed 2670 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2680 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:24.313208 140170411185984 infer_detections.py:85] Processed 2680 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2690 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:24.459869 140170411185984 infer_detections.py:85] Processed 2690 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2700 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:24.648846 140170411185984 infer_detections.py:85] Processed 2700 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2710 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:24.851430 140170411185984 infer_detections.py:85] Processed 2710 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2720 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:25.061130 140170411185984 infer_detections.py:85] Processed 2720 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2730 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:25.255330 140170411185984 infer_detections.py:85] Processed 2730 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2740 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:25.435648 140170411185984 infer_detections.py:85] Processed 2740 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2750 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:25.577569 140170411185984 infer_detections.py:85] Processed 2750 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2760 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:25.760743 140170411185984 infer_detections.py:85] Processed 2760 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2770 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:25.942934 140170411185984 infer_detections.py:85] Processed 2770 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2780 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:26.158625 140170411185984 infer_detections.py:85] Processed 2780 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2790 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:26.352773 140170411185984 infer_detections.py:85] Processed 2790 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2800 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:26.540165 140170411185984 infer_detections.py:85] Processed 2800 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2810 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:26.743318 140170411185984 infer_detections.py:85] Processed 2810 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2820 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:26.891844 140170411185984 infer_detections.py:85] Processed 2820 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2830 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:27.048446 140170411185984 infer_detections.py:85] Processed 2830 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2840 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:27.194334 140170411185984 infer_detections.py:85] Processed 2840 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2850 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:27.340028 140170411185984 infer_detections.py:85] Processed 2850 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2860 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:27.494899 140170411185984 infer_detections.py:85] Processed 2860 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2870 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:27.652929 140170411185984 infer_detections.py:85] Processed 2870 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2880 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:27.803317 140170411185984 infer_detections.py:85] Processed 2880 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2890 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:27.978730 140170411185984 infer_detections.py:85] Processed 2890 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2900 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:28.131596 140170411185984 infer_detections.py:85] Processed 2900 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2910 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:28.293834 140170411185984 infer_detections.py:85] Processed 2910 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2920 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:28.448452 140170411185984 infer_detections.py:85] Processed 2920 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2930 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:28.607381 140170411185984 infer_detections.py:85] Processed 2930 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2940 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:28.764373 140170411185984 infer_detections.py:85] Processed 2940 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2950 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:28.932561 140170411185984 infer_detections.py:85] Processed 2950 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2960 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:29.086925 140170411185984 infer_detections.py:85] Processed 2960 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2970 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:29.239805 140170411185984 infer_detections.py:85] Processed 2970 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2980 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:29.398910 140170411185984 infer_detections.py:85] Processed 2980 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 2990 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:29.546418 140170411185984 infer_detections.py:85] Processed 2990 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3000 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:29.692633 140170411185984 infer_detections.py:85] Processed 3000 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3010 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:29.840039 140170411185984 infer_detections.py:85] Processed 3010 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3020 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:29.997118 140170411185984 infer_detections.py:85] Processed 3020 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3030 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:30.153650 140170411185984 infer_detections.py:85] Processed 3030 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3040 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:30.306066 140170411185984 infer_detections.py:85] Processed 3040 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3050 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:30.461643 140170411185984 infer_detections.py:85] Processed 3050 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3060 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:30.630342 140170411185984 infer_detections.py:85] Processed 3060 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3070 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:30.798461 140170411185984 infer_detections.py:85] Processed 3070 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3080 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:30.967729 140170411185984 infer_detections.py:85] Processed 3080 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3090 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:31.130015 140170411185984 infer_detections.py:85] Processed 3090 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3100 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:31.315667 140170411185984 infer_detections.py:85] Processed 3100 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3110 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:31.489586 140170411185984 infer_detections.py:85] Processed 3110 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3120 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:31.652852 140170411185984 infer_detections.py:85] Processed 3120 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3130 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:31.816071 140170411185984 infer_detections.py:85] Processed 3130 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3140 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:31.999659 140170411185984 infer_detections.py:85] Processed 3140 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3150 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:32.165424 140170411185984 infer_detections.py:85] Processed 3150 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3160 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:32.332623 140170411185984 infer_detections.py:85] Processed 3160 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3170 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:32.499062 140170411185984 infer_detections.py:85] Processed 3170 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3180 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:32.664479 140170411185984 infer_detections.py:85] Processed 3180 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3190 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:32.844302 140170411185984 infer_detections.py:85] Processed 3190 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3200 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:33.009092 140170411185984 infer_detections.py:85] Processed 3200 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3210 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:33.169757 140170411185984 infer_detections.py:85] Processed 3210 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3220 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:33.331406 140170411185984 infer_detections.py:85] Processed 3220 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3230 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:33.488325 140170411185984 infer_detections.py:85] Processed 3230 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3240 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:33.639024 140170411185984 infer_detections.py:85] Processed 3240 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3250 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:33.791046 140170411185984 infer_detections.py:85] Processed 3250 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3260 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:33.943965 140170411185984 infer_detections.py:85] Processed 3260 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3270 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:34.100210 140170411185984 infer_detections.py:85] Processed 3270 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3280 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:34.252761 140170411185984 infer_detections.py:85] Processed 3280 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3290 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:34.404680 140170411185984 infer_detections.py:85] Processed 3290 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3300 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:34.558804 140170411185984 infer_detections.py:85] Processed 3300 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3310 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:34.708202 140170411185984 infer_detections.py:85] Processed 3310 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3320 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:34.870247 140170411185984 infer_detections.py:85] Processed 3320 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3330 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:35.033910 140170411185984 infer_detections.py:85] Processed 3330 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3340 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:35.187813 140170411185984 infer_detections.py:85] Processed 3340 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3350 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:35.344094 140170411185984 infer_detections.py:85] Processed 3350 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3360 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:35.502820 140170411185984 infer_detections.py:85] Processed 3360 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3370 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:35.658293 140170411185984 infer_detections.py:85] Processed 3370 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3380 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:35.819468 140170411185984 infer_detections.py:85] Processed 3380 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3390 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:35.985707 140170411185984 infer_detections.py:85] Processed 3390 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3400 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:36.159768 140170411185984 infer_detections.py:85] Processed 3400 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3410 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:36.334821 140170411185984 infer_detections.py:85] Processed 3410 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3420 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:36.495107 140170411185984 infer_detections.py:85] Processed 3420 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3430 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:36.648319 140170411185984 infer_detections.py:85] Processed 3430 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3440 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:36.801755 140170411185984 infer_detections.py:85] Processed 3440 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3450 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:36.955856 140170411185984 infer_detections.py:85] Processed 3450 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3460 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:37.108041 140170411185984 infer_detections.py:85] Processed 3460 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3470 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:37.267390 140170411185984 infer_detections.py:85] Processed 3470 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3480 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:37.421899 140170411185984 infer_detections.py:85] Processed 3480 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3490 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:37.606449 140170411185984 infer_detections.py:85] Processed 3490 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3500 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:37.789143 140170411185984 infer_detections.py:85] Processed 3500 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3510 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:37.963140 140170411185984 infer_detections.py:85] Processed 3510 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3520 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:38.133341 140170411185984 infer_detections.py:85] Processed 3520 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3530 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:38.302069 140170411185984 infer_detections.py:85] Processed 3530 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3540 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:38.469809 140170411185984 infer_detections.py:85] Processed 3540 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3550 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:38.639583 140170411185984 infer_detections.py:85] Processed 3550 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3560 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:38.825615 140170411185984 infer_detections.py:85] Processed 3560 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3570 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:38.990721 140170411185984 infer_detections.py:85] Processed 3570 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3580 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:39.153624 140170411185984 infer_detections.py:85] Processed 3580 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3590 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:39.322896 140170411185984 infer_detections.py:85] Processed 3590 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3600 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:39.498548 140170411185984 infer_detections.py:85] Processed 3600 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3610 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:39.663224 140170411185984 infer_detections.py:85] Processed 3610 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3620 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:39.835062 140170411185984 infer_detections.py:85] Processed 3620 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3630 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:39.999429 140170411185984 infer_detections.py:85] Processed 3630 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3640 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:40.167704 140170411185984 infer_detections.py:85] Processed 3640 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3650 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:40.333678 140170411185984 infer_detections.py:85] Processed 3650 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3660 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:40.500385 140170411185984 infer_detections.py:85] Processed 3660 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3670 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:40.672289 140170411185984 infer_detections.py:85] Processed 3670 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3680 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:40.840292 140170411185984 infer_detections.py:85] Processed 3680 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3690 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:41.013946 140170411185984 infer_detections.py:85] Processed 3690 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3700 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:41.181425 140170411185984 infer_detections.py:85] Processed 3700 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3710 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:41.370587 140170411185984 infer_detections.py:85] Processed 3710 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3720 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:41.534673 140170411185984 infer_detections.py:85] Processed 3720 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3730 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:41.701278 140170411185984 infer_detections.py:85] Processed 3730 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3740 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:41.856309 140170411185984 infer_detections.py:85] Processed 3740 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3750 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:42.028603 140170411185984 infer_detections.py:85] Processed 3750 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3760 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:42.187141 140170411185984 infer_detections.py:85] Processed 3760 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3770 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:42.364262 140170411185984 infer_detections.py:85] Processed 3770 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3780 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:42.531720 140170411185984 infer_detections.py:85] Processed 3780 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3790 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:42.695833 140170411185984 infer_detections.py:85] Processed 3790 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3800 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:42.870249 140170411185984 infer_detections.py:85] Processed 3800 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3810 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:43.038360 140170411185984 infer_detections.py:85] Processed 3810 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3820 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:43.212840 140170411185984 infer_detections.py:85] Processed 3820 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3830 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:43.389825 140170411185984 infer_detections.py:85] Processed 3830 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3840 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:43.562695 140170411185984 infer_detections.py:85] Processed 3840 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3850 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:43.735002 140170411185984 infer_detections.py:85] Processed 3850 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3860 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:43.904351 140170411185984 infer_detections.py:85] Processed 3860 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3870 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:44.067368 140170411185984 infer_detections.py:85] Processed 3870 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3880 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:44.240077 140170411185984 infer_detections.py:85] Processed 3880 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3890 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:44.406233 140170411185984 infer_detections.py:85] Processed 3890 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3900 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:44.580395 140170411185984 infer_detections.py:85] Processed 3900 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3910 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:44.749444 140170411185984 infer_detections.py:85] Processed 3910 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3920 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:44.916207 140170411185984 infer_detections.py:85] Processed 3920 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3930 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:45.081912 140170411185984 infer_detections.py:85] Processed 3930 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3940 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:45.251186 140170411185984 infer_detections.py:85] Processed 3940 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3950 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:45.414662 140170411185984 infer_detections.py:85] Processed 3950 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3960 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:45.585057 140170411185984 infer_detections.py:85] Processed 3960 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3970 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:45.753934 140170411185984 infer_detections.py:85] Processed 3970 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3980 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:45.919439 140170411185984 infer_detections.py:85] Processed 3980 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 3990 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:46.108157 140170411185984 infer_detections.py:85] Processed 3990 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Processed 4000 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:46.278093 140170411185984 infer_detections.py:85] Processed 4000 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished processing records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0412 10:13:46.300397 140170411185984 infer_detections.py:92] Finished processing records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/christina/Documents/Thesis/AutomaticLP\n"
     ]
    }
   ],
   "source": [
    "%cd models/research\n",
    "%run object_detection/inference/infer_detections.py --input_tfrecord_paths=../../FromScratch/TFRecordEval.tfrecord --inference_graph=../../inference_graph/frozen_inference_graph.pb --output_tfrecord_path=../../TFExamples.tfrecord\n",
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/christina/Documents/Thesis/AutomaticLP/tf_object_detection_cm\n",
      "WARNING:tensorflow:From /home/christina/Documents/Thesis/AutomaticLP/tf_object_detection_cm/confusion_matrix.py:45: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0412 10:13:49.284458 140170411185984 deprecation.py:323] From /home/christina/Documents/Thesis/AutomaticLP/tf_object_detection_cm/confusion_matrix.py:45: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 images\n",
      "Processed 200 images\n",
      "Processed 300 images\n",
      "Processed 400 images\n",
      "Processed 400 images\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 30.   0.   0. ...   0.   0. 160.]\n",
      " [  0.  43.   0. ...   0.   0. 153.]\n",
      " [  0.   3.   0. ...   0.   0. 203.]\n",
      " ...\n",
      " [  0.   0.   0. ...   0.   0.  33.]\n",
      " [  0.   0.   0. ...   0.   0. 188.]\n",
      " [  4.   0.   0. ...   0.   0.   0.]] \n",
      "\n",
      "   category  precision_@0.5IOU  recall_@0.5IOU\n",
      "0         0                NaN        0.000000\n",
      "1         1           0.535714        0.157895\n",
      "2         2           0.934783        0.219388\n",
      "3         3                NaN        0.000000\n",
      "4         4           1.000000        0.025641\n",
      "5         5           1.000000        0.043956\n",
      "6         6           1.000000        0.101449\n",
      "7         7           1.000000        0.058824\n",
      "8         8           0.015873        0.005181\n",
      "9         9                NaN        0.000000\n",
      "10        A                NaN        0.000000\n",
      "11        B                NaN        0.000000\n",
      "12        C                NaN        0.000000\n",
      "13        D                NaN        0.000000\n",
      "14        E                NaN        0.000000\n",
      "15        F                NaN        0.000000\n",
      "16        G                NaN        0.000000\n",
      "17        H                NaN        0.000000\n",
      "18        J                NaN        0.000000\n",
      "19        K                NaN        0.000000\n",
      "20        L                NaN        0.000000\n",
      "21        M                NaN        0.000000\n",
      "22        N                NaN        0.000000\n",
      "23        P                NaN        0.000000\n",
      "24        R                NaN        0.000000\n",
      "25        S                NaN        0.000000\n",
      "26        T                NaN        0.000000\n",
      "27        V                NaN        0.000000\n",
      "28        W                NaN        0.000000\n",
      "29        X                NaN        0.000000\n",
      "30        Y                NaN        0.000000\n",
      "31        Z                NaN        0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christina/Documents/Thesis/AutomaticLP/tf_object_detection_cm/confusion_matrix.py:125: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  precision = float(confusion_matrix[id, id] / total_predicted)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x1152 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/christina/Documents/Thesis/AutomaticLP\n"
     ]
    }
   ],
   "source": [
    "%cd tf_object_detection_cm\n",
    "%run confusion_matrix.py --detections_record=../Test.tfrecord --label_map=../FromScratch/data/label_map.pbtxt --output_path=confusion_matrix.csv\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LPKernel",
   "language": "python",
   "name": "lpkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
