{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Version to run on MARCC\n",
    "\n",
    "This notebook is assummed to be launched from the top level of the AutomaticLP github repo (where the notebook file is)\n",
    "\n",
    "This also assummes that you've already cloned the tensorflow object detection project\n",
    "https://github.com/tensorflow/models (since you need to do this to add the python path to  the bashrc file which has to be done before launching jupyter lab\n",
    "\n",
    "Run with the LPproject kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**If you have not followed the instructions in install.readme quit this lab / notebook and follow thoes steps first !!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests that Tensorflow GPU is installed & this notebook can see the GPU \n",
    "\n",
    "These don't need to be run everytime but are here as a sanity / debugging check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test that tensorflow can access a GPU\n",
    "import tensorflow as tf\n",
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Make sure at least 1 GPU device is listed\n",
    "print ('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected Result is 0\n",
    "!ml cuda/9.0\n",
    "!export CUDA_VISIBLE_DEVICES=1\n",
    "!echo ${CUDA_VISIBLE_DEVICES}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ScriptForBashFile generates both the training and test data and TFRecords from the image files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ScriptForBashFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This makes the output write to the file\n",
    "# https://stackoverflow.com/questions/45200375/stdout-redirect-from-jupyter-notebook-is-landing-in-the-terminal\n",
    "import sys\n",
    "old_stdout = sys.stdout\n",
    "sys.stdout = open('trainingLog.txt', 'w')\n",
    "\n",
    "%cd models/research\n",
    "%run object_detection/legacy/train.py --logtostderr --train_dir=../../trainingOutput/ --pipeline_config_path=../../configs/faster_rcnn_resnet101_coco.config \n",
    "%cd ../..\n",
    "\n",
    "# Put the cell output back to normal\n",
    "sys.stdout = old_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%run viewTraining.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We want to run Evaluation on the latest checkpoint \n",
    "# this code extracts the step number of the most recent checkpoint saved\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "%cd trainingOutput\n",
    "checkpointList = listdir()\n",
    "%cd ..\n",
    "\n",
    "numbers = []\n",
    "for filename in checkpointList:\n",
    "    match = re.search(\"^model.ckpt-\", filename)\n",
    "    if not match is None:\n",
    "        filename = filename.split(\".\")\n",
    "        filename = filename[1].split(\"-\")\n",
    "        numbers.append(filename[1])\n",
    "\n",
    "lastCheckpoint = max(numbers)\n",
    "print(lastCheckpoint)\n",
    "CHECKPOINT_PREFIX = \"../../trainingOutput/model.ckpt-\"+str(lastCheckpoint)\n",
    "\n",
    "# check to see if the infrence_graph folder exists - if it does ask if it should be deleted\n",
    "# if the directory exists the TF code won't work\n",
    "if(os.path.isdir(\"inference_graph\")):\n",
    "    choice = input(\"The Infrence Graph Directory already exists - to continue it needs to be deleted, is that OK (y/n)\")\n",
    "    if 'y' in choice.lower():\n",
    "        shutil.rmtree('inference_graph')\n",
    "    else:\n",
    "        exit()\n",
    "    \n",
    "%cd models/research\n",
    "%run object_detection/export_inference_graph.py --input_type image_tensor --pipeline_config_path ./../configs/faster_rcnn_resnet101_coco.config --trained_checkpoint_prefix $CHECKPOINT_PREFIX --output_directory ../../inference_graph\n",
    "%cd ../..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%cd models/research\n",
    "%run object_detection/inference/infer_detections.py --input_tfrecord_paths=../../FromScratch/TFRecordEval.tfrecord --inference_graph=../../inference_graph/frozen_inference_graph.pb --output_tfrecord_path=../../TFExamples.tfrecord\n",
    "%cd ../..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd tf_object_detection_cm\n",
    "%run confusion_matrix.py --detections_record=../TFExamples.tfrecord --label_map=../FromScratch/data/label_map.pbtxt --output_path=confusion_matrix.csv\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cells for augmentation test runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the augmentation type as needed\n",
    "%run augmentedTestDatasets.py -a GaussianNoise -n 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd models/research\n",
    "%run object_detection/inference/infer_detections.py --input_tfrecord_paths=../../FromScratch/TFRecordAugmented.tfrecord --inference_graph=../../inference_graph/frozen_inference_graph.pb --output_tfrecord_path=../../TFExamples.tfrecord\n",
    "%cd ../..\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LPKernel",
   "language": "python",
   "name": "lpkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
