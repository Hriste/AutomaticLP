<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />

<title>GPUTraining</title>

<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>



<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.7.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.7.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.7.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff2?v=4.7.0') format('woff2'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.7.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.7.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.7.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.fa-pull-left {
  float: left;
}
.fa-pull-right {
  float: right;
}
.fa.fa-pull-left {
  margin-right: .3em;
}
.fa.fa-pull-right {
  margin-left: .3em;
}
/* Deprecated as of 4.4.0 */
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
.fa-pulse {
  -webkit-animation: fa-spin 1s infinite steps(8);
  animation: fa-spin 1s infinite steps(8);
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=1)";
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2)";
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=3)";
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1)";
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1)";
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook-f:before,
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-feed:before,
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before,
.fa-gratipay:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper-pp:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-resistance:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-y-combinator-square:before,
.fa-yc-square:before,
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
.fa-buysellads:before {
  content: "\f20d";
}
.fa-connectdevelop:before {
  content: "\f20e";
}
.fa-dashcube:before {
  content: "\f210";
}
.fa-forumbee:before {
  content: "\f211";
}
.fa-leanpub:before {
  content: "\f212";
}
.fa-sellsy:before {
  content: "\f213";
}
.fa-shirtsinbulk:before {
  content: "\f214";
}
.fa-simplybuilt:before {
  content: "\f215";
}
.fa-skyatlas:before {
  content: "\f216";
}
.fa-cart-plus:before {
  content: "\f217";
}
.fa-cart-arrow-down:before {
  content: "\f218";
}
.fa-diamond:before {
  content: "\f219";
}
.fa-ship:before {
  content: "\f21a";
}
.fa-user-secret:before {
  content: "\f21b";
}
.fa-motorcycle:before {
  content: "\f21c";
}
.fa-street-view:before {
  content: "\f21d";
}
.fa-heartbeat:before {
  content: "\f21e";
}
.fa-venus:before {
  content: "\f221";
}
.fa-mars:before {
  content: "\f222";
}
.fa-mercury:before {
  content: "\f223";
}
.fa-intersex:before,
.fa-transgender:before {
  content: "\f224";
}
.fa-transgender-alt:before {
  content: "\f225";
}
.fa-venus-double:before {
  content: "\f226";
}
.fa-mars-double:before {
  content: "\f227";
}
.fa-venus-mars:before {
  content: "\f228";
}
.fa-mars-stroke:before {
  content: "\f229";
}
.fa-mars-stroke-v:before {
  content: "\f22a";
}
.fa-mars-stroke-h:before {
  content: "\f22b";
}
.fa-neuter:before {
  content: "\f22c";
}
.fa-genderless:before {
  content: "\f22d";
}
.fa-facebook-official:before {
  content: "\f230";
}
.fa-pinterest-p:before {
  content: "\f231";
}
.fa-whatsapp:before {
  content: "\f232";
}
.fa-server:before {
  content: "\f233";
}
.fa-user-plus:before {
  content: "\f234";
}
.fa-user-times:before {
  content: "\f235";
}
.fa-hotel:before,
.fa-bed:before {
  content: "\f236";
}
.fa-viacoin:before {
  content: "\f237";
}
.fa-train:before {
  content: "\f238";
}
.fa-subway:before {
  content: "\f239";
}
.fa-medium:before {
  content: "\f23a";
}
.fa-yc:before,
.fa-y-combinator:before {
  content: "\f23b";
}
.fa-optin-monster:before {
  content: "\f23c";
}
.fa-opencart:before {
  content: "\f23d";
}
.fa-expeditedssl:before {
  content: "\f23e";
}
.fa-battery-4:before,
.fa-battery:before,
.fa-battery-full:before {
  content: "\f240";
}
.fa-battery-3:before,
.fa-battery-three-quarters:before {
  content: "\f241";
}
.fa-battery-2:before,
.fa-battery-half:before {
  content: "\f242";
}
.fa-battery-1:before,
.fa-battery-quarter:before {
  content: "\f243";
}
.fa-battery-0:before,
.fa-battery-empty:before {
  content: "\f244";
}
.fa-mouse-pointer:before {
  content: "\f245";
}
.fa-i-cursor:before {
  content: "\f246";
}
.fa-object-group:before {
  content: "\f247";
}
.fa-object-ungroup:before {
  content: "\f248";
}
.fa-sticky-note:before {
  content: "\f249";
}
.fa-sticky-note-o:before {
  content: "\f24a";
}
.fa-cc-jcb:before {
  content: "\f24b";
}
.fa-cc-diners-club:before {
  content: "\f24c";
}
.fa-clone:before {
  content: "\f24d";
}
.fa-balance-scale:before {
  content: "\f24e";
}
.fa-hourglass-o:before {
  content: "\f250";
}
.fa-hourglass-1:before,
.fa-hourglass-start:before {
  content: "\f251";
}
.fa-hourglass-2:before,
.fa-hourglass-half:before {
  content: "\f252";
}
.fa-hourglass-3:before,
.fa-hourglass-end:before {
  content: "\f253";
}
.fa-hourglass:before {
  content: "\f254";
}
.fa-hand-grab-o:before,
.fa-hand-rock-o:before {
  content: "\f255";
}
.fa-hand-stop-o:before,
.fa-hand-paper-o:before {
  content: "\f256";
}
.fa-hand-scissors-o:before {
  content: "\f257";
}
.fa-hand-lizard-o:before {
  content: "\f258";
}
.fa-hand-spock-o:before {
  content: "\f259";
}
.fa-hand-pointer-o:before {
  content: "\f25a";
}
.fa-hand-peace-o:before {
  content: "\f25b";
}
.fa-trademark:before {
  content: "\f25c";
}
.fa-registered:before {
  content: "\f25d";
}
.fa-creative-commons:before {
  content: "\f25e";
}
.fa-gg:before {
  content: "\f260";
}
.fa-gg-circle:before {
  content: "\f261";
}
.fa-tripadvisor:before {
  content: "\f262";
}
.fa-odnoklassniki:before {
  content: "\f263";
}
.fa-odnoklassniki-square:before {
  content: "\f264";
}
.fa-get-pocket:before {
  content: "\f265";
}
.fa-wikipedia-w:before {
  content: "\f266";
}
.fa-safari:before {
  content: "\f267";
}
.fa-chrome:before {
  content: "\f268";
}
.fa-firefox:before {
  content: "\f269";
}
.fa-opera:before {
  content: "\f26a";
}
.fa-internet-explorer:before {
  content: "\f26b";
}
.fa-tv:before,
.fa-television:before {
  content: "\f26c";
}
.fa-contao:before {
  content: "\f26d";
}
.fa-500px:before {
  content: "\f26e";
}
.fa-amazon:before {
  content: "\f270";
}
.fa-calendar-plus-o:before {
  content: "\f271";
}
.fa-calendar-minus-o:before {
  content: "\f272";
}
.fa-calendar-times-o:before {
  content: "\f273";
}
.fa-calendar-check-o:before {
  content: "\f274";
}
.fa-industry:before {
  content: "\f275";
}
.fa-map-pin:before {
  content: "\f276";
}
.fa-map-signs:before {
  content: "\f277";
}
.fa-map-o:before {
  content: "\f278";
}
.fa-map:before {
  content: "\f279";
}
.fa-commenting:before {
  content: "\f27a";
}
.fa-commenting-o:before {
  content: "\f27b";
}
.fa-houzz:before {
  content: "\f27c";
}
.fa-vimeo:before {
  content: "\f27d";
}
.fa-black-tie:before {
  content: "\f27e";
}
.fa-fonticons:before {
  content: "\f280";
}
.fa-reddit-alien:before {
  content: "\f281";
}
.fa-edge:before {
  content: "\f282";
}
.fa-credit-card-alt:before {
  content: "\f283";
}
.fa-codiepie:before {
  content: "\f284";
}
.fa-modx:before {
  content: "\f285";
}
.fa-fort-awesome:before {
  content: "\f286";
}
.fa-usb:before {
  content: "\f287";
}
.fa-product-hunt:before {
  content: "\f288";
}
.fa-mixcloud:before {
  content: "\f289";
}
.fa-scribd:before {
  content: "\f28a";
}
.fa-pause-circle:before {
  content: "\f28b";
}
.fa-pause-circle-o:before {
  content: "\f28c";
}
.fa-stop-circle:before {
  content: "\f28d";
}
.fa-stop-circle-o:before {
  content: "\f28e";
}
.fa-shopping-bag:before {
  content: "\f290";
}
.fa-shopping-basket:before {
  content: "\f291";
}
.fa-hashtag:before {
  content: "\f292";
}
.fa-bluetooth:before {
  content: "\f293";
}
.fa-bluetooth-b:before {
  content: "\f294";
}
.fa-percent:before {
  content: "\f295";
}
.fa-gitlab:before {
  content: "\f296";
}
.fa-wpbeginner:before {
  content: "\f297";
}
.fa-wpforms:before {
  content: "\f298";
}
.fa-envira:before {
  content: "\f299";
}
.fa-universal-access:before {
  content: "\f29a";
}
.fa-wheelchair-alt:before {
  content: "\f29b";
}
.fa-question-circle-o:before {
  content: "\f29c";
}
.fa-blind:before {
  content: "\f29d";
}
.fa-audio-description:before {
  content: "\f29e";
}
.fa-volume-control-phone:before {
  content: "\f2a0";
}
.fa-braille:before {
  content: "\f2a1";
}
.fa-assistive-listening-systems:before {
  content: "\f2a2";
}
.fa-asl-interpreting:before,
.fa-american-sign-language-interpreting:before {
  content: "\f2a3";
}
.fa-deafness:before,
.fa-hard-of-hearing:before,
.fa-deaf:before {
  content: "\f2a4";
}
.fa-glide:before {
  content: "\f2a5";
}
.fa-glide-g:before {
  content: "\f2a6";
}
.fa-signing:before,
.fa-sign-language:before {
  content: "\f2a7";
}
.fa-low-vision:before {
  content: "\f2a8";
}
.fa-viadeo:before {
  content: "\f2a9";
}
.fa-viadeo-square:before {
  content: "\f2aa";
}
.fa-snapchat:before {
  content: "\f2ab";
}
.fa-snapchat-ghost:before {
  content: "\f2ac";
}
.fa-snapchat-square:before {
  content: "\f2ad";
}
.fa-pied-piper:before {
  content: "\f2ae";
}
.fa-first-order:before {
  content: "\f2b0";
}
.fa-yoast:before {
  content: "\f2b1";
}
.fa-themeisle:before {
  content: "\f2b2";
}
.fa-google-plus-circle:before,
.fa-google-plus-official:before {
  content: "\f2b3";
}
.fa-fa:before,
.fa-font-awesome:before {
  content: "\f2b4";
}
.fa-handshake-o:before {
  content: "\f2b5";
}
.fa-envelope-open:before {
  content: "\f2b6";
}
.fa-envelope-open-o:before {
  content: "\f2b7";
}
.fa-linode:before {
  content: "\f2b8";
}
.fa-address-book:before {
  content: "\f2b9";
}
.fa-address-book-o:before {
  content: "\f2ba";
}
.fa-vcard:before,
.fa-address-card:before {
  content: "\f2bb";
}
.fa-vcard-o:before,
.fa-address-card-o:before {
  content: "\f2bc";
}
.fa-user-circle:before {
  content: "\f2bd";
}
.fa-user-circle-o:before {
  content: "\f2be";
}
.fa-user-o:before {
  content: "\f2c0";
}
.fa-id-badge:before {
  content: "\f2c1";
}
.fa-drivers-license:before,
.fa-id-card:before {
  content: "\f2c2";
}
.fa-drivers-license-o:before,
.fa-id-card-o:before {
  content: "\f2c3";
}
.fa-quora:before {
  content: "\f2c4";
}
.fa-free-code-camp:before {
  content: "\f2c5";
}
.fa-telegram:before {
  content: "\f2c6";
}
.fa-thermometer-4:before,
.fa-thermometer:before,
.fa-thermometer-full:before {
  content: "\f2c7";
}
.fa-thermometer-3:before,
.fa-thermometer-three-quarters:before {
  content: "\f2c8";
}
.fa-thermometer-2:before,
.fa-thermometer-half:before {
  content: "\f2c9";
}
.fa-thermometer-1:before,
.fa-thermometer-quarter:before {
  content: "\f2ca";
}
.fa-thermometer-0:before,
.fa-thermometer-empty:before {
  content: "\f2cb";
}
.fa-shower:before {
  content: "\f2cc";
}
.fa-bathtub:before,
.fa-s15:before,
.fa-bath:before {
  content: "\f2cd";
}
.fa-podcast:before {
  content: "\f2ce";
}
.fa-window-maximize:before {
  content: "\f2d0";
}
.fa-window-minimize:before {
  content: "\f2d1";
}
.fa-window-restore:before {
  content: "\f2d2";
}
.fa-times-rectangle:before,
.fa-window-close:before {
  content: "\f2d3";
}
.fa-times-rectangle-o:before,
.fa-window-close-o:before {
  content: "\f2d4";
}
.fa-bandcamp:before {
  content: "\f2d5";
}
.fa-grav:before {
  content: "\f2d6";
}
.fa-etsy:before {
  content: "\f2d7";
}
.fa-imdb:before {
  content: "\f2d8";
}
.fa-ravelry:before {
  content: "\f2d9";
}
.fa-eercast:before {
  content: "\f2da";
}
.fa-microchip:before {
  content: "\f2db";
}
.fa-snowflake-o:before {
  content: "\f2dc";
}
.fa-superpowers:before {
  content: "\f2dd";
}
.fa-wpexplorer:before {
  content: "\f2de";
}
.fa-meetup:before {
  content: "\f2e0";
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  padding: 0;
  margin: -1px;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
div.traceback-wrapper pre.traceback {
  max-height: 600px;
  overflow: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  display: flex;
  flex-direction: row;
  justify-content: space-between;
  padding: 5px;
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
[dir="rtl"] #ipython_notebook {
  margin-right: 10px;
  margin-left: 0;
}
[dir="rtl"] #ipython_notebook.pull-left {
  float: right !important;
  float: right;
}
.flex-spacer {
  flex: 1;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#kernel_logo_widget {
  margin: 0 10px;
}
span#login_widget {
  float: right;
}
[dir="rtl"] span#login_widget {
  float: left;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
.modal-header {
  cursor: move;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
[dir="rtl"] .center-nav form.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] .center-nav .navbar-text {
  float: right;
}
[dir="rtl"] .navbar-inner {
  text-align: right;
}
[dir="rtl"] div.text-left {
  text-align: right;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  position: absolute;
  display: block;
  width: 100%;
  height: 100%;
  overflow: hidden;
  cursor: pointer;
  opacity: 0;
  z-index: 2;
}
.alternate_upload .btn-xs > input.fileinput {
  margin: -1px -5px;
}
.alternate_upload .btn-upload {
  position: relative;
  height: 22px;
}
::-webkit-file-upload-button {
  cursor: pointer;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
ul#tabs {
  margin-bottom: 4px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
[dir="rtl"] ul#tabs.nav-tabs > li {
  float: right;
}
[dir="rtl"] ul#tabs.nav.nav-tabs {
  padding-right: 0;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons .pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .list_toolbar .col-sm-4,
[dir="rtl"] .list_toolbar .col-sm-8 {
  float: right;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: text-bottom;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
[dir="rtl"] .list_item > div input {
  margin-right: 0;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_modified {
  margin-right: 7px;
  margin-left: 7px;
}
[dir="rtl"] .item_modified.pull-right {
  float: left !important;
  float: left;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
[dir="rtl"] .item_buttons.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .item_buttons .kernel-name {
  margin-left: 7px;
  float: right;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
.sort_button {
  display: inline-block;
  padding-left: 7px;
}
[dir="rtl"] .sort_button.pull-right {
  float: left !important;
  float: left;
}
#tree-selector {
  padding-right: 0px;
}
#button-select-all {
  min-width: 50px;
}
[dir="rtl"] #button-select-all.btn {
  float: right ;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
  margin-top: 2px;
  height: 16px;
}
[dir="rtl"] #select-all.pull-left {
  float: right !important;
  float: right;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.fa-pull-left {
  margin-right: .3em;
}
.folder_icon:before.fa-pull-right {
  margin-left: .3em;
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.fa-pull-left {
  margin-right: .3em;
}
.file_icon:before.fa-pull-right {
  margin-left: .3em;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
#new-menu .dropdown-header {
  font-size: 10px;
  border-bottom: 1px solid #e5e5e5;
  padding: 0 0 3px;
  margin: -3px 20px 0;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.move-button {
  display: none;
}
.download-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
.CodeMirror-dialog {
  background-color: #fff;
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI escape sequences */
/* The color values are a mix of
   http://www.xcolors.net/dl/baskerville-ivorylight and
   http://www.xcolors.net/dl/euphrasia */
.ansi-black-fg {
  color: #3E424D;
}
.ansi-black-bg {
  background-color: #3E424D;
}
.ansi-black-intense-fg {
  color: #282C36;
}
.ansi-black-intense-bg {
  background-color: #282C36;
}
.ansi-red-fg {
  color: #E75C58;
}
.ansi-red-bg {
  background-color: #E75C58;
}
.ansi-red-intense-fg {
  color: #B22B31;
}
.ansi-red-intense-bg {
  background-color: #B22B31;
}
.ansi-green-fg {
  color: #00A250;
}
.ansi-green-bg {
  background-color: #00A250;
}
.ansi-green-intense-fg {
  color: #007427;
}
.ansi-green-intense-bg {
  background-color: #007427;
}
.ansi-yellow-fg {
  color: #DDB62B;
}
.ansi-yellow-bg {
  background-color: #DDB62B;
}
.ansi-yellow-intense-fg {
  color: #B27D12;
}
.ansi-yellow-intense-bg {
  background-color: #B27D12;
}
.ansi-blue-fg {
  color: #208FFB;
}
.ansi-blue-bg {
  background-color: #208FFB;
}
.ansi-blue-intense-fg {
  color: #0065CA;
}
.ansi-blue-intense-bg {
  background-color: #0065CA;
}
.ansi-magenta-fg {
  color: #D160C4;
}
.ansi-magenta-bg {
  background-color: #D160C4;
}
.ansi-magenta-intense-fg {
  color: #A03196;
}
.ansi-magenta-intense-bg {
  background-color: #A03196;
}
.ansi-cyan-fg {
  color: #60C6C8;
}
.ansi-cyan-bg {
  background-color: #60C6C8;
}
.ansi-cyan-intense-fg {
  color: #258F8F;
}
.ansi-cyan-intense-bg {
  background-color: #258F8F;
}
.ansi-white-fg {
  color: #C5C1B4;
}
.ansi-white-bg {
  background-color: #C5C1B4;
}
.ansi-white-intense-fg {
  color: #A1A6B2;
}
.ansi-white-intense-bg {
  background-color: #A1A6B2;
}
.ansi-default-inverse-fg {
  color: #FFFFFF;
}
.ansi-default-inverse-bg {
  background-color: #000000;
}
.ansi-bold {
  font-weight: bold;
}
.ansi-underline {
  text-decoration: underline;
}
/* The following styles are deprecated an will be removed in a future version */
.ansibold {
  font-weight: bold;
}
.ansi-inverse {
  outline: 0.5px dotted;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  position: relative;
  overflow: visible;
}
div.cell:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: transparent;
}
div.cell.jupyter-soft-selected {
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected,
div.cell.selected.jupyter-soft-selected {
  border-color: #ababab;
}
div.cell.selected:before,
div.cell.selected.jupyter-soft-selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #42A5F5;
}
@media print {
  div.cell.selected,
  div.cell.selected.jupyter-soft-selected {
    border-color: transparent;
  }
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
}
.edit_mode div.cell.selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #66BB6A;
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  /* Note that this should set vertical padding only, since CodeMirror assumes
       that horizontal padding will be set on CodeMirror pre */
  padding: 0.4em 0;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only,
    use .CodeMirror-lines for vertical */
  padding: 0 0.4em;
  border: 0;
  border-radius: 0;
}
.CodeMirror-cursor {
  border-left: 1.4px solid black;
}
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .CodeMirror-cursor {
    border-left: 2px solid black;
  }
}
@media screen and (min-width: 4320px) {
  .CodeMirror-cursor {
    border-left: 4px solid black;
  }
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
div.output_area .mglyph > img {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 1px 0 1px 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul:not(.list-inline),
.rendered_html ol:not(.list-inline) {
  padding-left: 2em;
}
.rendered_html ul {
  list-style: disc;
}
.rendered_html ul ul {
  list-style: square;
  margin-top: 0;
}
.rendered_html ul ul ul {
  list-style: circle;
}
.rendered_html ol {
  list-style: decimal;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin-top: 0;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
  padding: 0px;
  background-color: #fff;
}
.rendered_html code {
  background-color: #eff0f1;
}
.rendered_html p code {
  padding: 1px 5px;
}
.rendered_html pre code {
  background-color: #fff;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  color: #000;
  font-size: 100%;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
.rendered_html .alert {
  margin-bottom: initial;
}
.rendered_html * + .alert {
  margin-top: 1em;
}
[dir="rtl"] .rendered_html p {
  text-align: right;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.rendered .rendered_html tr,
.text_cell.rendered .rendered_html th,
.text_cell.rendered .rendered_html td {
  max-width: none;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.text_cell .dropzone .input_area {
  border: 2px dashed #bababa;
  margin: -1px;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
.jupyter-keybindings {
  padding: 1px;
  line-height: 24px;
  border-bottom: 1px solid gray;
}
.jupyter-keybindings input {
  margin: 0;
  padding: 0;
  border: none;
}
.jupyter-keybindings i {
  padding: 6px;
}
.well code {
  background-color: #ffffff;
  border-color: #ababab;
  border-width: 1px;
  border-style: solid;
  padding: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.tags_button_container {
  width: 100%;
  display: flex;
}
.tag-container {
  display: flex;
  flex-direction: row;
  flex-grow: 1;
  overflow: hidden;
  position: relative;
}
.tag-container > * {
  margin: 0 4px;
}
.remove-tag-btn {
  margin-left: 4px;
}
.tags-input {
  display: flex;
}
.cell-tag:last-child:after {
  content: "";
  position: absolute;
  right: 0;
  width: 40px;
  height: 100%;
  /* Fade to background color of cell toolbar */
  background: linear-gradient(to right, rgba(0, 0, 0, 0), #EEE);
}
.tags-input > * {
  margin-left: 4px;
}
.cell-tag,
.tags-input input,
.tags-input button {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  box-shadow: none;
  width: inherit;
  font-size: inherit;
  height: 22px;
  line-height: 22px;
  padding: 0px 4px;
  display: inline-block;
}
.cell-tag:focus,
.tags-input input:focus,
.tags-input button:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.cell-tag::-moz-placeholder,
.tags-input input::-moz-placeholder,
.tags-input button::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.cell-tag:-ms-input-placeholder,
.tags-input input:-ms-input-placeholder,
.tags-input button:-ms-input-placeholder {
  color: #999;
}
.cell-tag::-webkit-input-placeholder,
.tags-input input::-webkit-input-placeholder,
.tags-input button::-webkit-input-placeholder {
  color: #999;
}
.cell-tag::-ms-expand,
.tags-input input::-ms-expand,
.tags-input button::-ms-expand {
  border: 0;
  background-color: transparent;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
.cell-tag[readonly],
.tags-input input[readonly],
.tags-input button[readonly],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  background-color: #eeeeee;
  opacity: 1;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  cursor: not-allowed;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button {
  height: auto;
}
select.cell-tag,
select.tags-input input,
select.tags-input button {
  height: 30px;
  line-height: 30px;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button,
select[multiple].cell-tag,
select[multiple].tags-input input,
select[multiple].tags-input button {
  height: auto;
}
.cell-tag,
.tags-input button {
  padding: 0px 4px;
}
.cell-tag {
  background-color: #fff;
  white-space: nowrap;
}
.tags-input input[type=text]:focus {
  outline: none;
  box-shadow: none;
  border-color: #ccc;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
[dir="rtl"] #kernel_logo_widget {
  float: left !important;
  float: left;
}
.modal .modal-body .move-path {
  display: flex;
  flex-direction: row;
  justify-content: space;
  align-items: center;
}
.modal .modal-body .move-path .server-root {
  padding-right: 20px;
}
.modal .modal-body .move-path .path-input {
  flex: 1;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
[dir="rtl"] #menubar .navbar-toggle {
  float: right;
}
[dir="rtl"] #menubar .navbar-collapse {
  clear: right;
}
[dir="rtl"] #menubar .navbar-nav {
  float: right;
}
[dir="rtl"] #menubar .nav {
  padding-right: 0px;
}
[dir="rtl"] #menubar .navbar-nav > li {
  float: right;
}
[dir="rtl"] #menubar .navbar-right {
  float: left !important;
}
[dir="rtl"] ul.dropdown-menu {
  text-align: right;
  left: auto;
}
[dir="rtl"] ul#new-menu.dropdown-menu {
  right: auto;
  left: 0;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
[dir="rtl"] i.menu-icon.pull-right {
  float: left !important;
  float: left;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
[dir="rtl"] ul#help_menu li a {
  padding-left: 2.2em;
}
[dir="rtl"] ul#help_menu li a i {
  margin-right: 0;
  margin-left: -1.2em;
}
[dir="rtl"] ul#help_menu li a i.pull-right {
  float: left !important;
  float: left;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
[dir="rtl"] .dropdown-submenu > .dropdown-menu {
  right: 100%;
  margin-right: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.fa-pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.fa-pull-right {
  margin-left: .3em;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
[dir="rtl"] .dropdown-submenu > a:after {
  float: left;
  content: "\f0d9";
  margin-right: 0;
  margin-left: -10px;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
[dir="rtl"] #notification_area {
  float: left !important;
  float: left;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] .indicator_area {
  float: left !important;
  float: left;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
[dir="rtl"] #kernel_indicator {
  float: left !important;
  float: left;
  border-left: 0;
  border-right: 1px solid;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] #modal_indicator {
  float: left !important;
  float: left;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  height: 30px;
  margin-top: 4px;
  display: flex;
  justify-content: flex-start;
  align-items: baseline;
  width: 50%;
  flex: 1;
}
span.save_widget span.filename {
  height: 100%;
  line-height: 1em;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  text-overflow: ellipsis;
  overflow: hidden;
  white-space: nowrap;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
[dir="rtl"] span.save_widget.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] span.save_widget span.filename {
  margin-left: 0;
  margin-right: 16px;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
  white-space: nowrap;
  padding: 0 5px;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
    padding: 0 0 0 5px;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
.toolbar-btn-label {
  margin-left: 6px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
[dir="rtl"] .btn-group > .btn,
.btn-group-vertical > .btn {
  float: right;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
[dir="rtl"] ul.typeahead-list i {
  margin-left: 0;
  margin-right: -10px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
ul.typeahead-list  > li > a.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .typeahead-list {
  text-align: right;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  min-width: 20px;
  color: transparent;
}
[dir="rtl"] .no-shortcut.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .command-shortcut.pull-right {
  float: left !important;
  float: left;
}
.command-shortcut:before {
  content: "(command mode)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
[dir="rtl"] .edit-shortcut.pull-right {
  float: left !important;
  float: left;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
[dir="ltr"] #find-and-replace .input-group-btn + .form-control {
  border-left: none;
}
[dir="rtl"] #find-and-replace .input-group-btn + .form-control {
  border-right: none;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="GPU-Version-to-run-on-MARCC">GPU Version to run on MARCC<a class="anchor-link" href="#GPU-Version-to-run-on-MARCC">&#182;</a></h1><p>This notebook is assummed to be launched from the top level of the AutomaticLP github repo (where the notebook file is)</p>
<p>This also assummes that you've already cloed the tensorflow object detection project
<a href="https://github.com/tensorflow/models">https://github.com/tensorflow/models</a> (since you need to do this to add the python path to  the bashrc file which has to be done before launching jupyter lab</p>
<p>Run with the LPproject kernel</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Setup-/-Installations">Setup / Installations<a class="anchor-link" href="#Setup-/-Installations">&#182;</a></h2><p>Add
<code>
export PYTHONPATH=$PYTHONPATH:`pwd`
export PYTHONPATH=$PYTHONPATH:<code>pwd</code>/slim</p>
<p>to your ~/.bashrc file where pwd is the full path to the models/research directory</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Tests-that-Tensorflow-GPU-is-installed-&amp;-this-notebook-can-see-the-GPU">Tests that Tensorflow GPU is installed &amp; this notebook can see the GPU<a class="anchor-link" href="#Tests-that-Tensorflow-GPU-is-installed-&amp;-this-notebook-can-see-the-GPU">&#182;</a></h3><p>These don't need to be run everytime but are here as a sanity / debugging check</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># test that tensorflow can access a GPU</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">is_built_with_cuda</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.python.client</span> <span class="k">import</span> <span class="n">device_lib</span>
<span class="nb">print</span><span class="p">(</span><span class="n">device_lib</span><span class="o">.</span><span class="n">list_local_devices</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;Default GPU Device: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">gpu_device_name</span><span class="p">()))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>%%bash 
<span class="nb">cd</span> models/research
<span class="nv">FILE</span><span class="o">=</span>protobuf.zip
<span class="k">if</span> <span class="o">[</span> ! -f <span class="s2">&quot;</span><span class="nv">$FILE</span><span class="s2">&quot;</span> <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
    wget -O protobuf.zip https://github.com/google/protobuf/releases/download/v3.0.0/protoc-3.0.0-linux-x86_64.zip
    unzip protobuf.zip
<span class="k">fi</span>
./bin/protoc object_detection/protos/*.proto --python_out<span class="o">=</span>.
pip install --user .
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>ml cuda/9.0
<span class="o">!</span><span class="nb">export</span> <span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">1</span>
<span class="o">!</span><span class="nb">echo</span> <span class="si">${</span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="si">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Generating-Datasets">Generating Datasets<a class="anchor-link" href="#Generating-Datasets">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The ScriptForBashFile generates both the training and test data and TFRecords from the image files</p>
<p>(For now hard coded to 100 images - TODO: switch back to user input, note then this won't be able to run with a bash script)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">run</span> ScriptForBashFile
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Train">Train<a class="anchor-link" href="#Train">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># If training output directory dosen&#39;t exist create it</span>
<span class="o">!</span>mkdir -p trainingOutput
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># This makes the output of the next cell write to the file</span>
<span class="c1"># https://stackoverflow.com/questions/45200375/stdout-redirect-from-jupyter-notebook-is-landing-in-the-terminal</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="n">sys</span><span class="o">.</span><span class="n">stdout</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;trainingLog.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">cd</span> models/research
<span class="o">%</span><span class="k">run</span> object_detection/legacy/train.py --logtostderr --train_dir=../../trainingOutput/ --pipeline_config_path=../../FromScratch/models/model/ssd_mobilenet_v1_coco.config 
<span class="o">%</span><span class="k">cd</span> ../..
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>W0404 20:04:45.054332 47978602034560 deprecation.py:323] From /home-1/cpaolic1@jhu.edu/.conda/envs/LPEnvironment/lib/python3.7/site-packages/absl/app.py:250: main (from __main__) is deprecated and will be removed in a future version.
Instructions for updating:
Use object_detection/model_main.py.
W0404 20:04:45.055131 47978602034560 module_wrapper.py:139] From /home-net/home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/legacy/train.py:91: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.

W0404 20:04:45.055983 47978602034560 module_wrapper.py:139] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.

W0404 20:04:45.060069 47978602034560 module_wrapper.py:139] From /home-net/home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/legacy/train.py:96: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.

W0404 20:04:45.063743 47978602034560 deprecation.py:323] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/legacy/trainer.py:267: create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.create_global_step
W0404 20:04:45.067856 47978602034560 module_wrapper.py:139] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.

W0404 20:04:45.068331 47978602034560 module_wrapper.py:139] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.

W0404 20:04:45.088019 47978602034560 module_wrapper.py:139] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.

W0404 20:04:45.089567 47978602034560 module_wrapper.py:139] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/builders/dataset_builder.py:71: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.

W0404 20:04:45.090031 47978602034560 dataset_builder.py:72] num_readers has been reduced to 1 to match input file shards.
W0404 20:04:45.095689 47978602034560 deprecation.py:323] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.experimental.parallel_interleave(...)`.
W0404 20:04:45.096131 47978602034560 deprecation.py:323] From /home-1/cpaolic1@jhu.edu/.conda/envs/LPEnvironment/lib/python3.7/site-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
W0404 20:04:45.116693 47978602034560 deprecation.py:323] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
W0404 20:04:45.663084 47978602034560 deprecation.py:323] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/builders/dataset_builder.py:43: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
W0404 20:04:45.668757 47978602034560 module_wrapper.py:139] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/builders/dataset_builder.py:44: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.

W0404 20:04:45.669220 47978602034560 module_wrapper.py:139] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/builders/dataset_builder.py:44: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

W0404 20:04:45.673495 47978602034560 module_wrapper.py:139] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/core/preprocessor.py:627: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

W0404 20:04:45.720537 47978602034560 deprecation.py:323] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/core/preprocessor.py:197: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.
Instructions for updating:
`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.
W0404 20:04:45.731422 47978602034560 deprecation.py:323] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/core/box_list_ops.py:206: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0404 20:04:46.355444 47978602034560 deprecation.py:323] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/core/batcher.py:101: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.
Instructions for updating:
Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).
W0404 20:04:46.359562 47978602034560 deprecation.py:323] From /home-1/cpaolic1@jhu.edu/.conda/envs/LPEnvironment/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:752: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
W0404 20:04:46.361072 47978602034560 deprecation.py:323] From /home-1/cpaolic1@jhu.edu/.conda/envs/LPEnvironment/lib/python3.7/site-packages/tensorflow_core/python/training/input.py:752: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.
Instructions for updating:
To construct input pipelines, use the `tf.data` module.
W0404 20:04:46.366414 47978602034560 module_wrapper.py:139] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/core/prefetcher.py:51: The name tf.PaddingFIFOQueue is deprecated. Please use tf.queue.PaddingFIFOQueue instead.

W0404 20:04:46.370114 47978602034560 module_wrapper.py:139] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/core/prefetcher.py:58: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

W0404 20:04:46.373436 47978602034560 module_wrapper.py:139] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/legacy/trainer.py:286: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

W0404 20:04:46.374074 47978602034560 module_wrapper.py:139] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/slim/deployment/model_deploy.py:192: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0404 20:04:46.374538 47978602034560 module_wrapper.py:139] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/slim/deployment/model_deploy.py:192: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.

W0404 20:04:47.141456 47978602034560 module_wrapper.py:139] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/core/preprocessor.py:2937: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.

W0404 20:04:47.415328 47978602034560 deprecation.py:323] From /home-1/cpaolic1@jhu.edu/.conda/envs/LPEnvironment/lib/python3.7/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
W0404 20:04:49.162724 47978602034560 module_wrapper.py:139] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.

W0404 20:04:49.174710 47978602034560 module_wrapper.py:139] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

I0404 20:04:49.175219 47978602034560 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0
I0404 20:04:49.206970 47978602034560 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0
I0404 20:04:49.238042 47978602034560 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0
I0404 20:04:49.269477 47978602034560 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0
I0404 20:04:49.300704 47978602034560 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0
I0404 20:04:49.331891 47978602034560 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0
W0404 20:04:49.500072 47978602034560 module_wrapper.py:139] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.

W0404 20:04:53.377352 47978602034560 module_wrapper.py:139] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/core/losses.py:79: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.

W0404 20:04:53.379292 47978602034560 module_wrapper.py:139] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.

W0404 20:04:53.380910 47978602034560 module_wrapper.py:139] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.

W0404 20:04:53.926125 47978602034560 module_wrapper.py:139] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/legacy/trainer.py:209: The name tf.losses.add_loss is deprecated. Please use tf.compat.v1.losses.add_loss instead.

W0404 20:04:53.927420 47978602034560 module_wrapper.py:139] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/builders/optimizer_builder.py:157: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.

W0404 20:04:53.927962 47978602034560 module_wrapper.py:139] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/utils/learning_schedules.py:66: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.

W0404 20:04:53.937073 47978602034560 module_wrapper.py:139] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/builders/optimizer_builder.py:47: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.

W0404 20:04:55.594027 47978602034560 module_wrapper.py:139] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/legacy/trainer.py:323: The name tf.check_numerics is deprecated. Please use tf.debugging.check_numerics instead.

W0404 20:04:55.596074 47978602034560 deprecation.py:506] From /home-1/cpaolic1@jhu.edu/.conda/envs/LPEnvironment/lib/python3.7/site-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0404 20:04:56.725020 47978602034560 deprecation.py:323] From /home-1/cpaolic1@jhu.edu/.conda/envs/LPEnvironment/lib/python3.7/site-packages/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0404 20:04:59.210984 47978602034560 module_wrapper.py:139] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/legacy/trainer.py:354: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

W0404 20:04:59.390482 47978602034560 module_wrapper.py:139] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/legacy/trainer.py:356: The name tf.losses.get_losses is deprecated. Please use tf.compat.v1.losses.get_losses instead.

W0404 20:04:59.393048 47978602034560 module_wrapper.py:139] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/legacy/trainer.py:360: The name tf.losses.get_total_loss is deprecated. Please use tf.compat.v1.losses.get_total_loss instead.

W0404 20:04:59.396392 47978602034560 module_wrapper.py:139] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/legacy/trainer.py:369: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.

W0404 20:04:59.401919 47978602034560 module_wrapper.py:139] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/legacy/trainer.py:372: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

W0404 20:04:59.402583 47978602034560 module_wrapper.py:139] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/legacy/trainer.py:377: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0404 20:04:59.856221 47978602034560 module_wrapper.py:139] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

W0404 20:04:59.858892 47978602034560 module_wrapper.py:139] From /home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.

W0404 20:04:59.861397 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.861878 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/beta/RMSProp] is not available in checkpoint
W0404 20:04:59.862272 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/beta/RMSProp_1] is not available in checkpoint
W0404 20:04:59.862668 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.863059 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/gamma/RMSProp] is not available in checkpoint
W0404 20:04:59.863429 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
W0404 20:04:59.863823 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_0/weights/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.864180 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_0/weights/RMSProp] is not available in checkpoint
W0404 20:04:59.864572 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_0/weights/RMSProp_1] is not available in checkpoint
W0404 20:04:59.864943 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.865300 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint
W0404 20:04:59.865675 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint
W0404 20:04:59.866043 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.866410 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint
W0404 20:04:59.866771 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
W0404 20:04:59.867147 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.867519 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/depthwise_weights/RMSProp] is not available in checkpoint
W0404 20:04:59.867889 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint
W0404 20:04:59.868259 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.868634 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint
W0404 20:04:59.869004 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint
W0404 20:04:59.869364 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.869735 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint
W0404 20:04:59.870090 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
W0404 20:04:59.870460 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.870836 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/weights/RMSProp] is not available in checkpoint
W0404 20:04:59.871184 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/weights/RMSProp_1] is not available in checkpoint
W0404 20:04:59.871555 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.871905 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint
W0404 20:04:59.872261 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint
W0404 20:04:59.872635 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.872992 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint
W0404 20:04:59.873344 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
W0404 20:04:59.873720 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.874076 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/depthwise_weights/RMSProp] is not available in checkpoint
W0404 20:04:59.874428 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint
W0404 20:04:59.874798 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.875162 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint
W0404 20:04:59.875528 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint
W0404 20:04:59.875890 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.876251 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint
W0404 20:04:59.876621 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
W0404 20:04:59.876988 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.877342 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/weights/RMSProp] is not available in checkpoint
W0404 20:04:59.877723 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/weights/RMSProp_1] is not available in checkpoint
W0404 20:04:59.878095 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.878450 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint
W0404 20:04:59.878810 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint
W0404 20:04:59.879182 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.879551 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint
W0404 20:04:59.879908 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
W0404 20:04:59.880278 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.880648 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/depthwise_weights/RMSProp] is not available in checkpoint
W0404 20:04:59.881010 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint
W0404 20:04:59.881371 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.881744 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint
W0404 20:04:59.882103 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint
W0404 20:04:59.882457 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.882820 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint
W0404 20:04:59.883177 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
W0404 20:04:59.883549 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.883899 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/weights/RMSProp] is not available in checkpoint
W0404 20:04:59.884272 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/weights/RMSProp_1] is not available in checkpoint
W0404 20:04:59.884642 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.885022 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint
W0404 20:04:59.885378 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint
W0404 20:04:59.885745 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.886100 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint
W0404 20:04:59.886449 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
W0404 20:04:59.886825 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.887182 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/depthwise_weights/RMSProp] is not available in checkpoint
W0404 20:04:59.887547 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint
W0404 20:04:59.887915 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.888268 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint
W0404 20:04:59.888633 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint
W0404 20:04:59.888983 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.889359 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint
W0404 20:04:59.889721 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
W0404 20:04:59.890091 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.890447 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/weights/RMSProp] is not available in checkpoint
W0404 20:04:59.897312 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/weights/RMSProp_1] is not available in checkpoint
W0404 20:04:59.897693 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.898054 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/beta/RMSProp] is not available in checkpoint
W0404 20:04:59.898410 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/beta/RMSProp_1] is not available in checkpoint
W0404 20:04:59.898816 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.899175 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/gamma/RMSProp] is not available in checkpoint
W0404 20:04:59.899544 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
W0404 20:04:59.899902 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/weights/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.900262 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/weights/RMSProp] is not available in checkpoint
W0404 20:04:59.900626 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/weights/RMSProp_1] is not available in checkpoint
W0404 20:04:59.900988 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.901337 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm/beta/RMSProp] is not available in checkpoint
W0404 20:04:59.901705 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm/beta/RMSProp_1] is not available in checkpoint
W0404 20:04:59.902064 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.902418 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm/gamma/RMSProp] is not available in checkpoint
W0404 20:04:59.902894 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
W0404 20:04:59.903278 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/weights/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.903650 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/weights/RMSProp] is not available in checkpoint
W0404 20:04:59.904000 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/weights/RMSProp_1] is not available in checkpoint
W0404 20:04:59.904372 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.904742 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm/beta/RMSProp] is not available in checkpoint
W0404 20:04:59.905110 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm/beta/RMSProp_1] is not available in checkpoint
W0404 20:04:59.905473 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.905835 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm/gamma/RMSProp] is not available in checkpoint
W0404 20:04:59.906194 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
W0404 20:04:59.906563 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/weights/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.906923 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/weights/RMSProp] is not available in checkpoint
W0404 20:04:59.907286 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/weights/RMSProp_1] is not available in checkpoint
W0404 20:04:59.907661 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.908051 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm/beta/RMSProp] is not available in checkpoint
W0404 20:04:59.908406 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm/beta/RMSProp_1] is not available in checkpoint
W0404 20:04:59.908778 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.909132 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm/gamma/RMSProp] is not available in checkpoint
W0404 20:04:59.909495 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
W0404 20:04:59.909863 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/weights/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.910224 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/weights/RMSProp] is not available in checkpoint
W0404 20:04:59.910584 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/weights/RMSProp_1] is not available in checkpoint
W0404 20:04:59.910950 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.911310 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm/beta/RMSProp] is not available in checkpoint
W0404 20:04:59.911695 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm/beta/RMSProp_1] is not available in checkpoint
W0404 20:04:59.912058 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.912417 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm/gamma/RMSProp] is not available in checkpoint
W0404 20:04:59.912782 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
W0404 20:04:59.913143 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/weights/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.913516 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/weights/RMSProp] is not available in checkpoint
W0404 20:04:59.913878 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/weights/RMSProp_1] is not available in checkpoint
W0404 20:04:59.914251 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.914605 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm/beta/RMSProp] is not available in checkpoint
W0404 20:04:59.914973 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm/beta/RMSProp_1] is not available in checkpoint
W0404 20:04:59.915334 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.915696 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm/gamma/RMSProp] is not available in checkpoint
W0404 20:04:59.916045 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
W0404 20:04:59.916412 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/weights/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.916775 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/weights/RMSProp] is not available in checkpoint
W0404 20:04:59.917130 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/weights/RMSProp_1] is not available in checkpoint
W0404 20:04:59.917488 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.917851 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm/beta/RMSProp] is not available in checkpoint
W0404 20:04:59.918206 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm/beta/RMSProp_1] is not available in checkpoint
W0404 20:04:59.918587 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.918958 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm/gamma/RMSProp] is not available in checkpoint
W0404 20:04:59.919316 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
W0404 20:04:59.919689 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/weights/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.920039 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/weights/RMSProp] is not available in checkpoint
W0404 20:04:59.920395 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/weights/RMSProp_1] is not available in checkpoint
W0404 20:04:59.920764 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.921123 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm/beta/RMSProp] is not available in checkpoint
W0404 20:04:59.921480 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm/beta/RMSProp_1] is not available in checkpoint
W0404 20:04:59.921855 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.922218 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm/gamma/RMSProp] is not available in checkpoint
W0404 20:04:59.922581 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
W0404 20:04:59.922949 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/weights/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.923311 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/weights/RMSProp] is not available in checkpoint
W0404 20:04:59.923678 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/weights/RMSProp_1] is not available in checkpoint
W0404 20:04:59.924033 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.924391 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint
W0404 20:04:59.924752 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint
W0404 20:04:59.925115 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.925467 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint
W0404 20:04:59.925832 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
W0404 20:04:59.926216 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.926570 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/depthwise_weights/RMSProp] is not available in checkpoint
W0404 20:04:59.926923 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint
W0404 20:04:59.927281 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.927650 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint
W0404 20:04:59.928002 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint
W0404 20:04:59.928366 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.928727 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint
W0404 20:04:59.929086 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
W0404 20:04:59.929448 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.929828 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/weights/RMSProp] is not available in checkpoint
W0404 20:04:59.930195 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/weights/RMSProp_1] is not available in checkpoint
W0404 20:04:59.930567 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.930933 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint
W0404 20:04:59.931286 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint
W0404 20:04:59.931655 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.932009 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint
W0404 20:04:59.932368 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
W0404 20:04:59.932746 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.933102 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/depthwise_weights/RMSProp] is not available in checkpoint
W0404 20:04:59.933451 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint
W0404 20:04:59.933822 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.934180 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint
W0404 20:04:59.934551 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint
W0404 20:04:59.934905 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.935266 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint
W0404 20:04:59.935632 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
W0404 20:04:59.935994 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.936345 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/weights/RMSProp] is not available in checkpoint
W0404 20:04:59.936713 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/weights/RMSProp_1] is not available in checkpoint
W0404 20:04:59.937074 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.937431 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint
W0404 20:04:59.937786 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint
W0404 20:04:59.938147 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.938523 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint
W0404 20:04:59.938920 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
W0404 20:04:59.939299 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.939667 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/depthwise_weights/RMSProp] is not available in checkpoint
W0404 20:04:59.940021 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint
W0404 20:04:59.940376 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.940753 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint
W0404 20:04:59.941123 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint
W0404 20:04:59.941488 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.941848 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint
W0404 20:04:59.942212 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
W0404 20:04:59.942588 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.942942 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/weights/RMSProp] is not available in checkpoint
W0404 20:04:59.943303 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/weights/RMSProp_1] is not available in checkpoint
W0404 20:04:59.943670 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.944027 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint
W0404 20:04:59.944374 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint
W0404 20:04:59.944743 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.945102 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint
W0404 20:04:59.945479 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
W0404 20:04:59.945850 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.946210 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/depthwise_weights/RMSProp] is not available in checkpoint
W0404 20:04:59.946580 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint
W0404 20:04:59.946944 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.947305 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint
W0404 20:04:59.947672 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint
W0404 20:04:59.948035 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.948385 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint
W0404 20:04:59.948750 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
W0404 20:04:59.949115 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.949480 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/weights/RMSProp] is not available in checkpoint
W0404 20:04:59.949836 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/weights/RMSProp_1] is not available in checkpoint
W0404 20:04:59.950200 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.950575 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint
W0404 20:04:59.950926 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint
W0404 20:04:59.951284 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.951654 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint
W0404 20:04:59.952017 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
W0404 20:04:59.952392 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.952762 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/depthwise_weights/RMSProp] is not available in checkpoint
W0404 20:04:59.953123 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint
W0404 20:04:59.953485 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.953838 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint
W0404 20:04:59.954198 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint
W0404 20:04:59.954566 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.954922 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint
W0404 20:04:59.955277 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
W0404 20:04:59.955657 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.956017 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/weights/RMSProp] is not available in checkpoint
W0404 20:04:59.956377 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/weights/RMSProp_1] is not available in checkpoint
W0404 20:04:59.956748 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.957107 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint
W0404 20:04:59.957461 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint
W0404 20:04:59.957824 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.958186 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint
W0404 20:04:59.958552 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
W0404 20:04:59.958919 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.959278 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/depthwise_weights/RMSProp] is not available in checkpoint
W0404 20:04:59.959645 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint
W0404 20:04:59.960008 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.960362 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint
W0404 20:04:59.960739 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint
W0404 20:04:59.961103 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.961461 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint
W0404 20:04:59.961821 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
W0404 20:04:59.962185 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.962558 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/weights/RMSProp] is not available in checkpoint
W0404 20:04:59.962911 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/weights/RMSProp_1] is not available in checkpoint
W0404 20:04:59.963276 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.963651 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint
W0404 20:04:59.964008 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint
W0404 20:04:59.964360 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.964728 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint
W0404 20:04:59.965092 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
W0404 20:04:59.965458 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.965825 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/depthwise_weights/RMSProp] is not available in checkpoint
W0404 20:04:59.966183 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint
W0404 20:04:59.966550 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.966905 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint
W0404 20:04:59.967266 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint
W0404 20:04:59.967637 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.967995 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint
W0404 20:04:59.968348 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
W0404 20:04:59.968727 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.969091 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/weights/RMSProp] is not available in checkpoint
W0404 20:04:59.969447 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/weights/RMSProp_1] is not available in checkpoint
W0404 20:04:59.969816 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.970176 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint
W0404 20:04:59.970539 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint
W0404 20:04:59.970892 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.971259 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint
W0404 20:04:59.971625 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
W0404 20:04:59.971998 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.972359 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/depthwise_weights/RMSProp] is not available in checkpoint
W0404 20:04:59.972726 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint
W0404 20:04:59.973087 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.973438 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint
W0404 20:04:59.973803 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint
W0404 20:04:59.974171 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.974543 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint
W0404 20:04:59.974953 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
W0404 20:04:59.975324 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.975705 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/weights/RMSProp] is not available in checkpoint
W0404 20:04:59.976066 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/weights/RMSProp_1] is not available in checkpoint
W0404 20:04:59.976432 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.976798 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint
W0404 20:04:59.977154 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint
W0404 20:04:59.977518 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.977879 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint
W0404 20:04:59.978236 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
W0404 20:04:59.978612 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.978971 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/depthwise_weights/RMSProp] is not available in checkpoint
W0404 20:04:59.979324 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint
W0404 20:04:59.979694 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.980048 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint
W0404 20:04:59.980421 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint
W0404 20:04:59.980786 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.981140 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint
W0404 20:04:59.981495 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint
W0404 20:04:59.981872 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint
W0404 20:04:59.982229 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/weights/RMSProp] is not available in checkpoint
W0404 20:04:59.982594 47978602034560 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/weights/RMSProp_1] is not available in checkpoint
W0404 20:05:00.519735 47978602034560 deprecation.py:323] From /home-1/cpaolic1@jhu.edu/.conda/envs/LPEnvironment/lib/python3.7/site-packages/tensorflow_core/contrib/slim/python/slim/learning.py:742: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
I0404 20:05:07.173621 47978602034560 saver.py:1284] Restoring parameters from ../../FromScratch/ssd_mobilenet_v1_coco_2018_01_28/model.ckpt
I0404 20:05:07.769450 47978602034560 session_manager.py:500] Running local_init_op.
I0404 20:05:08.423196 47978602034560 session_manager.py:502] Done running local_init_op.
I0404 20:05:16.260999 47978602034560 learning.py:754] Starting Session.
I0404 20:05:16.636432 47983666177792 supervisor.py:1117] Saving checkpoint to path ../../trainingOutput/model.ckpt
I0404 20:05:16.639666 47978602034560 learning.py:768] Starting Queues.
I0404 20:05:21.448167 47983664076544 supervisor.py:1099] global_step/sec: 0
I0404 20:05:34.514876 47983661975296 supervisor.py:1050] Recording summary at step 0.
I0404 20:05:36.822764 47978602034560 learning.py:507] global step 1: loss = 127.2383 (19.812 sec/step)
I0404 20:05:37.715223 47978602034560 learning.py:507] global step 2: loss = 112.2768 (0.534 sec/step)
I0404 20:05:38.216542 47978602034560 learning.py:507] global step 3: loss = 100.5301 (0.498 sec/step)
I0404 20:05:38.751767 47978602034560 learning.py:507] global step 4: loss = 89.2180 (0.534 sec/step)
I0404 20:05:39.255968 47978602034560 learning.py:507] global step 5: loss = 81.0019 (0.503 sec/step)
I0404 20:05:39.782193 47978602034560 learning.py:507] global step 6: loss = 75.5071 (0.525 sec/step)
I0404 20:05:40.285660 47978602034560 learning.py:507] global step 7: loss = 69.9436 (0.502 sec/step)
I0404 20:05:40.814895 47978602034560 learning.py:507] global step 8: loss = 62.4443 (0.528 sec/step)
I0404 20:05:41.323745 47978602034560 learning.py:507] global step 9: loss = 57.4108 (0.507 sec/step)
I0404 20:05:41.829421 47978602034560 learning.py:507] global step 10: loss = 51.4611 (0.504 sec/step)
I0404 20:05:42.343008 47978602034560 learning.py:507] global step 11: loss = 46.2839 (0.512 sec/step)
I0404 20:05:42.847716 47978602034560 learning.py:507] global step 12: loss = 41.9246 (0.503 sec/step)
I0404 20:05:43.377949 47978602034560 learning.py:507] global step 13: loss = 37.0476 (0.527 sec/step)
I0404 20:05:43.881996 47978602034560 learning.py:507] global step 14: loss = 32.9292 (0.502 sec/step)
I0404 20:05:44.398348 47978602034560 learning.py:507] global step 15: loss = 30.2045 (0.515 sec/step)
I0404 20:05:44.916360 47978602034560 learning.py:507] global step 16: loss = 27.2963 (0.516 sec/step)
I0404 20:05:45.428019 47978602034560 learning.py:507] global step 17: loss = 25.1982 (0.510 sec/step)
I0404 20:05:45.962754 47978602034560 learning.py:507] global step 18: loss = 22.3189 (0.532 sec/step)
I0404 20:05:46.486482 47978602034560 learning.py:507] global step 19: loss = 19.9167 (0.522 sec/step)
I0404 20:05:47.002825 47978602034560 learning.py:507] global step 20: loss = 19.2811 (0.515 sec/step)
I0404 20:05:47.515697 47978602034560 learning.py:507] global step 21: loss = 17.5797 (0.511 sec/step)
I0404 20:05:48.055976 47978602034560 learning.py:507] global step 22: loss = 16.2438 (0.539 sec/step)
I0404 20:05:48.590774 47978602034560 learning.py:507] global step 23: loss = 15.7411 (0.533 sec/step)
I0404 20:05:49.119929 47978602034560 learning.py:507] global step 24: loss = 15.2120 (0.526 sec/step)
I0404 20:05:49.640975 47978602034560 learning.py:507] global step 25: loss = 14.1380 (0.517 sec/step)
I0404 20:05:50.156563 47978602034560 learning.py:507] global step 26: loss = 14.0148 (0.513 sec/step)
I0404 20:05:50.668607 47978602034560 learning.py:507] global step 27: loss = 13.3884 (0.510 sec/step)
I0404 20:05:51.177925 47978602034560 learning.py:507] global step 28: loss = 12.6685 (0.508 sec/step)
I0404 20:05:51.695891 47978602034560 learning.py:507] global step 29: loss = 12.7803 (0.516 sec/step)
I0404 20:05:52.220914 47978602034560 learning.py:507] global step 30: loss = 11.7452 (0.522 sec/step)
I0404 20:05:52.740288 47978602034560 learning.py:507] global step 31: loss = 11.8477 (0.517 sec/step)
I0404 20:05:53.242926 47978602034560 learning.py:507] global step 32: loss = 13.2193 (0.501 sec/step)
I0404 20:05:53.751702 47978602034560 learning.py:507] global step 33: loss = 11.6580 (0.506 sec/step)
I0404 20:05:54.285824 47978602034560 learning.py:507] global step 34: loss = 10.7276 (0.531 sec/step)
I0404 20:05:54.797350 47978602034560 learning.py:507] global step 35: loss = 10.7237 (0.510 sec/step)
I0404 20:05:55.297305 47978602034560 learning.py:507] global step 36: loss = 11.5492 (0.498 sec/step)
I0404 20:05:55.812593 47978602034560 learning.py:507] global step 37: loss = 11.5092 (0.514 sec/step)
I0404 20:05:56.348080 47978602034560 learning.py:507] global step 38: loss = 11.1442 (0.534 sec/step)
I0404 20:05:56.851657 47978602034560 learning.py:507] global step 39: loss = 10.9582 (0.500 sec/step)
I0404 20:05:57.390072 47978602034560 learning.py:507] global step 40: loss = 11.6058 (0.535 sec/step)
I0404 20:05:57.928171 47978602034560 learning.py:507] global step 41: loss = 10.7554 (0.536 sec/step)
I0404 20:05:58.440744 47978602034560 learning.py:507] global step 42: loss = 10.6390 (0.511 sec/step)
I0404 20:05:58.947901 47978602034560 learning.py:507] global step 43: loss = 10.4715 (0.505 sec/step)
I0404 20:05:59.448765 47978602034560 learning.py:507] global step 44: loss = 11.6034 (0.499 sec/step)
I0404 20:05:59.960712 47978602034560 learning.py:507] global step 45: loss = 10.3874 (0.510 sec/step)
I0404 20:06:00.470895 47978602034560 learning.py:507] global step 46: loss = 9.8398 (0.509 sec/step)
I0404 20:06:00.978432 47978602034560 learning.py:507] global step 47: loss = 11.5671 (0.506 sec/step)
I0404 20:06:01.484690 47978602034560 learning.py:507] global step 48: loss = 9.9602 (0.504 sec/step)
I0404 20:06:01.992765 47978602034560 learning.py:507] global step 49: loss = 10.3786 (0.505 sec/step)
I0404 20:06:02.518301 47978602034560 learning.py:507] global step 50: loss = 11.0709 (0.522 sec/step)
I0404 20:06:03.022672 47978602034560 learning.py:507] global step 51: loss = 10.9252 (0.502 sec/step)
I0404 20:06:03.545335 47978602034560 learning.py:507] global step 52: loss = 10.4765 (0.521 sec/step)
I0404 20:06:04.067084 47978602034560 learning.py:507] global step 53: loss = 10.1114 (0.520 sec/step)
I0404 20:06:04.572098 47978602034560 learning.py:507] global step 54: loss = 11.5515 (0.504 sec/step)
I0404 20:06:05.098300 47978602034560 learning.py:507] global step 55: loss = 11.4286 (0.525 sec/step)
I0404 20:06:05.609844 47978602034560 learning.py:507] global step 56: loss = 11.1880 (0.508 sec/step)
I0404 20:06:06.127795 47978602034560 learning.py:507] global step 57: loss = 11.1475 (0.515 sec/step)
I0404 20:06:06.639204 47978602034560 learning.py:507] global step 58: loss = 10.6969 (0.509 sec/step)
I0404 20:06:07.174188 47978602034560 learning.py:507] global step 59: loss = 10.1200 (0.533 sec/step)
I0404 20:06:07.684898 47978602034560 learning.py:507] global step 60: loss = 10.8762 (0.509 sec/step)
I0404 20:06:08.215371 47978602034560 learning.py:507] global step 61: loss = 10.3093 (0.529 sec/step)
I0404 20:06:08.724478 47978602034560 learning.py:507] global step 62: loss = 11.2659 (0.508 sec/step)
I0404 20:06:09.231516 47978602034560 learning.py:507] global step 63: loss = 10.2615 (0.506 sec/step)
I0404 20:06:09.740331 47978602034560 learning.py:507] global step 64: loss = 10.9616 (0.507 sec/step)
I0404 20:06:10.253407 47978602034560 learning.py:507] global step 65: loss = 10.8269 (0.511 sec/step)
I0404 20:06:10.755984 47978602034560 learning.py:507] global step 66: loss = 10.1544 (0.500 sec/step)
I0404 20:06:11.259950 47978602034560 learning.py:507] global step 67: loss = 10.0458 (0.502 sec/step)
I0404 20:06:11.760065 47978602034560 learning.py:507] global step 68: loss = 10.2946 (0.498 sec/step)
I0404 20:06:12.304452 47978602034560 learning.py:507] global step 69: loss = 10.8337 (0.543 sec/step)
I0404 20:06:12.812244 47978602034560 learning.py:507] global step 70: loss = 10.1878 (0.506 sec/step)
I0404 20:06:13.343355 47978602034560 learning.py:507] global step 71: loss = 10.4353 (0.530 sec/step)
I0404 20:06:13.864185 47978602034560 learning.py:507] global step 72: loss = 10.0900 (0.519 sec/step)
I0404 20:06:14.386382 47978602034560 learning.py:507] global step 73: loss = 10.1054 (0.520 sec/step)
I0404 20:06:14.904170 47978602034560 learning.py:507] global step 74: loss = 10.2275 (0.516 sec/step)
I0404 20:06:15.420701 47978602034560 learning.py:507] global step 75: loss = 11.4148 (0.515 sec/step)
I0404 20:06:15.929518 47978602034560 learning.py:507] global step 76: loss = 9.9647 (0.507 sec/step)
I0404 20:06:16.463366 47978602034560 learning.py:507] global step 77: loss = 10.7464 (0.532 sec/step)
I0404 20:06:16.969878 47978602034560 learning.py:507] global step 78: loss = 10.5726 (0.504 sec/step)
I0404 20:06:17.489211 47978602034560 learning.py:507] global step 79: loss = 10.0261 (0.518 sec/step)
I0404 20:06:18.026654 47978602034560 learning.py:507] global step 80: loss = 10.4409 (0.536 sec/step)
I0404 20:06:18.558252 47978602034560 learning.py:507] global step 81: loss = 10.2777 (0.530 sec/step)
I0404 20:06:19.058910 47978602034560 learning.py:507] global step 82: loss = 10.8836 (0.498 sec/step)
I0404 20:06:19.570180 47978602034560 learning.py:507] global step 83: loss = 11.1958 (0.510 sec/step)
I0404 20:06:20.101200 47978602034560 learning.py:507] global step 84: loss = 9.7911 (0.528 sec/step)
I0404 20:06:20.622878 47978602034560 learning.py:507] global step 85: loss = 10.1621 (0.518 sec/step)
I0404 20:06:21.145616 47978602034560 learning.py:507] global step 86: loss = 10.6089 (0.521 sec/step)
I0404 20:06:21.654982 47978602034560 learning.py:507] global step 87: loss = 10.4171 (0.508 sec/step)
I0404 20:06:22.160739 47978602034560 learning.py:507] global step 88: loss = 9.3433 (0.503 sec/step)
I0404 20:06:22.668838 47978602034560 learning.py:507] global step 89: loss = 9.4217 (0.506 sec/step)
I0404 20:06:23.197772 47978602034560 learning.py:507] global step 90: loss = 9.6143 (0.526 sec/step)
I0404 20:06:23.714124 47978602034560 learning.py:507] global step 91: loss = 10.1198 (0.515 sec/step)
I0404 20:06:24.227975 47978602034560 learning.py:507] global step 92: loss = 10.5838 (0.511 sec/step)
I0404 20:06:24.736589 47978602034560 learning.py:507] global step 93: loss = 9.8716 (0.507 sec/step)
I0404 20:06:25.256403 47978602034560 learning.py:507] global step 94: loss = 10.4258 (0.518 sec/step)
I0404 20:06:25.773745 47978602034560 learning.py:507] global step 95: loss = 10.5008 (0.514 sec/step)
I0404 20:06:26.318877 47978602034560 learning.py:507] global step 96: loss = 9.7692 (0.544 sec/step)
I0404 20:06:26.845245 47978602034560 learning.py:507] global step 97: loss = 9.9453 (0.525 sec/step)
I0404 20:06:27.348895 47978602034560 learning.py:507] global step 98: loss = 10.1331 (0.502 sec/step)
I0404 20:06:27.861665 47978602034560 learning.py:507] global step 99: loss = 10.4090 (0.511 sec/step)
I0404 20:06:28.375382 47978602034560 learning.py:507] global step 100: loss = 10.1557 (0.512 sec/step)
I0404 20:06:28.893851 47978602034560 learning.py:507] global step 101: loss = 10.0427 (0.516 sec/step)
I0404 20:06:29.402924 47978602034560 learning.py:507] global step 102: loss = 10.2319 (0.508 sec/step)
I0404 20:06:29.942081 47978602034560 learning.py:507] global step 103: loss = 10.0999 (0.538 sec/step)
I0404 20:06:30.473226 47978602034560 learning.py:507] global step 104: loss = 9.3921 (0.530 sec/step)
I0404 20:06:30.977821 47978602034560 learning.py:507] global step 105: loss = 9.3475 (0.503 sec/step)
I0404 20:06:31.511230 47978602034560 learning.py:507] global step 106: loss = 10.3311 (0.532 sec/step)
I0404 20:06:32.047479 47978602034560 learning.py:507] global step 107: loss = 9.6692 (0.533 sec/step)
I0404 20:06:32.549592 47978602034560 learning.py:507] global step 108: loss = 9.8530 (0.501 sec/step)
I0404 20:06:33.060724 47978602034560 learning.py:507] global step 109: loss = 10.1955 (0.509 sec/step)
I0404 20:06:33.584486 47978602034560 learning.py:507] global step 110: loss = 9.8349 (0.522 sec/step)
I0404 20:06:34.109358 47978602034560 learning.py:507] global step 111: loss = 10.4118 (0.523 sec/step)
I0404 20:06:34.629708 47978602034560 learning.py:507] global step 112: loss = 9.7363 (0.518 sec/step)
I0404 20:06:35.135048 47978602034560 learning.py:507] global step 113: loss = 9.8523 (0.504 sec/step)
I0404 20:06:35.658977 47978602034560 learning.py:507] global step 114: loss = 9.6204 (0.522 sec/step)
I0404 20:06:36.176627 47978602034560 learning.py:507] global step 115: loss = 9.6155 (0.515 sec/step)
I0404 20:06:36.688210 47978602034560 learning.py:507] global step 116: loss = 9.7378 (0.509 sec/step)
I0404 20:06:37.217322 47978602034560 learning.py:507] global step 117: loss = 10.2854 (0.526 sec/step)
I0404 20:06:37.736103 47978602034560 learning.py:507] global step 118: loss = 9.8267 (0.517 sec/step)
I0404 20:06:38.247175 47978602034560 learning.py:507] global step 119: loss = 9.7678 (0.510 sec/step)
I0404 20:06:38.755808 47978602034560 learning.py:507] global step 120: loss = 9.6924 (0.507 sec/step)
I0404 20:06:39.276073 47978602034560 learning.py:507] global step 121: loss = 9.7420 (0.519 sec/step)
I0404 20:06:39.775269 47978602034560 learning.py:507] global step 122: loss = 9.8860 (0.496 sec/step)
I0404 20:06:40.300336 47978602034560 learning.py:507] global step 123: loss = 9.3855 (0.523 sec/step)
I0404 20:06:40.817748 47978602034560 learning.py:507] global step 124: loss = 10.5824 (0.516 sec/step)
I0404 20:06:41.347390 47978602034560 learning.py:507] global step 125: loss = 9.5002 (0.528 sec/step)
I0404 20:06:41.878521 47978602034560 learning.py:507] global step 126: loss = 9.7930 (0.528 sec/step)
I0404 20:06:42.385603 47978602034560 learning.py:507] global step 127: loss = 9.6096 (0.504 sec/step)
I0404 20:06:42.930348 47978602034560 learning.py:507] global step 128: loss = 10.7478 (0.542 sec/step)
I0404 20:06:43.447393 47978602034560 learning.py:507] global step 129: loss = 11.4828 (0.516 sec/step)
I0404 20:06:43.953790 47978602034560 learning.py:507] global step 130: loss = 10.3002 (0.505 sec/step)
I0404 20:06:44.458220 47978602034560 learning.py:507] global step 131: loss = 10.5781 (0.503 sec/step)
I0404 20:06:44.978391 47978602034560 learning.py:507] global step 132: loss = 9.9607 (0.519 sec/step)
I0404 20:06:45.476884 47978602034560 learning.py:507] global step 133: loss = 10.1629 (0.497 sec/step)
I0404 20:06:45.984520 47978602034560 learning.py:507] global step 134: loss = 9.7652 (0.505 sec/step)
I0404 20:06:46.492963 47978602034560 learning.py:507] global step 135: loss = 9.8450 (0.507 sec/step)
I0404 20:06:47.015396 47978602034560 learning.py:507] global step 136: loss = 9.4571 (0.521 sec/step)
I0404 20:06:47.527257 47978602034560 learning.py:507] global step 137: loss = 9.9960 (0.510 sec/step)
I0404 20:06:48.062723 47978602034560 learning.py:507] global step 138: loss = 10.4701 (0.534 sec/step)
I0404 20:06:48.573037 47978602034560 learning.py:507] global step 139: loss = 10.1734 (0.509 sec/step)
I0404 20:06:49.095618 47978602034560 learning.py:507] global step 140: loss = 9.2487 (0.521 sec/step)
I0404 20:06:49.606874 47978602034560 learning.py:507] global step 141: loss = 11.3326 (0.510 sec/step)
I0404 20:06:50.124924 47978602034560 learning.py:507] global step 142: loss = 9.6790 (0.516 sec/step)
I0404 20:06:50.652804 47978602034560 learning.py:507] global step 143: loss = 9.9744 (0.526 sec/step)
I0404 20:06:51.155569 47978602034560 learning.py:507] global step 144: loss = 9.8901 (0.500 sec/step)
I0404 20:06:51.658450 47978602034560 learning.py:507] global step 145: loss = 9.5694 (0.501 sec/step)
I0404 20:06:52.169965 47978602034560 learning.py:507] global step 146: loss = 9.7835 (0.510 sec/step)
I0404 20:06:52.682580 47978602034560 learning.py:507] global step 147: loss = 9.5080 (0.510 sec/step)
I0404 20:06:53.196990 47978602034560 learning.py:507] global step 148: loss = 9.7496 (0.513 sec/step)
I0404 20:06:53.733724 47978602034560 learning.py:507] global step 149: loss = 9.8684 (0.535 sec/step)
I0404 20:06:54.241338 47978602034560 learning.py:507] global step 150: loss = 9.9274 (0.506 sec/step)
I0404 20:06:54.755049 47978602034560 learning.py:507] global step 151: loss = 10.0033 (0.511 sec/step)
I0404 20:06:55.280817 47978602034560 learning.py:507] global step 152: loss = 9.8101 (0.524 sec/step)
I0404 20:06:55.821767 47978602034560 learning.py:507] global step 153: loss = 10.2323 (0.538 sec/step)
I0404 20:06:56.325239 47978602034560 learning.py:507] global step 154: loss = 10.1972 (0.502 sec/step)
I0404 20:06:56.856426 47978602034560 learning.py:507] global step 155: loss = 10.0940 (0.528 sec/step)
I0404 20:06:57.359001 47978602034560 learning.py:507] global step 156: loss = 10.1852 (0.500 sec/step)
I0404 20:06:57.870417 47978602034560 learning.py:507] global step 157: loss = 10.9871 (0.508 sec/step)
I0404 20:06:58.406170 47978602034560 learning.py:507] global step 158: loss = 9.2109 (0.533 sec/step)
I0404 20:06:58.929479 47978602034560 learning.py:507] global step 159: loss = 9.6950 (0.522 sec/step)
I0404 20:06:59.447392 47978602034560 learning.py:507] global step 160: loss = 9.1376 (0.515 sec/step)
I0404 20:06:59.952100 47978602034560 learning.py:507] global step 161: loss = 10.5045 (0.502 sec/step)
I0404 20:07:00.458207 47978602034560 learning.py:507] global step 162: loss = 10.1674 (0.503 sec/step)
I0404 20:07:00.966199 47978602034560 learning.py:507] global step 163: loss = 9.9662 (0.506 sec/step)
I0404 20:07:01.471925 47978602034560 learning.py:507] global step 164: loss = 10.1865 (0.504 sec/step)
I0404 20:07:01.987103 47978602034560 learning.py:507] global step 165: loss = 9.9564 (0.514 sec/step)
I0404 20:07:02.495736 47978602034560 learning.py:507] global step 166: loss = 9.8389 (0.507 sec/step)
I0404 20:07:03.009059 47978602034560 learning.py:507] global step 167: loss = 11.2156 (0.512 sec/step)
I0404 20:07:03.521725 47978602034560 learning.py:507] global step 168: loss = 9.9297 (0.511 sec/step)
I0404 20:07:04.026114 47978602034560 learning.py:507] global step 169: loss = 10.2007 (0.503 sec/step)
I0404 20:07:04.556526 47978602034560 learning.py:507] global step 170: loss = 9.6751 (0.528 sec/step)
I0404 20:07:05.058853 47978602034560 learning.py:507] global step 171: loss = 9.2909 (0.501 sec/step)
I0404 20:07:05.566316 47978602034560 learning.py:507] global step 172: loss = 9.3530 (0.505 sec/step)
I0404 20:07:06.086253 47978602034560 learning.py:507] global step 173: loss = 9.4821 (0.518 sec/step)
I0404 20:07:06.592190 47978602034560 learning.py:507] global step 174: loss = 9.6676 (0.504 sec/step)
I0404 20:07:07.098833 47978602034560 learning.py:507] global step 175: loss = 9.8576 (0.504 sec/step)
I0404 20:07:07.602503 47978602034560 learning.py:507] global step 176: loss = 10.1999 (0.502 sec/step)
I0404 20:07:08.103788 47978602034560 learning.py:507] global step 177: loss = 9.6333 (0.500 sec/step)
I0404 20:07:08.620484 47978602034560 learning.py:507] global step 178: loss = 9.3963 (0.515 sec/step)
I0404 20:07:09.142971 47978602034560 learning.py:507] global step 179: loss = 10.1260 (0.521 sec/step)
I0404 20:07:09.668869 47978602034560 learning.py:507] global step 180: loss = 9.7240 (0.524 sec/step)
I0404 20:07:10.189460 47978602034560 learning.py:507] global step 181: loss = 9.0355 (0.518 sec/step)
I0404 20:07:10.692980 47978602034560 learning.py:507] global step 182: loss = 11.0719 (0.501 sec/step)
I0404 20:07:11.199951 47978602034560 learning.py:507] global step 183: loss = 9.6024 (0.504 sec/step)
I0404 20:07:11.712514 47978602034560 learning.py:507] global step 184: loss = 9.6997 (0.511 sec/step)
I0404 20:07:12.213530 47978602034560 learning.py:507] global step 185: loss = 9.2898 (0.498 sec/step)
I0404 20:07:12.727002 47978602034560 learning.py:507] global step 186: loss = 9.9061 (0.512 sec/step)
I0404 20:07:13.247117 47978602034560 learning.py:507] global step 187: loss = 11.2279 (0.519 sec/step)
I0404 20:07:13.773981 47978602034560 learning.py:507] global step 188: loss = 9.8577 (0.524 sec/step)
I0404 20:07:14.281000 47978602034560 learning.py:507] global step 189: loss = 9.0862 (0.505 sec/step)
I0404 20:07:14.780593 47978602034560 learning.py:507] global step 190: loss = 9.5892 (0.498 sec/step)
I0404 20:07:15.285803 47978602034560 learning.py:507] global step 191: loss = 9.0272 (0.502 sec/step)
I0404 20:07:15.792942 47978602034560 learning.py:507] global step 192: loss = 9.1126 (0.506 sec/step)
I0404 20:07:16.306896 47978602034560 learning.py:507] global step 193: loss = 8.8159 (0.512 sec/step)
I0404 20:07:16.637219 47983664076544 supervisor.py:1099] global_step/sec: 1.6755
I0404 20:07:16.828260 47978602034560 learning.py:507] global step 194: loss = 9.1424 (0.517 sec/step)
I0404 20:07:17.191871 47983661975296 supervisor.py:1050] Recording summary at step 194.
I0404 20:07:17.514541 47978602034560 learning.py:507] global step 195: loss = 9.5736 (0.682 sec/step)
I0404 20:07:18.034369 47978602034560 learning.py:507] global step 196: loss = 9.0543 (0.518 sec/step)
I0404 20:07:18.535276 47978602034560 learning.py:507] global step 197: loss = 8.6418 (0.499 sec/step)
I0404 20:07:19.055538 47978602034560 learning.py:507] global step 198: loss = 9.7788 (0.519 sec/step)
I0404 20:07:19.564373 47978602034560 learning.py:507] global step 199: loss = 9.7943 (0.507 sec/step)
I0404 20:07:20.085368 47978602034560 learning.py:507] global step 200: loss = 9.8804 (0.519 sec/step)
I0404 20:07:20.596715 47978602034560 learning.py:507] global step 201: loss = 9.2224 (0.509 sec/step)
I0404 20:07:21.135025 47978602034560 learning.py:507] global step 202: loss = 9.5172 (0.536 sec/step)
I0404 20:07:21.644840 47978602034560 learning.py:507] global step 203: loss = 9.9669 (0.507 sec/step)
I0404 20:07:22.150495 47978602034560 learning.py:507] global step 204: loss = 8.7704 (0.504 sec/step)
I0404 20:07:22.662965 47978602034560 learning.py:507] global step 205: loss = 9.1208 (0.511 sec/step)
I0404 20:07:23.196957 47978602034560 learning.py:507] global step 206: loss = 9.6620 (0.532 sec/step)
I0404 20:07:23.716083 47978602034560 learning.py:507] global step 207: loss = 8.8515 (0.518 sec/step)
I0404 20:07:24.235087 47978602034560 learning.py:507] global step 208: loss = 8.9491 (0.517 sec/step)
I0404 20:07:24.747664 47978602034560 learning.py:507] global step 209: loss = 8.9676 (0.511 sec/step)
I0404 20:07:25.258004 47978602034560 learning.py:507] global step 210: loss = 9.1299 (0.509 sec/step)
I0404 20:07:25.768453 47978602034560 learning.py:507] global step 211: loss = 10.2051 (0.509 sec/step)
I0404 20:07:26.284806 47978602034560 learning.py:507] global step 212: loss = 9.3834 (0.515 sec/step)
I0404 20:07:26.788873 47978602034560 learning.py:507] global step 213: loss = 9.5345 (0.502 sec/step)
I0404 20:07:27.328447 47978602034560 learning.py:507] global step 214: loss = 9.2747 (0.538 sec/step)
I0404 20:07:27.842692 47978602034560 learning.py:507] global step 215: loss = 9.0064 (0.511 sec/step)
I0404 20:07:28.370663 47978602034560 learning.py:507] global step 216: loss = 9.6828 (0.526 sec/step)
I0404 20:07:28.893195 47978602034560 learning.py:507] global step 217: loss = 10.0848 (0.521 sec/step)
I0404 20:07:29.398672 47978602034560 learning.py:507] global step 218: loss = 9.5396 (0.504 sec/step)
I0404 20:07:29.901293 47978602034560 learning.py:507] global step 219: loss = 9.1314 (0.501 sec/step)
I0404 20:07:30.405523 47978602034560 learning.py:507] global step 220: loss = 8.6916 (0.503 sec/step)
I0404 20:07:30.946126 47978602034560 learning.py:507] global step 221: loss = 9.1932 (0.538 sec/step)
I0404 20:07:31.452773 47978602034560 learning.py:507] global step 222: loss = 9.2342 (0.504 sec/step)
I0404 20:07:31.987024 47978602034560 learning.py:507] global step 223: loss = 9.7225 (0.533 sec/step)
I0404 20:07:32.492206 47978602034560 learning.py:507] global step 224: loss = 9.4001 (0.504 sec/step)
I0404 20:07:33.011179 47978602034560 learning.py:507] global step 225: loss = 9.3400 (0.517 sec/step)
I0404 20:07:33.520192 47978602034560 learning.py:507] global step 226: loss = 9.3506 (0.508 sec/step)
I0404 20:07:34.023422 47978602034560 learning.py:507] global step 227: loss = 9.6316 (0.502 sec/step)
I0404 20:07:34.529363 47978602034560 learning.py:507] global step 228: loss = 10.0789 (0.503 sec/step)
I0404 20:07:35.068334 47978602034560 learning.py:507] global step 229: loss = 9.5965 (0.537 sec/step)
I0404 20:07:35.585393 47978602034560 learning.py:507] global step 230: loss = 9.6733 (0.516 sec/step)
I0404 20:07:36.122988 47978602034560 learning.py:507] global step 231: loss = 9.6934 (0.536 sec/step)
I0404 20:07:36.632245 47978602034560 learning.py:507] global step 232: loss = 9.0841 (0.508 sec/step)
I0404 20:07:37.155267 47978602034560 learning.py:507] global step 233: loss = 9.4166 (0.522 sec/step)
I0404 20:07:37.672084 47978602034560 learning.py:507] global step 234: loss = 8.6122 (0.515 sec/step)
I0404 20:07:38.194164 47978602034560 learning.py:507] global step 235: loss = 9.0797 (0.520 sec/step)
I0404 20:07:38.712834 47978602034560 learning.py:507] global step 236: loss = 10.1469 (0.517 sec/step)
I0404 20:07:39.233271 47978602034560 learning.py:507] global step 237: loss = 8.4324 (0.519 sec/step)
I0404 20:07:39.741566 47978602034560 learning.py:507] global step 238: loss = 8.6893 (0.507 sec/step)
I0404 20:07:40.249300 47978602034560 learning.py:507] global step 239: loss = 8.5345 (0.506 sec/step)
I0404 20:07:40.755475 47978602034560 learning.py:507] global step 240: loss = 10.5456 (0.503 sec/step)
I0404 20:07:41.257410 47978602034560 learning.py:507] global step 241: loss = 10.1316 (0.500 sec/step)
I0404 20:07:41.771822 47978602034560 learning.py:507] global step 242: loss = 9.4909 (0.513 sec/step)
I0404 20:07:42.279110 47978602034560 learning.py:507] global step 243: loss = 9.0977 (0.506 sec/step)
I0404 20:07:42.793542 47978602034560 learning.py:507] global step 244: loss = 8.8378 (0.513 sec/step)
I0404 20:07:43.302692 47978602034560 learning.py:507] global step 245: loss = 8.8078 (0.508 sec/step)
I0404 20:07:43.809686 47978602034560 learning.py:507] global step 246: loss = 9.2666 (0.504 sec/step)
I0404 20:07:44.323758 47978602034560 learning.py:507] global step 247: loss = 9.0980 (0.512 sec/step)
I0404 20:07:44.862629 47978602034560 learning.py:507] global step 248: loss = 9.1519 (0.537 sec/step)
I0404 20:07:45.372606 47978602034560 learning.py:507] global step 249: loss = 8.7084 (0.508 sec/step)
I0404 20:07:45.880862 47978602034560 learning.py:507] global step 250: loss = 9.1737 (0.505 sec/step)
I0404 20:07:46.383784 47978602034560 learning.py:507] global step 251: loss = 9.4564 (0.501 sec/step)
I0404 20:07:46.894226 47978602034560 learning.py:507] global step 252: loss = 8.7779 (0.508 sec/step)
I0404 20:07:47.395317 47978602034560 learning.py:507] global step 253: loss = 8.7472 (0.499 sec/step)
I0404 20:07:47.925547 47978602034560 learning.py:507] global step 254: loss = 9.3430 (0.527 sec/step)
I0404 20:07:48.437820 47978602034560 learning.py:507] global step 255: loss = 8.6816 (0.511 sec/step)
I0404 20:07:48.941272 47978602034560 learning.py:507] global step 256: loss = 8.6824 (0.502 sec/step)
I0404 20:07:49.456640 47978602034560 learning.py:507] global step 257: loss = 9.9429 (0.514 sec/step)
I0404 20:07:49.963804 47978602034560 learning.py:507] global step 258: loss = 8.9225 (0.506 sec/step)
I0404 20:07:50.493292 47978602034560 learning.py:507] global step 259: loss = 8.8092 (0.528 sec/step)
I0404 20:07:51.007821 47978602034560 learning.py:507] global step 260: loss = 8.5999 (0.513 sec/step)
I0404 20:07:51.518969 47978602034560 learning.py:507] global step 261: loss = 8.8727 (0.509 sec/step)
I0404 20:07:52.025907 47978602034560 learning.py:507] global step 262: loss = 9.6804 (0.505 sec/step)
I0404 20:07:52.538503 47978602034560 learning.py:507] global step 263: loss = 9.4194 (0.511 sec/step)
I0404 20:07:53.057315 47978602034560 learning.py:507] global step 264: loss = 9.4129 (0.517 sec/step)
I0404 20:07:53.563668 47978602034560 learning.py:507] global step 265: loss = 10.2484 (0.505 sec/step)
I0404 20:07:54.082686 47978602034560 learning.py:507] global step 266: loss = 9.2896 (0.517 sec/step)
I0404 20:07:54.597260 47978602034560 learning.py:507] global step 267: loss = 9.3841 (0.513 sec/step)
I0404 20:07:55.107191 47978602034560 learning.py:507] global step 268: loss = 9.1238 (0.508 sec/step)
I0404 20:07:55.650831 47978602034560 learning.py:507] global step 269: loss = 9.6955 (0.542 sec/step)
I0404 20:07:56.153358 47978602034560 learning.py:507] global step 270: loss = 8.6701 (0.501 sec/step)
I0404 20:07:56.684462 47978602034560 learning.py:507] global step 271: loss = 9.3901 (0.528 sec/step)
I0404 20:07:57.198192 47978602034560 learning.py:507] global step 272: loss = 9.6485 (0.512 sec/step)
I0404 20:07:57.708786 47978602034560 learning.py:507] global step 273: loss = 9.8910 (0.509 sec/step)
I0404 20:07:58.216182 47978602034560 learning.py:507] global step 274: loss = 9.1216 (0.506 sec/step)
I0404 20:07:58.721559 47978602034560 learning.py:507] global step 275: loss = 9.2390 (0.504 sec/step)
I0404 20:07:59.251290 47978602034560 learning.py:507] global step 276: loss = 9.3266 (0.528 sec/step)
I0404 20:07:59.762090 47978602034560 learning.py:507] global step 277: loss = 9.4042 (0.508 sec/step)
I0404 20:08:00.277465 47978602034560 learning.py:507] global step 278: loss = 8.9317 (0.513 sec/step)
I0404 20:08:00.786002 47978602034560 learning.py:507] global step 279: loss = 9.2567 (0.506 sec/step)
I0404 20:08:01.290581 47978602034560 learning.py:507] global step 280: loss = 8.6571 (0.503 sec/step)
I0404 20:08:01.792110 47978602034560 learning.py:507] global step 281: loss = 8.5178 (0.499 sec/step)
I0404 20:08:02.302204 47978602034560 learning.py:507] global step 282: loss = 9.2685 (0.507 sec/step)
I0404 20:08:02.804607 47978602034560 learning.py:507] global step 283: loss = 10.2689 (0.501 sec/step)
I0404 20:08:03.327633 47978602034560 learning.py:507] global step 284: loss = 9.2645 (0.521 sec/step)
I0404 20:08:03.838127 47978602034560 learning.py:507] global step 285: loss = 8.1335 (0.509 sec/step)
I0404 20:08:04.349487 47978602034560 learning.py:507] global step 286: loss = 8.4836 (0.510 sec/step)
I0404 20:08:04.857093 47978602034560 learning.py:507] global step 287: loss = 9.4196 (0.505 sec/step)
I0404 20:08:05.375877 47978602034560 learning.py:507] global step 288: loss = 9.6281 (0.516 sec/step)
I0404 20:08:05.883826 47978602034560 learning.py:507] global step 289: loss = 9.0563 (0.506 sec/step)
I0404 20:08:06.395545 47978602034560 learning.py:507] global step 290: loss = 9.3436 (0.510 sec/step)
I0404 20:08:06.926529 47978602034560 learning.py:507] global step 291: loss = 8.5753 (0.529 sec/step)
I0404 20:08:07.434973 47978602034560 learning.py:507] global step 292: loss = 9.7007 (0.506 sec/step)
I0404 20:08:07.948991 47978602034560 learning.py:507] global step 293: loss = 10.0178 (0.511 sec/step)
I0404 20:08:08.486985 47978602034560 learning.py:507] global step 294: loss = 8.9137 (0.535 sec/step)
I0404 20:08:08.986924 47978602034560 learning.py:507] global step 295: loss = 8.9152 (0.498 sec/step)
I0404 20:08:09.487422 47978602034560 learning.py:507] global step 296: loss = 9.0993 (0.499 sec/step)
I0404 20:08:09.998051 47978602034560 learning.py:507] global step 297: loss = 9.3128 (0.508 sec/step)
I0404 20:08:10.511024 47978602034560 learning.py:507] global step 298: loss = 9.5405 (0.510 sec/step)
I0404 20:08:11.050605 47978602034560 learning.py:507] global step 299: loss = 8.4752 (0.538 sec/step)
I0404 20:08:11.565671 47978602034560 learning.py:507] global step 300: loss = 9.0231 (0.514 sec/step)
I0404 20:08:12.070121 47978602034560 learning.py:507] global step 301: loss = 9.2873 (0.503 sec/step)
I0404 20:08:12.604564 47978602034560 learning.py:507] global step 302: loss = 9.1344 (0.532 sec/step)
I0404 20:08:13.107374 47978602034560 learning.py:507] global step 303: loss = 9.4001 (0.500 sec/step)
I0404 20:08:13.613602 47978602034560 learning.py:507] global step 304: loss = 9.1440 (0.505 sec/step)
I0404 20:08:14.118201 47978602034560 learning.py:507] global step 305: loss = 9.1246 (0.503 sec/step)
I0404 20:08:14.650164 47978602034560 learning.py:507] global step 306: loss = 8.6849 (0.530 sec/step)
I0404 20:08:15.166417 47978602034560 learning.py:507] global step 307: loss = 8.7083 (0.515 sec/step)
I0404 20:08:15.704355 47978602034560 learning.py:507] global step 308: loss = 8.1324 (0.536 sec/step)
I0404 20:08:16.208970 47978602034560 learning.py:507] global step 309: loss = 9.6408 (0.502 sec/step)
I0404 20:08:16.713189 47978602034560 learning.py:507] global step 310: loss = 9.0194 (0.501 sec/step)
I0404 20:08:17.233453 47978602034560 learning.py:507] global step 311: loss = 8.4276 (0.519 sec/step)
I0404 20:08:17.739961 47978602034560 learning.py:507] global step 312: loss = 9.2817 (0.504 sec/step)
I0404 20:08:18.260425 47978602034560 learning.py:507] global step 313: loss = 8.8464 (0.519 sec/step)
I0404 20:08:18.770151 47978602034560 learning.py:507] global step 314: loss = 8.5205 (0.508 sec/step)
I0404 20:08:19.283136 47978602034560 learning.py:507] global step 315: loss = 8.9868 (0.511 sec/step)
I0404 20:08:19.815743 47978602034560 learning.py:507] global step 316: loss = 9.2735 (0.530 sec/step)
I0404 20:08:20.323832 47978602034560 learning.py:507] global step 317: loss = 9.2159 (0.506 sec/step)
I0404 20:08:20.830499 47978602034560 learning.py:507] global step 318: loss = 8.9763 (0.504 sec/step)
I0404 20:08:21.343681 47978602034560 learning.py:507] global step 319: loss = 8.5611 (0.512 sec/step)
I0404 20:08:21.851957 47978602034560 learning.py:507] global step 320: loss = 8.5893 (0.507 sec/step)
I0404 20:08:22.364310 47978602034560 learning.py:507] global step 321: loss = 8.5790 (0.510 sec/step)
I0404 20:08:22.873980 47978602034560 learning.py:507] global step 322: loss = 8.8353 (0.507 sec/step)
I0404 20:08:23.390921 47978602034560 learning.py:507] global step 323: loss = 8.5972 (0.515 sec/step)
I0404 20:08:23.902204 47978602034560 learning.py:507] global step 324: loss = 8.7119 (0.508 sec/step)
I0404 20:08:24.408976 47978602034560 learning.py:507] global step 325: loss = 8.9098 (0.504 sec/step)
I0404 20:08:24.953642 47978602034560 learning.py:507] global step 326: loss = 8.6653 (0.543 sec/step)
I0404 20:08:25.454344 47978602034560 learning.py:507] global step 327: loss = 8.9521 (0.499 sec/step)
I0404 20:08:25.967026 47978602034560 learning.py:507] global step 328: loss = 9.3728 (0.511 sec/step)
I0404 20:08:26.480420 47978602034560 learning.py:507] global step 329: loss = 8.9829 (0.511 sec/step)
I0404 20:08:26.988430 47978602034560 learning.py:507] global step 330: loss = 9.1904 (0.505 sec/step)
I0404 20:08:27.493699 47978602034560 learning.py:507] global step 331: loss = 9.0198 (0.504 sec/step)
I0404 20:08:28.009786 47978602034560 learning.py:507] global step 332: loss = 9.0965 (0.515 sec/step)
I0404 20:08:28.536568 47978602034560 learning.py:507] global step 333: loss = 8.7022 (0.525 sec/step)
I0404 20:08:29.072730 47978602034560 learning.py:507] global step 334: loss = 7.7857 (0.535 sec/step)
I0404 20:08:29.580466 47978602034560 learning.py:507] global step 335: loss = 10.2477 (0.505 sec/step)
I0404 20:08:30.106050 47978602034560 learning.py:507] global step 336: loss = 8.6487 (0.524 sec/step)
I0404 20:08:30.625178 47978602034560 learning.py:507] global step 337: loss = 7.7202 (0.518 sec/step)
I0404 20:08:31.135402 47978602034560 learning.py:507] global step 338: loss = 9.3815 (0.507 sec/step)
I0404 20:08:31.645667 47978602034560 learning.py:507] global step 339: loss = 8.4959 (0.509 sec/step)
I0404 20:08:32.169981 47978602034560 learning.py:507] global step 340: loss = 8.2870 (0.523 sec/step)
I0404 20:08:32.680943 47978602034560 learning.py:507] global step 341: loss = 9.1911 (0.508 sec/step)
I0404 20:08:33.182748 47978602034560 learning.py:507] global step 342: loss = 9.5528 (0.499 sec/step)
I0404 20:08:33.703713 47978602034560 learning.py:507] global step 343: loss = 7.4869 (0.519 sec/step)
I0404 20:08:34.219025 47978602034560 learning.py:507] global step 344: loss = 9.8703 (0.514 sec/step)
I0404 20:08:34.749405 47978602034560 learning.py:507] global step 345: loss = 8.6194 (0.529 sec/step)
I0404 20:08:35.266650 47978602034560 learning.py:507] global step 346: loss = 8.1014 (0.514 sec/step)
I0404 20:08:35.774348 47978602034560 learning.py:507] global step 347: loss = 9.3480 (0.506 sec/step)
I0404 20:08:36.308847 47978602034560 learning.py:507] global step 348: loss = 8.0687 (0.532 sec/step)
I0404 20:08:36.821943 47978602034560 learning.py:507] global step 349: loss = 8.6466 (0.512 sec/step)
I0404 20:08:37.342669 47978602034560 learning.py:507] global step 350: loss = 8.3250 (0.519 sec/step)
I0404 20:08:37.881280 47978602034560 learning.py:507] global step 351: loss = 8.5337 (0.537 sec/step)
I0404 20:08:38.392860 47978602034560 learning.py:507] global step 352: loss = 8.6398 (0.509 sec/step)
I0404 20:08:38.906231 47978602034560 learning.py:507] global step 353: loss = 8.1265 (0.512 sec/step)
I0404 20:08:39.434314 47978602034560 learning.py:507] global step 354: loss = 9.0278 (0.526 sec/step)
I0404 20:08:39.975341 47978602034560 learning.py:507] global step 355: loss = 8.6894 (0.539 sec/step)
I0404 20:08:40.512726 47978602034560 learning.py:507] global step 356: loss = 9.5312 (0.536 sec/step)
I0404 20:08:41.021365 47978602034560 learning.py:507] global step 357: loss = 8.4622 (0.507 sec/step)
I0404 20:08:41.532821 47978602034560 learning.py:507] global step 358: loss = 8.2068 (0.510 sec/step)
I0404 20:08:42.041727 47978602034560 learning.py:507] global step 359: loss = 8.5179 (0.506 sec/step)
I0404 20:08:42.577420 47978602034560 learning.py:507] global step 360: loss = 8.7116 (0.533 sec/step)
I0404 20:08:43.114086 47978602034560 learning.py:507] global step 361: loss = 8.0515 (0.534 sec/step)
I0404 20:08:43.639203 47978602034560 learning.py:507] global step 362: loss = 8.3802 (0.524 sec/step)
I0404 20:08:44.150804 47978602034560 learning.py:507] global step 363: loss = 8.4593 (0.509 sec/step)
I0404 20:08:44.668802 47978602034560 learning.py:507] global step 364: loss = 9.1161 (0.516 sec/step)
I0404 20:08:45.182540 47978602034560 learning.py:507] global step 365: loss = 9.6702 (0.512 sec/step)
I0404 20:08:45.695192 47978602034560 learning.py:507] global step 366: loss = 9.0057 (0.511 sec/step)
I0404 20:08:46.208042 47978602034560 learning.py:507] global step 367: loss = 9.0342 (0.511 sec/step)
I0404 20:08:46.716877 47978602034560 learning.py:507] global step 368: loss = 9.6602 (0.506 sec/step)
I0404 20:08:47.240247 47978602034560 learning.py:507] global step 369: loss = 9.0624 (0.522 sec/step)
I0404 20:08:47.751109 47978602034560 learning.py:507] global step 370: loss = 8.0474 (0.508 sec/step)
I0404 20:08:48.254869 47978602034560 learning.py:507] global step 371: loss = 8.7572 (0.502 sec/step)
I0404 20:08:48.787728 47978602034560 learning.py:507] global step 372: loss = 8.5410 (0.530 sec/step)
I0404 20:08:49.326405 47978602034560 learning.py:507] global step 373: loss = 9.4481 (0.537 sec/step)
I0404 20:08:49.861728 47978602034560 learning.py:507] global step 374: loss = 8.4038 (0.534 sec/step)
I0404 20:08:50.372989 47978602034560 learning.py:507] global step 375: loss = 8.3029 (0.510 sec/step)
I0404 20:08:50.891133 47978602034560 learning.py:507] global step 376: loss = 8.4118 (0.517 sec/step)
I0404 20:08:51.405431 47978602034560 learning.py:507] global step 377: loss = 8.3240 (0.513 sec/step)
I0404 20:08:51.926160 47978602034560 learning.py:507] global step 378: loss = 9.0208 (0.518 sec/step)
I0404 20:08:52.455283 47978602034560 learning.py:507] global step 379: loss = 8.6700 (0.528 sec/step)
I0404 20:08:52.960067 47978602034560 learning.py:507] global step 380: loss = 8.4711 (0.503 sec/step)
I0404 20:08:53.468242 47978602034560 learning.py:507] global step 381: loss = 8.6965 (0.506 sec/step)
I0404 20:08:53.984960 47978602034560 learning.py:507] global step 382: loss = 8.6770 (0.515 sec/step)
I0404 20:08:54.493617 47978602034560 learning.py:507] global step 383: loss = 9.3375 (0.507 sec/step)
I0404 20:08:55.003297 47978602034560 learning.py:507] global step 384: loss = 9.2953 (0.508 sec/step)
I0404 20:08:55.521235 47978602034560 learning.py:507] global step 385: loss = 8.5660 (0.516 sec/step)
I0404 20:08:56.025478 47978602034560 learning.py:507] global step 386: loss = 8.3925 (0.503 sec/step)
I0404 20:08:56.534924 47978602034560 learning.py:507] global step 387: loss = 9.1178 (0.508 sec/step)
I0404 20:08:57.055080 47978602034560 learning.py:507] global step 388: loss = 8.8456 (0.519 sec/step)
I0404 20:08:57.562236 47978602034560 learning.py:507] global step 389: loss = 9.1819 (0.504 sec/step)
I0404 20:08:58.066998 47978602034560 learning.py:507] global step 390: loss = 9.0751 (0.503 sec/step)
I0404 20:08:58.568236 47978602034560 learning.py:507] global step 391: loss = 8.8720 (0.500 sec/step)
I0404 20:08:59.083226 47978602034560 learning.py:507] global step 392: loss = 7.8630 (0.513 sec/step)
I0404 20:08:59.601659 47978602034560 learning.py:507] global step 393: loss = 9.5017 (0.517 sec/step)
I0404 20:09:00.110216 47978602034560 learning.py:507] global step 394: loss = 8.4653 (0.507 sec/step)
I0404 20:09:00.618055 47978602034560 learning.py:507] global step 395: loss = 8.6863 (0.506 sec/step)
I0404 20:09:01.137965 47978602034560 learning.py:507] global step 396: loss = 8.0610 (0.517 sec/step)
I0404 20:09:01.649581 47978602034560 learning.py:507] global step 397: loss = 8.9583 (0.510 sec/step)
I0404 20:09:02.182777 47978602034560 learning.py:507] global step 398: loss = 8.3513 (0.532 sec/step)
I0404 20:09:02.717852 47978602034560 learning.py:507] global step 399: loss = 7.4154 (0.533 sec/step)
I0404 20:09:03.226831 47978602034560 learning.py:507] global step 400: loss = 7.6590 (0.506 sec/step)
I0404 20:09:03.734554 47978602034560 learning.py:507] global step 401: loss = 7.3965 (0.505 sec/step)
I0404 20:09:04.235299 47978602034560 learning.py:507] global step 402: loss = 9.4779 (0.498 sec/step)
I0404 20:09:04.760630 47978602034560 learning.py:507] global step 403: loss = 8.3611 (0.524 sec/step)
I0404 20:09:05.270591 47978602034560 learning.py:507] global step 404: loss = 9.2486 (0.507 sec/step)
I0404 20:09:05.777968 47978602034560 learning.py:507] global step 405: loss = 8.4886 (0.506 sec/step)
I0404 20:09:06.297842 47978602034560 learning.py:507] global step 406: loss = 8.4040 (0.517 sec/step)
I0404 20:09:06.802208 47978602034560 learning.py:507] global step 407: loss = 8.9171 (0.503 sec/step)
I0404 20:09:07.306623 47978602034560 learning.py:507] global step 408: loss = 8.4095 (0.503 sec/step)
I0404 20:09:07.813506 47978602034560 learning.py:507] global step 409: loss = 8.5300 (0.505 sec/step)
I0404 20:09:08.322106 47978602034560 learning.py:507] global step 410: loss = 9.3956 (0.507 sec/step)
I0404 20:09:08.853762 47978602034560 learning.py:507] global step 411: loss = 9.9849 (0.529 sec/step)
I0404 20:09:09.367379 47978602034560 learning.py:507] global step 412: loss = 9.1803 (0.512 sec/step)
I0404 20:09:09.876776 47978602034560 learning.py:507] global step 413: loss = 8.9530 (0.508 sec/step)
I0404 20:09:10.382331 47978602034560 learning.py:507] global step 414: loss = 9.4778 (0.504 sec/step)
I0404 20:09:10.890194 47978602034560 learning.py:507] global step 415: loss = 8.7412 (0.506 sec/step)
I0404 20:09:11.424028 47978602034560 learning.py:507] global step 416: loss = 9.3442 (0.532 sec/step)
I0404 20:09:11.931380 47978602034560 learning.py:507] global step 417: loss = 8.5079 (0.506 sec/step)
I0404 20:09:12.431195 47978602034560 learning.py:507] global step 418: loss = 8.3517 (0.498 sec/step)
I0404 20:09:12.935875 47978602034560 learning.py:507] global step 419: loss = 8.5796 (0.503 sec/step)
I0404 20:09:13.453739 47978602034560 learning.py:507] global step 420: loss = 7.8122 (0.516 sec/step)
I0404 20:09:13.971581 47978602034560 learning.py:507] global step 421: loss = 8.9874 (0.516 sec/step)
I0404 20:09:14.482047 47978602034560 learning.py:507] global step 422: loss = 7.9497 (0.508 sec/step)
I0404 20:09:14.985186 47978602034560 learning.py:507] global step 423: loss = 8.3048 (0.500 sec/step)
I0404 20:09:15.497118 47978602034560 learning.py:507] global step 424: loss = 9.3342 (0.510 sec/step)
I0404 20:09:16.003984 47978602034560 learning.py:507] global step 425: loss = 9.3157 (0.505 sec/step)
I0404 20:09:16.526437 47978602034560 learning.py:507] global step 426: loss = 8.3942 (0.520 sec/step)
I0404 20:09:16.637133 47983664076544 supervisor.py:1099] global_step/sec: 1.94167
I0404 20:09:17.229199 47978602034560 learning.py:507] global step 427: loss = 9.1273 (0.698 sec/step)
I0404 20:09:17.233555 47983661975296 supervisor.py:1050] Recording summary at step 427.
I0404 20:09:17.737586 47978602034560 learning.py:507] global step 428: loss = 9.1214 (0.506 sec/step)
I0404 20:09:18.245091 47978602034560 learning.py:507] global step 429: loss = 8.0224 (0.505 sec/step)
I0404 20:09:18.754873 47978602034560 learning.py:507] global step 430: loss = 8.9406 (0.508 sec/step)
I0404 20:09:19.261198 47978602034560 learning.py:507] global step 431: loss = 7.9269 (0.505 sec/step)
I0404 20:09:19.775708 47978602034560 learning.py:507] global step 432: loss = 8.4944 (0.512 sec/step)
I0404 20:09:20.279567 47978602034560 learning.py:507] global step 433: loss = 8.9681 (0.502 sec/step)
I0404 20:09:20.786369 47978602034560 learning.py:507] global step 434: loss = 8.3023 (0.505 sec/step)
I0404 20:09:21.287134 47978602034560 learning.py:507] global step 435: loss = 8.0056 (0.498 sec/step)
I0404 20:09:21.795306 47978602034560 learning.py:507] global step 436: loss = 8.6546 (0.507 sec/step)
I0404 20:09:22.307948 47978602034560 learning.py:507] global step 437: loss = 9.0359 (0.511 sec/step)
I0404 20:09:22.840751 47978602034560 learning.py:507] global step 438: loss = 9.0646 (0.531 sec/step)
I0404 20:09:23.349370 47978602034560 learning.py:507] global step 439: loss = 9.0490 (0.506 sec/step)
I0404 20:09:23.882538 47978602034560 learning.py:507] global step 440: loss = 8.7509 (0.532 sec/step)
I0404 20:09:24.402566 47978602034560 learning.py:507] global step 441: loss = 9.3033 (0.518 sec/step)
I0404 20:09:24.917657 47978602034560 learning.py:507] global step 442: loss = 9.3796 (0.514 sec/step)
I0404 20:09:25.432673 47978602034560 learning.py:507] global step 443: loss = 8.8662 (0.513 sec/step)
I0404 20:09:25.935853 47978602034560 learning.py:507] global step 444: loss = 8.0339 (0.502 sec/step)
I0404 20:09:26.455035 47978602034560 learning.py:507] global step 445: loss = 9.0096 (0.516 sec/step)
I0404 20:09:26.961128 47978602034560 learning.py:507] global step 446: loss = 9.8566 (0.504 sec/step)
I0404 20:09:27.484921 47978602034560 learning.py:507] global step 447: loss = 7.9661 (0.522 sec/step)
I0404 20:09:27.987016 47978602034560 learning.py:507] global step 448: loss = 8.9833 (0.501 sec/step)
I0404 20:09:28.515404 47978602034560 learning.py:507] global step 449: loss = 8.8405 (0.526 sec/step)
I0404 20:09:29.021000 47978602034560 learning.py:507] global step 450: loss = 8.4239 (0.503 sec/step)
I0404 20:09:29.554367 47978602034560 learning.py:507] global step 451: loss = 7.8908 (0.532 sec/step)
I0404 20:09:30.056820 47978602034560 learning.py:507] global step 452: loss = 7.9261 (0.501 sec/step)
I0404 20:09:30.565781 47978602034560 learning.py:507] global step 453: loss = 7.8280 (0.507 sec/step)
I0404 20:09:31.076395 47978602034560 learning.py:507] global step 454: loss = 8.1302 (0.508 sec/step)
I0404 20:09:31.604463 47978602034560 learning.py:507] global step 455: loss = 8.3318 (0.525 sec/step)
I0404 20:09:32.116376 47978602034560 learning.py:507] global step 456: loss = 8.0367 (0.509 sec/step)
I0404 20:09:32.631482 47978602034560 learning.py:507] global step 457: loss = 8.7854 (0.512 sec/step)
I0404 20:09:33.147268 47978602034560 learning.py:507] global step 458: loss = 8.0999 (0.513 sec/step)
I0404 20:09:33.655103 47978602034560 learning.py:507] global step 459: loss = 8.5319 (0.506 sec/step)
I0404 20:09:34.162089 47978602034560 learning.py:507] global step 460: loss = 8.9394 (0.504 sec/step)
I0404 20:09:34.670486 47978602034560 learning.py:507] global step 461: loss = 8.6455 (0.507 sec/step)
I0404 20:09:35.187412 47978602034560 learning.py:507] global step 462: loss = 8.5390 (0.514 sec/step)
I0404 20:09:35.721637 47978602034560 learning.py:507] global step 463: loss = 7.7949 (0.533 sec/step)
I0404 20:09:36.248712 47978602034560 learning.py:507] global step 464: loss = 7.8072 (0.526 sec/step)
I0404 20:09:36.792574 47978602034560 learning.py:507] global step 465: loss = 7.7961 (0.542 sec/step)
I0404 20:09:37.330369 47978602034560 learning.py:507] global step 466: loss = 7.8819 (0.536 sec/step)
I0404 20:09:37.846360 47978602034560 learning.py:507] global step 467: loss = 6.9362 (0.514 sec/step)
I0404 20:09:38.357176 47978602034560 learning.py:507] global step 468: loss = 8.4917 (0.508 sec/step)
I0404 20:09:38.868861 47978602034560 learning.py:507] global step 469: loss = 8.5011 (0.509 sec/step)
I0404 20:09:39.414125 47978602034560 learning.py:507] global step 470: loss = 8.9618 (0.544 sec/step)
I0404 20:09:39.921893 47978602034560 learning.py:507] global step 471: loss = 8.2522 (0.506 sec/step)
I0404 20:09:40.443128 47978602034560 learning.py:507] global step 472: loss = 8.5350 (0.519 sec/step)
I0404 20:09:40.958112 47978602034560 learning.py:507] global step 473: loss = 8.1845 (0.512 sec/step)
I0404 20:09:41.466784 47978602034560 learning.py:507] global step 474: loss = 8.5522 (0.506 sec/step)
I0404 20:09:41.994963 47978602034560 learning.py:507] global step 475: loss = 9.5000 (0.527 sec/step)
I0404 20:09:42.496218 47978602034560 learning.py:507] global step 476: loss = 7.8990 (0.500 sec/step)
I0404 20:09:43.000728 47978602034560 learning.py:507] global step 477: loss = 8.3364 (0.502 sec/step)
I0404 20:09:43.514873 47978602034560 learning.py:507] global step 478: loss = 7.8540 (0.511 sec/step)
I0404 20:09:44.026143 47978602034560 learning.py:507] global step 479: loss = 8.2384 (0.510 sec/step)
I0404 20:09:44.567799 47978602034560 learning.py:507] global step 480: loss = 7.8179 (0.540 sec/step)
I0404 20:09:45.080748 47978602034560 learning.py:507] global step 481: loss = 9.8168 (0.511 sec/step)
I0404 20:09:45.610528 47978602034560 learning.py:507] global step 482: loss = 8.4885 (0.527 sec/step)
I0404 20:09:46.123741 47978602034560 learning.py:507] global step 483: loss = 8.4030 (0.512 sec/step)
I0404 20:09:46.636101 47978602034560 learning.py:507] global step 484: loss = 8.7542 (0.511 sec/step)
I0404 20:09:47.168404 47978602034560 learning.py:507] global step 485: loss = 8.6866 (0.531 sec/step)
I0404 20:09:47.688277 47978602034560 learning.py:507] global step 486: loss = 8.9705 (0.518 sec/step)
I0404 20:09:48.197182 47978602034560 learning.py:507] global step 487: loss = 7.9060 (0.506 sec/step)
I0404 20:09:48.732231 47978602034560 learning.py:507] global step 488: loss = 7.7922 (0.532 sec/step)
I0404 20:09:49.245340 47978602034560 learning.py:507] global step 489: loss = 8.5998 (0.510 sec/step)
I0404 20:09:49.785381 47978602034560 learning.py:507] global step 490: loss = 8.3456 (0.538 sec/step)
I0404 20:09:50.297395 47978602034560 learning.py:507] global step 491: loss = 8.2636 (0.510 sec/step)
I0404 20:09:50.808998 47978602034560 learning.py:507] global step 492: loss = 8.0598 (0.510 sec/step)
I0404 20:09:51.319719 47978602034560 learning.py:507] global step 493: loss = 8.8361 (0.509 sec/step)
I0404 20:09:51.847717 47978602034560 learning.py:507] global step 494: loss = 7.5817 (0.526 sec/step)
I0404 20:09:52.359278 47978602034560 learning.py:507] global step 495: loss = 8.5634 (0.510 sec/step)
I0404 20:09:52.880683 47978602034560 learning.py:507] global step 496: loss = 8.3433 (0.520 sec/step)
I0404 20:09:53.411123 47978602034560 learning.py:507] global step 497: loss = 8.1690 (0.528 sec/step)
I0404 20:09:53.925270 47978602034560 learning.py:507] global step 498: loss = 8.1152 (0.512 sec/step)
I0404 20:09:54.438594 47978602034560 learning.py:507] global step 499: loss = 9.0878 (0.511 sec/step)
I0404 20:09:54.952409 47978602034560 learning.py:507] global step 500: loss = 8.1521 (0.512 sec/step)
I0404 20:09:55.494724 47978602034560 learning.py:507] global step 501: loss = 8.7224 (0.541 sec/step)
I0404 20:09:56.023668 47978602034560 learning.py:507] global step 502: loss = 8.2650 (0.527 sec/step)
I0404 20:09:56.531012 47978602034560 learning.py:507] global step 503: loss = 8.5820 (0.506 sec/step)
I0404 20:09:57.052990 47978602034560 learning.py:507] global step 504: loss = 7.9867 (0.520 sec/step)
I0404 20:09:57.569989 47978602034560 learning.py:507] global step 505: loss = 7.6382 (0.514 sec/step)
I0404 20:09:58.077317 47978602034560 learning.py:507] global step 506: loss = 7.0423 (0.506 sec/step)
I0404 20:09:58.592892 47978602034560 learning.py:507] global step 507: loss = 7.9931 (0.513 sec/step)
I0404 20:09:59.137060 47978602034560 learning.py:507] global step 508: loss = 8.1891 (0.541 sec/step)
I0404 20:09:59.651034 47978602034560 learning.py:507] global step 509: loss = 8.4813 (0.512 sec/step)
I0404 20:10:00.183979 47978602034560 learning.py:507] global step 510: loss = 9.2029 (0.531 sec/step)
I0404 20:10:00.695563 47978602034560 learning.py:507] global step 511: loss = 7.9633 (0.510 sec/step)
I0404 20:10:01.215389 47978602034560 learning.py:507] global step 512: loss = 9.2640 (0.518 sec/step)
I0404 20:10:01.724424 47978602034560 learning.py:507] global step 513: loss = 8.6709 (0.507 sec/step)
I0404 20:10:02.227863 47978602034560 learning.py:507] global step 514: loss = 8.1679 (0.501 sec/step)
I0404 20:10:02.757555 47978602034560 learning.py:507] global step 515: loss = 8.5284 (0.527 sec/step)
I0404 20:10:03.270120 47978602034560 learning.py:507] global step 516: loss = 8.8548 (0.510 sec/step)
I0404 20:10:03.780206 47978602034560 learning.py:507] global step 517: loss = 8.2583 (0.508 sec/step)
I0404 20:10:04.286690 47978602034560 learning.py:507] global step 518: loss = 8.1431 (0.505 sec/step)
I0404 20:10:04.800695 47978602034560 learning.py:507] global step 519: loss = 7.6372 (0.512 sec/step)
I0404 20:10:05.345533 47978602034560 learning.py:507] global step 520: loss = 8.7522 (0.543 sec/step)
I0404 20:10:05.879363 47978602034560 learning.py:507] global step 521: loss = 8.1606 (0.532 sec/step)
I0404 20:10:06.414417 47978602034560 learning.py:507] global step 522: loss = 7.6108 (0.533 sec/step)
I0404 20:10:06.929884 47978602034560 learning.py:507] global step 523: loss = 8.1478 (0.514 sec/step)
I0404 20:10:07.437359 47978602034560 learning.py:507] global step 524: loss = 8.3584 (0.506 sec/step)
I0404 20:10:07.949315 47978602034560 learning.py:507] global step 525: loss = 7.6728 (0.510 sec/step)
I0404 20:10:08.466850 47978602034560 learning.py:507] global step 526: loss = 8.7232 (0.516 sec/step)
I0404 20:10:08.997869 47978602034560 learning.py:507] global step 527: loss = 7.7631 (0.529 sec/step)
I0404 20:10:09.534949 47978602034560 learning.py:507] global step 528: loss = 8.2239 (0.535 sec/step)
I0404 20:10:10.038160 47978602034560 learning.py:507] global step 529: loss = 9.3529 (0.502 sec/step)
I0404 20:10:10.541583 47978602034560 learning.py:507] global step 530: loss = 7.4806 (0.502 sec/step)
I0404 20:10:11.044000 47978602034560 learning.py:507] global step 531: loss = 7.8030 (0.501 sec/step)
I0404 20:10:11.552270 47978602034560 learning.py:507] global step 532: loss = 8.5924 (0.507 sec/step)
I0404 20:10:12.054306 47978602034560 learning.py:507] global step 533: loss = 9.4547 (0.500 sec/step)
I0404 20:10:12.565877 47978602034560 learning.py:507] global step 534: loss = 8.1265 (0.510 sec/step)
I0404 20:10:13.082232 47978602034560 learning.py:507] global step 535: loss = 8.1749 (0.515 sec/step)
I0404 20:10:13.616118 47978602034560 learning.py:507] global step 536: loss = 7.9444 (0.532 sec/step)
I0404 20:10:14.137531 47978602034560 learning.py:507] global step 537: loss = 8.3480 (0.520 sec/step)
I0404 20:10:14.646754 47978602034560 learning.py:507] global step 538: loss = 8.4172 (0.508 sec/step)
I0404 20:10:15.159774 47978602034560 learning.py:507] global step 539: loss = 7.5390 (0.511 sec/step)
I0404 20:10:15.671015 47978602034560 learning.py:507] global step 540: loss = 8.4537 (0.508 sec/step)
I0404 20:10:16.181674 47978602034560 learning.py:507] global step 541: loss = 8.8613 (0.509 sec/step)
I0404 20:10:16.695113 47978602034560 learning.py:507] global step 542: loss = 8.4172 (0.512 sec/step)
I0404 20:10:17.214599 47978602034560 learning.py:507] global step 543: loss = 8.7376 (0.518 sec/step)
I0404 20:10:17.715452 47978602034560 learning.py:507] global step 544: loss = 7.7681 (0.499 sec/step)
I0404 20:10:18.252894 47978602034560 learning.py:507] global step 545: loss = 7.8201 (0.536 sec/step)
I0404 20:10:18.756828 47978602034560 learning.py:507] global step 546: loss = 8.2699 (0.502 sec/step)
I0404 20:10:19.281940 47978602034560 learning.py:507] global step 547: loss = 8.4193 (0.524 sec/step)
I0404 20:10:19.789274 47978602034560 learning.py:507] global step 548: loss = 8.7760 (0.506 sec/step)
I0404 20:10:20.303228 47978602034560 learning.py:507] global step 549: loss = 6.8245 (0.512 sec/step)
I0404 20:10:20.836401 47978602034560 learning.py:507] global step 550: loss = 9.0080 (0.530 sec/step)
I0404 20:10:21.348740 47978602034560 learning.py:507] global step 551: loss = 8.1180 (0.509 sec/step)
I0404 20:10:21.854888 47978602034560 learning.py:507] global step 552: loss = 8.3557 (0.504 sec/step)
I0404 20:10:22.368709 47978602034560 learning.py:507] global step 553: loss = 8.4639 (0.512 sec/step)
I0404 20:10:22.875741 47978602034560 learning.py:507] global step 554: loss = 7.7181 (0.505 sec/step)
I0404 20:10:23.386268 47978602034560 learning.py:507] global step 555: loss = 8.0447 (0.509 sec/step)
I0404 20:10:23.922257 47978602034560 learning.py:507] global step 556: loss = 7.7358 (0.533 sec/step)
I0404 20:10:24.461940 47978602034560 learning.py:507] global step 557: loss = 8.6870 (0.538 sec/step)
I0404 20:10:24.973483 47978602034560 learning.py:507] global step 558: loss = 7.9669 (0.510 sec/step)
I0404 20:10:25.489559 47978602034560 learning.py:507] global step 559: loss = 7.0787 (0.514 sec/step)
I0404 20:10:25.993221 47978602034560 learning.py:507] global step 560: loss = 7.8133 (0.502 sec/step)
I0404 20:10:26.526964 47978602034560 learning.py:507] global step 561: loss = 8.1764 (0.532 sec/step)
I0404 20:10:27.050592 47978602034560 learning.py:507] global step 562: loss = 7.3979 (0.522 sec/step)
I0404 20:10:27.562723 47978602034560 learning.py:507] global step 563: loss = 7.2757 (0.511 sec/step)
I0404 20:10:28.091704 47978602034560 learning.py:507] global step 564: loss = 8.4773 (0.527 sec/step)
I0404 20:10:28.626051 47978602034560 learning.py:507] global step 565: loss = 8.3301 (0.533 sec/step)
I0404 20:10:29.136061 47978602034560 learning.py:507] global step 566: loss = 8.3382 (0.508 sec/step)
I0404 20:10:29.639409 47978602034560 learning.py:507] global step 567: loss = 9.1198 (0.502 sec/step)
I0404 20:10:30.157002 47978602034560 learning.py:507] global step 568: loss = 7.5154 (0.516 sec/step)
I0404 20:10:30.658721 47978602034560 learning.py:507] global step 569: loss = 7.7098 (0.500 sec/step)
I0404 20:10:31.195994 47978602034560 learning.py:507] global step 570: loss = 8.2920 (0.534 sec/step)
I0404 20:10:31.742557 47978602034560 learning.py:507] global step 571: loss = 8.8308 (0.545 sec/step)
I0404 20:10:32.247810 47978602034560 learning.py:507] global step 572: loss = 8.2674 (0.504 sec/step)
I0404 20:10:32.779556 47978602034560 learning.py:507] global step 573: loss = 7.9077 (0.530 sec/step)
I0404 20:10:33.282091 47978602034560 learning.py:507] global step 574: loss = 8.5746 (0.501 sec/step)
I0404 20:10:33.823735 47978602034560 learning.py:507] global step 575: loss = 7.5279 (0.540 sec/step)
I0404 20:10:34.329106 47978602034560 learning.py:507] global step 576: loss = 7.9907 (0.504 sec/step)
I0404 20:10:34.847547 47978602034560 learning.py:507] global step 577: loss = 7.7836 (0.517 sec/step)
I0404 20:10:35.352329 47978602034560 learning.py:507] global step 578: loss = 7.9431 (0.502 sec/step)
I0404 20:10:35.862178 47978602034560 learning.py:507] global step 579: loss = 7.3704 (0.508 sec/step)
I0404 20:10:36.369707 47978602034560 learning.py:507] global step 580: loss = 7.3599 (0.506 sec/step)
I0404 20:10:36.869951 47978602034560 learning.py:507] global step 581: loss = 10.0547 (0.499 sec/step)
I0404 20:10:37.391368 47978602034560 learning.py:507] global step 582: loss = 7.9547 (0.519 sec/step)
I0404 20:10:37.911164 47978602034560 learning.py:507] global step 583: loss = 7.6751 (0.518 sec/step)
I0404 20:10:38.424841 47978602034560 learning.py:507] global step 584: loss = 7.3537 (0.512 sec/step)
I0404 20:10:38.938013 47978602034560 learning.py:507] global step 585: loss = 8.2348 (0.511 sec/step)
I0404 20:10:39.447145 47978602034560 learning.py:507] global step 586: loss = 8.5832 (0.508 sec/step)
I0404 20:10:39.984316 47978602034560 learning.py:507] global step 587: loss = 7.8544 (0.536 sec/step)
I0404 20:10:40.519028 47978602034560 learning.py:507] global step 588: loss = 7.3629 (0.533 sec/step)
I0404 20:10:41.037129 47978602034560 learning.py:507] global step 589: loss = 7.8608 (0.517 sec/step)
I0404 20:10:41.548954 47978602034560 learning.py:507] global step 590: loss = 8.0150 (0.510 sec/step)
I0404 20:10:42.058628 47978602034560 learning.py:507] global step 591: loss = 7.8812 (0.507 sec/step)
I0404 20:10:42.579549 47978602034560 learning.py:507] global step 592: loss = 8.3364 (0.518 sec/step)
I0404 20:10:43.097848 47978602034560 learning.py:507] global step 593: loss = 8.6258 (0.517 sec/step)
I0404 20:10:43.616178 47978602034560 learning.py:507] global step 594: loss = 7.3971 (0.515 sec/step)
I0404 20:10:44.120797 47978602034560 learning.py:507] global step 595: loss = 8.0189 (0.503 sec/step)
I0404 20:10:44.665446 47978602034560 learning.py:507] global step 596: loss = 7.8749 (0.542 sec/step)
I0404 20:10:45.187580 47978602034560 learning.py:507] global step 597: loss = 8.4153 (0.521 sec/step)
I0404 20:10:45.693704 47978602034560 learning.py:507] global step 598: loss = 7.3760 (0.505 sec/step)
I0404 20:10:46.194860 47978602034560 learning.py:507] global step 599: loss = 8.7097 (0.500 sec/step)
I0404 20:10:46.725249 47978602034560 learning.py:507] global step 600: loss = 7.9597 (0.528 sec/step)
I0404 20:10:47.242635 47978602034560 learning.py:507] global step 601: loss = 8.1736 (0.516 sec/step)
I0404 20:10:47.752581 47978602034560 learning.py:507] global step 602: loss = 8.0301 (0.507 sec/step)
I0404 20:10:48.285247 47978602034560 learning.py:507] global step 603: loss = 8.0586 (0.530 sec/step)
I0404 20:10:48.788334 47978602034560 learning.py:507] global step 604: loss = 9.1389 (0.502 sec/step)
I0404 20:10:49.317419 47978602034560 learning.py:507] global step 605: loss = 8.7085 (0.528 sec/step)
I0404 20:10:49.831537 47978602034560 learning.py:507] global step 606: loss = 8.7834 (0.512 sec/step)
I0404 20:10:50.339740 47978602034560 learning.py:507] global step 607: loss = 7.2022 (0.507 sec/step)
I0404 20:10:50.839743 47978602034560 learning.py:507] global step 608: loss = 8.1098 (0.498 sec/step)
I0404 20:10:51.348518 47978602034560 learning.py:507] global step 609: loss = 7.8884 (0.507 sec/step)
I0404 20:10:51.863537 47978602034560 learning.py:507] global step 610: loss = 7.8399 (0.512 sec/step)
I0404 20:10:52.384070 47978602034560 learning.py:507] global step 611: loss = 8.5779 (0.519 sec/step)
I0404 20:10:52.892522 47978602034560 learning.py:507] global step 612: loss = 7.7659 (0.505 sec/step)
I0404 20:10:53.404646 47978602034560 learning.py:507] global step 613: loss = 8.5544 (0.510 sec/step)
I0404 20:10:53.909448 47978602034560 learning.py:507] global step 614: loss = 7.9555 (0.502 sec/step)
I0404 20:10:54.434004 47978602034560 learning.py:507] global step 615: loss = 7.8273 (0.523 sec/step)
I0404 20:10:54.959276 47978602034560 learning.py:507] global step 616: loss = 7.9899 (0.524 sec/step)
I0404 20:10:55.465604 47978602034560 learning.py:507] global step 617: loss = 8.5999 (0.505 sec/step)
I0404 20:10:55.986120 47978602034560 learning.py:507] global step 618: loss = 7.5173 (0.519 sec/step)
I0404 20:10:56.529802 47978602034560 learning.py:507] global step 619: loss = 7.6921 (0.542 sec/step)
I0404 20:10:57.038494 47978602034560 learning.py:507] global step 620: loss = 8.7292 (0.506 sec/step)
I0404 20:10:57.555179 47978602034560 learning.py:507] global step 621: loss = 8.5902 (0.515 sec/step)
I0404 20:10:58.090101 47978602034560 learning.py:507] global step 622: loss = 7.6910 (0.532 sec/step)
I0404 20:10:58.600093 47978602034560 learning.py:507] global step 623: loss = 6.7611 (0.508 sec/step)
I0404 20:10:59.103944 47978602034560 learning.py:507] global step 624: loss = 8.3451 (0.501 sec/step)
I0404 20:10:59.614742 47978602034560 learning.py:507] global step 625: loss = 7.1336 (0.508 sec/step)
I0404 20:11:00.144702 47978602034560 learning.py:507] global step 626: loss = 7.3041 (0.528 sec/step)
I0404 20:11:00.655494 47978602034560 learning.py:507] global step 627: loss = 7.1390 (0.509 sec/step)
I0404 20:11:01.161433 47978602034560 learning.py:507] global step 628: loss = 8.3173 (0.504 sec/step)
I0404 20:11:01.671041 47978602034560 learning.py:507] global step 629: loss = 9.5823 (0.508 sec/step)
I0404 20:11:02.177137 47978602034560 learning.py:507] global step 630: loss = 7.6261 (0.505 sec/step)
I0404 20:11:02.681429 47978602034560 learning.py:507] global step 631: loss = 8.1360 (0.503 sec/step)
I0404 20:11:03.206601 47978602034560 learning.py:507] global step 632: loss = 7.9965 (0.524 sec/step)
I0404 20:11:03.738438 47978602034560 learning.py:507] global step 633: loss = 7.7648 (0.530 sec/step)
I0404 20:11:04.257826 47978602034560 learning.py:507] global step 634: loss = 7.5696 (0.516 sec/step)
I0404 20:11:04.778668 47978602034560 learning.py:507] global step 635: loss = 8.8674 (0.518 sec/step)
I0404 20:11:05.301418 47978602034560 learning.py:507] global step 636: loss = 7.0747 (0.520 sec/step)
I0404 20:11:05.808551 47978602034560 learning.py:507] global step 637: loss = 8.8708 (0.505 sec/step)
I0404 20:11:06.320402 47978602034560 learning.py:507] global step 638: loss = 7.8798 (0.509 sec/step)
I0404 20:11:06.834247 47978602034560 learning.py:507] global step 639: loss = 7.4735 (0.512 sec/step)
I0404 20:11:07.346266 47978602034560 learning.py:507] global step 640: loss = 8.0123 (0.510 sec/step)
I0404 20:11:07.875363 47978602034560 learning.py:507] global step 641: loss = 8.2765 (0.528 sec/step)
I0404 20:11:08.410520 47978602034560 learning.py:507] global step 642: loss = 8.0629 (0.534 sec/step)
I0404 20:11:08.928270 47978602034560 learning.py:507] global step 643: loss = 7.5461 (0.515 sec/step)
I0404 20:11:09.456295 47978602034560 learning.py:507] global step 644: loss = 7.5146 (0.525 sec/step)
I0404 20:11:09.967575 47978602034560 learning.py:507] global step 645: loss = 7.1273 (0.508 sec/step)
I0404 20:11:10.498783 47978602034560 learning.py:507] global step 646: loss = 8.9383 (0.530 sec/step)
I0404 20:11:11.008876 47978602034560 learning.py:507] global step 647: loss = 8.4931 (0.508 sec/step)
I0404 20:11:11.525186 47978602034560 learning.py:507] global step 648: loss = 8.7494 (0.514 sec/step)
I0404 20:11:12.027879 47978602034560 learning.py:507] global step 649: loss = 7.5370 (0.500 sec/step)
I0404 20:11:12.552435 47978602034560 learning.py:507] global step 650: loss = 7.2863 (0.523 sec/step)
I0404 20:11:13.093602 47978602034560 learning.py:507] global step 651: loss = 7.9168 (0.540 sec/step)
I0404 20:11:13.625726 47978602034560 learning.py:507] global step 652: loss = 7.8587 (0.531 sec/step)
I0404 20:11:14.155587 47978602034560 learning.py:507] global step 653: loss = 7.4065 (0.528 sec/step)
I0404 20:11:14.663864 47978602034560 learning.py:507] global step 654: loss = 7.8080 (0.507 sec/step)
I0404 20:11:15.183293 47978602034560 learning.py:507] global step 655: loss = 8.5470 (0.518 sec/step)
I0404 20:11:15.715681 47978602034560 learning.py:507] global step 656: loss = 7.1055 (0.531 sec/step)
I0404 20:11:16.222739 47978602034560 learning.py:507] global step 657: loss = 8.5181 (0.505 sec/step)
I0404 20:11:16.637161 47983664076544 supervisor.py:1099] global_step/sec: 1.925
I0404 20:11:16.747723 47978602034560 learning.py:507] global step 658: loss = 8.0116 (0.516 sec/step)
I0404 20:11:17.129809 47983661975296 supervisor.py:1050] Recording summary at step 658.
I0404 20:11:17.472173 47978602034560 learning.py:507] global step 659: loss = 7.5168 (0.698 sec/step)
I0404 20:11:17.991541 47978602034560 learning.py:507] global step 660: loss = 7.1784 (0.516 sec/step)
I0404 20:11:18.526729 47978602034560 learning.py:507] global step 661: loss = 7.8771 (0.534 sec/step)
I0404 20:11:19.041650 47978602034560 learning.py:507] global step 662: loss = 7.3909 (0.513 sec/step)
I0404 20:11:19.551517 47978602034560 learning.py:507] global step 663: loss = 7.3351 (0.508 sec/step)
I0404 20:11:20.090350 47978602034560 learning.py:507] global step 664: loss = 7.4840 (0.537 sec/step)
I0404 20:11:20.607660 47978602034560 learning.py:507] global step 665: loss = 6.1375 (0.516 sec/step)
I0404 20:11:21.132087 47978602034560 learning.py:507] global step 666: loss = 8.4765 (0.522 sec/step)
I0404 20:11:21.651454 47978602034560 learning.py:507] global step 667: loss = 8.0455 (0.518 sec/step)
I0404 20:11:22.156889 47978602034560 learning.py:507] global step 668: loss = 7.7502 (0.504 sec/step)
I0404 20:11:22.689699 47978602034560 learning.py:507] global step 669: loss = 8.3869 (0.531 sec/step)
I0404 20:11:23.209237 47978602034560 learning.py:507] global step 670: loss = 7.6788 (0.518 sec/step)
I0404 20:11:23.717413 47978602034560 learning.py:507] global step 671: loss = 8.9559 (0.507 sec/step)
I0404 20:11:24.255697 47978602034560 learning.py:507] global step 672: loss = 7.4818 (0.535 sec/step)
I0404 20:11:24.761525 47978602034560 learning.py:507] global step 673: loss = 7.4277 (0.504 sec/step)
I0404 20:11:25.278494 47978602034560 learning.py:507] global step 674: loss = 8.1359 (0.515 sec/step)
I0404 20:11:25.793595 47978602034560 learning.py:507] global step 675: loss = 7.5516 (0.513 sec/step)
I0404 20:11:26.309603 47978602034560 learning.py:507] global step 676: loss = 8.0943 (0.514 sec/step)
I0404 20:11:26.815413 47978602034560 learning.py:507] global step 677: loss = 7.2790 (0.504 sec/step)
I0404 20:11:27.342394 47978602034560 learning.py:507] global step 678: loss = 7.1701 (0.525 sec/step)
I0404 20:11:27.881601 47978602034560 learning.py:507] global step 679: loss = 9.4126 (0.538 sec/step)
I0404 20:11:28.397292 47978602034560 learning.py:507] global step 680: loss = 7.2789 (0.514 sec/step)
I0404 20:11:28.903983 47978602034560 learning.py:507] global step 681: loss = 6.8770 (0.504 sec/step)
I0404 20:11:29.415589 47978602034560 learning.py:507] global step 682: loss = 7.3731 (0.510 sec/step)
I0404 20:11:29.931129 47978602034560 learning.py:507] global step 683: loss = 7.5580 (0.513 sec/step)
I0404 20:11:30.452858 47978602034560 learning.py:507] global step 684: loss = 8.4710 (0.520 sec/step)
I0404 20:11:30.962659 47978602034560 learning.py:507] global step 685: loss = 8.0105 (0.507 sec/step)
I0404 20:11:31.475610 47978602034560 learning.py:507] global step 686: loss = 8.6333 (0.510 sec/step)
I0404 20:11:31.973897 47978602034560 learning.py:507] global step 687: loss = 7.0737 (0.497 sec/step)
I0404 20:11:32.495239 47978602034560 learning.py:507] global step 688: loss = 7.3797 (0.520 sec/step)
I0404 20:11:33.023273 47978602034560 learning.py:507] global step 689: loss = 8.6699 (0.526 sec/step)
I0404 20:11:33.534070 47978602034560 learning.py:507] global step 690: loss = 7.9182 (0.509 sec/step)
I0404 20:11:34.055268 47978602034560 learning.py:507] global step 691: loss = 7.6031 (0.520 sec/step)
I0404 20:11:34.567574 47978602034560 learning.py:507] global step 692: loss = 6.7098 (0.511 sec/step)
I0404 20:11:35.083059 47978602034560 learning.py:507] global step 693: loss = 7.6384 (0.514 sec/step)
I0404 20:11:35.610454 47978602034560 learning.py:507] global step 694: loss = 8.0209 (0.525 sec/step)
I0404 20:11:36.124284 47978602034560 learning.py:507] global step 695: loss = 8.2728 (0.512 sec/step)
I0404 20:11:36.646380 47978602034560 learning.py:507] global step 696: loss = 6.8224 (0.519 sec/step)
I0404 20:11:37.159158 47978602034560 learning.py:507] global step 697: loss = 6.7367 (0.511 sec/step)
I0404 20:11:37.664862 47978602034560 learning.py:507] global step 698: loss = 8.4477 (0.504 sec/step)
I0404 20:11:38.191304 47978602034560 learning.py:507] global step 699: loss = 7.0456 (0.524 sec/step)
I0404 20:11:38.707034 47978602034560 learning.py:507] global step 700: loss = 7.8118 (0.514 sec/step)
I0404 20:11:39.238271 47978602034560 learning.py:507] global step 701: loss = 7.5050 (0.530 sec/step)
I0404 20:11:39.756679 47978602034560 learning.py:507] global step 702: loss = 8.0363 (0.517 sec/step)
I0404 20:11:40.272669 47978602034560 learning.py:507] global step 703: loss = 8.0305 (0.514 sec/step)
I0404 20:11:40.783690 47978602034560 learning.py:507] global step 704: loss = 7.6528 (0.510 sec/step)
I0404 20:11:41.285481 47978602034560 learning.py:507] global step 705: loss = 8.9451 (0.500 sec/step)
I0404 20:11:41.816155 47978602034560 learning.py:507] global step 706: loss = 8.2216 (0.528 sec/step)
I0404 20:11:42.327626 47978602034560 learning.py:507] global step 707: loss = 7.7624 (0.510 sec/step)
I0404 20:11:42.842134 47978602034560 learning.py:507] global step 708: loss = 7.1015 (0.513 sec/step)
I0404 20:11:43.368402 47978602034560 learning.py:507] global step 709: loss = 7.8931 (0.523 sec/step)
I0404 20:11:43.917690 47978602034560 learning.py:507] global step 710: loss = 7.4455 (0.547 sec/step)
I0404 20:11:44.455916 47978602034560 learning.py:507] global step 711: loss = 7.8243 (0.536 sec/step)
I0404 20:11:44.958853 47978602034560 learning.py:507] global step 712: loss = 7.5519 (0.501 sec/step)
I0404 20:11:45.494734 47978602034560 learning.py:507] global step 713: loss = 7.7924 (0.533 sec/step)
I0404 20:11:46.006637 47978602034560 learning.py:507] global step 714: loss = 8.2662 (0.509 sec/step)
I0404 20:11:46.511568 47978602034560 learning.py:507] global step 715: loss = 8.0707 (0.503 sec/step)
I0404 20:11:47.032492 47978602034560 learning.py:507] global step 716: loss = 6.9046 (0.519 sec/step)
I0404 20:11:47.541118 47978602034560 learning.py:507] global step 717: loss = 7.9474 (0.507 sec/step)
I0404 20:11:48.076881 47978602034560 learning.py:507] global step 718: loss = 7.9756 (0.533 sec/step)
I0404 20:11:48.617076 47978602034560 learning.py:507] global step 719: loss = 7.6775 (0.539 sec/step)
I0404 20:11:49.132297 47978602034560 learning.py:507] global step 720: loss = 8.3206 (0.514 sec/step)
I0404 20:11:49.642315 47978602034560 learning.py:507] global step 721: loss = 7.8049 (0.508 sec/step)
I0404 20:11:50.159670 47978602034560 learning.py:507] global step 722: loss = 7.7800 (0.516 sec/step)
I0404 20:11:50.667956 47978602034560 learning.py:507] global step 723: loss = 7.5465 (0.505 sec/step)
I0404 20:11:51.198935 47978602034560 learning.py:507] global step 724: loss = 7.6490 (0.529 sec/step)
I0404 20:11:51.698748 47978602034560 learning.py:507] global step 725: loss = 8.3411 (0.497 sec/step)
I0404 20:11:52.219787 47978602034560 learning.py:507] global step 726: loss = 8.6266 (0.519 sec/step)
I0404 20:11:52.732429 47978602034560 learning.py:507] global step 727: loss = 7.8734 (0.511 sec/step)
I0404 20:11:53.255984 47978602034560 learning.py:507] global step 728: loss = 8.0608 (0.522 sec/step)
I0404 20:11:53.765728 47978602034560 learning.py:507] global step 729: loss = 7.2742 (0.508 sec/step)
I0404 20:11:54.275601 47978602034560 learning.py:507] global step 730: loss = 8.4834 (0.508 sec/step)
I0404 20:11:54.783878 47978602034560 learning.py:507] global step 731: loss = 7.4759 (0.507 sec/step)
I0404 20:11:55.303186 47978602034560 learning.py:507] global step 732: loss = 8.8782 (0.518 sec/step)
I0404 20:11:55.808160 47978602034560 learning.py:507] global step 733: loss = 7.8626 (0.503 sec/step)
I0404 20:11:56.322218 47978602034560 learning.py:507] global step 734: loss = 7.5333 (0.511 sec/step)
I0404 20:11:56.837091 47978602034560 learning.py:507] global step 735: loss = 7.5159 (0.513 sec/step)
I0404 20:11:57.341721 47978602034560 learning.py:507] global step 736: loss = 7.5528 (0.503 sec/step)
I0404 20:11:57.876406 47978602034560 learning.py:507] global step 737: loss = 7.7440 (0.532 sec/step)
I0404 20:11:58.393333 47978602034560 learning.py:507] global step 738: loss = 7.2894 (0.515 sec/step)
I0404 20:11:58.911115 47978602034560 learning.py:507] global step 739: loss = 8.3224 (0.516 sec/step)
I0404 20:11:59.426538 47978602034560 learning.py:507] global step 740: loss = 7.7356 (0.512 sec/step)
I0404 20:11:59.940022 47978602034560 learning.py:507] global step 741: loss = 8.2579 (0.512 sec/step)
I0404 20:12:00.451231 47978602034560 learning.py:507] global step 742: loss = 7.4604 (0.508 sec/step)
I0404 20:12:00.991120 47978602034560 learning.py:507] global step 743: loss = 6.8824 (0.538 sec/step)
I0404 20:12:01.530709 47978602034560 learning.py:507] global step 744: loss = 7.0163 (0.538 sec/step)
I0404 20:12:02.044974 47978602034560 learning.py:507] global step 745: loss = 8.6162 (0.511 sec/step)
I0404 20:12:02.580607 47978602034560 learning.py:507] global step 746: loss = 7.5259 (0.534 sec/step)
I0404 20:12:03.096603 47978602034560 learning.py:507] global step 747: loss = 9.6528 (0.514 sec/step)
I0404 20:12:03.610621 47978602034560 learning.py:507] global step 748: loss = 7.7234 (0.512 sec/step)
I0404 20:12:04.116855 47978602034560 learning.py:507] global step 749: loss = 7.9630 (0.505 sec/step)
I0404 20:12:04.621920 47978602034560 learning.py:507] global step 750: loss = 7.9699 (0.502 sec/step)
I0404 20:12:05.139370 47978602034560 learning.py:507] global step 751: loss = 7.1631 (0.516 sec/step)
I0404 20:12:05.660581 47978602034560 learning.py:507] global step 752: loss = 9.7257 (0.518 sec/step)
I0404 20:12:06.169134 47978602034560 learning.py:507] global step 753: loss = 7.7463 (0.506 sec/step)
I0404 20:12:06.685244 47978602034560 learning.py:507] global step 754: loss = 7.5845 (0.515 sec/step)
I0404 20:12:07.217745 47978602034560 learning.py:507] global step 755: loss = 8.7892 (0.531 sec/step)
I0404 20:12:07.750596 47978602034560 learning.py:507] global step 756: loss = 6.5658 (0.531 sec/step)
I0404 20:12:08.257247 47978602034560 learning.py:507] global step 757: loss = 8.5485 (0.505 sec/step)
I0404 20:12:08.772417 47978602034560 learning.py:507] global step 758: loss = 7.6196 (0.512 sec/step)
I0404 20:12:09.274212 47978602034560 learning.py:507] global step 759: loss = 8.2756 (0.499 sec/step)
I0404 20:12:09.782391 47978602034560 learning.py:507] global step 760: loss = 7.2556 (0.507 sec/step)
I0404 20:12:10.315530 47978602034560 learning.py:507] global step 761: loss = 7.0466 (0.532 sec/step)
I0404 20:12:10.820741 47978602034560 learning.py:507] global step 762: loss = 8.3588 (0.504 sec/step)
I0404 20:12:11.333282 47978602034560 learning.py:507] global step 763: loss = 8.5740 (0.511 sec/step)
I0404 20:12:11.843454 47978602034560 learning.py:507] global step 764: loss = 8.1597 (0.509 sec/step)
I0404 20:12:12.351595 47978602034560 learning.py:507] global step 765: loss = 8.1653 (0.507 sec/step)
I0404 20:12:12.861162 47978602034560 learning.py:507] global step 766: loss = 7.3066 (0.508 sec/step)
I0404 20:12:13.372887 47978602034560 learning.py:507] global step 767: loss = 8.8129 (0.510 sec/step)
I0404 20:12:13.891287 47978602034560 learning.py:507] global step 768: loss = 7.7951 (0.517 sec/step)
I0404 20:12:14.408718 47978602034560 learning.py:507] global step 769: loss = 8.0581 (0.516 sec/step)
I0404 20:12:14.910620 47978602034560 learning.py:507] global step 770: loss = 8.2299 (0.500 sec/step)
I0404 20:12:15.413814 47978602034560 learning.py:507] global step 771: loss = 7.1343 (0.502 sec/step)
I0404 20:12:15.935339 47978602034560 learning.py:507] global step 772: loss = 9.0395 (0.520 sec/step)
I0404 20:12:16.445826 47978602034560 learning.py:507] global step 773: loss = 7.7264 (0.508 sec/step)
I0404 20:12:16.982106 47978602034560 learning.py:507] global step 774: loss = 8.8183 (0.535 sec/step)
I0404 20:12:17.499076 47978602034560 learning.py:507] global step 775: loss = 6.7908 (0.515 sec/step)
I0404 20:12:18.014763 47978602034560 learning.py:507] global step 776: loss = 7.5378 (0.514 sec/step)
I0404 20:12:18.521016 47978602034560 learning.py:507] global step 777: loss = 7.3452 (0.505 sec/step)
I0404 20:12:19.019340 47978602034560 learning.py:507] global step 778: loss = 8.9725 (0.497 sec/step)
I0404 20:12:19.547328 47978602034560 learning.py:507] global step 779: loss = 8.4495 (0.525 sec/step)
I0404 20:12:20.052724 47978602034560 learning.py:507] global step 780: loss = 8.1429 (0.504 sec/step)
I0404 20:12:20.565567 47978602034560 learning.py:507] global step 781: loss = 8.0180 (0.511 sec/step)
I0404 20:12:21.077027 47978602034560 learning.py:507] global step 782: loss = 8.2662 (0.510 sec/step)
I0404 20:12:21.585457 47978602034560 learning.py:507] global step 783: loss = 7.9492 (0.507 sec/step)
I0404 20:12:22.108198 47978602034560 learning.py:507] global step 784: loss = 7.4122 (0.520 sec/step)
I0404 20:12:22.622729 47978602034560 learning.py:507] global step 785: loss = 7.6934 (0.513 sec/step)
I0404 20:12:23.142702 47978602034560 learning.py:507] global step 786: loss = 9.0188 (0.518 sec/step)
I0404 20:12:23.651926 47978602034560 learning.py:507] global step 787: loss = 8.2026 (0.508 sec/step)
I0404 20:12:24.175302 47978602034560 learning.py:507] global step 788: loss = 7.5486 (0.521 sec/step)
I0404 20:12:24.682696 47978602034560 learning.py:507] global step 789: loss = 9.0933 (0.504 sec/step)
I0404 20:12:25.198116 47978602034560 learning.py:507] global step 790: loss = 7.2831 (0.513 sec/step)
I0404 20:12:25.707834 47978602034560 learning.py:507] global step 791: loss = 7.3958 (0.508 sec/step)
I0404 20:12:26.231419 47978602034560 learning.py:507] global step 792: loss = 7.3985 (0.522 sec/step)
I0404 20:12:26.763238 47978602034560 learning.py:507] global step 793: loss = 9.6768 (0.530 sec/step)
I0404 20:12:27.294178 47978602034560 learning.py:507] global step 794: loss = 6.7619 (0.529 sec/step)
I0404 20:12:27.812154 47978602034560 learning.py:507] global step 795: loss = 7.8203 (0.516 sec/step)
I0404 20:12:28.323645 47978602034560 learning.py:507] global step 796: loss = 7.2839 (0.510 sec/step)
I0404 20:12:28.837419 47978602034560 learning.py:507] global step 797: loss = 7.5189 (0.511 sec/step)
I0404 20:12:29.376452 47978602034560 learning.py:507] global step 798: loss = 8.2755 (0.537 sec/step)
I0404 20:12:29.886379 47978602034560 learning.py:507] global step 799: loss = 7.9629 (0.508 sec/step)
I0404 20:12:30.393721 47978602034560 learning.py:507] global step 800: loss = 7.7289 (0.506 sec/step)
I0404 20:12:30.898626 47978602034560 learning.py:507] global step 801: loss = 8.2073 (0.502 sec/step)
I0404 20:12:31.401420 47978602034560 learning.py:507] global step 802: loss = 8.4594 (0.501 sec/step)
I0404 20:12:31.934569 47978602034560 learning.py:507] global step 803: loss = 8.5598 (0.530 sec/step)
I0404 20:12:32.441379 47978602034560 learning.py:507] global step 804: loss = 7.4128 (0.505 sec/step)
I0404 20:12:32.953064 47978602034560 learning.py:507] global step 805: loss = 7.5544 (0.510 sec/step)
I0404 20:12:33.489187 47978602034560 learning.py:507] global step 806: loss = 9.2561 (0.535 sec/step)
I0404 20:12:34.027042 47978602034560 learning.py:507] global step 807: loss = 6.8451 (0.536 sec/step)
I0404 20:12:34.532723 47978602034560 learning.py:507] global step 808: loss = 7.9009 (0.504 sec/step)
I0404 20:12:35.043035 47978602034560 learning.py:507] global step 809: loss = 7.8792 (0.509 sec/step)
I0404 20:12:35.546427 47978602034560 learning.py:507] global step 810: loss = 6.8141 (0.501 sec/step)
I0404 20:12:36.071258 47978602034560 learning.py:507] global step 811: loss = 7.2758 (0.523 sec/step)
I0404 20:12:36.583513 47978602034560 learning.py:507] global step 812: loss = 7.4025 (0.511 sec/step)
I0404 20:12:37.123014 47978602034560 learning.py:507] global step 813: loss = 6.8717 (0.538 sec/step)
I0404 20:12:37.639310 47978602034560 learning.py:507] global step 814: loss = 7.7127 (0.515 sec/step)
I0404 20:12:38.162161 47978602034560 learning.py:507] global step 815: loss = 7.2555 (0.521 sec/step)
I0404 20:12:38.674159 47978602034560 learning.py:507] global step 816: loss = 7.6310 (0.510 sec/step)
I0404 20:12:39.179195 47978602034560 learning.py:507] global step 817: loss = 6.9358 (0.503 sec/step)
I0404 20:12:39.685123 47978602034560 learning.py:507] global step 818: loss = 7.7570 (0.504 sec/step)
I0404 20:12:40.190844 47978602034560 learning.py:507] global step 819: loss = 7.5258 (0.504 sec/step)
I0404 20:12:40.694151 47978602034560 learning.py:507] global step 820: loss = 6.8444 (0.502 sec/step)
I0404 20:12:41.205234 47978602034560 learning.py:507] global step 821: loss = 6.7692 (0.508 sec/step)
I0404 20:12:41.722715 47978602034560 learning.py:507] global step 822: loss = 7.8411 (0.516 sec/step)
I0404 20:12:42.248032 47978602034560 learning.py:507] global step 823: loss = 7.6514 (0.524 sec/step)
I0404 20:12:42.757299 47978602034560 learning.py:507] global step 824: loss = 6.7998 (0.506 sec/step)
I0404 20:12:43.282050 47978602034560 learning.py:507] global step 825: loss = 7.7053 (0.523 sec/step)
I0404 20:12:43.795375 47978602034560 learning.py:507] global step 826: loss = 7.5759 (0.512 sec/step)
I0404 20:12:44.331117 47978602034560 learning.py:507] global step 827: loss = 7.2585 (0.534 sec/step)
I0404 20:12:44.843930 47978602034560 learning.py:507] global step 828: loss = 7.2908 (0.511 sec/step)
I0404 20:12:45.355311 47978602034560 learning.py:507] global step 829: loss = 7.4525 (0.510 sec/step)
I0404 20:12:45.867119 47978602034560 learning.py:507] global step 830: loss = 8.3380 (0.510 sec/step)
I0404 20:12:46.398355 47978602034560 learning.py:507] global step 831: loss = 7.7492 (0.529 sec/step)
I0404 20:12:46.906056 47978602034560 learning.py:507] global step 832: loss = 6.4855 (0.506 sec/step)
I0404 20:12:47.417531 47978602034560 learning.py:507] global step 833: loss = 7.1889 (0.510 sec/step)
I0404 20:12:47.948442 47978602034560 learning.py:507] global step 834: loss = 7.4936 (0.529 sec/step)
I0404 20:12:48.452672 47978602034560 learning.py:507] global step 835: loss = 7.2848 (0.503 sec/step)
I0404 20:12:48.989027 47978602034560 learning.py:507] global step 836: loss = 7.4108 (0.535 sec/step)
I0404 20:12:49.495776 47978602034560 learning.py:507] global step 837: loss = 7.4290 (0.505 sec/step)
I0404 20:12:49.999467 47978602034560 learning.py:507] global step 838: loss = 6.9148 (0.502 sec/step)
I0404 20:12:50.534486 47978602034560 learning.py:507] global step 839: loss = 7.9394 (0.533 sec/step)
I0404 20:12:51.038267 47978602034560 learning.py:507] global step 840: loss = 7.0219 (0.502 sec/step)
I0404 20:12:51.557116 47978602034560 learning.py:507] global step 841: loss = 8.2708 (0.517 sec/step)
I0404 20:12:52.079464 47978602034560 learning.py:507] global step 842: loss = 6.9555 (0.521 sec/step)
I0404 20:12:52.591440 47978602034560 learning.py:507] global step 843: loss = 7.8451 (0.509 sec/step)
I0404 20:12:53.101789 47978602034560 learning.py:507] global step 844: loss = 8.6833 (0.509 sec/step)
I0404 20:12:53.602076 47978602034560 learning.py:507] global step 845: loss = 7.0170 (0.497 sec/step)
I0404 20:12:54.119515 47978602034560 learning.py:507] global step 846: loss = 7.4553 (0.516 sec/step)
I0404 20:12:54.645778 47978602034560 learning.py:507] global step 847: loss = 7.7584 (0.525 sec/step)
I0404 20:12:55.174285 47978602034560 learning.py:507] global step 848: loss = 6.7512 (0.527 sec/step)
I0404 20:12:55.716982 47978602034560 learning.py:507] global step 849: loss = 7.9792 (0.538 sec/step)
I0404 20:12:56.225386 47978602034560 learning.py:507] global step 850: loss = 6.7652 (0.506 sec/step)
I0404 20:12:56.744239 47978602034560 learning.py:507] global step 851: loss = 8.0681 (0.517 sec/step)
I0404 20:12:57.256717 47978602034560 learning.py:507] global step 852: loss = 6.9122 (0.510 sec/step)
I0404 20:12:57.782624 47978602034560 learning.py:507] global step 853: loss = 7.9852 (0.524 sec/step)
I0404 20:12:58.288893 47978602034560 learning.py:507] global step 854: loss = 7.1065 (0.505 sec/step)
I0404 20:12:58.797180 47978602034560 learning.py:507] global step 855: loss = 6.5446 (0.507 sec/step)
I0404 20:12:59.328383 47978602034560 learning.py:507] global step 856: loss = 8.4008 (0.530 sec/step)
I0404 20:12:59.837879 47978602034560 learning.py:507] global step 857: loss = 6.9771 (0.508 sec/step)
I0404 20:13:00.342377 47978602034560 learning.py:507] global step 858: loss = 6.6658 (0.503 sec/step)
I0404 20:13:00.843986 47978602034560 learning.py:507] global step 859: loss = 7.5820 (0.500 sec/step)
I0404 20:13:01.352606 47978602034560 learning.py:507] global step 860: loss = 8.0615 (0.507 sec/step)
I0404 20:13:01.861935 47978602034560 learning.py:507] global step 861: loss = 8.8381 (0.506 sec/step)
I0404 20:13:02.400343 47978602034560 learning.py:507] global step 862: loss = 8.2637 (0.537 sec/step)
I0404 20:13:02.907313 47978602034560 learning.py:507] global step 863: loss = 6.8491 (0.505 sec/step)
I0404 20:13:03.413236 47978602034560 learning.py:507] global step 864: loss = 8.3057 (0.503 sec/step)
I0404 20:13:03.920372 47978602034560 learning.py:507] global step 865: loss = 8.2117 (0.506 sec/step)
I0404 20:13:04.432751 47978602034560 learning.py:507] global step 866: loss = 8.9088 (0.509 sec/step)
I0404 20:13:04.960546 47978602034560 learning.py:507] global step 867: loss = 7.3388 (0.525 sec/step)
I0404 20:13:05.481006 47978602034560 learning.py:507] global step 868: loss = 7.7805 (0.519 sec/step)
I0404 20:13:05.988293 47978602034560 learning.py:507] global step 869: loss = 7.7490 (0.506 sec/step)
I0404 20:13:06.493321 47978602034560 learning.py:507] global step 870: loss = 7.9375 (0.504 sec/step)
I0404 20:13:07.028772 47978602034560 learning.py:507] global step 871: loss = 7.3927 (0.534 sec/step)
I0404 20:13:07.536922 47978602034560 learning.py:507] global step 872: loss = 8.1388 (0.507 sec/step)
I0404 20:13:08.078836 47978602034560 learning.py:507] global step 873: loss = 8.1146 (0.539 sec/step)
I0404 20:13:08.595840 47978602034560 learning.py:507] global step 874: loss = 6.6843 (0.515 sec/step)
I0404 20:13:09.103382 47978602034560 learning.py:507] global step 875: loss = 8.3090 (0.506 sec/step)
I0404 20:13:09.615430 47978602034560 learning.py:507] global step 876: loss = 7.0338 (0.509 sec/step)
I0404 20:13:10.142720 47978602034560 learning.py:507] global step 877: loss = 7.4106 (0.526 sec/step)
I0404 20:13:10.654521 47978602034560 learning.py:507] global step 878: loss = 7.6338 (0.510 sec/step)
I0404 20:13:11.165938 47978602034560 learning.py:507] global step 879: loss = 7.7850 (0.510 sec/step)
I0404 20:13:11.680140 47978602034560 learning.py:507] global step 880: loss = 7.5171 (0.513 sec/step)
I0404 20:13:12.185384 47978602034560 learning.py:507] global step 881: loss = 7.9374 (0.502 sec/step)
I0404 20:13:12.736720 47978602034560 learning.py:507] global step 882: loss = 7.2584 (0.550 sec/step)
I0404 20:13:13.250139 47978602034560 learning.py:507] global step 883: loss = 8.2469 (0.512 sec/step)
I0404 20:13:13.767665 47978602034560 learning.py:507] global step 884: loss = 7.9005 (0.516 sec/step)
I0404 20:13:14.279056 47978602034560 learning.py:507] global step 885: loss = 7.4867 (0.510 sec/step)
I0404 20:13:14.781835 47978602034560 learning.py:507] global step 886: loss = 7.9542 (0.501 sec/step)
I0404 20:13:15.295090 47978602034560 learning.py:507] global step 887: loss = 7.9233 (0.512 sec/step)
I0404 20:13:15.804650 47978602034560 learning.py:507] global step 888: loss = 7.7740 (0.508 sec/step)
I0404 20:13:16.322095 47978602034560 learning.py:507] global step 889: loss = 7.7061 (0.516 sec/step)
I0404 20:13:16.637259 47983664076544 supervisor.py:1099] global_step/sec: 1.93333
I0404 20:13:16.853007 47978602034560 learning.py:507] global step 890: loss = 6.6886 (0.504 sec/step)
I0404 20:13:17.205637 47983661975296 supervisor.py:1050] Recording summary at step 890.
I0404 20:13:17.526749 47978602034560 learning.py:507] global step 891: loss = 8.2410 (0.672 sec/step)
I0404 20:13:18.035534 47978602034560 learning.py:507] global step 892: loss = 7.1152 (0.507 sec/step)
I0404 20:13:18.562495 47978602034560 learning.py:507] global step 893: loss = 7.6421 (0.525 sec/step)
I0404 20:13:19.074495 47978602034560 learning.py:507] global step 894: loss = 6.2148 (0.510 sec/step)
I0404 20:13:19.593087 47978602034560 learning.py:507] global step 895: loss = 7.5758 (0.517 sec/step)
I0404 20:13:20.099767 47978602034560 learning.py:507] global step 896: loss = 7.8073 (0.505 sec/step)
I0404 20:13:20.632436 47978602034560 learning.py:507] global step 897: loss = 7.5067 (0.531 sec/step)
I0404 20:13:21.143760 47978602034560 learning.py:507] global step 898: loss = 7.5894 (0.510 sec/step)
I0404 20:13:21.653125 47978602034560 learning.py:507] global step 899: loss = 7.4473 (0.508 sec/step)
I0404 20:13:22.180453 47978602034560 learning.py:507] global step 900: loss = 7.9326 (0.524 sec/step)
I0404 20:13:22.711908 47978602034560 learning.py:507] global step 901: loss = 7.0686 (0.529 sec/step)
I0404 20:13:23.217088 47978602034560 learning.py:507] global step 902: loss = 7.5117 (0.504 sec/step)
I0404 20:13:23.754711 47978602034560 learning.py:507] global step 903: loss = 7.4797 (0.536 sec/step)
I0404 20:13:24.257143 47978602034560 learning.py:507] global step 904: loss = 7.9299 (0.501 sec/step)
I0404 20:13:24.782463 47978602034560 learning.py:507] global step 905: loss = 7.9210 (0.524 sec/step)
I0404 20:13:25.333434 47978602034560 learning.py:507] global step 906: loss = 7.6069 (0.549 sec/step)
I0404 20:13:25.856323 47978602034560 learning.py:507] global step 907: loss = 8.0094 (0.521 sec/step)
I0404 20:13:26.358948 47978602034560 learning.py:507] global step 908: loss = 7.7175 (0.501 sec/step)
I0404 20:13:26.870834 47978602034560 learning.py:507] global step 909: loss = 7.7572 (0.510 sec/step)
I0404 20:13:27.388619 47978602034560 learning.py:507] global step 910: loss = 6.9626 (0.516 sec/step)
I0404 20:13:27.909342 47978602034560 learning.py:507] global step 911: loss = 6.3529 (0.519 sec/step)
I0404 20:13:28.418462 47978602034560 learning.py:507] global step 912: loss = 7.5897 (0.506 sec/step)
I0404 20:13:28.934000 47978602034560 learning.py:507] global step 913: loss = 6.9688 (0.514 sec/step)
I0404 20:13:29.434538 47978602034560 learning.py:507] global step 914: loss = 6.0649 (0.499 sec/step)
I0404 20:13:29.948501 47978602034560 learning.py:507] global step 915: loss = 8.3495 (0.512 sec/step)
I0404 20:13:30.450669 47978602034560 learning.py:507] global step 916: loss = 7.4046 (0.501 sec/step)
I0404 20:13:30.959485 47978602034560 learning.py:507] global step 917: loss = 6.8651 (0.506 sec/step)
I0404 20:13:31.491401 47978602034560 learning.py:507] global step 918: loss = 7.5159 (0.529 sec/step)
I0404 20:13:31.992402 47978602034560 learning.py:507] global step 919: loss = 7.3317 (0.499 sec/step)
I0404 20:13:32.538100 47978602034560 learning.py:507] global step 920: loss = 7.1872 (0.543 sec/step)
I0404 20:13:33.047970 47978602034560 learning.py:507] global step 921: loss = 7.3262 (0.508 sec/step)
I0404 20:13:33.568304 47978602034560 learning.py:507] global step 922: loss = 7.5132 (0.519 sec/step)
I0404 20:13:34.080299 47978602034560 learning.py:507] global step 923: loss = 7.0752 (0.509 sec/step)
I0404 20:13:34.614140 47978602034560 learning.py:507] global step 924: loss = 6.9566 (0.531 sec/step)
I0404 20:13:35.134443 47978602034560 learning.py:507] global step 925: loss = 6.9533 (0.519 sec/step)
I0404 20:13:35.646539 47978602034560 learning.py:507] global step 926: loss = 7.1613 (0.509 sec/step)
I0404 20:13:36.159782 47978602034560 learning.py:507] global step 927: loss = 8.2802 (0.510 sec/step)
I0404 20:13:36.697030 47978602034560 learning.py:507] global step 928: loss = 8.1814 (0.536 sec/step)
I0404 20:13:37.226364 47978602034560 learning.py:507] global step 929: loss = 6.6805 (0.528 sec/step)
I0404 20:13:37.739387 47978602034560 learning.py:507] global step 930: loss = 7.5792 (0.511 sec/step)
I0404 20:13:38.252612 47978602034560 learning.py:507] global step 931: loss = 6.8193 (0.510 sec/step)
I0404 20:13:38.771920 47978602034560 learning.py:507] global step 932: loss = 7.4562 (0.518 sec/step)
I0404 20:13:39.284573 47978602034560 learning.py:507] global step 933: loss = 9.4258 (0.511 sec/step)
I0404 20:13:39.799120 47978602034560 learning.py:507] global step 934: loss = 6.8687 (0.513 sec/step)
I0404 20:13:40.312811 47978602034560 learning.py:507] global step 935: loss = 7.0290 (0.512 sec/step)
I0404 20:13:40.821520 47978602034560 learning.py:507] global step 936: loss = 7.1016 (0.507 sec/step)
I0404 20:13:41.334781 47978602034560 learning.py:507] global step 937: loss = 7.4621 (0.512 sec/step)
I0404 20:13:41.841936 47978602034560 learning.py:507] global step 938: loss = 7.5906 (0.505 sec/step)
I0404 20:13:42.369448 47978602034560 learning.py:507] global step 939: loss = 7.1484 (0.525 sec/step)
I0404 20:13:42.882420 47978602034560 learning.py:507] global step 940: loss = 6.4442 (0.511 sec/step)
I0404 20:13:43.391001 47978602034560 learning.py:507] global step 941: loss = 7.0405 (0.507 sec/step)
I0404 20:13:43.893964 47978602034560 learning.py:507] global step 942: loss = 8.4128 (0.500 sec/step)
I0404 20:13:44.408709 47978602034560 learning.py:507] global step 943: loss = 8.5872 (0.513 sec/step)
I0404 20:13:44.915462 47978602034560 learning.py:507] global step 944: loss = 7.7692 (0.505 sec/step)
I0404 20:13:45.424034 47978602034560 learning.py:507] global step 945: loss = 7.3444 (0.507 sec/step)
I0404 20:13:45.929300 47978602034560 learning.py:507] global step 946: loss = 8.4485 (0.504 sec/step)
I0404 20:13:46.438793 47978602034560 learning.py:507] global step 947: loss = 7.0054 (0.508 sec/step)
I0404 20:13:46.955828 47978602034560 learning.py:507] global step 948: loss = 8.0840 (0.515 sec/step)
I0404 20:13:47.463625 47978602034560 learning.py:507] global step 949: loss = 7.9499 (0.506 sec/step)
I0404 20:13:47.972169 47978602034560 learning.py:507] global step 950: loss = 7.1469 (0.507 sec/step)
I0404 20:13:48.501330 47978602034560 learning.py:507] global step 951: loss = 8.0991 (0.528 sec/step)
I0404 20:13:49.023804 47978602034560 learning.py:507] global step 952: loss = 7.8343 (0.521 sec/step)
I0404 20:13:49.531520 47978602034560 learning.py:507] global step 953: loss = 7.2699 (0.506 sec/step)
I0404 20:13:50.038551 47978602034560 learning.py:507] global step 954: loss = 7.7972 (0.505 sec/step)
I0404 20:13:50.576392 47978602034560 learning.py:507] global step 955: loss = 6.9791 (0.536 sec/step)
I0404 20:13:51.077557 47978602034560 learning.py:507] global step 956: loss = 6.8284 (0.500 sec/step)
I0404 20:13:51.582214 47978602034560 learning.py:507] global step 957: loss = 6.6976 (0.503 sec/step)
I0404 20:13:52.086807 47978602034560 learning.py:507] global step 958: loss = 7.3120 (0.503 sec/step)
I0404 20:13:52.624876 47978602034560 learning.py:507] global step 959: loss = 7.5877 (0.535 sec/step)
I0404 20:13:53.131246 47978602034560 learning.py:507] global step 960: loss = 6.3824 (0.505 sec/step)
I0404 20:13:53.656653 47978602034560 learning.py:507] global step 961: loss = 9.0907 (0.524 sec/step)
I0404 20:13:54.192642 47978602034560 learning.py:507] global step 962: loss = 7.6033 (0.533 sec/step)
I0404 20:13:54.710990 47978602034560 learning.py:507] global step 963: loss = 7.2188 (0.517 sec/step)
I0404 20:13:55.232516 47978602034560 learning.py:507] global step 964: loss = 7.9513 (0.520 sec/step)
I0404 20:13:55.753069 47978602034560 learning.py:507] global step 965: loss = 7.1179 (0.518 sec/step)
I0404 20:13:56.263026 47978602034560 learning.py:507] global step 966: loss = 6.6723 (0.508 sec/step)
I0404 20:13:56.770866 47978602034560 learning.py:507] global step 967: loss = 8.3032 (0.505 sec/step)
I0404 20:13:57.290075 47978602034560 learning.py:507] global step 968: loss = 8.5479 (0.518 sec/step)
I0404 20:13:57.792801 47978602034560 learning.py:507] global step 969: loss = 8.6201 (0.501 sec/step)
I0404 20:13:58.303598 47978602034560 learning.py:507] global step 970: loss = 7.6854 (0.508 sec/step)
I0404 20:13:58.831079 47978602034560 learning.py:507] global step 971: loss = 8.4579 (0.526 sec/step)
I0404 20:13:59.355518 47978602034560 learning.py:507] global step 972: loss = 6.8468 (0.523 sec/step)
I0404 20:13:59.888523 47978602034560 learning.py:507] global step 973: loss = 7.1008 (0.530 sec/step)
I0404 20:14:00.391866 47978602034560 learning.py:507] global step 974: loss = 6.5824 (0.502 sec/step)
I0404 20:14:00.904867 47978602034560 learning.py:507] global step 975: loss = 7.9871 (0.511 sec/step)
I0404 20:14:01.433938 47978602034560 learning.py:507] global step 976: loss = 7.6697 (0.527 sec/step)
I0404 20:14:01.953741 47978602034560 learning.py:507] global step 977: loss = 7.5565 (0.518 sec/step)
I0404 20:14:02.483444 47978602034560 learning.py:507] global step 978: loss = 7.9491 (0.528 sec/step)
I0404 20:14:03.014230 47978602034560 learning.py:507] global step 979: loss = 7.1478 (0.529 sec/step)
I0404 20:14:03.523764 47978602034560 learning.py:507] global step 980: loss = 7.8330 (0.507 sec/step)
I0404 20:14:04.035725 47978602034560 learning.py:507] global step 981: loss = 7.0675 (0.510 sec/step)
I0404 20:14:04.542537 47978602034560 learning.py:507] global step 982: loss = 7.5553 (0.505 sec/step)
I0404 20:14:05.053675 47978602034560 learning.py:507] global step 983: loss = 6.9510 (0.510 sec/step)
I0404 20:14:05.564465 47978602034560 learning.py:507] global step 984: loss = 7.8130 (0.509 sec/step)
I0404 20:14:06.099278 47978602034560 learning.py:507] global step 985: loss = 6.6044 (0.532 sec/step)
I0404 20:14:06.615278 47978602034560 learning.py:507] global step 986: loss = 6.8025 (0.513 sec/step)
I0404 20:14:07.123331 47978602034560 learning.py:507] global step 987: loss = 7.4727 (0.505 sec/step)
I0404 20:14:07.636846 47978602034560 learning.py:507] global step 988: loss = 7.7769 (0.511 sec/step)
I0404 20:14:08.154188 47978602034560 learning.py:507] global step 989: loss = 7.2547 (0.516 sec/step)
I0404 20:14:08.664088 47978602034560 learning.py:507] global step 990: loss = 7.5956 (0.508 sec/step)
I0404 20:14:09.185320 47978602034560 learning.py:507] global step 991: loss = 7.6432 (0.520 sec/step)
I0404 20:14:09.708482 47978602034560 learning.py:507] global step 992: loss = 7.8850 (0.522 sec/step)
I0404 20:14:10.215606 47978602034560 learning.py:507] global step 993: loss = 6.7786 (0.505 sec/step)
I0404 20:14:10.723316 47978602034560 learning.py:507] global step 994: loss = 6.8368 (0.506 sec/step)
I0404 20:14:11.261725 47978602034560 learning.py:507] global step 995: loss = 7.7554 (0.537 sec/step)
I0404 20:14:11.768106 47978602034560 learning.py:507] global step 996: loss = 7.3579 (0.503 sec/step)
I0404 20:14:12.276523 47978602034560 learning.py:507] global step 997: loss = 7.3695 (0.507 sec/step)
I0404 20:14:12.790811 47978602034560 learning.py:507] global step 998: loss = 8.3135 (0.513 sec/step)
I0404 20:14:13.312705 47978602034560 learning.py:507] global step 999: loss = 9.5928 (0.520 sec/step)
I0404 20:14:13.825635 47978602034560 learning.py:507] global step 1000: loss = 7.8899 (0.510 sec/step)
I0404 20:14:14.333253 47978602034560 learning.py:507] global step 1001: loss = 7.1878 (0.505 sec/step)
I0404 20:14:14.842873 47978602034560 learning.py:507] global step 1002: loss = 6.9811 (0.508 sec/step)
I0404 20:14:15.358460 47978602034560 learning.py:507] global step 1003: loss = 6.3334 (0.514 sec/step)
I0404 20:14:15.871107 47978602034560 learning.py:507] global step 1004: loss = 7.7379 (0.511 sec/step)
I0404 20:14:16.399761 47978602034560 learning.py:507] global step 1005: loss = 7.1345 (0.527 sec/step)
I0404 20:14:16.938009 47978602034560 learning.py:507] global step 1006: loss = 7.7304 (0.537 sec/step)
I0404 20:14:17.440075 47978602034560 learning.py:507] global step 1007: loss = 7.4749 (0.500 sec/step)
I0404 20:14:17.936747 47978602034560 learning.py:507] global step 1008: loss = 8.8497 (0.495 sec/step)
I0404 20:14:18.462393 47978602034560 learning.py:507] global step 1009: loss = 6.5834 (0.524 sec/step)
I0404 20:14:18.968436 47978602034560 learning.py:507] global step 1010: loss = 6.4017 (0.504 sec/step)
I0404 20:14:19.479706 47978602034560 learning.py:507] global step 1011: loss = 6.4061 (0.510 sec/step)
I0404 20:14:20.010534 47978602034560 learning.py:507] global step 1012: loss = 7.2002 (0.529 sec/step)
I0404 20:14:20.514809 47978602034560 learning.py:507] global step 1013: loss = 7.4507 (0.503 sec/step)
I0404 20:14:21.020843 47978602034560 learning.py:507] global step 1014: loss = 7.7428 (0.504 sec/step)
I0404 20:14:21.523843 47978602034560 learning.py:507] global step 1015: loss = 6.9735 (0.501 sec/step)
I0404 20:14:22.043256 47978602034560 learning.py:507] global step 1016: loss = 7.5262 (0.518 sec/step)
I0404 20:14:22.577252 47978602034560 learning.py:507] global step 1017: loss = 7.6070 (0.531 sec/step)
I0404 20:14:23.092962 47978602034560 learning.py:507] global step 1018: loss = 7.8140 (0.514 sec/step)
I0404 20:14:23.624696 47978602034560 learning.py:507] global step 1019: loss = 7.8370 (0.530 sec/step)
I0404 20:14:24.137363 47978602034560 learning.py:507] global step 1020: loss = 7.7128 (0.511 sec/step)
I0404 20:14:24.648487 47978602034560 learning.py:507] global step 1021: loss = 7.8985 (0.510 sec/step)
I0404 20:14:25.187985 47978602034560 learning.py:507] global step 1022: loss = 6.8105 (0.538 sec/step)
I0404 20:14:25.700862 47978602034560 learning.py:507] global step 1023: loss = 7.1337 (0.511 sec/step)
I0404 20:14:26.210406 47978602034560 learning.py:507] global step 1024: loss = 7.3472 (0.508 sec/step)
I0404 20:14:26.726786 47978602034560 learning.py:507] global step 1025: loss = 7.8090 (0.515 sec/step)
I0404 20:14:27.253445 47978602034560 learning.py:507] global step 1026: loss = 7.7116 (0.524 sec/step)
I0404 20:14:27.765213 47978602034560 learning.py:507] global step 1027: loss = 7.1811 (0.510 sec/step)
I0404 20:14:28.276306 47978602034560 learning.py:507] global step 1028: loss = 7.0522 (0.509 sec/step)
I0404 20:14:28.784047 47978602034560 learning.py:507] global step 1029: loss = 6.5331 (0.506 sec/step)
I0404 20:14:29.314847 47978602034560 learning.py:507] global step 1030: loss = 8.2553 (0.528 sec/step)
I0404 20:14:29.845453 47978602034560 learning.py:507] global step 1031: loss = 7.7162 (0.529 sec/step)
I0404 20:14:30.350629 47978602034560 learning.py:507] global step 1032: loss = 8.1441 (0.504 sec/step)
I0404 20:14:30.870019 47978602034560 learning.py:507] global step 1033: loss = 7.3760 (0.518 sec/step)
I0404 20:14:31.379986 47978602034560 learning.py:507] global step 1034: loss = 6.4698 (0.508 sec/step)
I0404 20:14:31.917936 47978602034560 learning.py:507] global step 1035: loss = 6.6887 (0.536 sec/step)
I0404 20:14:32.450955 47978602034560 learning.py:507] global step 1036: loss = 6.2070 (0.531 sec/step)
I0404 20:14:32.951996 47978602034560 learning.py:507] global step 1037: loss = 6.0979 (0.499 sec/step)
I0404 20:14:33.490509 47978602034560 learning.py:507] global step 1038: loss = 6.4524 (0.537 sec/step)
I0404 20:14:34.005079 47978602034560 learning.py:507] global step 1039: loss = 7.7076 (0.513 sec/step)
I0404 20:14:34.520943 47978602034560 learning.py:507] global step 1040: loss = 7.1283 (0.513 sec/step)
I0404 20:14:35.050458 47978602034560 learning.py:507] global step 1041: loss = 7.2477 (0.528 sec/step)
I0404 20:14:35.572309 47978602034560 learning.py:507] global step 1042: loss = 6.2549 (0.520 sec/step)
I0404 20:14:36.078758 47978602034560 learning.py:507] global step 1043: loss = 8.5735 (0.505 sec/step)
I0404 20:14:36.609495 47978602034560 learning.py:507] global step 1044: loss = 7.0872 (0.529 sec/step)
I0404 20:14:37.112151 47978602034560 learning.py:507] global step 1045: loss = 6.5667 (0.500 sec/step)
I0404 20:14:37.632052 47978602034560 learning.py:507] global step 1046: loss = 6.9992 (0.518 sec/step)
I0404 20:14:38.158391 47978602034560 learning.py:507] global step 1047: loss = 7.6974 (0.525 sec/step)
I0404 20:14:38.677878 47978602034560 learning.py:507] global step 1048: loss = 7.2252 (0.518 sec/step)
I0404 20:14:39.191226 47978602034560 learning.py:507] global step 1049: loss = 7.2233 (0.512 sec/step)
I0404 20:14:39.694600 47978602034560 learning.py:507] global step 1050: loss = 6.4023 (0.502 sec/step)
I0404 20:14:40.223908 47978602034560 learning.py:507] global step 1051: loss = 6.6831 (0.528 sec/step)
I0404 20:14:40.762485 47978602034560 learning.py:507] global step 1052: loss = 7.4439 (0.536 sec/step)
I0404 20:14:41.279664 47978602034560 learning.py:507] global step 1053: loss = 7.2191 (0.516 sec/step)
I0404 20:14:41.807792 47978602034560 learning.py:507] global step 1054: loss = 6.5507 (0.526 sec/step)
I0404 20:14:42.339046 47978602034560 learning.py:507] global step 1055: loss = 6.8660 (0.530 sec/step)
I0404 20:14:42.844538 47978602034560 learning.py:507] global step 1056: loss = 8.0234 (0.504 sec/step)
I0404 20:14:43.346453 47978602034560 learning.py:507] global step 1057: loss = 6.5258 (0.500 sec/step)
I0404 20:14:43.855113 47978602034560 learning.py:507] global step 1058: loss = 7.2523 (0.507 sec/step)
I0404 20:14:44.389415 47978602034560 learning.py:507] global step 1059: loss = 6.7365 (0.531 sec/step)
I0404 20:14:44.897576 47978602034560 learning.py:507] global step 1060: loss = 6.9178 (0.507 sec/step)
I0404 20:14:45.419158 47978602034560 learning.py:507] global step 1061: loss = 6.4269 (0.520 sec/step)
I0404 20:14:45.943431 47978602034560 learning.py:507] global step 1062: loss = 6.1182 (0.523 sec/step)
I0404 20:14:46.455634 47978602034560 learning.py:507] global step 1063: loss = 8.1323 (0.511 sec/step)
I0404 20:14:46.965211 47978602034560 learning.py:507] global step 1064: loss = 8.7370 (0.507 sec/step)
I0404 20:14:47.475658 47978602034560 learning.py:507] global step 1065: loss = 7.3393 (0.509 sec/step)
I0404 20:14:47.986412 47978602034560 learning.py:507] global step 1066: loss = 7.4627 (0.509 sec/step)
I0404 20:14:48.496978 47978602034560 learning.py:507] global step 1067: loss = 8.0175 (0.509 sec/step)
I0404 20:14:48.999388 47978602034560 learning.py:507] global step 1068: loss = 6.7942 (0.501 sec/step)
I0404 20:14:49.509147 47978602034560 learning.py:507] global step 1069: loss = 7.5067 (0.508 sec/step)
I0404 20:14:50.030373 47978602034560 learning.py:507] global step 1070: loss = 7.2431 (0.520 sec/step)
I0404 20:14:50.563145 47978602034560 learning.py:507] global step 1071: loss = 7.0653 (0.531 sec/step)
I0404 20:14:51.075690 47978602034560 learning.py:507] global step 1072: loss = 7.1201 (0.510 sec/step)
I0404 20:14:51.587288 47978602034560 learning.py:507] global step 1073: loss = 6.1093 (0.510 sec/step)
I0404 20:14:52.096710 47978602034560 learning.py:507] global step 1074: loss = 8.4027 (0.508 sec/step)
I0404 20:14:52.601272 47978602034560 learning.py:507] global step 1075: loss = 6.9718 (0.503 sec/step)
I0404 20:14:53.116136 47978602034560 learning.py:507] global step 1076: loss = 8.0675 (0.513 sec/step)
I0404 20:14:53.657368 47978602034560 learning.py:507] global step 1077: loss = 6.5316 (0.538 sec/step)
I0404 20:14:54.190705 47978602034560 learning.py:507] global step 1078: loss = 6.5380 (0.532 sec/step)
I0404 20:14:54.701862 47978602034560 learning.py:507] global step 1079: loss = 7.9689 (0.509 sec/step)
I0404 20:14:55.221888 47978602034560 learning.py:507] global step 1080: loss = 6.9570 (0.517 sec/step)
I0404 20:14:55.734222 47978602034560 learning.py:507] global step 1081: loss = 6.2941 (0.511 sec/step)
I0404 20:14:56.264985 47978602034560 learning.py:507] global step 1082: loss = 6.9922 (0.529 sec/step)
I0404 20:14:56.771826 47978602034560 learning.py:507] global step 1083: loss = 7.1774 (0.505 sec/step)
I0404 20:14:57.278159 47978602034560 learning.py:507] global step 1084: loss = 6.1458 (0.505 sec/step)
I0404 20:14:57.815379 47978602034560 learning.py:507] global step 1085: loss = 7.4166 (0.536 sec/step)
I0404 20:14:58.324593 47978602034560 learning.py:507] global step 1086: loss = 7.8666 (0.508 sec/step)
I0404 20:14:58.830855 47978602034560 learning.py:507] global step 1087: loss = 7.1330 (0.503 sec/step)
I0404 20:14:59.361341 47978602034560 learning.py:507] global step 1088: loss = 7.8590 (0.529 sec/step)
I0404 20:14:59.881107 47978602034560 learning.py:507] global step 1089: loss = 6.3698 (0.518 sec/step)
I0404 20:15:00.393530 47978602034560 learning.py:507] global step 1090: loss = 7.7416 (0.511 sec/step)
I0404 20:15:00.915152 47978602034560 learning.py:507] global step 1091: loss = 7.6027 (0.520 sec/step)
I0404 20:15:01.443611 47978602034560 learning.py:507] global step 1092: loss = 5.8852 (0.527 sec/step)
I0404 20:15:01.950723 47978602034560 learning.py:507] global step 1093: loss = 7.8919 (0.506 sec/step)
I0404 20:15:02.460211 47978602034560 learning.py:507] global step 1094: loss = 7.0042 (0.508 sec/step)
I0404 20:15:02.976127 47978602034560 learning.py:507] global step 1095: loss = 8.0738 (0.514 sec/step)
I0404 20:15:03.483467 47978602034560 learning.py:507] global step 1096: loss = 7.6288 (0.504 sec/step)
I0404 20:15:04.004130 47978602034560 learning.py:507] global step 1097: loss = 6.6065 (0.518 sec/step)
I0404 20:15:04.525668 47978602034560 learning.py:507] global step 1098: loss = 6.2583 (0.520 sec/step)
I0404 20:15:05.037287 47978602034560 learning.py:507] global step 1099: loss = 8.7249 (0.510 sec/step)
I0404 20:15:05.551438 47978602034560 learning.py:507] global step 1100: loss = 6.6503 (0.513 sec/step)
I0404 20:15:06.068803 47978602034560 learning.py:507] global step 1101: loss = 7.6314 (0.516 sec/step)
I0404 20:15:06.583837 47978602034560 learning.py:507] global step 1102: loss = 7.2919 (0.513 sec/step)
I0404 20:15:07.096929 47978602034560 learning.py:507] global step 1103: loss = 7.7533 (0.512 sec/step)
I0404 20:15:07.613983 47978602034560 learning.py:507] global step 1104: loss = 7.1608 (0.515 sec/step)
I0404 20:15:08.117709 47978602034560 learning.py:507] global step 1105: loss = 6.2533 (0.502 sec/step)
I0404 20:15:08.619807 47978602034560 learning.py:507] global step 1106: loss = 7.6819 (0.500 sec/step)
I0404 20:15:09.134275 47978602034560 learning.py:507] global step 1107: loss = 6.9100 (0.513 sec/step)
I0404 20:15:09.647558 47978602034560 learning.py:507] global step 1108: loss = 7.8686 (0.512 sec/step)
I0404 20:15:10.147738 47978602034560 learning.py:507] global step 1109: loss = 8.0855 (0.499 sec/step)
I0404 20:15:10.672378 47978602034560 learning.py:507] global step 1110: loss = 6.2458 (0.523 sec/step)
I0404 20:15:11.190185 47978602034560 learning.py:507] global step 1111: loss = 7.4990 (0.516 sec/step)
I0404 20:15:11.701610 47978602034560 learning.py:507] global step 1112: loss = 6.9166 (0.510 sec/step)
I0404 20:15:12.212880 47978602034560 learning.py:507] global step 1113: loss = 6.5499 (0.510 sec/step)
I0404 20:15:12.731213 47978602034560 learning.py:507] global step 1114: loss = 7.7665 (0.517 sec/step)
I0404 20:15:13.237485 47978602034560 learning.py:507] global step 1115: loss = 5.9173 (0.505 sec/step)
I0404 20:15:13.745824 47978602034560 learning.py:507] global step 1116: loss = 6.3287 (0.507 sec/step)
I0404 20:15:14.267099 47978602034560 learning.py:507] global step 1117: loss = 8.4583 (0.520 sec/step)
I0404 20:15:14.779130 47978602034560 learning.py:507] global step 1118: loss = 7.5968 (0.509 sec/step)
I0404 20:15:15.298151 47978602034560 learning.py:507] global step 1119: loss = 7.4767 (0.517 sec/step)
I0404 20:15:15.820374 47978602034560 learning.py:507] global step 1120: loss = 8.0502 (0.521 sec/step)
I0404 20:15:16.330716 47978602034560 learning.py:507] global step 1121: loss = 7.3161 (0.509 sec/step)
I0404 20:15:16.636543 47983666177792 supervisor.py:1117] Saving checkpoint to path ../../trainingOutput/model.ckpt
I0404 20:15:16.637190 47983664076544 supervisor.py:1099] global_step/sec: 1.93333
I0404 20:15:16.847380 47978602034560 learning.py:507] global step 1122: loss = 7.1561 (0.506 sec/step)
I0404 20:15:17.553015 47983661975296 supervisor.py:1050] Recording summary at step 1123.
I0404 20:15:17.564340 47978602034560 learning.py:507] global step 1123: loss = 6.2793 (0.703 sec/step)
I0404 20:15:18.199007 47978602034560 learning.py:507] global step 1124: loss = 6.9874 (0.547 sec/step)
I0404 20:15:18.715503 47978602034560 learning.py:507] global step 1125: loss = 7.8810 (0.511 sec/step)
I0404 20:15:19.219026 47978602034560 learning.py:507] global step 1126: loss = 7.9141 (0.502 sec/step)
I0404 20:15:19.723674 47978602034560 learning.py:507] global step 1127: loss = 7.5557 (0.503 sec/step)
I0404 20:15:20.251491 47978602034560 learning.py:507] global step 1128: loss = 6.7136 (0.526 sec/step)
I0404 20:15:20.754893 47978602034560 learning.py:507] global step 1129: loss = 6.7416 (0.502 sec/step)
I0404 20:15:21.260345 47978602034560 learning.py:507] global step 1130: loss = 8.2535 (0.504 sec/step)
I0404 20:15:21.765402 47978602034560 learning.py:507] global step 1131: loss = 7.4069 (0.503 sec/step)
I0404 20:15:22.284399 47978602034560 learning.py:507] global step 1132: loss = 6.5721 (0.517 sec/step)
I0404 20:15:22.812571 47978602034560 learning.py:507] global step 1133: loss = 8.0295 (0.527 sec/step)
I0404 20:15:23.324822 47978602034560 learning.py:507] global step 1134: loss = 7.8948 (0.511 sec/step)
I0404 20:15:23.839765 47978602034560 learning.py:507] global step 1135: loss = 7.4518 (0.513 sec/step)
I0404 20:15:24.351970 47978602034560 learning.py:507] global step 1136: loss = 7.8240 (0.511 sec/step)
I0404 20:15:24.865410 47978602034560 learning.py:507] global step 1137: loss = 7.0445 (0.512 sec/step)
I0404 20:15:25.380303 47978602034560 learning.py:507] global step 1138: loss = 6.5897 (0.513 sec/step)
I0404 20:15:25.884965 47978602034560 learning.py:507] global step 1139: loss = 8.0474 (0.503 sec/step)
I0404 20:15:26.401176 47978602034560 learning.py:507] global step 1140: loss = 8.8447 (0.515 sec/step)
I0404 20:15:26.915095 47978602034560 learning.py:507] global step 1141: loss = 7.0740 (0.512 sec/step)
I0404 20:15:27.428717 47978602034560 learning.py:507] global step 1142: loss = 7.1513 (0.512 sec/step)
I0404 20:15:27.934426 47978602034560 learning.py:507] global step 1143: loss = 6.8455 (0.504 sec/step)
I0404 20:15:28.445398 47978602034560 learning.py:507] global step 1144: loss = 8.2719 (0.508 sec/step)
I0404 20:15:28.986205 47978602034560 learning.py:507] global step 1145: loss = 7.6615 (0.539 sec/step)
I0404 20:15:29.503142 47978602034560 learning.py:507] global step 1146: loss = 7.8979 (0.515 sec/step)
I0404 20:15:30.027831 47978602034560 learning.py:507] global step 1147: loss = 6.9136 (0.523 sec/step)
I0404 20:15:30.529535 47978602034560 learning.py:507] global step 1148: loss = 7.0261 (0.500 sec/step)
I0404 20:15:31.050366 47978602034560 learning.py:507] global step 1149: loss = 7.4338 (0.519 sec/step)
I0404 20:15:31.559962 47978602034560 learning.py:507] global step 1150: loss = 6.9924 (0.508 sec/step)
I0404 20:15:32.066073 47978602034560 learning.py:507] global step 1151: loss = 6.4223 (0.504 sec/step)
I0404 20:15:32.584332 47978602034560 learning.py:507] global step 1152: loss = 7.1229 (0.517 sec/step)
I0404 20:15:33.091496 47978602034560 learning.py:507] global step 1153: loss = 8.4561 (0.504 sec/step)
I0404 20:15:33.607786 47978602034560 learning.py:507] global step 1154: loss = 6.9555 (0.513 sec/step)
I0404 20:15:34.114452 47978602034560 learning.py:507] global step 1155: loss = 7.9330 (0.505 sec/step)
I0404 20:15:34.625556 47978602034560 learning.py:507] global step 1156: loss = 6.6663 (0.508 sec/step)
I0404 20:15:35.135483 47978602034560 learning.py:507] global step 1157: loss = 7.1783 (0.508 sec/step)
I0404 20:15:35.653254 47978602034560 learning.py:507] global step 1158: loss = 8.3424 (0.516 sec/step)
I0404 20:15:36.163995 47978602034560 learning.py:507] global step 1159: loss = 6.9197 (0.509 sec/step)
I0404 20:15:36.677339 47978602034560 learning.py:507] global step 1160: loss = 7.2398 (0.512 sec/step)
I0404 20:15:37.199220 47978602034560 learning.py:507] global step 1161: loss = 6.7766 (0.519 sec/step)
I0404 20:15:37.730174 47978602034560 learning.py:507] global step 1162: loss = 6.3566 (0.529 sec/step)
I0404 20:15:38.244880 47978602034560 learning.py:507] global step 1163: loss = 6.3212 (0.513 sec/step)
I0404 20:15:38.751805 47978602034560 learning.py:507] global step 1164: loss = 6.8448 (0.504 sec/step)
I0404 20:15:39.267237 47978602034560 learning.py:507] global step 1165: loss = 7.8863 (0.514 sec/step)
I0404 20:15:39.770270 47978602034560 learning.py:507] global step 1166: loss = 7.4185 (0.500 sec/step)
I0404 20:15:40.274265 47978602034560 learning.py:507] global step 1167: loss = 7.2192 (0.502 sec/step)
I0404 20:15:40.782846 47978602034560 learning.py:507] global step 1168: loss = 7.9184 (0.507 sec/step)
I0404 20:15:41.312100 47978602034560 learning.py:507] global step 1169: loss = 7.1617 (0.528 sec/step)
I0404 20:15:41.823705 47978602034560 learning.py:507] global step 1170: loss = 6.7455 (0.509 sec/step)
I0404 20:15:42.328684 47978602034560 learning.py:507] global step 1171: loss = 6.8750 (0.503 sec/step)
I0404 20:15:42.839346 47978602034560 learning.py:507] global step 1172: loss = 6.9773 (0.508 sec/step)
I0404 20:15:43.358966 47978602034560 learning.py:507] global step 1173: loss = 8.0048 (0.517 sec/step)
I0404 20:15:43.902412 47978602034560 learning.py:507] global step 1174: loss = 6.7135 (0.542 sec/step)
I0404 20:15:44.410759 47978602034560 learning.py:507] global step 1175: loss = 7.5354 (0.507 sec/step)
I0404 20:15:44.938284 47978602034560 learning.py:507] global step 1176: loss = 8.2305 (0.526 sec/step)
I0404 20:15:45.460806 47978602034560 learning.py:507] global step 1177: loss = 6.7481 (0.521 sec/step)
I0404 20:15:45.970769 47978602034560 learning.py:507] global step 1178: loss = 6.7637 (0.508 sec/step)
I0404 20:15:46.499798 47978602034560 learning.py:507] global step 1179: loss = 6.6705 (0.527 sec/step)
I0404 20:15:47.010388 47978602034560 learning.py:507] global step 1180: loss = 7.1924 (0.508 sec/step)
I0404 20:15:47.524354 47978602034560 learning.py:507] global step 1181: loss = 6.1120 (0.512 sec/step)
I0404 20:15:48.036257 47978602034560 learning.py:507] global step 1182: loss = 7.6275 (0.510 sec/step)
I0404 20:15:48.549526 47978602034560 learning.py:507] global step 1183: loss = 7.7582 (0.510 sec/step)
I0404 20:15:49.051554 47978602034560 learning.py:507] global step 1184: loss = 6.4914 (0.499 sec/step)
I0404 20:15:49.557826 47978602034560 learning.py:507] global step 1185: loss = 6.7765 (0.505 sec/step)
I0404 20:15:50.073518 47978602034560 learning.py:507] global step 1186: loss = 7.2681 (0.514 sec/step)
I0404 20:15:50.591272 47978602034560 learning.py:507] global step 1187: loss = 7.5082 (0.516 sec/step)
I0404 20:15:51.101804 47978602034560 learning.py:507] global step 1188: loss = 7.3889 (0.509 sec/step)
I0404 20:15:51.612828 47978602034560 learning.py:507] global step 1189: loss = 7.3244 (0.508 sec/step)
I0404 20:15:52.121458 47978602034560 learning.py:507] global step 1190: loss = 6.0904 (0.506 sec/step)
I0404 20:15:52.628081 47978602034560 learning.py:507] global step 1191: loss = 7.1529 (0.504 sec/step)
I0404 20:15:53.145493 47978602034560 learning.py:507] global step 1192: loss = 7.3247 (0.515 sec/step)
I0404 20:15:53.662816 47978602034560 learning.py:507] global step 1193: loss = 6.5465 (0.516 sec/step)
I0404 20:15:54.195440 47978602034560 learning.py:507] global step 1194: loss = 7.9843 (0.531 sec/step)
I0404 20:15:54.698368 47978602034560 learning.py:507] global step 1195: loss = 6.8805 (0.501 sec/step)
I0404 20:15:55.214095 47978602034560 learning.py:507] global step 1196: loss = 7.3941 (0.513 sec/step)
I0404 20:15:55.746158 47978602034560 learning.py:507] global step 1197: loss = 6.8349 (0.530 sec/step)
I0404 20:15:56.257487 47978602034560 learning.py:507] global step 1198: loss = 7.2695 (0.510 sec/step)
I0404 20:15:56.790151 47978602034560 learning.py:507] global step 1199: loss = 6.7772 (0.531 sec/step)
I0404 20:15:57.321565 47978602034560 learning.py:507] global step 1200: loss = 7.2327 (0.530 sec/step)
I0404 20:15:57.823655 47978602034560 learning.py:507] global step 1201: loss = 7.5921 (0.499 sec/step)
I0404 20:15:58.330690 47978602034560 learning.py:507] global step 1202: loss = 7.2719 (0.504 sec/step)
I0404 20:15:58.845128 47978602034560 learning.py:507] global step 1203: loss = 6.9651 (0.513 sec/step)
I0404 20:15:59.360610 47978602034560 learning.py:507] global step 1204: loss = 6.7104 (0.514 sec/step)
I0404 20:15:59.878737 47978602034560 learning.py:507] global step 1205: loss = 7.0219 (0.517 sec/step)
I0404 20:16:00.398633 47978602034560 learning.py:507] global step 1206: loss = 6.9984 (0.517 sec/step)
I0404 20:16:00.913955 47978602034560 learning.py:507] global step 1207: loss = 6.8589 (0.514 sec/step)
I0404 20:16:01.417482 47978602034560 learning.py:507] global step 1208: loss = 7.3965 (0.502 sec/step)
I0404 20:16:01.943516 47978602034560 learning.py:507] global step 1209: loss = 7.2415 (0.523 sec/step)
I0404 20:16:02.457334 47978602034560 learning.py:507] global step 1210: loss = 7.8122 (0.512 sec/step)
I0404 20:16:02.965611 47978602034560 learning.py:507] global step 1211: loss = 6.9458 (0.507 sec/step)
I0404 20:16:03.484625 47978602034560 learning.py:507] global step 1212: loss = 7.0116 (0.516 sec/step)
I0404 20:16:03.999224 47978602034560 learning.py:507] global step 1213: loss = 6.8970 (0.513 sec/step)
I0404 20:16:04.501012 47978602034560 learning.py:507] global step 1214: loss = 6.8931 (0.499 sec/step)
I0404 20:16:05.022384 47978602034560 learning.py:507] global step 1215: loss = 7.0979 (0.520 sec/step)
I0404 20:16:05.524064 47978602034560 learning.py:507] global step 1216: loss = 6.9649 (0.500 sec/step)
I0404 20:16:06.029134 47978602034560 learning.py:507] global step 1217: loss = 8.0408 (0.502 sec/step)
I0404 20:16:06.563570 47978602034560 learning.py:507] global step 1218: loss = 7.0738 (0.533 sec/step)
I0404 20:16:07.076027 47978602034560 learning.py:507] global step 1219: loss = 7.1799 (0.510 sec/step)
I0404 20:16:07.590430 47978602034560 learning.py:507] global step 1220: loss = 6.3746 (0.513 sec/step)
I0404 20:16:08.101388 47978602034560 learning.py:507] global step 1221: loss = 9.0348 (0.508 sec/step)
I0404 20:16:08.626636 47978602034560 learning.py:507] global step 1222: loss = 7.0999 (0.524 sec/step)
I0404 20:16:09.134745 47978602034560 learning.py:507] global step 1223: loss = 6.4943 (0.506 sec/step)
I0404 20:16:09.664106 47978602034560 learning.py:507] global step 1224: loss = 7.7391 (0.528 sec/step)
I0404 20:16:10.198852 47978602034560 learning.py:507] global step 1225: loss = 7.4482 (0.533 sec/step)
I0404 20:16:10.714811 47978602034560 learning.py:507] global step 1226: loss = 8.1823 (0.514 sec/step)
I0404 20:16:11.223527 47978602034560 learning.py:507] global step 1227: loss = 7.0560 (0.507 sec/step)
I0404 20:16:11.742955 47978602034560 learning.py:507] global step 1228: loss = 7.3566 (0.517 sec/step)
I0404 20:16:12.271388 47978602034560 learning.py:507] global step 1229: loss = 7.5137 (0.527 sec/step)
I0404 20:16:12.780030 47978602034560 learning.py:507] global step 1230: loss = 7.3993 (0.506 sec/step)
I0404 20:16:13.290251 47978602034560 learning.py:507] global step 1231: loss = 7.6520 (0.509 sec/step)
I0404 20:16:13.812355 47978602034560 learning.py:507] global step 1232: loss = 7.7150 (0.521 sec/step)
I0404 20:16:14.335486 47978602034560 learning.py:507] global step 1233: loss = 8.2296 (0.522 sec/step)
I0404 20:16:14.874391 47978602034560 learning.py:507] global step 1234: loss = 7.4777 (0.536 sec/step)
I0404 20:16:15.385699 47978602034560 learning.py:507] global step 1235: loss = 8.2372 (0.508 sec/step)
I0404 20:16:15.898262 47978602034560 learning.py:507] global step 1236: loss = 6.3613 (0.511 sec/step)
I0404 20:16:16.400331 47978602034560 learning.py:507] global step 1237: loss = 7.4067 (0.500 sec/step)
I0404 20:16:16.905136 47978602034560 learning.py:507] global step 1238: loss = 7.0530 (0.503 sec/step)
I0404 20:16:17.409822 47978602034560 learning.py:507] global step 1239: loss = 7.0225 (0.502 sec/step)
I0404 20:16:17.921821 47978602034560 learning.py:507] global step 1240: loss = 6.2954 (0.510 sec/step)
I0404 20:16:18.434330 47978602034560 learning.py:507] global step 1241: loss = 6.8830 (0.511 sec/step)
I0404 20:16:18.943345 47978602034560 learning.py:507] global step 1242: loss = 6.4786 (0.506 sec/step)
I0404 20:16:19.448176 47978602034560 learning.py:507] global step 1243: loss = 6.8715 (0.503 sec/step)
I0404 20:16:19.966864 47978602034560 learning.py:507] global step 1244: loss = 7.7357 (0.516 sec/step)
I0404 20:16:20.486599 47978602034560 learning.py:507] global step 1245: loss = 7.2223 (0.518 sec/step)
I0404 20:16:20.992432 47978602034560 learning.py:507] global step 1246: loss = 7.0688 (0.503 sec/step)
I0404 20:16:21.505118 47978602034560 learning.py:507] global step 1247: loss = 7.4666 (0.511 sec/step)
I0404 20:16:22.021954 47978602034560 learning.py:507] global step 1248: loss = 6.8087 (0.515 sec/step)
I0404 20:16:22.535097 47978602034560 learning.py:507] global step 1249: loss = 7.4091 (0.512 sec/step)
I0404 20:16:23.045654 47978602034560 learning.py:507] global step 1250: loss = 8.0543 (0.509 sec/step)
I0404 20:16:23.557077 47978602034560 learning.py:507] global step 1251: loss = 6.7848 (0.509 sec/step)
I0404 20:16:24.086255 47978602034560 learning.py:507] global step 1252: loss = 6.5480 (0.528 sec/step)
I0404 20:16:24.598326 47978602034560 learning.py:507] global step 1253: loss = 8.3473 (0.511 sec/step)
I0404 20:16:25.108941 47978602034560 learning.py:507] global step 1254: loss = 7.1338 (0.509 sec/step)
I0404 20:16:25.620899 47978602034560 learning.py:507] global step 1255: loss = 6.4123 (0.510 sec/step)
I0404 20:16:26.129059 47978602034560 learning.py:507] global step 1256: loss = 6.6530 (0.505 sec/step)
I0404 20:16:26.637568 47978602034560 learning.py:507] global step 1257: loss = 7.2837 (0.507 sec/step)
I0404 20:16:27.175811 47978602034560 learning.py:507] global step 1258: loss = 7.3424 (0.537 sec/step)
I0404 20:16:27.686196 47978602034560 learning.py:507] global step 1259: loss = 6.6681 (0.509 sec/step)
I0404 20:16:28.194795 47978602034560 learning.py:507] global step 1260: loss = 6.7771 (0.506 sec/step)
I0404 20:16:28.693044 47978602034560 learning.py:507] global step 1261: loss = 7.4204 (0.495 sec/step)
I0404 20:16:29.207645 47978602034560 learning.py:507] global step 1262: loss = 6.7270 (0.512 sec/step)
I0404 20:16:29.712370 47978602034560 learning.py:507] global step 1263: loss = 7.3314 (0.503 sec/step)
I0404 20:16:30.247105 47978602034560 learning.py:507] global step 1264: loss = 6.5618 (0.533 sec/step)
I0404 20:16:30.777256 47978602034560 learning.py:507] global step 1265: loss = 6.8416 (0.529 sec/step)
I0404 20:16:31.297960 47978602034560 learning.py:507] global step 1266: loss = 6.7590 (0.519 sec/step)
I0404 20:16:31.808465 47978602034560 learning.py:507] global step 1267: loss = 6.2553 (0.509 sec/step)
I0404 20:16:32.335302 47978602034560 learning.py:507] global step 1268: loss = 6.9093 (0.525 sec/step)
I0404 20:16:32.873816 47978602034560 learning.py:507] global step 1269: loss = 6.2517 (0.537 sec/step)
I0404 20:16:33.387716 47978602034560 learning.py:507] global step 1270: loss = 7.2615 (0.512 sec/step)
I0404 20:16:33.918994 47978602034560 learning.py:507] global step 1271: loss = 6.4307 (0.528 sec/step)
I0404 20:16:34.453247 47978602034560 learning.py:507] global step 1272: loss = 8.0505 (0.531 sec/step)
I0404 20:16:34.964362 47978602034560 learning.py:507] global step 1273: loss = 7.1890 (0.510 sec/step)
I0404 20:16:35.496426 47978602034560 learning.py:507] global step 1274: loss = 7.2077 (0.530 sec/step)
I0404 20:16:36.009994 47978602034560 learning.py:507] global step 1275: loss = 8.2101 (0.512 sec/step)
I0404 20:16:36.527528 47978602034560 learning.py:507] global step 1276: loss = 7.2032 (0.515 sec/step)
I0404 20:16:37.031073 47978602034560 learning.py:507] global step 1277: loss = 7.6101 (0.502 sec/step)
I0404 20:16:37.556881 47978602034560 learning.py:507] global step 1278: loss = 7.9302 (0.524 sec/step)
I0404 20:16:38.092168 47978602034560 learning.py:507] global step 1279: loss = 6.6029 (0.534 sec/step)
I0404 20:16:38.608070 47978602034560 learning.py:507] global step 1280: loss = 7.9305 (0.514 sec/step)
I0404 20:16:39.118697 47978602034560 learning.py:507] global step 1281: loss = 7.7505 (0.508 sec/step)
I0404 20:16:39.636276 47978602034560 learning.py:507] global step 1282: loss = 6.9269 (0.515 sec/step)
I0404 20:16:40.156171 47978602034560 learning.py:507] global step 1283: loss = 7.5611 (0.518 sec/step)
I0404 20:16:40.665271 47978602034560 learning.py:507] global step 1284: loss = 8.6115 (0.508 sec/step)
I0404 20:16:41.168449 47978602034560 learning.py:507] global step 1285: loss = 6.3847 (0.502 sec/step)
I0404 20:16:41.669235 47978602034560 learning.py:507] global step 1286: loss = 6.9004 (0.499 sec/step)
I0404 20:16:42.177810 47978602034560 learning.py:507] global step 1287: loss = 6.2203 (0.507 sec/step)
I0404 20:16:42.687604 47978602034560 learning.py:507] global step 1288: loss = 6.2018 (0.508 sec/step)
I0404 20:16:43.193979 47978602034560 learning.py:507] global step 1289: loss = 6.7675 (0.505 sec/step)
I0404 20:16:43.728765 47978602034560 learning.py:507] global step 1290: loss = 7.0276 (0.532 sec/step)
I0404 20:16:44.239273 47978602034560 learning.py:507] global step 1291: loss = 6.7690 (0.508 sec/step)
I0404 20:16:44.778528 47978602034560 learning.py:507] global step 1292: loss = 7.9528 (0.536 sec/step)
I0404 20:16:45.286022 47978602034560 learning.py:507] global step 1293: loss = 6.4112 (0.505 sec/step)
I0404 20:16:45.803828 47978602034560 learning.py:507] global step 1294: loss = 6.8683 (0.516 sec/step)
I0404 20:16:46.338909 47978602034560 learning.py:507] global step 1295: loss = 6.8330 (0.534 sec/step)
I0404 20:16:46.859333 47978602034560 learning.py:507] global step 1296: loss = 6.5146 (0.519 sec/step)
I0404 20:16:47.365830 47978602034560 learning.py:507] global step 1297: loss = 6.7787 (0.504 sec/step)
I0404 20:16:47.880726 47978602034560 learning.py:507] global step 1298: loss = 8.3265 (0.513 sec/step)
I0404 20:16:48.401202 47978602034560 learning.py:507] global step 1299: loss = 7.9300 (0.518 sec/step)
I0404 20:16:48.916673 47978602034560 learning.py:507] global step 1300: loss = 7.8026 (0.514 sec/step)
I0404 20:16:49.425402 47978602034560 learning.py:507] global step 1301: loss = 7.2767 (0.507 sec/step)
I0404 20:16:49.927078 47978602034560 learning.py:507] global step 1302: loss = 6.7407 (0.500 sec/step)
I0404 20:16:50.437648 47978602034560 learning.py:507] global step 1303: loss = 6.8478 (0.509 sec/step)
I0404 20:16:50.957766 47978602034560 learning.py:507] global step 1304: loss = 5.9588 (0.518 sec/step)
I0404 20:16:51.468438 47978602034560 learning.py:507] global step 1305: loss = 6.6098 (0.508 sec/step)
I0404 20:16:51.976000 47978602034560 learning.py:507] global step 1306: loss = 7.3577 (0.506 sec/step)
I0404 20:16:52.496796 47978602034560 learning.py:507] global step 1307: loss = 8.7377 (0.519 sec/step)
I0404 20:16:53.008734 47978602034560 learning.py:507] global step 1308: loss = 8.5684 (0.510 sec/step)
I0404 20:16:53.511171 47978602034560 learning.py:507] global step 1309: loss = 7.4248 (0.501 sec/step)
I0404 20:16:54.045339 47978602034560 learning.py:507] global step 1310: loss = 7.0343 (0.533 sec/step)
I0404 20:16:54.566820 47978602034560 learning.py:507] global step 1311: loss = 6.8292 (0.519 sec/step)
I0404 20:16:55.087512 47978602034560 learning.py:507] global step 1312: loss = 7.1556 (0.518 sec/step)
I0404 20:16:55.620959 47978602034560 learning.py:507] global step 1313: loss = 7.9987 (0.532 sec/step)
I0404 20:16:56.167556 47978602034560 learning.py:507] global step 1314: loss = 6.9830 (0.544 sec/step)
I0404 20:16:56.691183 47978602034560 learning.py:507] global step 1315: loss = 6.7241 (0.522 sec/step)
I0404 20:16:57.209960 47978602034560 learning.py:507] global step 1316: loss = 7.4204 (0.517 sec/step)
I0404 20:16:57.715732 47978602034560 learning.py:507] global step 1317: loss = 7.3522 (0.503 sec/step)
I0404 20:16:58.223848 47978602034560 learning.py:507] global step 1318: loss = 6.2413 (0.507 sec/step)
I0404 20:16:58.739955 47978602034560 learning.py:507] global step 1319: loss = 8.0755 (0.513 sec/step)
I0404 20:16:59.251186 47978602034560 learning.py:507] global step 1320: loss = 7.7885 (0.510 sec/step)
I0404 20:16:59.762624 47978602034560 learning.py:507] global step 1321: loss = 6.3385 (0.510 sec/step)
I0404 20:17:00.279960 47978602034560 learning.py:507] global step 1322: loss = 7.1590 (0.515 sec/step)
I0404 20:17:00.814306 47978602034560 learning.py:507] global step 1323: loss = 6.5562 (0.531 sec/step)
I0404 20:17:01.323322 47978602034560 learning.py:507] global step 1324: loss = 6.8158 (0.506 sec/step)
I0404 20:17:01.837096 47978602034560 learning.py:507] global step 1325: loss = 6.5699 (0.512 sec/step)
I0404 20:17:02.353937 47978602034560 learning.py:507] global step 1326: loss = 6.6838 (0.515 sec/step)
I0404 20:17:02.859495 47978602034560 learning.py:507] global step 1327: loss = 6.9189 (0.503 sec/step)
I0404 20:17:03.368087 47978602034560 learning.py:507] global step 1328: loss = 7.4555 (0.507 sec/step)
I0404 20:17:03.877109 47978602034560 learning.py:507] global step 1329: loss = 6.4206 (0.507 sec/step)
I0404 20:17:04.387461 47978602034560 learning.py:507] global step 1330: loss = 6.0015 (0.509 sec/step)
I0404 20:17:04.907360 47978602034560 learning.py:507] global step 1331: loss = 7.7872 (0.518 sec/step)
I0404 20:17:05.414924 47978602034560 learning.py:507] global step 1332: loss = 7.8629 (0.506 sec/step)
I0404 20:17:05.951434 47978602034560 learning.py:507] global step 1333: loss = 7.0918 (0.535 sec/step)
I0404 20:17:06.461354 47978602034560 learning.py:507] global step 1334: loss = 7.3499 (0.508 sec/step)
I0404 20:17:06.971012 47978602034560 learning.py:507] global step 1335: loss = 6.7106 (0.508 sec/step)
I0404 20:17:07.504955 47978602034560 learning.py:507] global step 1336: loss = 7.3241 (0.532 sec/step)
I0404 20:17:08.023371 47978602034560 learning.py:507] global step 1337: loss = 7.4777 (0.517 sec/step)
I0404 20:17:08.542998 47978602034560 learning.py:507] global step 1338: loss = 6.5345 (0.518 sec/step)
I0404 20:17:09.049300 47978602034560 learning.py:507] global step 1339: loss = 6.4608 (0.503 sec/step)
I0404 20:17:09.585352 47978602034560 learning.py:507] global step 1340: loss = 7.0785 (0.534 sec/step)
I0404 20:17:10.086594 47978602034560 learning.py:507] global step 1341: loss = 6.6161 (0.499 sec/step)
I0404 20:17:10.601094 47978602034560 learning.py:507] global step 1342: loss = 6.2896 (0.512 sec/step)
I0404 20:17:11.119272 47978602034560 learning.py:507] global step 1343: loss = 7.5683 (0.517 sec/step)
I0404 20:17:11.633346 47978602034560 learning.py:507] global step 1344: loss = 6.4645 (0.512 sec/step)
I0404 20:17:12.143978 47978602034560 learning.py:507] global step 1345: loss = 7.3588 (0.509 sec/step)
I0404 20:17:12.664463 47978602034560 learning.py:507] global step 1346: loss = 7.6461 (0.519 sec/step)
I0404 20:17:13.171059 47978602034560 learning.py:507] global step 1347: loss = 7.1897 (0.504 sec/step)
I0404 20:17:13.699498 47978602034560 learning.py:507] global step 1348: loss = 7.0823 (0.527 sec/step)
I0404 20:17:14.223609 47978602034560 learning.py:507] global step 1349: loss = 7.7706 (0.523 sec/step)
I0404 20:17:14.724086 47978602034560 learning.py:507] global step 1350: loss = 6.6667 (0.499 sec/step)
I0404 20:17:15.242100 47978602034560 learning.py:507] global step 1351: loss = 6.7389 (0.516 sec/step)
I0404 20:17:15.751795 47978602034560 learning.py:507] global step 1352: loss = 7.9189 (0.508 sec/step)
I0404 20:17:16.284751 47978602034560 learning.py:507] global step 1353: loss = 7.6316 (0.531 sec/step)
I0404 20:17:16.637161 47983664076544 supervisor.py:1099] global_step/sec: 1.93333
I0404 20:17:16.798712 47978602034560 learning.py:507] global step 1354: loss = 6.8219 (0.508 sec/step)
I0404 20:17:17.167124 47983661975296 supervisor.py:1050] Recording summary at step 1354.
I0404 20:17:17.502614 47978602034560 learning.py:507] global step 1355: loss = 7.2740 (0.700 sec/step)
I0404 20:17:18.011257 47978602034560 learning.py:507] global step 1356: loss = 7.1965 (0.506 sec/step)
I0404 20:17:18.513496 47978602034560 learning.py:507] global step 1357: loss = 6.7861 (0.499 sec/step)
I0404 20:17:19.018783 47978602034560 learning.py:507] global step 1358: loss = 6.5359 (0.503 sec/step)
I0404 20:17:19.519609 47978602034560 learning.py:507] global step 1359: loss = 7.4312 (0.499 sec/step)
I0404 20:17:20.018977 47978602034560 learning.py:507] global step 1360: loss = 6.9927 (0.498 sec/step)
I0404 20:17:20.538460 47978602034560 learning.py:507] global step 1361: loss = 6.4805 (0.518 sec/step)
I0404 20:17:21.043767 47978602034560 learning.py:507] global step 1362: loss = 8.1506 (0.504 sec/step)
I0404 20:17:21.546814 47978602034560 learning.py:507] global step 1363: loss = 6.3553 (0.501 sec/step)
I0404 20:17:22.062906 47978602034560 learning.py:507] global step 1364: loss = 7.8165 (0.515 sec/step)
I0404 20:17:22.566351 47978602034560 learning.py:507] global step 1365: loss = 7.0986 (0.502 sec/step)
I0404 20:17:23.080591 47978602034560 learning.py:507] global step 1366: loss = 7.0410 (0.511 sec/step)
I0404 20:17:23.597277 47978602034560 learning.py:507] global step 1367: loss = 6.2000 (0.514 sec/step)
I0404 20:17:24.106497 47978602034560 learning.py:507] global step 1368: loss = 7.1586 (0.506 sec/step)
I0404 20:17:24.642652 47978602034560 learning.py:507] global step 1369: loss = 7.7788 (0.535 sec/step)
I0404 20:17:25.158453 47978602034560 learning.py:507] global step 1370: loss = 6.2753 (0.513 sec/step)
I0404 20:17:25.666958 47978602034560 learning.py:507] global step 1371: loss = 7.4594 (0.507 sec/step)
I0404 20:17:26.179686 47978602034560 learning.py:507] global step 1372: loss = 6.8396 (0.511 sec/step)
I0404 20:17:26.691891 47978602034560 learning.py:507] global step 1373: loss = 8.2815 (0.511 sec/step)
I0404 20:17:27.235399 47978602034560 learning.py:507] global step 1374: loss = 7.8148 (0.542 sec/step)
I0404 20:17:27.774943 47978602034560 learning.py:507] global step 1375: loss = 6.4527 (0.538 sec/step)
I0404 20:17:28.298597 47978602034560 learning.py:507] global step 1376: loss = 6.9002 (0.522 sec/step)
I0404 20:17:28.803928 47978602034560 learning.py:507] global step 1377: loss = 7.3943 (0.502 sec/step)
I0404 20:17:29.321458 47978602034560 learning.py:507] global step 1378: loss = 6.8649 (0.515 sec/step)
I0404 20:17:29.822381 47978602034560 learning.py:507] global step 1379: loss = 6.3238 (0.499 sec/step)
I0404 20:17:30.341162 47978602034560 learning.py:507] global step 1380: loss = 7.0127 (0.517 sec/step)
I0404 20:17:30.851509 47978602034560 learning.py:507] global step 1381: loss = 6.0632 (0.509 sec/step)
I0404 20:17:31.364680 47978602034560 learning.py:507] global step 1382: loss = 7.0433 (0.510 sec/step)
I0404 20:17:31.870341 47978602034560 learning.py:507] global step 1383: loss = 7.1637 (0.504 sec/step)
I0404 20:17:32.389917 47978602034560 learning.py:507] global step 1384: loss = 7.7121 (0.518 sec/step)
I0404 20:17:32.897868 47978602034560 learning.py:507] global step 1385: loss = 7.4583 (0.506 sec/step)
I0404 20:17:33.408847 47978602034560 learning.py:507] global step 1386: loss = 6.2500 (0.509 sec/step)
I0404 20:17:33.940307 47978602034560 learning.py:507] global step 1387: loss = 6.8402 (0.529 sec/step)
I0404 20:17:34.460966 47978602034560 learning.py:507] global step 1388: loss = 6.8372 (0.518 sec/step)
I0404 20:17:34.970279 47978602034560 learning.py:507] global step 1389: loss = 7.3627 (0.508 sec/step)
I0404 20:17:35.488153 47978602034560 learning.py:507] global step 1390: loss = 7.2867 (0.516 sec/step)
I0404 20:17:36.015738 47978602034560 learning.py:507] global step 1391: loss = 7.2432 (0.526 sec/step)
I0404 20:17:36.549808 47978602034560 learning.py:507] global step 1392: loss = 8.1206 (0.533 sec/step)
I0404 20:17:37.064809 47978602034560 learning.py:507] global step 1393: loss = 8.0181 (0.512 sec/step)
I0404 20:17:37.569052 47978602034560 learning.py:507] global step 1394: loss = 7.3023 (0.501 sec/step)
I0404 20:17:38.072039 47978602034560 learning.py:507] global step 1395: loss = 7.5453 (0.501 sec/step)
I0404 20:17:38.605387 47978602034560 learning.py:507] global step 1396: loss = 7.9664 (0.532 sec/step)
I0404 20:17:39.138997 47978602034560 learning.py:507] global step 1397: loss = 7.4425 (0.532 sec/step)
I0404 20:17:39.644844 47978602034560 learning.py:507] global step 1398: loss = 7.9978 (0.503 sec/step)
I0404 20:17:40.155619 47978602034560 learning.py:507] global step 1399: loss = 7.3795 (0.509 sec/step)
I0404 20:17:40.665153 47978602034560 learning.py:507] global step 1400: loss = 7.0027 (0.508 sec/step)
I0404 20:17:41.183674 47978602034560 learning.py:507] global step 1401: loss = 7.3274 (0.516 sec/step)
I0404 20:17:41.707782 47978602034560 learning.py:507] global step 1402: loss = 6.9512 (0.522 sec/step)
I0404 20:17:42.245666 47978602034560 learning.py:507] global step 1403: loss = 7.1029 (0.535 sec/step)
I0404 20:17:42.760411 47978602034560 learning.py:507] global step 1404: loss = 7.5073 (0.513 sec/step)
I0404 20:17:43.290172 47978602034560 learning.py:507] global step 1405: loss = 7.2842 (0.528 sec/step)
I0404 20:17:43.801165 47978602034560 learning.py:507] global step 1406: loss = 7.2415 (0.509 sec/step)
I0404 20:17:44.329706 47978602034560 learning.py:507] global step 1407: loss = 6.8177 (0.526 sec/step)
I0404 20:17:44.836142 47978602034560 learning.py:507] global step 1408: loss = 6.8744 (0.504 sec/step)
I0404 20:17:45.353304 47978602034560 learning.py:507] global step 1409: loss = 7.8858 (0.516 sec/step)
I0404 20:17:45.873311 47978602034560 learning.py:507] global step 1410: loss = 6.6378 (0.518 sec/step)
I0404 20:17:46.382772 47978602034560 learning.py:507] global step 1411: loss = 6.7729 (0.507 sec/step)
I0404 20:17:46.891709 47978602034560 learning.py:507] global step 1412: loss = 7.8029 (0.507 sec/step)
I0404 20:17:47.396617 47978602034560 learning.py:507] global step 1413: loss = 7.0496 (0.502 sec/step)
I0404 20:17:47.910044 47978602034560 learning.py:507] global step 1414: loss = 8.2308 (0.511 sec/step)
I0404 20:17:48.427677 47978602034560 learning.py:507] global step 1415: loss = 5.8654 (0.516 sec/step)
I0404 20:17:48.940316 47978602034560 learning.py:507] global step 1416: loss = 6.6295 (0.510 sec/step)
I0404 20:17:49.479463 47978602034560 learning.py:507] global step 1417: loss = 6.0689 (0.536 sec/step)
I0404 20:17:49.985683 47978602034560 learning.py:507] global step 1418: loss = 6.5028 (0.505 sec/step)
I0404 20:17:50.497406 47978602034560 learning.py:507] global step 1419: loss = 6.3691 (0.510 sec/step)
I0404 20:17:51.009425 47978602034560 learning.py:507] global step 1420: loss = 6.4182 (0.509 sec/step)
I0404 20:17:51.540243 47978602034560 learning.py:507] global step 1421: loss = 6.3153 (0.529 sec/step)
I0404 20:17:52.071991 47978602034560 learning.py:507] global step 1422: loss = 6.5155 (0.530 sec/step)
I0404 20:17:52.585956 47978602034560 learning.py:507] global step 1423: loss = 6.7662 (0.512 sec/step)
I0404 20:17:53.122087 47978602034560 learning.py:507] global step 1424: loss = 7.3213 (0.534 sec/step)
I0404 20:17:53.632231 47978602034560 learning.py:507] global step 1425: loss = 6.5498 (0.509 sec/step)
I0404 20:17:54.137436 47978602034560 learning.py:507] global step 1426: loss = 7.4966 (0.504 sec/step)
I0404 20:17:54.664888 47978602034560 learning.py:507] global step 1427: loss = 5.9925 (0.525 sec/step)
I0404 20:17:55.191709 47978602034560 learning.py:507] global step 1428: loss = 6.4281 (0.525 sec/step)
I0404 20:17:55.724014 47978602034560 learning.py:507] global step 1429: loss = 6.8489 (0.529 sec/step)
I0404 20:17:56.245950 47978602034560 learning.py:507] global step 1430: loss = 6.8098 (0.520 sec/step)
I0404 20:17:56.785311 47978602034560 learning.py:507] global step 1431: loss = 6.8169 (0.538 sec/step)
I0404 20:17:57.297247 47978602034560 learning.py:507] global step 1432: loss = 6.6937 (0.510 sec/step)
I0404 20:17:57.805591 47978602034560 learning.py:507] global step 1433: loss = 6.0238 (0.507 sec/step)
I0404 20:17:58.308360 47978602034560 learning.py:507] global step 1434: loss = 6.9173 (0.500 sec/step)
I0404 20:17:58.823983 47978602034560 learning.py:507] global step 1435: loss = 5.9333 (0.513 sec/step)
I0404 20:17:59.347671 47978602034560 learning.py:507] global step 1436: loss = 6.4937 (0.521 sec/step)
I0404 20:17:59.855847 47978602034560 learning.py:507] global step 1437: loss = 7.9045 (0.505 sec/step)
I0404 20:18:00.373034 47978602034560 learning.py:507] global step 1438: loss = 7.0920 (0.516 sec/step)
I0404 20:18:00.885603 47978602034560 learning.py:507] global step 1439: loss = 6.6832 (0.510 sec/step)
I0404 20:18:01.412542 47978602034560 learning.py:507] global step 1440: loss = 7.7851 (0.525 sec/step)
I0404 20:18:01.916699 47978602034560 learning.py:507] global step 1441: loss = 6.8260 (0.501 sec/step)
I0404 20:18:02.426509 47978602034560 learning.py:507] global step 1442: loss = 6.8826 (0.508 sec/step)
I0404 20:18:02.940213 47978602034560 learning.py:507] global step 1443: loss = 6.9215 (0.512 sec/step)
I0404 20:18:03.447522 47978602034560 learning.py:507] global step 1444: loss = 7.9444 (0.506 sec/step)
I0404 20:18:03.986605 47978602034560 learning.py:507] global step 1445: loss = 8.4757 (0.537 sec/step)
I0404 20:18:04.503728 47978602034560 learning.py:507] global step 1446: loss = 7.3477 (0.516 sec/step)
I0404 20:18:05.015982 47978602034560 learning.py:507] global step 1447: loss = 6.3711 (0.511 sec/step)
I0404 20:18:05.541317 47978602034560 learning.py:507] global step 1448: loss = 7.5904 (0.523 sec/step)
I0404 20:18:06.079204 47978602034560 learning.py:507] global step 1449: loss = 6.8958 (0.536 sec/step)
I0404 20:18:06.589001 47978602034560 learning.py:507] global step 1450: loss = 6.2516 (0.508 sec/step)
I0404 20:18:07.108685 47978602034560 learning.py:507] global step 1451: loss = 6.7434 (0.518 sec/step)
I0404 20:18:07.613769 47978602034560 learning.py:507] global step 1452: loss = 6.5057 (0.502 sec/step)
I0404 20:18:08.122096 47978602034560 learning.py:507] global step 1453: loss = 6.7756 (0.507 sec/step)
I0404 20:18:08.626493 47978602034560 learning.py:507] global step 1454: loss = 6.5969 (0.503 sec/step)
I0404 20:18:09.144484 47978602034560 learning.py:507] global step 1455: loss = 6.8131 (0.516 sec/step)
I0404 20:18:09.656428 47978602034560 learning.py:507] global step 1456: loss = 6.7846 (0.510 sec/step)
I0404 20:18:10.161971 47978602034560 learning.py:507] global step 1457: loss = 7.7782 (0.504 sec/step)
I0404 20:18:10.664458 47978602034560 learning.py:507] global step 1458: loss = 7.6630 (0.501 sec/step)
I0404 20:18:11.181806 47978602034560 learning.py:507] global step 1459: loss = 6.7740 (0.516 sec/step)
I0404 20:18:11.701732 47978602034560 learning.py:507] global step 1460: loss = 7.3327 (0.518 sec/step)
I0404 20:18:12.210440 47978602034560 learning.py:507] global step 1461: loss = 6.6605 (0.507 sec/step)
I0404 20:18:12.727933 47978602034560 learning.py:507] global step 1462: loss = 5.9532 (0.516 sec/step)
I0404 20:18:13.236155 47978602034560 learning.py:507] global step 1463: loss = 8.0690 (0.505 sec/step)
I0404 20:18:13.766556 47978602034560 learning.py:507] global step 1464: loss = 7.3761 (0.527 sec/step)
I0404 20:18:14.280622 47978602034560 learning.py:507] global step 1465: loss = 6.6633 (0.512 sec/step)
I0404 20:18:14.813619 47978602034560 learning.py:507] global step 1466: loss = 7.2151 (0.530 sec/step)
I0404 20:18:15.323283 47978602034560 learning.py:507] global step 1467: loss = 6.9649 (0.508 sec/step)
I0404 20:18:15.851614 47978602034560 learning.py:507] global step 1468: loss = 6.3646 (0.525 sec/step)
I0404 20:18:16.365459 47978602034560 learning.py:507] global step 1469: loss = 7.3585 (0.512 sec/step)
I0404 20:18:16.873549 47978602034560 learning.py:507] global step 1470: loss = 7.7488 (0.506 sec/step)
I0404 20:18:17.390808 47978602034560 learning.py:507] global step 1471: loss = 7.0950 (0.516 sec/step)
I0404 20:18:17.900800 47978602034560 learning.py:507] global step 1472: loss = 7.7989 (0.508 sec/step)
I0404 20:18:18.409922 47978602034560 learning.py:507] global step 1473: loss = 6.4322 (0.506 sec/step)
I0404 20:18:18.919906 47978602034560 learning.py:507] global step 1474: loss = 6.7053 (0.508 sec/step)
I0404 20:18:19.454887 47978602034560 learning.py:507] global step 1475: loss = 6.4766 (0.533 sec/step)
I0404 20:18:19.964772 47978602034560 learning.py:507] global step 1476: loss = 7.3043 (0.508 sec/step)
I0404 20:18:20.477812 47978602034560 learning.py:507] global step 1477: loss = 8.0954 (0.511 sec/step)
I0404 20:18:20.986787 47978602034560 learning.py:507] global step 1478: loss = 6.4154 (0.507 sec/step)
I0404 20:18:21.496096 47978602034560 learning.py:507] global step 1479: loss = 6.7448 (0.508 sec/step)
I0404 20:18:22.028046 47978602034560 learning.py:507] global step 1480: loss = 6.6651 (0.530 sec/step)
I0404 20:18:22.561374 47978602034560 learning.py:507] global step 1481: loss = 7.5541 (0.532 sec/step)
I0404 20:18:23.077901 47978602034560 learning.py:507] global step 1482: loss = 7.9893 (0.514 sec/step)
I0404 20:18:23.614523 47978602034560 learning.py:507] global step 1483: loss = 6.0748 (0.535 sec/step)
I0404 20:18:24.139291 47978602034560 learning.py:507] global step 1484: loss = 7.2160 (0.523 sec/step)
I0404 20:18:24.660682 47978602034560 learning.py:507] global step 1485: loss = 7.2793 (0.520 sec/step)
I0404 20:18:25.164159 47978602034560 learning.py:507] global step 1486: loss = 8.2818 (0.502 sec/step)
I0404 20:18:25.673283 47978602034560 learning.py:507] global step 1487: loss = 6.0958 (0.508 sec/step)
I0404 20:18:26.187873 47978602034560 learning.py:507] global step 1488: loss = 6.6691 (0.513 sec/step)
I0404 20:18:26.695875 47978602034560 learning.py:507] global step 1489: loss = 7.2962 (0.506 sec/step)
I0404 20:18:27.191521 47978602034560 learning.py:507] global step 1490: loss = 6.8011 (0.494 sec/step)
I0404 20:18:27.727790 47978602034560 learning.py:507] global step 1491: loss = 6.6160 (0.533 sec/step)
I0404 20:18:28.249244 47978602034560 learning.py:507] global step 1492: loss = 6.8534 (0.519 sec/step)
I0404 20:18:28.753980 47978602034560 learning.py:507] global step 1493: loss = 6.7377 (0.502 sec/step)
I0404 20:18:29.256680 47978602034560 learning.py:507] global step 1494: loss = 7.9047 (0.501 sec/step)
I0404 20:18:29.764593 47978602034560 learning.py:507] global step 1495: loss = 7.0376 (0.506 sec/step)
I0404 20:18:30.277182 47978602034560 learning.py:507] global step 1496: loss = 6.7888 (0.511 sec/step)
I0404 20:18:30.781696 47978602034560 learning.py:507] global step 1497: loss = 7.7198 (0.502 sec/step)
I0404 20:18:31.296277 47978602034560 learning.py:507] global step 1498: loss = 7.3668 (0.513 sec/step)
I0404 20:18:31.825182 47978602034560 learning.py:507] global step 1499: loss = 7.2568 (0.527 sec/step)
I0404 20:18:32.332340 47978602034560 learning.py:507] global step 1500: loss = 7.0092 (0.504 sec/step)
I0404 20:18:32.880556 47978602034560 learning.py:507] global step 1501: loss = 6.7890 (0.547 sec/step)
I0404 20:18:33.393268 47978602034560 learning.py:507] global step 1502: loss = 7.3117 (0.510 sec/step)
I0404 20:18:33.912170 47978602034560 learning.py:507] global step 1503: loss = 7.3384 (0.517 sec/step)
I0404 20:18:34.415266 47978602034560 learning.py:507] global step 1504: loss = 8.1575 (0.501 sec/step)
I0404 20:18:34.933044 47978602034560 learning.py:507] global step 1505: loss = 6.9845 (0.516 sec/step)
I0404 20:18:35.442311 47978602034560 learning.py:507] global step 1506: loss = 6.0504 (0.508 sec/step)
I0404 20:18:35.963498 47978602034560 learning.py:507] global step 1507: loss = 7.1450 (0.520 sec/step)
I0404 20:18:36.476992 47978602034560 learning.py:507] global step 1508: loss = 6.9024 (0.512 sec/step)
I0404 20:18:37.002250 47978602034560 learning.py:507] global step 1509: loss = 7.9787 (0.522 sec/step)
I0404 20:18:37.513695 47978602034560 learning.py:507] global step 1510: loss = 6.8320 (0.510 sec/step)
I0404 20:18:38.046556 47978602034560 learning.py:507] global step 1511: loss = 7.4907 (0.530 sec/step)
I0404 20:18:38.552722 47978602034560 learning.py:507] global step 1512: loss = 7.6717 (0.505 sec/step)
I0404 20:18:39.067653 47978602034560 learning.py:507] global step 1513: loss = 7.2768 (0.513 sec/step)
I0404 20:18:39.583535 47978602034560 learning.py:507] global step 1514: loss = 7.0141 (0.514 sec/step)
I0404 20:18:40.094843 47978602034560 learning.py:507] global step 1515: loss = 6.9323 (0.508 sec/step)
I0404 20:18:40.614014 47978602034560 learning.py:507] global step 1516: loss = 7.7341 (0.518 sec/step)
I0404 20:18:41.148543 47978602034560 learning.py:507] global step 1517: loss = 7.7784 (0.533 sec/step)
I0404 20:18:41.696838 47978602034560 learning.py:507] global step 1518: loss = 6.3038 (0.545 sec/step)
I0404 20:18:42.201598 47978602034560 learning.py:507] global step 1519: loss = 7.1631 (0.503 sec/step)
I0404 20:18:42.709303 47978602034560 learning.py:507] global step 1520: loss = 7.7098 (0.506 sec/step)
I0404 20:18:43.217738 47978602034560 learning.py:507] global step 1521: loss = 7.1588 (0.507 sec/step)
I0404 20:18:43.735479 47978602034560 learning.py:507] global step 1522: loss = 7.5244 (0.516 sec/step)
I0404 20:18:44.262915 47978602034560 learning.py:507] global step 1523: loss = 8.1970 (0.526 sec/step)
I0404 20:18:44.773547 47978602034560 learning.py:507] global step 1524: loss = 7.0446 (0.509 sec/step)
I0404 20:18:45.311420 47978602034560 learning.py:507] global step 1525: loss = 6.7941 (0.535 sec/step)
I0404 20:18:45.820499 47978602034560 learning.py:507] global step 1526: loss = 7.4758 (0.506 sec/step)
I0404 20:18:46.335223 47978602034560 learning.py:507] global step 1527: loss = 6.0015 (0.512 sec/step)
I0404 20:18:46.843178 47978602034560 learning.py:507] global step 1528: loss = 8.3621 (0.506 sec/step)
I0404 20:18:47.358954 47978602034560 learning.py:507] global step 1529: loss = 6.1238 (0.514 sec/step)
I0404 20:18:47.871665 47978602034560 learning.py:507] global step 1530: loss = 7.1694 (0.509 sec/step)
I0404 20:18:48.408882 47978602034560 learning.py:507] global step 1531: loss = 6.5486 (0.535 sec/step)
I0404 20:18:48.918442 47978602034560 learning.py:507] global step 1532: loss = 6.9158 (0.508 sec/step)
I0404 20:18:49.449288 47978602034560 learning.py:507] global step 1533: loss = 6.6595 (0.529 sec/step)
I0404 20:18:49.959872 47978602034560 learning.py:507] global step 1534: loss = 7.6946 (0.509 sec/step)
I0404 20:18:50.500181 47978602034560 learning.py:507] global step 1535: loss = 7.5317 (0.539 sec/step)
I0404 20:18:51.029271 47978602034560 learning.py:507] global step 1536: loss = 7.7070 (0.526 sec/step)
I0404 20:18:51.533321 47978602034560 learning.py:507] global step 1537: loss = 6.1306 (0.502 sec/step)
I0404 20:18:52.070210 47978602034560 learning.py:507] global step 1538: loss = 7.7838 (0.535 sec/step)
I0404 20:18:52.614332 47978602034560 learning.py:507] global step 1539: loss = 8.2458 (0.543 sec/step)
I0404 20:18:53.124715 47978602034560 learning.py:507] global step 1540: loss = 7.6937 (0.509 sec/step)
I0404 20:18:53.633051 47978602034560 learning.py:507] global step 1541: loss = 6.4966 (0.505 sec/step)
I0404 20:18:54.143623 47978602034560 learning.py:507] global step 1542: loss = 6.3397 (0.509 sec/step)
I0404 20:18:54.651361 47978602034560 learning.py:507] global step 1543: loss = 6.7141 (0.506 sec/step)
I0404 20:18:55.184711 47978602034560 learning.py:507] global step 1544: loss = 7.3148 (0.532 sec/step)
I0404 20:18:55.712224 47978602034560 learning.py:507] global step 1545: loss = 6.6426 (0.526 sec/step)
I0404 20:18:56.227948 47978602034560 learning.py:507] global step 1546: loss = 6.0510 (0.514 sec/step)
I0404 20:18:56.741714 47978602034560 learning.py:507] global step 1547: loss = 6.1955 (0.511 sec/step)
I0404 20:18:57.254946 47978602034560 learning.py:507] global step 1548: loss = 8.3648 (0.512 sec/step)
I0404 20:18:57.789927 47978602034560 learning.py:507] global step 1549: loss = 6.0338 (0.533 sec/step)
I0404 20:18:58.325567 47978602034560 learning.py:507] global step 1550: loss = 7.0605 (0.534 sec/step)
I0404 20:18:58.859429 47978602034560 learning.py:507] global step 1551: loss = 7.5217 (0.532 sec/step)
I0404 20:18:59.370028 47978602034560 learning.py:507] global step 1552: loss = 6.3938 (0.509 sec/step)
I0404 20:18:59.892002 47978602034560 learning.py:507] global step 1553: loss = 6.8740 (0.520 sec/step)
I0404 20:19:00.418747 47978602034560 learning.py:507] global step 1554: loss = 6.4187 (0.525 sec/step)
I0404 20:19:00.936644 47978602034560 learning.py:507] global step 1555: loss = 7.5330 (0.515 sec/step)
I0404 20:19:01.465685 47978602034560 learning.py:507] global step 1556: loss = 8.0122 (0.527 sec/step)
I0404 20:19:01.978682 47978602034560 learning.py:507] global step 1557: loss = 7.5734 (0.511 sec/step)
I0404 20:19:02.490176 47978602034560 learning.py:507] global step 1558: loss = 6.9162 (0.510 sec/step)
I0404 20:19:03.002485 47978602034560 learning.py:507] global step 1559: loss = 6.6494 (0.511 sec/step)
I0404 20:19:03.508805 47978602034560 learning.py:507] global step 1560: loss = 7.9919 (0.505 sec/step)
I0404 20:19:04.020215 47978602034560 learning.py:507] global step 1561: loss = 6.9091 (0.510 sec/step)
I0404 20:19:04.532161 47978602034560 learning.py:507] global step 1562: loss = 7.5909 (0.510 sec/step)
I0404 20:19:05.047043 47978602034560 learning.py:507] global step 1563: loss = 8.1240 (0.513 sec/step)
I0404 20:19:05.590535 47978602034560 learning.py:507] global step 1564: loss = 7.5410 (0.542 sec/step)
I0404 20:19:06.109372 47978602034560 learning.py:507] global step 1565: loss = 7.1017 (0.517 sec/step)
I0404 20:19:06.625395 47978602034560 learning.py:507] global step 1566: loss = 6.6691 (0.514 sec/step)
I0404 20:19:07.143343 47978602034560 learning.py:507] global step 1567: loss = 5.9151 (0.516 sec/step)
I0404 20:19:07.657410 47978602034560 learning.py:507] global step 1568: loss = 7.5563 (0.513 sec/step)
I0404 20:19:08.174070 47978602034560 learning.py:507] global step 1569: loss = 7.4814 (0.515 sec/step)
I0404 20:19:08.710117 47978602034560 learning.py:507] global step 1570: loss = 7.5539 (0.533 sec/step)
I0404 20:19:09.240008 47978602034560 learning.py:507] global step 1571: loss = 5.9731 (0.527 sec/step)
I0404 20:19:09.762215 47978602034560 learning.py:507] global step 1572: loss = 5.9442 (0.521 sec/step)
I0404 20:19:10.269375 47978602034560 learning.py:507] global step 1573: loss = 7.0857 (0.506 sec/step)
I0404 20:19:10.803347 47978602034560 learning.py:507] global step 1574: loss = 7.6001 (0.532 sec/step)
I0404 20:19:11.316997 47978602034560 learning.py:507] global step 1575: loss = 7.1074 (0.511 sec/step)
I0404 20:19:11.831044 47978602034560 learning.py:507] global step 1576: loss = 7.7825 (0.511 sec/step)
I0404 20:19:12.349575 47978602034560 learning.py:507] global step 1577: loss = 6.9661 (0.517 sec/step)
I0404 20:19:12.860622 47978602034560 learning.py:507] global step 1578: loss = 7.6532 (0.509 sec/step)
I0404 20:19:13.361504 47978602034560 learning.py:507] global step 1579: loss = 6.6471 (0.498 sec/step)
I0404 20:19:13.875111 47978602034560 learning.py:507] global step 1580: loss = 5.7028 (0.512 sec/step)
I0404 20:19:14.389100 47978602034560 learning.py:507] global step 1581: loss = 6.4921 (0.512 sec/step)
I0404 20:19:14.897715 47978602034560 learning.py:507] global step 1582: loss = 5.9045 (0.507 sec/step)
I0404 20:19:15.423075 47978602034560 learning.py:507] global step 1583: loss = 5.9207 (0.524 sec/step)
I0404 20:19:15.955197 47978602034560 learning.py:507] global step 1584: loss = 6.2382 (0.531 sec/step)
I0404 20:19:16.463877 47978602034560 learning.py:507] global step 1585: loss = 7.3864 (0.507 sec/step)
I0404 20:19:16.637151 47983664076544 supervisor.py:1099] global_step/sec: 1.93333
I0404 20:19:17.120814 47978602034560 learning.py:507] global step 1586: loss = 6.9137 (0.651 sec/step)
I0404 20:19:17.315884 47983661975296 supervisor.py:1050] Recording summary at step 1586.
I0404 20:19:17.676079 47978602034560 learning.py:507] global step 1587: loss = 6.6587 (0.550 sec/step)
I0404 20:19:18.179828 47978602034560 learning.py:507] global step 1588: loss = 6.9428 (0.501 sec/step)
I0404 20:19:18.691973 47978602034560 learning.py:507] global step 1589: loss = 6.5543 (0.511 sec/step)
I0404 20:19:19.200947 47978602034560 learning.py:507] global step 1590: loss = 7.8800 (0.506 sec/step)
I0404 20:19:19.734327 47978602034560 learning.py:507] global step 1591: loss = 5.8591 (0.532 sec/step)
I0404 20:19:20.243267 47978602034560 learning.py:507] global step 1592: loss = 5.9786 (0.507 sec/step)
I0404 20:19:20.779489 47978602034560 learning.py:507] global step 1593: loss = 7.2189 (0.533 sec/step)
I0404 20:19:21.298409 47978602034560 learning.py:507] global step 1594: loss = 6.5084 (0.516 sec/step)
I0404 20:19:21.810666 47978602034560 learning.py:507] global step 1595: loss = 6.7763 (0.509 sec/step)
I0404 20:19:22.312683 47978602034560 learning.py:507] global step 1596: loss = 7.3154 (0.500 sec/step)
I0404 20:19:22.830289 47978602034560 learning.py:507] global step 1597: loss = 7.1632 (0.516 sec/step)
I0404 20:19:23.350604 47978602034560 learning.py:507] global step 1598: loss = 7.5144 (0.517 sec/step)
I0404 20:19:23.856643 47978602034560 learning.py:507] global step 1599: loss = 6.6101 (0.504 sec/step)
I0404 20:19:24.371748 47978602034560 learning.py:507] global step 1600: loss = 5.6004 (0.514 sec/step)
I0404 20:19:24.885241 47978602034560 learning.py:507] global step 1601: loss = 6.7257 (0.512 sec/step)
I0404 20:19:25.422315 47978602034560 learning.py:507] global step 1602: loss = 5.8270 (0.534 sec/step)
I0404 20:19:25.963462 47978602034560 learning.py:507] global step 1603: loss = 5.6562 (0.540 sec/step)
I0404 20:19:26.497717 47978602034560 learning.py:507] global step 1604: loss = 6.8684 (0.533 sec/step)
I0404 20:19:27.035627 47978602034560 learning.py:507] global step 1605: loss = 6.8822 (0.536 sec/step)
I0404 20:19:27.546495 47978602034560 learning.py:507] global step 1606: loss = 5.4010 (0.509 sec/step)
I0404 20:19:28.079755 47978602034560 learning.py:507] global step 1607: loss = 6.7168 (0.532 sec/step)
I0404 20:19:28.585100 47978602034560 learning.py:507] global step 1608: loss = 6.5108 (0.504 sec/step)
I0404 20:19:29.098209 47978602034560 learning.py:507] global step 1609: loss = 7.7463 (0.512 sec/step)
I0404 20:19:29.598839 47978602034560 learning.py:507] global step 1610: loss = 5.8253 (0.499 sec/step)
I0404 20:19:30.129004 47978602034560 learning.py:507] global step 1611: loss = 6.4708 (0.529 sec/step)
I0404 20:19:30.643673 47978602034560 learning.py:507] global step 1612: loss = 7.3076 (0.512 sec/step)
I0404 20:19:31.182174 47978602034560 learning.py:507] global step 1613: loss = 7.4212 (0.537 sec/step)
I0404 20:19:31.695649 47978602034560 learning.py:507] global step 1614: loss = 8.1318 (0.511 sec/step)
I0404 20:19:32.207886 47978602034560 learning.py:507] global step 1615: loss = 6.4923 (0.509 sec/step)
I0404 20:19:32.720687 47978602034560 learning.py:507] global step 1616: loss = 6.4360 (0.511 sec/step)
I0404 20:19:33.231987 47978602034560 learning.py:507] global step 1617: loss = 7.5326 (0.510 sec/step)
I0404 20:19:33.733536 47978602034560 learning.py:507] global step 1618: loss = 6.8154 (0.499 sec/step)
I0404 20:19:34.250564 47978602034560 learning.py:507] global step 1619: loss = 7.0951 (0.516 sec/step)
I0404 20:19:34.773788 47978602034560 learning.py:507] global step 1620: loss = 6.3549 (0.522 sec/step)
I0404 20:19:35.299710 47978602034560 learning.py:507] global step 1621: loss = 7.5906 (0.524 sec/step)
I0404 20:19:35.817569 47978602034560 learning.py:507] global step 1622: loss = 7.5667 (0.516 sec/step)
I0404 20:19:36.331367 47978602034560 learning.py:507] global step 1623: loss = 6.9711 (0.512 sec/step)
I0404 20:19:36.860842 47978602034560 learning.py:507] global step 1624: loss = 7.2175 (0.528 sec/step)
I0404 20:19:37.373700 47978602034560 learning.py:507] global step 1625: loss = 5.8982 (0.511 sec/step)
I0404 20:19:37.882902 47978602034560 learning.py:507] global step 1626: loss = 7.5456 (0.508 sec/step)
I0404 20:19:38.386783 47978602034560 learning.py:507] global step 1627: loss = 7.7331 (0.502 sec/step)
I0404 20:19:38.902581 47978602034560 learning.py:507] global step 1628: loss = 8.0305 (0.513 sec/step)
I0404 20:19:39.431949 47978602034560 learning.py:507] global step 1629: loss = 7.6667 (0.526 sec/step)
I0404 20:19:39.940354 47978602034560 learning.py:507] global step 1630: loss = 7.3150 (0.507 sec/step)
I0404 20:19:40.450622 47978602034560 learning.py:507] global step 1631: loss = 8.5236 (0.509 sec/step)
I0404 20:19:40.984203 47978602034560 learning.py:507] global step 1632: loss = 6.9277 (0.532 sec/step)
I0404 20:19:41.491898 47978602034560 learning.py:507] global step 1633: loss = 7.0674 (0.505 sec/step)
I0404 20:19:42.005076 47978602034560 learning.py:507] global step 1634: loss = 7.4512 (0.512 sec/step)
I0404 20:19:42.522241 47978602034560 learning.py:507] global step 1635: loss = 8.3821 (0.514 sec/step)
I0404 20:19:43.058513 47978602034560 learning.py:507] global step 1636: loss = 7.7190 (0.535 sec/step)
I0404 20:19:43.565751 47978602034560 learning.py:507] global step 1637: loss = 7.5431 (0.506 sec/step)
I0404 20:19:44.068296 47978602034560 learning.py:507] global step 1638: loss = 7.4669 (0.501 sec/step)
I0404 20:19:44.573397 47978602034560 learning.py:507] global step 1639: loss = 6.1341 (0.502 sec/step)
I0404 20:19:45.113967 47978602034560 learning.py:507] global step 1640: loss = 7.4752 (0.539 sec/step)
I0404 20:19:45.629079 47978602034560 learning.py:507] global step 1641: loss = 6.6725 (0.514 sec/step)
I0404 20:19:46.133677 47978602034560 learning.py:507] global step 1642: loss = 6.4705 (0.502 sec/step)
I0404 20:19:46.658709 47978602034560 learning.py:507] global step 1643: loss = 8.1486 (0.524 sec/step)
I0404 20:19:47.173532 47978602034560 learning.py:507] global step 1644: loss = 6.4619 (0.513 sec/step)
I0404 20:19:47.686644 47978602034560 learning.py:507] global step 1645: loss = 6.6387 (0.512 sec/step)
I0404 20:19:48.208656 47978602034560 learning.py:507] global step 1646: loss = 7.3272 (0.520 sec/step)
I0404 20:19:48.718853 47978602034560 learning.py:507] global step 1647: loss = 6.1561 (0.509 sec/step)
I0404 20:19:49.223526 47978602034560 learning.py:507] global step 1648: loss = 6.4036 (0.502 sec/step)
I0404 20:19:49.740037 47978602034560 learning.py:507] global step 1649: loss = 7.0772 (0.515 sec/step)
I0404 20:19:50.251206 47978602034560 learning.py:507] global step 1650: loss = 7.4284 (0.510 sec/step)
I0404 20:19:50.764575 47978602034560 learning.py:507] global step 1651: loss = 6.3018 (0.512 sec/step)
I0404 20:19:51.285735 47978602034560 learning.py:507] global step 1652: loss = 6.8779 (0.520 sec/step)
I0404 20:19:51.797946 47978602034560 learning.py:507] global step 1653: loss = 6.8762 (0.511 sec/step)
I0404 20:19:52.318557 47978602034560 learning.py:507] global step 1654: loss = 6.5891 (0.519 sec/step)
I0404 20:19:52.827543 47978602034560 learning.py:507] global step 1655: loss = 6.1082 (0.506 sec/step)
I0404 20:19:53.361746 47978602034560 learning.py:507] global step 1656: loss = 7.0214 (0.531 sec/step)
I0404 20:19:53.875900 47978602034560 learning.py:507] global step 1657: loss = 6.2062 (0.513 sec/step)
I0404 20:19:54.387732 47978602034560 learning.py:507] global step 1658: loss = 6.8557 (0.509 sec/step)
I0404 20:19:54.927925 47978602034560 learning.py:507] global step 1659: loss = 8.5046 (0.539 sec/step)
I0404 20:19:55.453065 47978602034560 learning.py:507] global step 1660: loss = 6.8197 (0.524 sec/step)
I0404 20:19:55.960081 47978602034560 learning.py:507] global step 1661: loss = 5.7714 (0.505 sec/step)
I0404 20:19:56.476601 47978602034560 learning.py:507] global step 1662: loss = 6.0782 (0.515 sec/step)
I0404 20:19:56.989281 47978602034560 learning.py:507] global step 1663: loss = 6.3243 (0.511 sec/step)
I0404 20:19:57.523157 47978602034560 learning.py:507] global step 1664: loss = 6.9097 (0.531 sec/step)
I0404 20:19:58.055298 47978602034560 learning.py:507] global step 1665: loss = 6.3860 (0.531 sec/step)
I0404 20:19:58.564905 47978602034560 learning.py:507] global step 1666: loss = 8.1122 (0.508 sec/step)
I0404 20:19:59.086529 47978602034560 learning.py:507] global step 1667: loss = 7.2515 (0.520 sec/step)
I0404 20:19:59.619438 47978602034560 learning.py:507] global step 1668: loss = 7.2209 (0.531 sec/step)
I0404 20:20:00.130219 47978602034560 learning.py:507] global step 1669: loss = 7.0494 (0.509 sec/step)
I0404 20:20:00.651835 47978602034560 learning.py:507] global step 1670: loss = 7.6431 (0.520 sec/step)
I0404 20:20:01.157429 47978602034560 learning.py:507] global step 1671: loss = 7.1978 (0.503 sec/step)
I0404 20:20:01.671807 47978602034560 learning.py:507] global step 1672: loss = 6.3256 (0.513 sec/step)
I0404 20:20:02.188056 47978602034560 learning.py:507] global step 1673: loss = 6.9297 (0.513 sec/step)
I0404 20:20:02.708329 47978602034560 learning.py:507] global step 1674: loss = 7.2318 (0.519 sec/step)
I0404 20:20:03.225894 47978602034560 learning.py:507] global step 1675: loss = 6.7085 (0.516 sec/step)
I0404 20:20:03.732895 47978602034560 learning.py:507] global step 1676: loss = 6.2137 (0.504 sec/step)
I0404 20:20:04.235689 47978602034560 learning.py:507] global step 1677: loss = 6.8618 (0.501 sec/step)
I0404 20:20:04.775928 47978602034560 learning.py:507] global step 1678: loss = 6.8485 (0.539 sec/step)
I0404 20:20:05.285989 47978602034560 learning.py:507] global step 1679: loss = 6.3609 (0.509 sec/step)
I0404 20:20:05.795423 47978602034560 learning.py:507] global step 1680: loss = 7.8577 (0.507 sec/step)
I0404 20:20:06.327399 47978602034560 learning.py:507] global step 1681: loss = 7.2636 (0.530 sec/step)
I0404 20:20:06.836443 47978602034560 learning.py:507] global step 1682: loss = 7.3945 (0.508 sec/step)
I0404 20:20:07.356374 47978602034560 learning.py:507] global step 1683: loss = 6.9792 (0.518 sec/step)
I0404 20:20:07.885862 47978602034560 learning.py:507] global step 1684: loss = 7.2655 (0.527 sec/step)
I0404 20:20:08.389674 47978602034560 learning.py:507] global step 1685: loss = 7.4651 (0.502 sec/step)
I0404 20:20:08.900681 47978602034560 learning.py:507] global step 1686: loss = 6.9391 (0.509 sec/step)
I0404 20:20:09.424624 47978602034560 learning.py:507] global step 1687: loss = 7.3941 (0.522 sec/step)
I0404 20:20:09.936383 47978602034560 learning.py:507] global step 1688: loss = 6.5993 (0.510 sec/step)
I0404 20:20:10.449164 47978602034560 learning.py:507] global step 1689: loss = 6.6718 (0.510 sec/step)
I0404 20:20:10.956354 47978602034560 learning.py:507] global step 1690: loss = 6.2819 (0.506 sec/step)
I0404 20:20:11.459071 47978602034560 learning.py:507] global step 1691: loss = 7.0601 (0.501 sec/step)
I0404 20:20:11.974174 47978602034560 learning.py:507] global step 1692: loss = 6.3232 (0.514 sec/step)
I0404 20:20:12.495223 47978602034560 learning.py:507] global step 1693: loss = 7.7132 (0.519 sec/step)
I0404 20:20:13.018721 47978602034560 learning.py:507] global step 1694: loss = 7.3356 (0.521 sec/step)
I0404 20:20:13.559060 47978602034560 learning.py:507] global step 1695: loss = 5.8795 (0.539 sec/step)
I0404 20:20:14.058155 47978602034560 learning.py:507] global step 1696: loss = 5.8154 (0.497 sec/step)
I0404 20:20:14.559808 47978602034560 learning.py:507] global step 1697: loss = 6.7380 (0.500 sec/step)
I0404 20:20:15.068466 47978602034560 learning.py:507] global step 1698: loss = 6.9607 (0.507 sec/step)
I0404 20:20:15.573668 47978602034560 learning.py:507] global step 1699: loss = 6.2593 (0.502 sec/step)
I0404 20:20:16.080663 47978602034560 learning.py:507] global step 1700: loss = 5.8592 (0.505 sec/step)
I0404 20:20:16.588507 47978602034560 learning.py:507] global step 1701: loss = 7.4961 (0.506 sec/step)
I0404 20:20:17.095492 47978602034560 learning.py:507] global step 1702: loss = 7.2322 (0.504 sec/step)
I0404 20:20:17.629272 47978602034560 learning.py:507] global step 1703: loss = 6.4067 (0.532 sec/step)
I0404 20:20:18.158687 47978602034560 learning.py:507] global step 1704: loss = 6.8317 (0.528 sec/step)
I0404 20:20:18.676768 47978602034560 learning.py:507] global step 1705: loss = 7.2391 (0.515 sec/step)
I0404 20:20:19.186042 47978602034560 learning.py:507] global step 1706: loss = 6.2647 (0.508 sec/step)
I0404 20:20:19.693032 47978602034560 learning.py:507] global step 1707: loss = 7.6684 (0.506 sec/step)
I0404 20:20:20.200919 47978602034560 learning.py:507] global step 1708: loss = 7.4647 (0.505 sec/step)
I0404 20:20:20.709656 47978602034560 learning.py:507] global step 1709: loss = 6.9454 (0.506 sec/step)
I0404 20:20:21.227268 47978602034560 learning.py:507] global step 1710: loss = 7.6200 (0.516 sec/step)
I0404 20:20:21.744455 47978602034560 learning.py:507] global step 1711: loss = 8.0685 (0.514 sec/step)
I0404 20:20:22.249425 47978602034560 learning.py:507] global step 1712: loss = 7.1104 (0.503 sec/step)
I0404 20:20:22.760984 47978602034560 learning.py:507] global step 1713: loss = 6.6827 (0.509 sec/step)
I0404 20:20:23.278809 47978602034560 learning.py:507] global step 1714: loss = 6.8905 (0.516 sec/step)
I0404 20:20:23.788286 47978602034560 learning.py:507] global step 1715: loss = 6.5911 (0.507 sec/step)
I0404 20:20:24.294132 47978602034560 learning.py:507] global step 1716: loss = 8.4105 (0.503 sec/step)
I0404 20:20:24.804827 47978602034560 learning.py:507] global step 1717: loss = 6.5189 (0.508 sec/step)
I0404 20:20:25.345021 47978602034560 learning.py:507] global step 1718: loss = 7.1686 (0.539 sec/step)
I0404 20:20:25.864694 47978602034560 learning.py:507] global step 1719: loss = 6.3225 (0.518 sec/step)
I0404 20:20:26.376911 47978602034560 learning.py:507] global step 1720: loss = 6.6496 (0.511 sec/step)
I0404 20:20:26.884932 47978602034560 learning.py:507] global step 1721: loss = 6.6260 (0.506 sec/step)
I0404 20:20:27.403240 47978602034560 learning.py:507] global step 1722: loss = 7.1058 (0.517 sec/step)
I0404 20:20:27.920630 47978602034560 learning.py:507] global step 1723: loss = 6.2780 (0.516 sec/step)
I0404 20:20:28.451697 47978602034560 learning.py:507] global step 1724: loss = 6.7011 (0.530 sec/step)
I0404 20:20:28.987464 47978602034560 learning.py:507] global step 1725: loss = 5.6941 (0.534 sec/step)
I0404 20:20:29.490651 47978602034560 learning.py:507] global step 1726: loss = 7.4199 (0.502 sec/step)
I0404 20:20:30.002951 47978602034560 learning.py:507] global step 1727: loss = 6.1544 (0.511 sec/step)
I0404 20:20:30.504749 47978602034560 learning.py:507] global step 1728: loss = 6.0786 (0.500 sec/step)
I0404 20:20:31.037291 47978602034560 learning.py:507] global step 1729: loss = 6.1677 (0.531 sec/step)
I0404 20:20:31.548327 47978602034560 learning.py:507] global step 1730: loss = 6.7009 (0.509 sec/step)
I0404 20:20:32.061430 47978602034560 learning.py:507] global step 1731: loss = 7.5487 (0.512 sec/step)
I0404 20:20:32.569016 47978602034560 learning.py:507] global step 1732: loss = 7.5765 (0.506 sec/step)
I0404 20:20:33.087032 47978602034560 learning.py:507] global step 1733: loss = 7.2420 (0.515 sec/step)
I0404 20:20:33.611195 47978602034560 learning.py:507] global step 1734: loss = 6.7988 (0.523 sec/step)
I0404 20:20:34.122038 47978602034560 learning.py:507] global step 1735: loss = 6.7877 (0.509 sec/step)
I0404 20:20:34.628639 47978602034560 learning.py:507] global step 1736: loss = 6.2267 (0.505 sec/step)
I0404 20:20:35.160480 47978602034560 learning.py:507] global step 1737: loss = 6.8487 (0.530 sec/step)
I0404 20:20:35.684385 47978602034560 learning.py:507] global step 1738: loss = 6.8373 (0.522 sec/step)
I0404 20:20:36.187170 47978602034560 learning.py:507] global step 1739: loss = 7.3030 (0.501 sec/step)
I0404 20:20:36.690567 47978602034560 learning.py:507] global step 1740: loss = 6.3331 (0.502 sec/step)
I0404 20:20:37.195921 47978602034560 learning.py:507] global step 1741: loss = 7.4439 (0.504 sec/step)
I0404 20:20:37.736705 47978602034560 learning.py:507] global step 1742: loss = 6.1655 (0.539 sec/step)
I0404 20:20:38.246343 47978602034560 learning.py:507] global step 1743: loss = 6.6495 (0.508 sec/step)
I0404 20:20:38.755987 47978602034560 learning.py:507] global step 1744: loss = 6.9238 (0.508 sec/step)
I0404 20:20:39.287574 47978602034560 learning.py:507] global step 1745: loss = 7.0606 (0.529 sec/step)
I0404 20:20:39.794331 47978602034560 learning.py:507] global step 1746: loss = 7.6393 (0.505 sec/step)
I0404 20:20:40.313208 47978602034560 learning.py:507] global step 1747: loss = 6.7503 (0.517 sec/step)
I0404 20:20:40.825486 47978602034560 learning.py:507] global step 1748: loss = 7.4645 (0.511 sec/step)
I0404 20:20:41.332066 47978602034560 learning.py:507] global step 1749: loss = 7.1019 (0.504 sec/step)
I0404 20:20:41.847124 47978602034560 learning.py:507] global step 1750: loss = 7.3004 (0.512 sec/step)
I0404 20:20:42.363869 47978602034560 learning.py:507] global step 1751: loss = 7.8088 (0.514 sec/step)
I0404 20:20:42.889919 47978602034560 learning.py:507] global step 1752: loss = 7.0853 (0.525 sec/step)
I0404 20:20:43.394744 47978602034560 learning.py:507] global step 1753: loss = 6.9925 (0.503 sec/step)
I0404 20:20:43.898106 47978602034560 learning.py:507] global step 1754: loss = 6.2774 (0.502 sec/step)
I0404 20:20:44.399550 47978602034560 learning.py:507] global step 1755: loss = 6.8394 (0.500 sec/step)
I0404 20:20:44.920293 47978602034560 learning.py:507] global step 1756: loss = 6.4012 (0.519 sec/step)
I0404 20:20:45.440277 47978602034560 learning.py:507] global step 1757: loss = 6.0822 (0.517 sec/step)
I0404 20:20:45.952749 47978602034560 learning.py:507] global step 1758: loss = 7.2073 (0.511 sec/step)
I0404 20:20:46.465278 47978602034560 learning.py:507] global step 1759: loss = 7.3349 (0.511 sec/step)
I0404 20:20:46.994632 47978602034560 learning.py:507] global step 1760: loss = 6.8712 (0.528 sec/step)
I0404 20:20:47.508021 47978602034560 learning.py:507] global step 1761: loss = 6.8485 (0.512 sec/step)
I0404 20:20:48.048711 47978602034560 learning.py:507] global step 1762: loss = 6.8639 (0.539 sec/step)
I0404 20:20:48.577757 47978602034560 learning.py:507] global step 1763: loss = 6.3539 (0.527 sec/step)
I0404 20:20:49.107082 47978602034560 learning.py:507] global step 1764: loss = 7.0390 (0.526 sec/step)
I0404 20:20:49.630164 47978602034560 learning.py:507] global step 1765: loss = 7.4664 (0.522 sec/step)
I0404 20:20:50.137502 47978602034560 learning.py:507] global step 1766: loss = 6.6753 (0.506 sec/step)
I0404 20:20:50.650330 47978602034560 learning.py:507] global step 1767: loss = 7.8036 (0.511 sec/step)
I0404 20:20:51.167356 47978602034560 learning.py:507] global step 1768: loss = 6.7243 (0.515 sec/step)
I0404 20:20:51.681610 47978602034560 learning.py:507] global step 1769: loss = 6.9607 (0.513 sec/step)
I0404 20:20:52.192500 47978602034560 learning.py:507] global step 1770: loss = 6.9743 (0.509 sec/step)
I0404 20:20:52.722962 47978602034560 learning.py:507] global step 1771: loss = 6.5556 (0.529 sec/step)
I0404 20:20:53.236858 47978602034560 learning.py:507] global step 1772: loss = 6.5873 (0.512 sec/step)
I0404 20:20:53.744809 47978602034560 learning.py:507] global step 1773: loss = 7.0987 (0.506 sec/step)
I0404 20:20:54.276231 47978602034560 learning.py:507] global step 1774: loss = 6.3709 (0.529 sec/step)
I0404 20:20:54.789865 47978602034560 learning.py:507] global step 1775: loss = 6.0631 (0.512 sec/step)
I0404 20:20:55.319081 47978602034560 learning.py:507] global step 1776: loss = 6.7725 (0.528 sec/step)
I0404 20:20:55.832259 47978602034560 learning.py:507] global step 1777: loss = 7.1198 (0.512 sec/step)
I0404 20:20:56.337802 47978602034560 learning.py:507] global step 1778: loss = 6.6359 (0.504 sec/step)
I0404 20:20:56.864405 47978602034560 learning.py:507] global step 1779: loss = 7.3124 (0.525 sec/step)
I0404 20:20:57.368755 47978602034560 learning.py:507] global step 1780: loss = 6.3224 (0.503 sec/step)
I0404 20:20:57.880771 47978602034560 learning.py:507] global step 1781: loss = 6.8369 (0.509 sec/step)
I0404 20:20:58.417822 47978602034560 learning.py:507] global step 1782: loss = 6.2843 (0.536 sec/step)
I0404 20:20:58.931127 47978602034560 learning.py:507] global step 1783: loss = 6.6728 (0.512 sec/step)
I0404 20:20:59.463294 47978602034560 learning.py:507] global step 1784: loss = 6.7586 (0.529 sec/step)
I0404 20:20:59.969467 47978602034560 learning.py:507] global step 1785: loss = 6.8281 (0.505 sec/step)
I0404 20:21:00.482913 47978602034560 learning.py:507] global step 1786: loss = 6.7843 (0.511 sec/step)
I0404 20:21:01.020370 47978602034560 learning.py:507] global step 1787: loss = 7.6664 (0.536 sec/step)
I0404 20:21:01.553533 47978602034560 learning.py:507] global step 1788: loss = 6.3196 (0.532 sec/step)
I0404 20:21:02.064447 47978602034560 learning.py:507] global step 1789: loss = 6.8249 (0.509 sec/step)
I0404 20:21:02.598962 47978602034560 learning.py:507] global step 1790: loss = 7.9721 (0.533 sec/step)
I0404 20:21:03.119215 47978602034560 learning.py:507] global step 1791: loss = 6.3512 (0.517 sec/step)
I0404 20:21:03.635531 47978602034560 learning.py:507] global step 1792: loss = 6.6771 (0.515 sec/step)
I0404 20:21:04.139596 47978602034560 learning.py:507] global step 1793: loss = 7.9422 (0.501 sec/step)
I0404 20:21:04.645648 47978602034560 learning.py:507] global step 1794: loss = 7.1184 (0.504 sec/step)
I0404 20:21:05.153051 47978602034560 learning.py:507] global step 1795: loss = 6.7384 (0.506 sec/step)
I0404 20:21:05.660177 47978602034560 learning.py:507] global step 1796: loss = 7.2588 (0.506 sec/step)
I0404 20:21:06.167866 47978602034560 learning.py:507] global step 1797: loss = 6.5439 (0.506 sec/step)
I0404 20:21:06.681689 47978602034560 learning.py:507] global step 1798: loss = 6.9003 (0.512 sec/step)
I0404 20:21:07.215416 47978602034560 learning.py:507] global step 1799: loss = 5.6426 (0.532 sec/step)
I0404 20:21:07.738096 47978602034560 learning.py:507] global step 1800: loss = 7.2606 (0.521 sec/step)
I0404 20:21:08.244591 47978602034560 learning.py:507] global step 1801: loss = 6.0511 (0.505 sec/step)
I0404 20:21:08.774941 47978602034560 learning.py:507] global step 1802: loss = 7.3062 (0.529 sec/step)
I0404 20:21:09.283020 47978602034560 learning.py:507] global step 1803: loss = 7.1796 (0.507 sec/step)
I0404 20:21:09.820069 47978602034560 learning.py:507] global step 1804: loss = 6.4231 (0.535 sec/step)
I0404 20:21:10.359068 47978602034560 learning.py:507] global step 1805: loss = 6.0556 (0.537 sec/step)
I0404 20:21:10.867126 47978602034560 learning.py:507] global step 1806: loss = 6.6815 (0.505 sec/step)
I0404 20:21:11.387962 47978602034560 learning.py:507] global step 1807: loss = 6.4660 (0.518 sec/step)
I0404 20:21:11.907631 47978602034560 learning.py:507] global step 1808: loss = 7.3109 (0.518 sec/step)
I0404 20:21:12.437606 47978602034560 learning.py:507] global step 1809: loss = 6.4825 (0.528 sec/step)
I0404 20:21:12.957286 47978602034560 learning.py:507] global step 1810: loss = 6.1605 (0.518 sec/step)
I0404 20:21:13.471357 47978602034560 learning.py:507] global step 1811: loss = 5.8860 (0.512 sec/step)
I0404 20:21:13.988401 47978602034560 learning.py:507] global step 1812: loss = 6.7535 (0.515 sec/step)
I0404 20:21:14.528374 47978602034560 learning.py:507] global step 1813: loss = 6.4737 (0.537 sec/step)
I0404 20:21:15.043485 47978602034560 learning.py:507] global step 1814: loss = 6.1552 (0.514 sec/step)
I0404 20:21:15.556624 47978602034560 learning.py:507] global step 1815: loss = 6.8386 (0.512 sec/step)
I0404 20:21:16.059454 47978602034560 learning.py:507] global step 1816: loss = 6.8813 (0.501 sec/step)
I0404 20:21:16.562242 47978602034560 learning.py:507] global step 1817: loss = 7.4667 (0.501 sec/step)
I0404 20:21:16.637859 47983664076544 supervisor.py:1099] global_step/sec: 1.93332
I0404 20:21:17.248113 47978602034560 learning.py:507] global step 1818: loss = 6.6963 (0.683 sec/step)
I0404 20:21:17.253176 47983661975296 supervisor.py:1050] Recording summary at step 1818.
I0404 20:21:17.751955 47978602034560 learning.py:507] global step 1819: loss = 5.9223 (0.501 sec/step)
I0404 20:21:18.254660 47978602034560 learning.py:507] global step 1820: loss = 6.1589 (0.501 sec/step)
I0404 20:21:18.759816 47978602034560 learning.py:507] global step 1821: loss = 7.4061 (0.504 sec/step)
I0404 20:21:19.279140 47978602034560 learning.py:507] global step 1822: loss = 6.8266 (0.518 sec/step)
I0404 20:21:19.820701 47978602034560 learning.py:507] global step 1823: loss = 7.0489 (0.539 sec/step)
I0404 20:21:20.330883 47978602034560 learning.py:507] global step 1824: loss = 6.8551 (0.509 sec/step)
I0404 20:21:20.835100 47978602034560 learning.py:507] global step 1825: loss = 6.6593 (0.503 sec/step)
I0404 20:21:21.356234 47978602034560 learning.py:507] global step 1826: loss = 6.8327 (0.520 sec/step)
I0404 20:21:21.872523 47978602034560 learning.py:507] global step 1827: loss = 6.3794 (0.515 sec/step)
I0404 20:21:22.404692 47978602034560 learning.py:507] global step 1828: loss = 7.0233 (0.529 sec/step)
I0404 20:21:22.916626 47978602034560 learning.py:507] global step 1829: loss = 7.1328 (0.510 sec/step)
I0404 20:21:23.429421 47978602034560 learning.py:507] global step 1830: loss = 6.1981 (0.511 sec/step)
I0404 20:21:23.932145 47978602034560 learning.py:507] global step 1831: loss = 6.3447 (0.501 sec/step)
I0404 20:21:24.470824 47978602034560 learning.py:507] global step 1832: loss = 6.7417 (0.537 sec/step)
I0404 20:21:24.999712 47978602034560 learning.py:507] global step 1833: loss = 6.7344 (0.526 sec/step)
I0404 20:21:25.510641 47978602034560 learning.py:507] global step 1834: loss = 6.2922 (0.509 sec/step)
I0404 20:21:26.027832 47978602034560 learning.py:507] global step 1835: loss = 6.2314 (0.516 sec/step)
I0404 20:21:26.567218 47978602034560 learning.py:507] global step 1836: loss = 6.7792 (0.538 sec/step)
I0404 20:21:27.071330 47978602034560 learning.py:507] global step 1837: loss = 6.0777 (0.503 sec/step)
I0404 20:21:27.580495 47978602034560 learning.py:507] global step 1838: loss = 6.9201 (0.506 sec/step)
I0404 20:21:28.114414 47978602034560 learning.py:507] global step 1839: loss = 6.3249 (0.532 sec/step)
I0404 20:21:28.624523 47978602034560 learning.py:507] global step 1840: loss = 6.5071 (0.509 sec/step)
I0404 20:21:29.137314 47978602034560 learning.py:507] global step 1841: loss = 6.9924 (0.510 sec/step)
I0404 20:21:29.642906 47978602034560 learning.py:507] global step 1842: loss = 7.8012 (0.504 sec/step)
I0404 20:21:30.157203 47978602034560 learning.py:507] global step 1843: loss = 6.3147 (0.513 sec/step)
I0404 20:21:30.660609 47978602034560 learning.py:507] global step 1844: loss = 6.4394 (0.501 sec/step)
I0404 20:21:31.164529 47978602034560 learning.py:507] global step 1845: loss = 6.5880 (0.502 sec/step)
I0404 20:21:31.680027 47978602034560 learning.py:507] global step 1846: loss = 8.9151 (0.514 sec/step)
I0404 20:21:32.200490 47978602034560 learning.py:507] global step 1847: loss = 6.3789 (0.519 sec/step)
I0404 20:21:32.712731 47978602034560 learning.py:507] global step 1848: loss = 6.4721 (0.511 sec/step)
I0404 20:21:33.220303 47978602034560 learning.py:507] global step 1849: loss = 6.6708 (0.506 sec/step)
I0404 20:21:33.731293 47978602034560 learning.py:507] global step 1850: loss = 6.8092 (0.509 sec/step)
I0404 20:21:34.245859 47978602034560 learning.py:507] global step 1851: loss = 6.5043 (0.513 sec/step)
I0404 20:21:34.747438 47978602034560 learning.py:507] global step 1852: loss = 6.2914 (0.500 sec/step)
I0404 20:21:35.262028 47978602034560 learning.py:507] global step 1853: loss = 6.8784 (0.513 sec/step)
I0404 20:21:35.794233 47978602034560 learning.py:507] global step 1854: loss = 6.6981 (0.531 sec/step)
I0404 20:21:36.308521 47978602034560 learning.py:507] global step 1855: loss = 6.4110 (0.511 sec/step)
I0404 20:21:36.847351 47978602034560 learning.py:507] global step 1856: loss = 6.5351 (0.537 sec/step)
I0404 20:21:37.351475 47978602034560 learning.py:507] global step 1857: loss = 6.7807 (0.502 sec/step)
I0404 20:21:37.852405 47978602034560 learning.py:507] global step 1858: loss = 6.7619 (0.499 sec/step)
I0404 20:21:38.373786 47978602034560 learning.py:507] global step 1859: loss = 7.0322 (0.520 sec/step)
I0404 20:21:38.910203 47978602034560 learning.py:507] global step 1860: loss = 7.3907 (0.535 sec/step)
I0404 20:21:39.424464 47978602034560 learning.py:507] global step 1861: loss = 7.0683 (0.511 sec/step)
I0404 20:21:39.936318 47978602034560 learning.py:507] global step 1862: loss = 6.0857 (0.509 sec/step)
I0404 20:21:40.455658 47978602034560 learning.py:507] global step 1863: loss = 7.0352 (0.518 sec/step)
I0404 20:21:40.990485 47978602034560 learning.py:507] global step 1864: loss = 7.8008 (0.533 sec/step)
I0404 20:21:41.507170 47978602034560 learning.py:507] global step 1865: loss = 6.2211 (0.514 sec/step)
I0404 20:21:42.012593 47978602034560 learning.py:507] global step 1866: loss = 7.0217 (0.503 sec/step)
I0404 20:21:42.530158 47978602034560 learning.py:507] global step 1867: loss = 7.1346 (0.516 sec/step)
I0404 20:21:43.065161 47978602034560 learning.py:507] global step 1868: loss = 6.4248 (0.534 sec/step)
I0404 20:21:43.577302 47978602034560 learning.py:507] global step 1869: loss = 7.0304 (0.509 sec/step)
I0404 20:21:44.085272 47978602034560 learning.py:507] global step 1870: loss = 6.2266 (0.506 sec/step)
I0404 20:21:44.598411 47978602034560 learning.py:507] global step 1871: loss = 6.5877 (0.511 sec/step)
I0404 20:21:45.109650 47978602034560 learning.py:507] global step 1872: loss = 6.8304 (0.510 sec/step)
I0404 20:21:45.617547 47978602034560 learning.py:507] global step 1873: loss = 6.6975 (0.506 sec/step)
I0404 20:21:46.129742 47978602034560 learning.py:507] global step 1874: loss = 7.2571 (0.511 sec/step)
I0404 20:21:46.633836 47978602034560 learning.py:507] global step 1875: loss = 6.7820 (0.501 sec/step)
I0404 20:21:47.139206 47978602034560 learning.py:507] global step 1876: loss = 7.4691 (0.504 sec/step)
I0404 20:21:47.656703 47978602034560 learning.py:507] global step 1877: loss = 7.0677 (0.516 sec/step)
I0404 20:21:48.171015 47978602034560 learning.py:507] global step 1878: loss = 7.7331 (0.513 sec/step)
I0404 20:21:48.688871 47978602034560 learning.py:507] global step 1879: loss = 6.0649 (0.515 sec/step)
I0404 20:21:49.214836 47978602034560 learning.py:507] global step 1880: loss = 7.4856 (0.524 sec/step)
I0404 20:21:49.725574 47978602034560 learning.py:507] global step 1881: loss = 7.4579 (0.509 sec/step)
I0404 20:21:50.225484 47978602034560 learning.py:507] global step 1882: loss = 7.5858 (0.498 sec/step)
I0404 20:21:50.754181 47978602034560 learning.py:507] global step 1883: loss = 7.7453 (0.527 sec/step)
I0404 20:21:51.294331 47978602034560 learning.py:507] global step 1884: loss = 7.5344 (0.539 sec/step)
I0404 20:21:51.804863 47978602034560 learning.py:507] global step 1885: loss = 7.5656 (0.508 sec/step)
I0404 20:21:52.314867 47978602034560 learning.py:507] global step 1886: loss = 6.6358 (0.508 sec/step)
I0404 20:21:52.832779 47978602034560 learning.py:507] global step 1887: loss = 6.5309 (0.516 sec/step)
I0404 20:21:53.343459 47978602034560 learning.py:507] global step 1888: loss = 5.8483 (0.509 sec/step)
I0404 20:21:53.854434 47978602034560 learning.py:507] global step 1889: loss = 6.8401 (0.509 sec/step)
I0404 20:21:54.365165 47978602034560 learning.py:507] global step 1890: loss = 5.8488 (0.508 sec/step)
I0404 20:21:54.882163 47978602034560 learning.py:507] global step 1891: loss = 7.5356 (0.515 sec/step)
I0404 20:21:55.393110 47978602034560 learning.py:507] global step 1892: loss = 6.1248 (0.508 sec/step)
I0404 20:21:55.925738 47978602034560 learning.py:507] global step 1893: loss = 6.5325 (0.531 sec/step)
I0404 20:21:56.424300 47978602034560 learning.py:507] global step 1894: loss = 7.1068 (0.497 sec/step)
I0404 20:21:56.925876 47978602034560 learning.py:507] global step 1895: loss = 6.9469 (0.500 sec/step)
I0404 20:21:57.474938 47978602034560 learning.py:507] global step 1896: loss = 7.1999 (0.547 sec/step)
I0404 20:21:58.010567 47978602034560 learning.py:507] global step 1897: loss = 5.7194 (0.533 sec/step)
I0404 20:21:58.520894 47978602034560 learning.py:507] global step 1898: loss = 6.4768 (0.509 sec/step)
I0404 20:21:59.036701 47978602034560 learning.py:507] global step 1899: loss = 7.2567 (0.514 sec/step)
I0404 20:21:59.556208 47978602034560 learning.py:507] global step 1900: loss = 6.8963 (0.518 sec/step)
I0404 20:22:00.084991 47978602034560 learning.py:507] global step 1901: loss = 5.9729 (0.526 sec/step)
I0404 20:22:00.598695 47978602034560 learning.py:507] global step 1902: loss = 6.4008 (0.512 sec/step)
I0404 20:22:01.111850 47978602034560 learning.py:507] global step 1903: loss = 6.4296 (0.512 sec/step)
I0404 20:22:01.618378 47978602034560 learning.py:507] global step 1904: loss = 5.8647 (0.504 sec/step)
I0404 20:22:02.119521 47978602034560 learning.py:507] global step 1905: loss = 6.4267 (0.499 sec/step)
I0404 20:22:02.625733 47978602034560 learning.py:507] global step 1906: loss = 6.5121 (0.505 sec/step)
I0404 20:22:03.160381 47978602034560 learning.py:507] global step 1907: loss = 6.6143 (0.532 sec/step)
I0404 20:22:03.695898 47978602034560 learning.py:507] global step 1908: loss = 6.2879 (0.534 sec/step)
I0404 20:22:04.207925 47978602034560 learning.py:507] global step 1909: loss = 6.5534 (0.509 sec/step)
I0404 20:22:04.723814 47978602034560 learning.py:507] global step 1910: loss = 6.8015 (0.513 sec/step)
I0404 20:22:05.268375 47978602034560 learning.py:507] global step 1911: loss = 7.3834 (0.543 sec/step)
I0404 20:22:05.786274 47978602034560 learning.py:507] global step 1912: loss = 5.8804 (0.516 sec/step)
I0404 20:22:06.310570 47978602034560 learning.py:507] global step 1913: loss = 5.1802 (0.523 sec/step)
I0404 20:22:06.816854 47978602034560 learning.py:507] global step 1914: loss = 5.7506 (0.505 sec/step)
I0404 20:22:07.358016 47978602034560 learning.py:507] global step 1915: loss = 6.7958 (0.539 sec/step)
I0404 20:22:07.873753 47978602034560 learning.py:507] global step 1916: loss = 6.4649 (0.514 sec/step)
I0404 20:22:08.391623 47978602034560 learning.py:507] global step 1917: loss = 6.3775 (0.516 sec/step)
I0404 20:22:08.910158 47978602034560 learning.py:507] global step 1918: loss = 7.0173 (0.516 sec/step)
I0404 20:22:09.443628 47978602034560 learning.py:507] global step 1919: loss = 6.8584 (0.532 sec/step)
I0404 20:22:09.960844 47978602034560 learning.py:507] global step 1920: loss = 6.5279 (0.516 sec/step)
I0404 20:22:10.468761 47978602034560 learning.py:507] global step 1921: loss = 6.7763 (0.506 sec/step)
I0404 20:22:10.981393 47978602034560 learning.py:507] global step 1922: loss = 6.6578 (0.510 sec/step)
I0404 20:22:11.482071 47978602034560 learning.py:507] global step 1923: loss = 6.7161 (0.498 sec/step)
I0404 20:22:11.984833 47978602034560 learning.py:507] global step 1924: loss = 6.4015 (0.500 sec/step)
I0404 20:22:12.486865 47978602034560 learning.py:507] global step 1925: loss = 6.4302 (0.500 sec/step)
I0404 20:22:12.998307 47978602034560 learning.py:507] global step 1926: loss = 6.9803 (0.510 sec/step)
I0404 20:22:13.498401 47978602034560 learning.py:507] global step 1927: loss = 6.8159 (0.499 sec/step)
I0404 20:22:14.017626 47978602034560 learning.py:507] global step 1928: loss = 7.2392 (0.518 sec/step)
I0404 20:22:14.528149 47978602034560 learning.py:507] global step 1929: loss = 6.5991 (0.509 sec/step)
I0404 20:22:15.047977 47978602034560 learning.py:507] global step 1930: loss = 7.4597 (0.517 sec/step)
I0404 20:22:15.563521 47978602034560 learning.py:507] global step 1931: loss = 6.2518 (0.514 sec/step)
I0404 20:22:16.077602 47978602034560 learning.py:507] global step 1932: loss = 6.2183 (0.511 sec/step)
I0404 20:22:16.591995 47978602034560 learning.py:507] global step 1933: loss = 7.3680 (0.512 sec/step)
I0404 20:22:17.101522 47978602034560 learning.py:507] global step 1934: loss = 7.4374 (0.508 sec/step)
I0404 20:22:17.650733 47978602034560 learning.py:507] global step 1935: loss = 8.2657 (0.548 sec/step)
I0404 20:22:18.168858 47978602034560 learning.py:507] global step 1936: loss = 6.3844 (0.517 sec/step)
I0404 20:22:18.693376 47978602034560 learning.py:507] global step 1937: loss = 7.5846 (0.522 sec/step)
I0404 20:22:19.200333 47978602034560 learning.py:507] global step 1938: loss = 6.3941 (0.504 sec/step)
I0404 20:22:19.704870 47978602034560 learning.py:507] global step 1939: loss = 7.3941 (0.503 sec/step)
I0404 20:22:20.232027 47978602034560 learning.py:507] global step 1940: loss = 6.5768 (0.526 sec/step)
I0404 20:22:20.745371 47978602034560 learning.py:507] global step 1941: loss = 6.5406 (0.512 sec/step)
I0404 20:22:21.262186 47978602034560 learning.py:507] global step 1942: loss = 7.0194 (0.515 sec/step)
I0404 20:22:21.774613 47978602034560 learning.py:507] global step 1943: loss = 7.6940 (0.511 sec/step)
I0404 20:22:22.289000 47978602034560 learning.py:507] global step 1944: loss = 6.2490 (0.512 sec/step)
I0404 20:22:22.791342 47978602034560 learning.py:507] global step 1945: loss = 6.6160 (0.501 sec/step)
I0404 20:22:23.324587 47978602034560 learning.py:507] global step 1946: loss = 5.5869 (0.530 sec/step)
I0404 20:22:23.836068 47978602034560 learning.py:507] global step 1947: loss = 6.9397 (0.510 sec/step)
I0404 20:22:24.351798 47978602034560 learning.py:507] global step 1948: loss = 6.9472 (0.514 sec/step)
I0404 20:22:24.866071 47978602034560 learning.py:507] global step 1949: loss = 6.5751 (0.511 sec/step)
I0404 20:22:25.396545 47978602034560 learning.py:507] global step 1950: loss = 7.4901 (0.529 sec/step)
I0404 20:22:25.912914 47978602034560 learning.py:507] global step 1951: loss = 7.0740 (0.515 sec/step)
I0404 20:22:26.426123 47978602034560 learning.py:507] global step 1952: loss = 6.9428 (0.510 sec/step)
I0404 20:22:26.947128 47978602034560 learning.py:507] global step 1953: loss = 6.4650 (0.519 sec/step)
I0404 20:22:27.459032 47978602034560 learning.py:507] global step 1954: loss = 6.3398 (0.510 sec/step)
I0404 20:22:27.972261 47978602034560 learning.py:507] global step 1955: loss = 6.2060 (0.510 sec/step)
I0404 20:22:28.476036 47978602034560 learning.py:507] global step 1956: loss = 6.6675 (0.501 sec/step)
I0404 20:22:28.979928 47978602034560 learning.py:507] global step 1957: loss = 5.2954 (0.502 sec/step)
I0404 20:22:29.486886 47978602034560 learning.py:507] global step 1958: loss = 7.2130 (0.505 sec/step)
I0404 20:22:30.000997 47978602034560 learning.py:507] global step 1959: loss = 6.8088 (0.513 sec/step)
I0404 20:22:30.510946 47978602034560 learning.py:507] global step 1960: loss = 6.9665 (0.508 sec/step)
I0404 20:22:31.021660 47978602034560 learning.py:507] global step 1961: loss = 7.0084 (0.509 sec/step)
I0404 20:22:31.533581 47978602034560 learning.py:507] global step 1962: loss = 6.9949 (0.510 sec/step)
I0404 20:22:32.049259 47978602034560 learning.py:507] global step 1963: loss = 8.0392 (0.514 sec/step)
I0404 20:22:32.581631 47978602034560 learning.py:507] global step 1964: loss = 5.5947 (0.531 sec/step)
I0404 20:22:33.095396 47978602034560 learning.py:507] global step 1965: loss = 7.4656 (0.512 sec/step)
I0404 20:22:33.603744 47978602034560 learning.py:507] global step 1966: loss = 6.9602 (0.507 sec/step)
I0404 20:22:34.109967 47978602034560 learning.py:507] global step 1967: loss = 5.7074 (0.505 sec/step)
I0404 20:22:34.635626 47978602034560 learning.py:507] global step 1968: loss = 6.4405 (0.524 sec/step)
I0404 20:22:35.142889 47978602034560 learning.py:507] global step 1969: loss = 5.8748 (0.506 sec/step)
I0404 20:22:35.682909 47978602034560 learning.py:507] global step 1970: loss = 6.6600 (0.538 sec/step)
I0404 20:22:36.224751 47978602034560 learning.py:507] global step 1971: loss = 7.9108 (0.540 sec/step)
I0404 20:22:36.741818 47978602034560 learning.py:507] global step 1972: loss = 6.8071 (0.515 sec/step)
I0404 20:22:37.282450 47978602034560 learning.py:507] global step 1973: loss = 6.7988 (0.539 sec/step)
I0404 20:22:37.790427 47978602034560 learning.py:507] global step 1974: loss = 5.8890 (0.506 sec/step)
I0404 20:22:38.299541 47978602034560 learning.py:507] global step 1975: loss = 6.8828 (0.508 sec/step)
I0404 20:22:38.800055 47978602034560 learning.py:507] global step 1976: loss = 5.7691 (0.499 sec/step)
I0404 20:22:39.309155 47978602034560 learning.py:507] global step 1977: loss = 6.6161 (0.507 sec/step)
I0404 20:22:39.845725 47978602034560 learning.py:507] global step 1978: loss = 6.9072 (0.535 sec/step)
I0404 20:22:40.358102 47978602034560 learning.py:507] global step 1979: loss = 6.4730 (0.511 sec/step)
I0404 20:22:40.880290 47978602034560 learning.py:507] global step 1980: loss = 7.3712 (0.521 sec/step)
I0404 20:22:41.392795 47978602034560 learning.py:507] global step 1981: loss = 7.2713 (0.511 sec/step)
I0404 20:22:41.898018 47978602034560 learning.py:507] global step 1982: loss = 6.2691 (0.502 sec/step)
I0404 20:22:42.399849 47978602034560 learning.py:507] global step 1983: loss = 7.9972 (0.500 sec/step)
I0404 20:22:42.904009 47978602034560 learning.py:507] global step 1984: loss = 5.8416 (0.503 sec/step)
I0404 20:22:43.439600 47978602034560 learning.py:507] global step 1985: loss = 7.2078 (0.534 sec/step)
I0404 20:22:43.973755 47978602034560 learning.py:507] global step 1986: loss = 7.1445 (0.532 sec/step)
I0404 20:22:44.494094 47978602034560 learning.py:507] global step 1987: loss = 6.2563 (0.519 sec/step)
I0404 20:22:44.998790 47978602034560 learning.py:507] global step 1988: loss = 6.7270 (0.503 sec/step)
I0404 20:22:45.533342 47978602034560 learning.py:507] global step 1989: loss = 6.3433 (0.533 sec/step)
I0404 20:22:46.041113 47978602034560 learning.py:507] global step 1990: loss = 6.4423 (0.506 sec/step)
I0404 20:22:46.559995 47978602034560 learning.py:507] global step 1991: loss = 6.1318 (0.517 sec/step)
I0404 20:22:47.086344 47978602034560 learning.py:507] global step 1992: loss = 7.9035 (0.525 sec/step)
I0404 20:22:47.600058 47978602034560 learning.py:507] global step 1993: loss = 6.5916 (0.512 sec/step)
I0404 20:22:48.117105 47978602034560 learning.py:507] global step 1994: loss = 6.5515 (0.515 sec/step)
I0404 20:22:48.639280 47978602034560 learning.py:507] global step 1995: loss = 7.6794 (0.521 sec/step)
I0404 20:22:49.152594 47978602034560 learning.py:507] global step 1996: loss = 6.4486 (0.512 sec/step)
I0404 20:22:49.673915 47978602034560 learning.py:507] global step 1997: loss = 6.4262 (0.520 sec/step)
I0404 20:22:50.178944 47978602034560 learning.py:507] global step 1998: loss = 6.4104 (0.503 sec/step)
I0404 20:22:50.692113 47978602034560 learning.py:507] global step 1999: loss = 6.1380 (0.510 sec/step)
I0404 20:22:51.196239 47978602034560 learning.py:507] global step 2000: loss = 6.1019 (0.503 sec/step)
I0404 20:22:51.703226 47978602034560 learning.py:507] global step 2001: loss = 6.6547 (0.505 sec/step)
I0404 20:22:52.205832 47978602034560 learning.py:507] global step 2002: loss = 7.6063 (0.501 sec/step)
I0404 20:22:52.723085 47978602034560 learning.py:507] global step 2003: loss = 6.4708 (0.516 sec/step)
I0404 20:22:53.266986 47978602034560 learning.py:507] global step 2004: loss = 6.1587 (0.542 sec/step)
I0404 20:22:53.769051 47978602034560 learning.py:507] global step 2005: loss = 7.4758 (0.499 sec/step)
I0404 20:22:54.275271 47978602034560 learning.py:507] global step 2006: loss = 7.0203 (0.503 sec/step)
I0404 20:22:54.781558 47978602034560 learning.py:507] global step 2007: loss = 7.2426 (0.504 sec/step)
I0404 20:22:55.290763 47978602034560 learning.py:507] global step 2008: loss = 6.5915 (0.508 sec/step)
I0404 20:22:55.794215 47978602034560 learning.py:507] global step 2009: loss = 7.1441 (0.502 sec/step)
I0404 20:22:56.311291 47978602034560 learning.py:507] global step 2010: loss = 7.3162 (0.514 sec/step)
I0404 20:22:56.824449 47978602034560 learning.py:507] global step 2011: loss = 7.2811 (0.510 sec/step)
I0404 20:22:57.354450 47978602034560 learning.py:507] global step 2012: loss = 6.5668 (0.528 sec/step)
I0404 20:22:57.864459 47978602034560 learning.py:507] global step 2013: loss = 6.6060 (0.509 sec/step)
I0404 20:22:58.371127 47978602034560 learning.py:507] global step 2014: loss = 7.2353 (0.504 sec/step)
I0404 20:22:58.890366 47978602034560 learning.py:507] global step 2015: loss = 6.8704 (0.516 sec/step)
I0404 20:22:59.429713 47978602034560 learning.py:507] global step 2016: loss = 9.4166 (0.536 sec/step)
I0404 20:22:59.955769 47978602034560 learning.py:507] global step 2017: loss = 7.1873 (0.525 sec/step)
I0404 20:23:00.466907 47978602034560 learning.py:507] global step 2018: loss = 6.7920 (0.510 sec/step)
I0404 20:23:00.995661 47978602034560 learning.py:507] global step 2019: loss = 7.2636 (0.527 sec/step)
I0404 20:23:01.522300 47978602034560 learning.py:507] global step 2020: loss = 6.5831 (0.525 sec/step)
I0404 20:23:02.061373 47978602034560 learning.py:507] global step 2021: loss = 6.8874 (0.538 sec/step)
I0404 20:23:02.563244 47978602034560 learning.py:507] global step 2022: loss = 7.2548 (0.500 sec/step)
I0404 20:23:03.069919 47978602034560 learning.py:507] global step 2023: loss = 7.1190 (0.505 sec/step)
I0404 20:23:03.576290 47978602034560 learning.py:507] global step 2024: loss = 6.6134 (0.505 sec/step)
I0404 20:23:04.081932 47978602034560 learning.py:507] global step 2025: loss = 7.5122 (0.504 sec/step)
I0404 20:23:04.602539 47978602034560 learning.py:507] global step 2026: loss = 7.2747 (0.519 sec/step)
I0404 20:23:05.109573 47978602034560 learning.py:507] global step 2027: loss = 6.8589 (0.505 sec/step)
I0404 20:23:05.630836 47978602034560 learning.py:507] global step 2028: loss = 6.6045 (0.520 sec/step)
I0404 20:23:06.141098 47978602034560 learning.py:507] global step 2029: loss = 7.4813 (0.509 sec/step)
I0404 20:23:06.680401 47978602034560 learning.py:507] global step 2030: loss = 6.2382 (0.536 sec/step)
I0404 20:23:07.186394 47978602034560 learning.py:507] global step 2031: loss = 7.1588 (0.503 sec/step)
I0404 20:23:07.700780 47978602034560 learning.py:507] global step 2032: loss = 7.2471 (0.513 sec/step)
I0404 20:23:08.218816 47978602034560 learning.py:507] global step 2033: loss = 5.7264 (0.516 sec/step)
I0404 20:23:08.735104 47978602034560 learning.py:507] global step 2034: loss = 6.9156 (0.515 sec/step)
I0404 20:23:09.249598 47978602034560 learning.py:507] global step 2035: loss = 5.6621 (0.513 sec/step)
I0404 20:23:09.772361 47978602034560 learning.py:507] global step 2036: loss = 5.7784 (0.521 sec/step)
I0404 20:23:10.281864 47978602034560 learning.py:507] global step 2037: loss = 6.9075 (0.508 sec/step)
I0404 20:23:10.787895 47978602034560 learning.py:507] global step 2038: loss = 6.4693 (0.504 sec/step)
I0404 20:23:11.298351 47978602034560 learning.py:507] global step 2039: loss = 6.4424 (0.508 sec/step)
I0404 20:23:11.806086 47978602034560 learning.py:507] global step 2040: loss = 6.3744 (0.506 sec/step)
I0404 20:23:12.340594 47978602034560 learning.py:507] global step 2041: loss = 7.1144 (0.533 sec/step)
I0404 20:23:12.847337 47978602034560 learning.py:507] global step 2042: loss = 5.3500 (0.505 sec/step)
I0404 20:23:13.357857 47978602034560 learning.py:507] global step 2043: loss = 7.1079 (0.509 sec/step)
I0404 20:23:13.872428 47978602034560 learning.py:507] global step 2044: loss = 6.5418 (0.512 sec/step)
I0404 20:23:14.409729 47978602034560 learning.py:507] global step 2045: loss = 7.5049 (0.536 sec/step)
I0404 20:23:14.915484 47978602034560 learning.py:507] global step 2046: loss = 6.8060 (0.504 sec/step)
I0404 20:23:15.433615 47978602034560 learning.py:507] global step 2047: loss = 7.0321 (0.517 sec/step)
I0404 20:23:15.944340 47978602034560 learning.py:507] global step 2048: loss = 7.8459 (0.509 sec/step)
I0404 20:23:16.449277 47978602034560 learning.py:507] global step 2049: loss = 6.5796 (0.503 sec/step)
I0404 20:23:16.637347 47983664076544 supervisor.py:1099] global_step/sec: 1.93334
I0404 20:23:17.075079 47978602034560 learning.py:507] global step 2050: loss = 6.4419 (0.597 sec/step)
I0404 20:23:17.291466 47983661975296 supervisor.py:1050] Recording summary at step 2050.
I0404 20:23:17.645603 47978602034560 learning.py:507] global step 2051: loss = 6.4422 (0.565 sec/step)
I0404 20:23:18.155809 47978602034560 learning.py:507] global step 2052: loss = 5.9089 (0.509 sec/step)
I0404 20:23:18.664924 47978602034560 learning.py:507] global step 2053: loss = 7.5780 (0.508 sec/step)
I0404 20:23:19.174307 47978602034560 learning.py:507] global step 2054: loss = 6.4925 (0.508 sec/step)
I0404 20:23:19.711198 47978602034560 learning.py:507] global step 2055: loss = 6.1464 (0.535 sec/step)
I0404 20:23:20.228733 47978602034560 learning.py:507] global step 2056: loss = 7.0210 (0.516 sec/step)
I0404 20:23:20.773851 47978602034560 learning.py:507] global step 2057: loss = 6.1287 (0.543 sec/step)
I0404 20:23:21.281369 47978602034560 learning.py:507] global step 2058: loss = 6.8506 (0.506 sec/step)
I0404 20:23:21.805370 47978602034560 learning.py:507] global step 2059: loss = 6.9200 (0.522 sec/step)
I0404 20:23:22.329424 47978602034560 learning.py:507] global step 2060: loss = 7.3566 (0.523 sec/step)
I0404 20:23:22.838656 47978602034560 learning.py:507] global step 2061: loss = 7.2968 (0.508 sec/step)
I0404 20:23:23.345859 47978602034560 learning.py:507] global step 2062: loss = 7.5185 (0.506 sec/step)
I0404 20:23:23.852978 47978602034560 learning.py:507] global step 2063: loss = 6.9466 (0.506 sec/step)
I0404 20:23:24.362287 47978602034560 learning.py:507] global step 2064: loss = 6.4470 (0.508 sec/step)
I0404 20:23:24.872663 47978602034560 learning.py:507] global step 2065: loss = 7.0131 (0.508 sec/step)
I0404 20:23:25.389056 47978602034560 learning.py:507] global step 2066: loss = 6.2267 (0.514 sec/step)
I0404 20:23:25.906961 47978602034560 learning.py:507] global step 2067: loss = 5.4973 (0.516 sec/step)
I0404 20:23:26.425345 47978602034560 learning.py:507] global step 2068: loss = 6.3225 (0.517 sec/step)
I0404 20:23:26.936321 47978602034560 learning.py:507] global step 2069: loss = 6.3607 (0.508 sec/step)
I0404 20:23:27.448195 47978602034560 learning.py:507] global step 2070: loss = 6.8979 (0.510 sec/step)
I0404 20:23:27.977377 47978602034560 learning.py:507] global step 2071: loss = 6.7167 (0.528 sec/step)
I0404 20:23:28.483326 47978602034560 learning.py:507] global step 2072: loss = 6.1920 (0.504 sec/step)
I0404 20:23:28.994807 47978602034560 learning.py:507] global step 2073: loss = 6.1227 (0.510 sec/step)
I0404 20:23:29.528383 47978602034560 learning.py:507] global step 2074: loss = 6.4609 (0.532 sec/step)
I0404 20:23:30.047328 47978602034560 learning.py:507] global step 2075: loss = 7.0464 (0.517 sec/step)
I0404 20:23:30.564821 47978602034560 learning.py:507] global step 2076: loss = 5.8975 (0.516 sec/step)
I0404 20:23:31.102199 47978602034560 learning.py:507] global step 2077: loss = 6.3525 (0.536 sec/step)
I0404 20:23:31.614670 47978602034560 learning.py:507] global step 2078: loss = 6.5928 (0.511 sec/step)
I0404 20:23:32.131479 47978602034560 learning.py:507] global step 2079: loss = 7.0737 (0.515 sec/step)
I0404 20:23:32.645829 47978602034560 learning.py:507] global step 2080: loss = 6.6419 (0.513 sec/step)
I0404 20:23:33.186883 47978602034560 learning.py:507] global step 2081: loss = 5.9801 (0.539 sec/step)
I0404 20:23:33.687504 47978602034560 learning.py:507] global step 2082: loss = 5.8679 (0.499 sec/step)
I0404 20:23:34.215040 47978602034560 learning.py:507] global step 2083: loss = 6.5426 (0.526 sec/step)
I0404 20:23:34.726619 47978602034560 learning.py:507] global step 2084: loss = 7.3941 (0.510 sec/step)
I0404 20:23:35.256073 47978602034560 learning.py:507] global step 2085: loss = 6.6891 (0.528 sec/step)
I0404 20:23:35.771524 47978602034560 learning.py:507] global step 2086: loss = 6.6925 (0.514 sec/step)
I0404 20:23:36.278063 47978602034560 learning.py:507] global step 2087: loss = 6.4503 (0.504 sec/step)
I0404 20:23:36.787883 47978602034560 learning.py:507] global step 2088: loss = 6.6344 (0.507 sec/step)
I0404 20:23:37.294183 47978602034560 learning.py:507] global step 2089: loss = 5.1631 (0.505 sec/step)
I0404 20:23:37.805700 47978602034560 learning.py:507] global step 2090: loss = 7.0498 (0.509 sec/step)
I0404 20:23:38.318438 47978602034560 learning.py:507] global step 2091: loss = 5.7015 (0.511 sec/step)
I0404 20:23:38.834158 47978602034560 learning.py:507] global step 2092: loss = 7.5686 (0.514 sec/step)
I0404 20:23:39.347838 47978602034560 learning.py:507] global step 2093: loss = 6.4290 (0.512 sec/step)
I0404 20:23:39.882351 47978602034560 learning.py:507] global step 2094: loss = 6.9320 (0.533 sec/step)
I0404 20:23:40.413479 47978602034560 learning.py:507] global step 2095: loss = 6.3175 (0.530 sec/step)
I0404 20:23:40.925111 47978602034560 learning.py:507] global step 2096: loss = 6.6898 (0.510 sec/step)
I0404 20:23:41.448209 47978602034560 learning.py:507] global step 2097: loss = 5.6564 (0.521 sec/step)
I0404 20:23:41.982630 47978602034560 learning.py:507] global step 2098: loss = 6.7507 (0.533 sec/step)
I0404 20:23:42.499730 47978602034560 learning.py:507] global step 2099: loss = 6.7655 (0.515 sec/step)
I0404 20:23:43.025236 47978602034560 learning.py:507] global step 2100: loss = 7.3157 (0.524 sec/step)
I0404 20:23:43.536306 47978602034560 learning.py:507] global step 2101: loss = 6.0020 (0.510 sec/step)
I0404 20:23:44.042832 47978602034560 learning.py:507] global step 2102: loss = 7.7688 (0.505 sec/step)
I0404 20:23:44.544758 47978602034560 learning.py:507] global step 2103: loss = 5.6938 (0.500 sec/step)
I0404 20:23:45.060905 47978602034560 learning.py:507] global step 2104: loss = 6.8038 (0.515 sec/step)
I0404 20:23:45.579582 47978602034560 learning.py:507] global step 2105: loss = 6.8466 (0.516 sec/step)
I0404 20:23:46.116061 47978602034560 learning.py:507] global step 2106: loss = 6.2660 (0.534 sec/step)
I0404 20:23:46.626642 47978602034560 learning.py:507] global step 2107: loss = 6.3006 (0.509 sec/step)
I0404 20:23:47.132408 47978602034560 learning.py:507] global step 2108: loss = 7.3210 (0.504 sec/step)
I0404 20:23:47.635512 47978602034560 learning.py:507] global step 2109: loss = 6.6166 (0.502 sec/step)
I0404 20:23:48.143937 47978602034560 learning.py:507] global step 2110: loss = 6.1808 (0.507 sec/step)
I0404 20:23:48.677291 47978602034560 learning.py:507] global step 2111: loss = 6.8588 (0.532 sec/step)
I0404 20:23:49.201015 47978602034560 learning.py:507] global step 2112: loss = 6.1235 (0.522 sec/step)
I0404 20:23:49.718450 47978602034560 learning.py:507] global step 2113: loss = 5.4201 (0.515 sec/step)
I0404 20:23:50.223999 47978602034560 learning.py:507] global step 2114: loss = 7.8207 (0.504 sec/step)
I0404 20:23:50.735975 47978602034560 learning.py:507] global step 2115: loss = 6.8272 (0.510 sec/step)
I0404 20:23:51.246131 47978602034560 learning.py:507] global step 2116: loss = 7.2259 (0.509 sec/step)
I0404 20:23:51.757280 47978602034560 learning.py:507] global step 2117: loss = 6.8580 (0.510 sec/step)
I0404 20:23:52.288826 47978602034560 learning.py:507] global step 2118: loss = 7.7929 (0.530 sec/step)
I0404 20:23:52.793542 47978602034560 learning.py:507] global step 2119: loss = 6.8036 (0.502 sec/step)
I0404 20:23:53.299524 47978602034560 learning.py:507] global step 2120: loss = 6.9314 (0.504 sec/step)
I0404 20:23:53.799897 47978602034560 learning.py:507] global step 2121: loss = 6.7277 (0.499 sec/step)
I0404 20:23:54.309067 47978602034560 learning.py:507] global step 2122: loss = 7.1456 (0.508 sec/step)
I0404 20:23:54.841176 47978602034560 learning.py:507] global step 2123: loss = 6.2450 (0.531 sec/step)
I0404 20:23:55.354685 47978602034560 learning.py:507] global step 2124: loss = 7.4299 (0.512 sec/step)
I0404 20:23:55.869842 47978602034560 learning.py:507] global step 2125: loss = 6.6752 (0.514 sec/step)
I0404 20:23:56.405308 47978602034560 learning.py:507] global step 2126: loss = 5.8459 (0.534 sec/step)
I0404 20:23:56.926127 47978602034560 learning.py:507] global step 2127: loss = 7.4794 (0.518 sec/step)
I0404 20:23:57.439724 47978602034560 learning.py:507] global step 2128: loss = 7.2199 (0.511 sec/step)
I0404 20:23:57.955636 47978602034560 learning.py:507] global step 2129: loss = 6.8094 (0.514 sec/step)
I0404 20:23:58.465073 47978602034560 learning.py:507] global step 2130: loss = 6.2383 (0.508 sec/step)
I0404 20:23:58.976026 47978602034560 learning.py:507] global step 2131: loss = 6.2983 (0.509 sec/step)
I0404 20:23:59.491751 47978602034560 learning.py:507] global step 2132: loss = 5.8796 (0.514 sec/step)
I0404 20:24:00.015796 47978602034560 learning.py:507] global step 2133: loss = 6.4394 (0.522 sec/step)
I0404 20:24:00.545747 47978602034560 learning.py:507] global step 2134: loss = 6.3973 (0.528 sec/step)
I0404 20:24:01.052273 47978602034560 learning.py:507] global step 2135: loss = 6.3241 (0.505 sec/step)
I0404 20:24:01.567270 47978602034560 learning.py:507] global step 2136: loss = 7.4722 (0.512 sec/step)
I0404 20:24:02.080397 47978602034560 learning.py:507] global step 2137: loss = 5.7084 (0.511 sec/step)
I0404 20:24:02.592592 47978602034560 learning.py:507] global step 2138: loss = 6.9923 (0.509 sec/step)
I0404 20:24:03.110690 47978602034560 learning.py:507] global step 2139: loss = 6.9549 (0.515 sec/step)
I0404 20:24:03.645325 47978602034560 learning.py:507] global step 2140: loss = 5.9537 (0.533 sec/step)
I0404 20:24:04.160219 47978602034560 learning.py:507] global step 2141: loss = 6.8845 (0.512 sec/step)
I0404 20:24:04.676195 47978602034560 learning.py:507] global step 2142: loss = 7.2014 (0.514 sec/step)
I0404 20:24:05.178946 47978602034560 learning.py:507] global step 2143: loss = 8.5628 (0.500 sec/step)
I0404 20:24:05.696602 47978602034560 learning.py:507] global step 2144: loss = 6.0488 (0.515 sec/step)
I0404 20:24:06.240136 47978602034560 learning.py:507] global step 2145: loss = 6.1326 (0.542 sec/step)
I0404 20:24:06.749480 47978602034560 learning.py:507] global step 2146: loss = 6.3979 (0.508 sec/step)
I0404 20:24:07.278215 47978602034560 learning.py:507] global step 2147: loss = 6.4192 (0.526 sec/step)
I0404 20:24:07.787987 47978602034560 learning.py:507] global step 2148: loss = 6.9273 (0.507 sec/step)
I0404 20:24:08.299107 47978602034560 learning.py:507] global step 2149: loss = 6.9942 (0.508 sec/step)
I0404 20:24:08.806957 47978602034560 learning.py:507] global step 2150: loss = 6.2149 (0.506 sec/step)
I0404 20:24:09.321815 47978602034560 learning.py:507] global step 2151: loss = 6.8585 (0.513 sec/step)
I0404 20:24:09.822312 47978602034560 learning.py:507] global step 2152: loss = 5.9150 (0.499 sec/step)
I0404 20:24:10.337346 47978602034560 learning.py:507] global step 2153: loss = 8.6426 (0.513 sec/step)
I0404 20:24:10.872414 47978602034560 learning.py:507] global step 2154: loss = 6.4321 (0.534 sec/step)
I0404 20:24:11.386059 47978602034560 learning.py:507] global step 2155: loss = 7.6646 (0.512 sec/step)
I0404 20:24:11.900319 47978602034560 learning.py:507] global step 2156: loss = 5.9480 (0.513 sec/step)
I0404 20:24:12.409582 47978602034560 learning.py:507] global step 2157: loss = 6.2504 (0.508 sec/step)
I0404 20:24:12.940397 47978602034560 learning.py:507] global step 2158: loss = 6.5873 (0.529 sec/step)
I0404 20:24:13.440809 47978602034560 learning.py:507] global step 2159: loss = 6.2080 (0.499 sec/step)
I0404 20:24:13.956405 47978602034560 learning.py:507] global step 2160: loss = 6.7428 (0.514 sec/step)
I0404 20:24:14.477441 47978602034560 learning.py:507] global step 2161: loss = 6.5463 (0.519 sec/step)
I0404 20:24:15.005025 47978602034560 learning.py:507] global step 2162: loss = 6.6098 (0.526 sec/step)
I0404 20:24:15.515183 47978602034560 learning.py:507] global step 2163: loss = 7.1624 (0.509 sec/step)
I0404 20:24:16.025283 47978602034560 learning.py:507] global step 2164: loss = 6.0642 (0.509 sec/step)
I0404 20:24:16.536426 47978602034560 learning.py:507] global step 2165: loss = 8.1571 (0.510 sec/step)
I0404 20:24:17.068450 47978602034560 learning.py:507] global step 2166: loss = 6.7119 (0.529 sec/step)
I0404 20:24:17.597512 47978602034560 learning.py:507] global step 2167: loss = 6.1316 (0.528 sec/step)
I0404 20:24:18.102918 47978602034560 learning.py:507] global step 2168: loss = 7.0357 (0.504 sec/step)
I0404 20:24:18.613905 47978602034560 learning.py:507] global step 2169: loss = 7.4872 (0.509 sec/step)
I0404 20:24:19.127769 47978602034560 learning.py:507] global step 2170: loss = 6.2180 (0.512 sec/step)
I0404 20:24:19.638916 47978602034560 learning.py:507] global step 2171: loss = 7.0971 (0.510 sec/step)
I0404 20:24:20.149725 47978602034560 learning.py:507] global step 2172: loss = 6.8940 (0.509 sec/step)
I0404 20:24:20.664073 47978602034560 learning.py:507] global step 2173: loss = 6.0899 (0.513 sec/step)
I0404 20:24:21.204652 47978602034560 learning.py:507] global step 2174: loss = 6.2114 (0.539 sec/step)
I0404 20:24:21.718296 47978602034560 learning.py:507] global step 2175: loss = 6.4816 (0.512 sec/step)
I0404 20:24:22.236954 47978602034560 learning.py:507] global step 2176: loss = 6.2708 (0.517 sec/step)
I0404 20:24:22.745054 47978602034560 learning.py:507] global step 2177: loss = 6.9920 (0.507 sec/step)
I0404 20:24:23.258424 47978602034560 learning.py:507] global step 2178: loss = 5.2972 (0.512 sec/step)
I0404 20:24:23.768850 47978602034560 learning.py:507] global step 2179: loss = 7.7104 (0.509 sec/step)
I0404 20:24:24.293721 47978602034560 learning.py:507] global step 2180: loss = 6.4070 (0.523 sec/step)
I0404 20:24:24.796842 47978602034560 learning.py:507] global step 2181: loss = 7.5383 (0.502 sec/step)
I0404 20:24:25.329150 47978602034560 learning.py:507] global step 2182: loss = 5.6908 (0.531 sec/step)
I0404 20:24:25.836679 47978602034560 learning.py:507] global step 2183: loss = 6.6944 (0.506 sec/step)
I0404 20:24:26.343215 47978602034560 learning.py:507] global step 2184: loss = 6.6746 (0.505 sec/step)
I0404 20:24:26.850785 47978602034560 learning.py:507] global step 2185: loss = 7.1238 (0.506 sec/step)
I0404 20:24:27.390087 47978602034560 learning.py:507] global step 2186: loss = 7.1126 (0.538 sec/step)
I0404 20:24:27.908921 47978602034560 learning.py:507] global step 2187: loss = 6.6620 (0.517 sec/step)
I0404 20:24:28.414309 47978602034560 learning.py:507] global step 2188: loss = 6.0546 (0.504 sec/step)
I0404 20:24:28.953901 47978602034560 learning.py:507] global step 2189: loss = 6.4930 (0.538 sec/step)
I0404 20:24:29.482638 47978602034560 learning.py:507] global step 2190: loss = 6.3751 (0.527 sec/step)
I0404 20:24:29.983681 47978602034560 learning.py:507] global step 2191: loss = 6.5908 (0.500 sec/step)
I0404 20:24:30.505007 47978602034560 learning.py:507] global step 2192: loss = 7.1542 (0.520 sec/step)
I0404 20:24:31.011111 47978602034560 learning.py:507] global step 2193: loss = 7.7203 (0.504 sec/step)
I0404 20:24:31.527719 47978602034560 learning.py:507] global step 2194: loss = 6.5122 (0.514 sec/step)
I0404 20:24:32.039324 47978602034560 learning.py:507] global step 2195: loss = 7.7410 (0.510 sec/step)
I0404 20:24:32.550305 47978602034560 learning.py:507] global step 2196: loss = 6.9376 (0.508 sec/step)
I0404 20:24:33.050304 47978602034560 learning.py:507] global step 2197: loss = 7.6110 (0.497 sec/step)
I0404 20:24:33.584446 47978602034560 learning.py:507] global step 2198: loss = 6.9267 (0.533 sec/step)
I0404 20:24:34.098297 47978602034560 learning.py:507] global step 2199: loss = 6.9717 (0.512 sec/step)
I0404 20:24:34.602380 47978602034560 learning.py:507] global step 2200: loss = 7.5814 (0.502 sec/step)
I0404 20:24:35.110411 47978602034560 learning.py:507] global step 2201: loss = 7.1390 (0.505 sec/step)
I0404 20:24:35.627107 47978602034560 learning.py:507] global step 2202: loss = 6.8733 (0.514 sec/step)
I0404 20:24:36.137271 47978602034560 learning.py:507] global step 2203: loss = 6.3641 (0.507 sec/step)
I0404 20:24:36.647407 47978602034560 learning.py:507] global step 2204: loss = 7.3548 (0.507 sec/step)
I0404 20:24:37.153291 47978602034560 learning.py:507] global step 2205: loss = 7.0904 (0.503 sec/step)
I0404 20:24:37.665085 47978602034560 learning.py:507] global step 2206: loss = 5.5637 (0.510 sec/step)
I0404 20:24:38.176716 47978602034560 learning.py:507] global step 2207: loss = 6.8396 (0.510 sec/step)
I0404 20:24:38.699008 47978602034560 learning.py:507] global step 2208: loss = 6.8651 (0.520 sec/step)
I0404 20:24:39.211728 47978602034560 learning.py:507] global step 2209: loss = 6.8602 (0.511 sec/step)
I0404 20:24:39.741672 47978602034560 learning.py:507] global step 2210: loss = 6.3549 (0.527 sec/step)
I0404 20:24:40.276347 47978602034560 learning.py:507] global step 2211: loss = 7.1854 (0.533 sec/step)
I0404 20:24:40.784617 47978602034560 learning.py:507] global step 2212: loss = 6.9517 (0.505 sec/step)
I0404 20:24:41.306060 47978602034560 learning.py:507] global step 2213: loss = 7.5837 (0.520 sec/step)
I0404 20:24:41.811400 47978602034560 learning.py:507] global step 2214: loss = 6.1893 (0.504 sec/step)
I0404 20:24:42.326990 47978602034560 learning.py:507] global step 2215: loss = 6.1590 (0.514 sec/step)
I0404 20:24:42.835948 47978602034560 learning.py:507] global step 2216: loss = 7.4083 (0.507 sec/step)
I0404 20:24:43.336921 47978602034560 learning.py:507] global step 2217: loss = 7.2918 (0.498 sec/step)
I0404 20:24:43.849958 47978602034560 learning.py:507] global step 2218: loss = 6.3563 (0.511 sec/step)
I0404 20:24:44.351764 47978602034560 learning.py:507] global step 2219: loss = 6.5853 (0.500 sec/step)
I0404 20:24:44.858809 47978602034560 learning.py:507] global step 2220: loss = 6.8091 (0.506 sec/step)
I0404 20:24:45.367902 47978602034560 learning.py:507] global step 2221: loss = 6.5120 (0.508 sec/step)
I0404 20:24:45.875279 47978602034560 learning.py:507] global step 2222: loss = 7.2140 (0.506 sec/step)
I0404 20:24:46.389049 47978602034560 learning.py:507] global step 2223: loss = 6.5312 (0.511 sec/step)
I0404 20:24:46.924282 47978602034560 learning.py:507] global step 2224: loss = 7.2400 (0.534 sec/step)
I0404 20:24:47.440319 47978602034560 learning.py:507] global step 2225: loss = 7.0321 (0.514 sec/step)
I0404 20:24:47.951000 47978602034560 learning.py:507] global step 2226: loss = 6.6171 (0.509 sec/step)
I0404 20:24:48.462008 47978602034560 learning.py:507] global step 2227: loss = 6.5790 (0.508 sec/step)
I0404 20:24:48.969920 47978602034560 learning.py:507] global step 2228: loss = 6.1387 (0.506 sec/step)
I0404 20:24:49.499583 47978602034560 learning.py:507] global step 2229: loss = 7.0068 (0.528 sec/step)
I0404 20:24:50.004984 47978602034560 learning.py:507] global step 2230: loss = 6.3142 (0.504 sec/step)
I0404 20:24:50.524798 47978602034560 learning.py:507] global step 2231: loss = 7.0151 (0.518 sec/step)
I0404 20:24:51.033458 47978602034560 learning.py:507] global step 2232: loss = 7.4553 (0.507 sec/step)
I0404 20:24:51.562637 47978602034560 learning.py:507] global step 2233: loss = 6.9280 (0.528 sec/step)
I0404 20:24:52.066496 47978602034560 learning.py:507] global step 2234: loss = 7.2954 (0.502 sec/step)
I0404 20:24:52.578508 47978602034560 learning.py:507] global step 2235: loss = 7.1962 (0.510 sec/step)
I0404 20:24:53.087972 47978602034560 learning.py:507] global step 2236: loss = 7.7837 (0.508 sec/step)
I0404 20:24:53.619820 47978602034560 learning.py:507] global step 2237: loss = 5.7967 (0.530 sec/step)
I0404 20:24:54.152394 47978602034560 learning.py:507] global step 2238: loss = 5.8187 (0.531 sec/step)
I0404 20:24:54.670305 47978602034560 learning.py:507] global step 2239: loss = 6.2974 (0.515 sec/step)
I0404 20:24:55.207170 47978602034560 learning.py:507] global step 2240: loss = 6.8638 (0.535 sec/step)
I0404 20:24:55.723210 47978602034560 learning.py:507] global step 2241: loss = 6.7783 (0.514 sec/step)
I0404 20:24:56.235870 47978602034560 learning.py:507] global step 2242: loss = 7.2303 (0.511 sec/step)
I0404 20:24:56.738633 47978602034560 learning.py:507] global step 2243: loss = 6.1994 (0.501 sec/step)
I0404 20:24:57.242710 47978602034560 learning.py:507] global step 2244: loss = 6.3800 (0.501 sec/step)
I0404 20:24:57.782754 47978602034560 learning.py:507] global step 2245: loss = 6.7041 (0.538 sec/step)
I0404 20:24:58.315398 47978602034560 learning.py:507] global step 2246: loss = 6.3784 (0.531 sec/step)
I0404 20:24:58.826180 47978602034560 learning.py:507] global step 2247: loss = 6.9278 (0.509 sec/step)
I0404 20:24:59.359683 47978602034560 learning.py:507] global step 2248: loss = 7.1011 (0.532 sec/step)
I0404 20:24:59.875041 47978602034560 learning.py:507] global step 2249: loss = 8.2306 (0.514 sec/step)
I0404 20:25:00.383097 47978602034560 learning.py:507] global step 2250: loss = 7.4647 (0.506 sec/step)
I0404 20:25:00.902012 47978602034560 learning.py:507] global step 2251: loss = 6.6895 (0.517 sec/step)
I0404 20:25:01.446133 47978602034560 learning.py:507] global step 2252: loss = 6.3859 (0.543 sec/step)
I0404 20:25:01.959351 47978602034560 learning.py:507] global step 2253: loss = 5.6569 (0.512 sec/step)
I0404 20:25:02.464691 47978602034560 learning.py:507] global step 2254: loss = 8.2105 (0.504 sec/step)
I0404 20:25:02.977517 47978602034560 learning.py:507] global step 2255: loss = 6.5887 (0.510 sec/step)
I0404 20:25:03.497334 47978602034560 learning.py:507] global step 2256: loss = 7.9816 (0.518 sec/step)
I0404 20:25:04.002453 47978602034560 learning.py:507] global step 2257: loss = 5.9215 (0.504 sec/step)
I0404 20:25:04.513006 47978602034560 learning.py:507] global step 2258: loss = 6.4455 (0.509 sec/step)
I0404 20:25:05.018212 47978602034560 learning.py:507] global step 2259: loss = 7.2524 (0.504 sec/step)
I0404 20:25:05.538583 47978602034560 learning.py:507] global step 2260: loss = 6.8168 (0.518 sec/step)
I0404 20:25:06.042482 47978602034560 learning.py:507] global step 2261: loss = 6.2550 (0.502 sec/step)
I0404 20:25:06.563044 47978602034560 learning.py:507] global step 2262: loss = 6.3808 (0.519 sec/step)
I0404 20:25:07.067607 47978602034560 learning.py:507] global step 2263: loss = 6.0119 (0.503 sec/step)
I0404 20:25:07.580822 47978602034560 learning.py:507] global step 2264: loss = 6.3733 (0.510 sec/step)
I0404 20:25:08.123687 47978602034560 learning.py:507] global step 2265: loss = 7.6024 (0.541 sec/step)
I0404 20:25:08.645677 47978602034560 learning.py:507] global step 2266: loss = 6.6496 (0.520 sec/step)
I0404 20:25:09.179590 47978602034560 learning.py:507] global step 2267: loss = 6.5476 (0.532 sec/step)
I0404 20:25:09.695558 47978602034560 learning.py:507] global step 2268: loss = 5.7388 (0.514 sec/step)
I0404 20:25:10.203271 47978602034560 learning.py:507] global step 2269: loss = 6.6276 (0.506 sec/step)
I0404 20:25:10.725867 47978602034560 learning.py:507] global step 2270: loss = 6.0817 (0.521 sec/step)
I0404 20:25:11.234666 47978602034560 learning.py:507] global step 2271: loss = 6.7883 (0.507 sec/step)
I0404 20:25:11.764280 47978602034560 learning.py:507] global step 2272: loss = 5.9408 (0.528 sec/step)
I0404 20:25:12.278349 47978602034560 learning.py:507] global step 2273: loss = 7.8256 (0.513 sec/step)
I0404 20:25:12.808668 47978602034560 learning.py:507] global step 2274: loss = 6.7246 (0.527 sec/step)
I0404 20:25:13.346902 47978602034560 learning.py:507] global step 2275: loss = 6.9893 (0.537 sec/step)
I0404 20:25:13.859273 47978602034560 learning.py:507] global step 2276: loss = 6.4805 (0.510 sec/step)
I0404 20:25:14.369620 47978602034560 learning.py:507] global step 2277: loss = 7.4001 (0.509 sec/step)
I0404 20:25:14.879976 47978602034560 learning.py:507] global step 2278: loss = 7.5967 (0.509 sec/step)
I0404 20:25:15.410647 47978602034560 learning.py:507] global step 2279: loss = 5.9803 (0.529 sec/step)
I0404 20:25:15.918230 47978602034560 learning.py:507] global step 2280: loss = 6.1390 (0.506 sec/step)
I0404 20:25:16.431767 47978602034560 learning.py:507] global step 2281: loss = 6.0110 (0.512 sec/step)
I0404 20:25:16.636535 47983666177792 supervisor.py:1117] Saving checkpoint to path ../../trainingOutput/model.ckpt
I0404 20:25:17.076715 47978602034560 learning.py:507] global step 2282: loss = 6.2333 (0.524 sec/step)
I0404 20:25:17.173608 47983661975296 supervisor.py:1050] Recording summary at step 2282.
I0404 20:25:17.705168 47978602034560 learning.py:507] global step 2283: loss = 6.8870 (0.521 sec/step)
I0404 20:25:18.256429 47978602034560 learning.py:507] global step 2284: loss = 6.2861 (0.501 sec/step)
I0404 20:25:18.763461 47978602034560 learning.py:507] global step 2285: loss = 6.4370 (0.505 sec/step)
I0404 20:25:19.286975 47978602034560 learning.py:507] global step 2286: loss = 5.9434 (0.522 sec/step)
I0404 20:25:19.792250 47978602034560 learning.py:507] global step 2287: loss = 7.1721 (0.504 sec/step)
I0404 20:25:20.302671 47978602034560 learning.py:507] global step 2288: loss = 6.7714 (0.509 sec/step)
I0404 20:25:20.814896 47978602034560 learning.py:507] global step 2289: loss = 6.0426 (0.509 sec/step)
I0404 20:25:21.320644 47978602034560 learning.py:507] global step 2290: loss = 7.8741 (0.504 sec/step)
I0404 20:25:21.824621 47978602034560 learning.py:507] global step 2291: loss = 7.7852 (0.502 sec/step)
I0404 20:25:22.369169 47978602034560 learning.py:507] global step 2292: loss = 6.1525 (0.543 sec/step)
I0404 20:25:22.884973 47978602034560 learning.py:507] global step 2293: loss = 7.6523 (0.514 sec/step)
I0404 20:25:23.390892 47978602034560 learning.py:507] global step 2294: loss = 5.6806 (0.503 sec/step)
I0404 20:25:23.909600 47978602034560 learning.py:507] global step 2295: loss = 6.6231 (0.517 sec/step)
I0404 20:25:24.416988 47978602034560 learning.py:507] global step 2296: loss = 6.4727 (0.506 sec/step)
I0404 20:25:24.923922 47978602034560 learning.py:507] global step 2297: loss = 7.3298 (0.505 sec/step)
I0404 20:25:25.449419 47978602034560 learning.py:507] global step 2298: loss = 6.8482 (0.524 sec/step)
I0404 20:25:25.960139 47978602034560 learning.py:507] global step 2299: loss = 6.3906 (0.509 sec/step)
I0404 20:25:26.470976 47978602034560 learning.py:507] global step 2300: loss = 6.2633 (0.509 sec/step)
I0404 20:25:27.000712 47978602034560 learning.py:507] global step 2301: loss = 6.8266 (0.527 sec/step)
I0404 20:25:27.516698 47978602034560 learning.py:507] global step 2302: loss = 6.2604 (0.514 sec/step)
I0404 20:25:28.026323 47978602034560 learning.py:507] global step 2303: loss = 5.8988 (0.508 sec/step)
I0404 20:25:28.562783 47978602034560 learning.py:507] global step 2304: loss = 6.1725 (0.535 sec/step)
I0404 20:25:29.075390 47978602034560 learning.py:507] global step 2305: loss = 6.4815 (0.510 sec/step)
I0404 20:25:29.586463 47978602034560 learning.py:507] global step 2306: loss = 6.5609 (0.510 sec/step)
I0404 20:25:30.121218 47978602034560 learning.py:507] global step 2307: loss = 6.3454 (0.533 sec/step)
I0404 20:25:30.632664 47978602034560 learning.py:507] global step 2308: loss = 5.6536 (0.510 sec/step)
I0404 20:25:31.147830 47978602034560 learning.py:507] global step 2309: loss = 8.0087 (0.514 sec/step)
I0404 20:25:31.650853 47978602034560 learning.py:507] global step 2310: loss = 7.2030 (0.501 sec/step)
I0404 20:25:32.190484 47978602034560 learning.py:507] global step 2311: loss = 6.6884 (0.537 sec/step)
I0404 20:25:32.704502 47978602034560 learning.py:507] global step 2312: loss = 6.2701 (0.513 sec/step)
I0404 20:25:33.213667 47978602034560 learning.py:507] global step 2313: loss = 5.9187 (0.508 sec/step)
I0404 20:25:33.762007 47978602034560 learning.py:507] global step 2314: loss = 5.4444 (0.547 sec/step)
I0404 20:25:34.271368 47978602034560 learning.py:507] global step 2315: loss = 6.4101 (0.508 sec/step)
I0404 20:25:34.785455 47978602034560 learning.py:507] global step 2316: loss = 6.7947 (0.512 sec/step)
I0404 20:25:35.302990 47978602034560 learning.py:507] global step 2317: loss = 7.0008 (0.516 sec/step)
I0404 20:25:35.812883 47978602034560 learning.py:507] global step 2318: loss = 5.9535 (0.508 sec/step)
I0404 20:25:36.322291 47978602034560 learning.py:507] global step 2319: loss = 6.5244 (0.508 sec/step)
I0404 20:25:36.851061 47978602034560 learning.py:507] global step 2320: loss = 5.8670 (0.527 sec/step)
I0404 20:25:37.363142 47978602034560 learning.py:507] global step 2321: loss = 6.7638 (0.509 sec/step)
I0404 20:25:37.906596 47978602034560 learning.py:507] global step 2322: loss = 7.2549 (0.542 sec/step)
I0404 20:25:38.413886 47978602034560 learning.py:507] global step 2323: loss = 6.2867 (0.506 sec/step)
I0404 20:25:38.943309 47978602034560 learning.py:507] global step 2324: loss = 6.5798 (0.528 sec/step)
I0404 20:25:39.447366 47978602034560 learning.py:507] global step 2325: loss = 6.7911 (0.501 sec/step)
I0404 20:25:39.967896 47978602034560 learning.py:507] global step 2326: loss = 6.3402 (0.519 sec/step)
I0404 20:25:40.485513 47978602034560 learning.py:507] global step 2327: loss = 6.5662 (0.515 sec/step)
I0404 20:25:40.997317 47978602034560 learning.py:507] global step 2328: loss = 6.9870 (0.510 sec/step)
I0404 20:25:41.504010 47978602034560 learning.py:507] global step 2329: loss = 6.3066 (0.505 sec/step)
I0404 20:25:42.014353 47978602034560 learning.py:507] global step 2330: loss = 6.8939 (0.509 sec/step)
I0404 20:25:42.525210 47978602034560 learning.py:507] global step 2331: loss = 6.3110 (0.509 sec/step)
I0404 20:25:43.056715 47978602034560 learning.py:507] global step 2332: loss = 6.7359 (0.530 sec/step)
I0404 20:25:43.580305 47978602034560 learning.py:507] global step 2333: loss = 6.9080 (0.522 sec/step)
I0404 20:25:44.098856 47978602034560 learning.py:507] global step 2334: loss = 6.2422 (0.517 sec/step)
I0404 20:25:44.631012 47978602034560 learning.py:507] global step 2335: loss = 6.9559 (0.531 sec/step)
I0404 20:25:45.142333 47978602034560 learning.py:507] global step 2336: loss = 5.9775 (0.510 sec/step)
I0404 20:25:45.666661 47978602034560 learning.py:507] global step 2337: loss = 6.5013 (0.523 sec/step)
I0404 20:25:46.200490 47978602034560 learning.py:507] global step 2338: loss = 5.9526 (0.532 sec/step)
I0404 20:25:46.719624 47978602034560 learning.py:507] global step 2339: loss = 5.1692 (0.518 sec/step)
I0404 20:25:47.227247 47978602034560 learning.py:507] global step 2340: loss = 6.7946 (0.506 sec/step)
I0404 20:25:47.761122 47978602034560 learning.py:507] global step 2341: loss = 6.0059 (0.532 sec/step)
I0404 20:25:48.269228 47978602034560 learning.py:507] global step 2342: loss = 6.7231 (0.505 sec/step)
I0404 20:25:48.780839 47978602034560 learning.py:507] global step 2343: loss = 6.9474 (0.509 sec/step)
I0404 20:25:49.314999 47978602034560 learning.py:507] global step 2344: loss = 6.6249 (0.531 sec/step)
I0404 20:25:49.823083 47978602034560 learning.py:507] global step 2345: loss = 6.7691 (0.506 sec/step)
I0404 20:25:50.328997 47978602034560 learning.py:507] global step 2346: loss = 7.3047 (0.504 sec/step)
I0404 20:25:50.838143 47978602034560 learning.py:507] global step 2347: loss = 7.0075 (0.508 sec/step)
I0404 20:25:51.350320 47978602034560 learning.py:507] global step 2348: loss = 7.7028 (0.511 sec/step)
I0404 20:25:51.859261 47978602034560 learning.py:507] global step 2349: loss = 6.5172 (0.506 sec/step)
I0404 20:25:52.378380 47978602034560 learning.py:507] global step 2350: loss = 5.3788 (0.517 sec/step)
I0404 20:25:52.883387 47978602034560 learning.py:507] global step 2351: loss = 6.9846 (0.503 sec/step)
I0404 20:25:53.399744 47978602034560 learning.py:507] global step 2352: loss = 6.1422 (0.515 sec/step)
I0404 20:25:53.912724 47978602034560 learning.py:507] global step 2353: loss = 8.1572 (0.511 sec/step)
I0404 20:25:54.425107 47978602034560 learning.py:507] global step 2354: loss = 5.2970 (0.509 sec/step)
I0404 20:25:54.943092 47978602034560 learning.py:507] global step 2355: loss = 7.3037 (0.516 sec/step)
I0404 20:25:55.476169 47978602034560 learning.py:507] global step 2356: loss = 6.2407 (0.531 sec/step)
I0404 20:25:55.989500 47978602034560 learning.py:507] global step 2357: loss = 7.5085 (0.512 sec/step)
I0404 20:25:56.501014 47978602034560 learning.py:507] global step 2358: loss = 6.4424 (0.510 sec/step)
I0404 20:25:57.003899 47978602034560 learning.py:507] global step 2359: loss = 5.6062 (0.501 sec/step)
I0404 20:25:57.517044 47978602034560 learning.py:507] global step 2360: loss = 6.5731 (0.511 sec/step)
I0404 20:25:58.019858 47978602034560 learning.py:507] global step 2361: loss = 6.0802 (0.501 sec/step)
I0404 20:25:58.557818 47978602034560 learning.py:507] global step 2362: loss = 7.2179 (0.535 sec/step)
I0404 20:25:59.081933 47978602034560 learning.py:507] global step 2363: loss = 6.4471 (0.523 sec/step)
I0404 20:25:59.602551 47978602034560 learning.py:507] global step 2364: loss = 6.8490 (0.519 sec/step)
I0404 20:26:00.113984 47978602034560 learning.py:507] global step 2365: loss = 6.3359 (0.510 sec/step)
I0404 20:26:00.633114 47978602034560 learning.py:507] global step 2366: loss = 6.6984 (0.518 sec/step)
I0404 20:26:01.165693 47978602034560 learning.py:507] global step 2367: loss = 6.5677 (0.531 sec/step)
I0404 20:26:01.670932 47978602034560 learning.py:507] global step 2368: loss = 7.5063 (0.504 sec/step)
I0404 20:26:02.180251 47978602034560 learning.py:507] global step 2369: loss = 6.9960 (0.508 sec/step)
I0404 20:26:02.697082 47978602034560 learning.py:507] global step 2370: loss = 6.7463 (0.515 sec/step)
I0404 20:26:03.222086 47978602034560 learning.py:507] global step 2371: loss = 6.7836 (0.522 sec/step)
I0404 20:26:03.746650 47978602034560 learning.py:507] global step 2372: loss = 6.1921 (0.523 sec/step)
I0404 20:26:04.262514 47978602034560 learning.py:507] global step 2373: loss = 5.9570 (0.513 sec/step)
I0404 20:26:04.794651 47978602034560 learning.py:507] global step 2374: loss = 6.7319 (0.531 sec/step)
I0404 20:26:05.329278 47978602034560 learning.py:507] global step 2375: loss = 6.4709 (0.533 sec/step)
I0404 20:26:05.836787 47978602034560 learning.py:507] global step 2376: loss = 5.5839 (0.505 sec/step)
I0404 20:26:06.373912 47978602034560 learning.py:507] global step 2377: loss = 7.4219 (0.536 sec/step)
I0404 20:26:06.881906 47978602034560 learning.py:507] global step 2378: loss = 5.6469 (0.506 sec/step)
I0404 20:26:07.392357 47978602034560 learning.py:507] global step 2379: loss = 6.2321 (0.508 sec/step)
I0404 20:26:07.900583 47978602034560 learning.py:507] global step 2380: loss = 5.5621 (0.507 sec/step)
I0404 20:26:08.417269 47978602034560 learning.py:507] global step 2381: loss = 6.9328 (0.515 sec/step)
I0404 20:26:08.926536 47978602034560 learning.py:507] global step 2382: loss = 6.6009 (0.508 sec/step)
I0404 20:26:09.464683 47978602034560 learning.py:507] global step 2383: loss = 6.1885 (0.537 sec/step)
I0404 20:26:09.976657 47978602034560 learning.py:507] global step 2384: loss = 6.8643 (0.509 sec/step)
I0404 20:26:10.494857 47978602034560 learning.py:507] global step 2385: loss = 6.6299 (0.517 sec/step)
I0404 20:26:11.033009 47978602034560 learning.py:507] global step 2386: loss = 7.1879 (0.537 sec/step)
I0404 20:26:11.546506 47978602034560 learning.py:507] global step 2387: loss = 7.0758 (0.512 sec/step)
I0404 20:26:12.052742 47978602034560 learning.py:507] global step 2388: loss = 5.9824 (0.503 sec/step)
I0404 20:26:12.557048 47978602034560 learning.py:507] global step 2389: loss = 7.9889 (0.501 sec/step)
I0404 20:26:13.067926 47978602034560 learning.py:507] global step 2390: loss = 5.7441 (0.509 sec/step)
I0404 20:26:13.604015 47978602034560 learning.py:507] global step 2391: loss = 5.8329 (0.535 sec/step)
I0404 20:26:14.115560 47978602034560 learning.py:507] global step 2392: loss = 6.5967 (0.510 sec/step)
I0404 20:26:14.634624 47978602034560 learning.py:507] global step 2393: loss = 6.6283 (0.516 sec/step)
I0404 20:26:15.163596 47978602034560 learning.py:507] global step 2394: loss = 6.7588 (0.527 sec/step)
I0404 20:26:15.690210 47978602034560 learning.py:507] global step 2395: loss = 6.1076 (0.524 sec/step)
I0404 20:26:16.206678 47978602034560 learning.py:507] global step 2396: loss = 6.4220 (0.515 sec/step)
I0404 20:26:16.716917 47978602034560 learning.py:507] global step 2397: loss = 6.5091 (0.509 sec/step)
I0404 20:26:17.229433 47978602034560 learning.py:507] global step 2398: loss = 5.7783 (0.511 sec/step)
I0404 20:26:17.737043 47978602034560 learning.py:507] global step 2399: loss = 7.3719 (0.505 sec/step)
I0404 20:26:18.247766 47978602034560 learning.py:507] global step 2400: loss = 6.4492 (0.509 sec/step)
I0404 20:26:18.785880 47978602034560 learning.py:507] global step 2401: loss = 7.6500 (0.537 sec/step)
I0404 20:26:19.306600 47978602034560 learning.py:507] global step 2402: loss = 7.2139 (0.518 sec/step)
I0404 20:26:19.804544 47978602034560 learning.py:507] global step 2403: loss = 7.3906 (0.496 sec/step)
I0404 20:26:20.319498 47978602034560 learning.py:507] global step 2404: loss = 7.9106 (0.513 sec/step)
I0404 20:26:20.827547 47978602034560 learning.py:507] global step 2405: loss = 6.5667 (0.505 sec/step)
I0404 20:26:21.368717 47978602034560 learning.py:507] global step 2406: loss = 6.8799 (0.540 sec/step)
I0404 20:26:21.874142 47978602034560 learning.py:507] global step 2407: loss = 7.9693 (0.504 sec/step)
I0404 20:26:22.383830 47978602034560 learning.py:507] global step 2408: loss = 5.9404 (0.508 sec/step)
I0404 20:26:22.908211 47978602034560 learning.py:507] global step 2409: loss = 6.7873 (0.521 sec/step)
I0404 20:26:23.423907 47978602034560 learning.py:507] global step 2410: loss = 6.9014 (0.514 sec/step)
I0404 20:26:23.933380 47978602034560 learning.py:507] global step 2411: loss = 7.2728 (0.508 sec/step)
I0404 20:26:24.443080 47978602034560 learning.py:507] global step 2412: loss = 7.1925 (0.508 sec/step)
I0404 20:26:24.945009 47978602034560 learning.py:507] global step 2413: loss = 6.9048 (0.500 sec/step)
I0404 20:26:25.484144 47978602034560 learning.py:507] global step 2414: loss = 6.0599 (0.538 sec/step)
I0404 20:26:25.992558 47978602034560 learning.py:507] global step 2415: loss = 6.4932 (0.507 sec/step)
I0404 20:26:26.498537 47978602034560 learning.py:507] global step 2416: loss = 5.9839 (0.504 sec/step)
I0404 20:26:27.010661 47978602034560 learning.py:507] global step 2417: loss = 7.1098 (0.511 sec/step)
I0404 20:26:27.529254 47978602034560 learning.py:507] global step 2418: loss = 6.8148 (0.516 sec/step)
I0404 20:26:28.053250 47978602034560 learning.py:507] global step 2419: loss = 7.3634 (0.522 sec/step)
I0404 20:26:28.579068 47978602034560 learning.py:507] global step 2420: loss = 7.0556 (0.524 sec/step)
I0404 20:26:29.086791 47978602034560 learning.py:507] global step 2421: loss = 6.6816 (0.506 sec/step)
I0404 20:26:29.608232 47978602034560 learning.py:507] global step 2422: loss = 6.6898 (0.519 sec/step)
I0404 20:26:30.119049 47978602034560 learning.py:507] global step 2423: loss = 5.7855 (0.509 sec/step)
I0404 20:26:30.624541 47978602034560 learning.py:507] global step 2424: loss = 7.9986 (0.504 sec/step)
I0404 20:26:31.139697 47978602034560 learning.py:507] global step 2425: loss = 6.8792 (0.514 sec/step)
I0404 20:26:31.650291 47978602034560 learning.py:507] global step 2426: loss = 6.2783 (0.509 sec/step)
I0404 20:26:32.180889 47978602034560 learning.py:507] global step 2427: loss = 7.1459 (0.529 sec/step)
I0404 20:26:32.691776 47978602034560 learning.py:507] global step 2428: loss = 6.2247 (0.508 sec/step)
I0404 20:26:33.226042 47978602034560 learning.py:507] global step 2429: loss = 7.2321 (0.533 sec/step)
I0404 20:26:33.727432 47978602034560 learning.py:507] global step 2430: loss = 5.8142 (0.500 sec/step)
I0404 20:26:34.245423 47978602034560 learning.py:507] global step 2431: loss = 7.5100 (0.516 sec/step)
I0404 20:26:34.770907 47978602034560 learning.py:507] global step 2432: loss = 6.5780 (0.524 sec/step)
I0404 20:26:35.286431 47978602034560 learning.py:507] global step 2433: loss = 6.0703 (0.514 sec/step)
I0404 20:26:35.801398 47978602034560 learning.py:507] global step 2434: loss = 7.5154 (0.513 sec/step)
I0404 20:26:36.318740 47978602034560 learning.py:507] global step 2435: loss = 6.1736 (0.516 sec/step)
I0404 20:26:36.820820 47978602034560 learning.py:507] global step 2436: loss = 6.5141 (0.501 sec/step)
I0404 20:26:37.334115 47978602034560 learning.py:507] global step 2437: loss = 6.0898 (0.512 sec/step)
I0404 20:26:37.837188 47978602034560 learning.py:507] global step 2438: loss = 6.4862 (0.502 sec/step)
I0404 20:26:38.350429 47978602034560 learning.py:507] global step 2439: loss = 5.9975 (0.512 sec/step)
I0404 20:26:38.864368 47978602034560 learning.py:507] global step 2440: loss = 6.7222 (0.512 sec/step)
I0404 20:26:39.368843 47978602034560 learning.py:507] global step 2441: loss = 7.3781 (0.503 sec/step)
I0404 20:26:39.902952 47978602034560 learning.py:507] global step 2442: loss = 6.1382 (0.533 sec/step)
I0404 20:26:40.415599 47978602034560 learning.py:507] global step 2443: loss = 6.1443 (0.511 sec/step)
I0404 20:26:40.924032 47978602034560 learning.py:507] global step 2444: loss = 5.7581 (0.507 sec/step)
I0404 20:26:41.435513 47978602034560 learning.py:507] global step 2445: loss = 7.7109 (0.509 sec/step)
I0404 20:26:41.938188 47978602034560 learning.py:507] global step 2446: loss = 5.8533 (0.500 sec/step)
I0404 20:26:42.472047 47978602034560 learning.py:507] global step 2447: loss = 6.0835 (0.531 sec/step)
I0404 20:26:42.997291 47978602034560 learning.py:507] global step 2448: loss = 5.9435 (0.524 sec/step)
I0404 20:26:43.514073 47978602034560 learning.py:507] global step 2449: loss = 6.2455 (0.515 sec/step)
I0404 20:26:44.038411 47978602034560 learning.py:507] global step 2450: loss = 5.6176 (0.521 sec/step)
I0404 20:26:44.560341 47978602034560 learning.py:507] global step 2451: loss = 7.5931 (0.520 sec/step)
I0404 20:26:45.078974 47978602034560 learning.py:507] global step 2452: loss = 6.6083 (0.517 sec/step)
I0404 20:26:45.586782 47978602034560 learning.py:507] global step 2453: loss = 6.9604 (0.506 sec/step)
I0404 20:26:46.090742 47978602034560 learning.py:507] global step 2454: loss = 6.5141 (0.501 sec/step)
I0404 20:26:46.610021 47978602034560 learning.py:507] global step 2455: loss = 6.4905 (0.516 sec/step)
I0404 20:26:47.117342 47978602034560 learning.py:507] global step 2456: loss = 5.8275 (0.504 sec/step)
I0404 20:26:47.626595 47978602034560 learning.py:507] global step 2457: loss = 6.0103 (0.508 sec/step)
I0404 20:26:48.123686 47978602034560 learning.py:507] global step 2458: loss = 6.2055 (0.495 sec/step)
I0404 20:26:48.624861 47978602034560 learning.py:507] global step 2459: loss = 6.1885 (0.500 sec/step)
I0404 20:26:49.131609 47978602034560 learning.py:507] global step 2460: loss = 6.8421 (0.504 sec/step)
I0404 20:26:49.639419 47978602034560 learning.py:507] global step 2461: loss = 7.6330 (0.506 sec/step)
I0404 20:26:50.149924 47978602034560 learning.py:507] global step 2462: loss = 7.7029 (0.509 sec/step)
I0404 20:26:50.663050 47978602034560 learning.py:507] global step 2463: loss = 6.4827 (0.512 sec/step)
I0404 20:26:51.174396 47978602034560 learning.py:507] global step 2464: loss = 6.5754 (0.510 sec/step)
I0404 20:26:51.704490 47978602034560 learning.py:507] global step 2465: loss = 6.6356 (0.529 sec/step)
I0404 20:26:52.233751 47978602034560 learning.py:507] global step 2466: loss = 5.6138 (0.526 sec/step)
I0404 20:26:52.765964 47978602034560 learning.py:507] global step 2467: loss = 6.4686 (0.529 sec/step)
I0404 20:26:53.272626 47978602034560 learning.py:507] global step 2468: loss = 7.6275 (0.505 sec/step)
I0404 20:26:53.803911 47978602034560 learning.py:507] global step 2469: loss = 6.2410 (0.530 sec/step)
I0404 20:26:54.319843 47978602034560 learning.py:507] global step 2470: loss = 5.8537 (0.514 sec/step)
I0404 20:26:54.853503 47978602034560 learning.py:507] global step 2471: loss = 6.6313 (0.532 sec/step)
I0404 20:26:55.386828 47978602034560 learning.py:507] global step 2472: loss = 6.2351 (0.532 sec/step)
I0404 20:26:55.891422 47978602034560 learning.py:507] global step 2473: loss = 6.7323 (0.502 sec/step)
I0404 20:26:56.404351 47978602034560 learning.py:507] global step 2474: loss = 6.3514 (0.511 sec/step)
I0404 20:26:56.921343 47978602034560 learning.py:507] global step 2475: loss = 6.4954 (0.515 sec/step)
I0404 20:26:57.443769 47978602034560 learning.py:507] global step 2476: loss = 6.8064 (0.521 sec/step)
I0404 20:26:57.960358 47978602034560 learning.py:507] global step 2477: loss = 7.2426 (0.514 sec/step)
I0404 20:26:58.476099 47978602034560 learning.py:507] global step 2478: loss = 6.9590 (0.514 sec/step)
I0404 20:26:58.980885 47978602034560 learning.py:507] global step 2479: loss = 7.8868 (0.503 sec/step)
I0404 20:26:59.485945 47978602034560 learning.py:507] global step 2480: loss = 6.9488 (0.502 sec/step)
I0404 20:27:00.013173 47978602034560 learning.py:507] global step 2481: loss = 6.8792 (0.526 sec/step)
I0404 20:27:00.548801 47978602034560 learning.py:507] global step 2482: loss = 6.8274 (0.534 sec/step)
I0404 20:27:01.064094 47978602034560 learning.py:507] global step 2483: loss = 5.8902 (0.514 sec/step)
I0404 20:27:01.586139 47978602034560 learning.py:507] global step 2484: loss = 6.6684 (0.520 sec/step)
I0404 20:27:02.102425 47978602034560 learning.py:507] global step 2485: loss = 7.1330 (0.515 sec/step)
I0404 20:27:02.624375 47978602034560 learning.py:507] global step 2486: loss = 6.5638 (0.520 sec/step)
I0404 20:27:03.129743 47978602034560 learning.py:507] global step 2487: loss = 5.7090 (0.502 sec/step)
I0404 20:27:03.660088 47978602034560 learning.py:507] global step 2488: loss = 6.8610 (0.529 sec/step)
I0404 20:27:04.182265 47978602034560 learning.py:507] global step 2489: loss = 6.2517 (0.521 sec/step)
I0404 20:27:04.700846 47978602034560 learning.py:507] global step 2490: loss = 6.6283 (0.517 sec/step)
I0404 20:27:05.212380 47978602034560 learning.py:507] global step 2491: loss = 6.6049 (0.510 sec/step)
I0404 20:27:05.722873 47978602034560 learning.py:507] global step 2492: loss = 6.1413 (0.509 sec/step)
I0404 20:27:06.237060 47978602034560 learning.py:507] global step 2493: loss = 8.0719 (0.512 sec/step)
I0404 20:27:06.740851 47978602034560 learning.py:507] global step 2494: loss = 6.5889 (0.502 sec/step)
I0404 20:27:07.267039 47978602034560 learning.py:507] global step 2495: loss = 7.2484 (0.525 sec/step)
I0404 20:27:07.811924 47978602034560 learning.py:507] global step 2496: loss = 5.7745 (0.543 sec/step)
I0404 20:27:08.327751 47978602034560 learning.py:507] global step 2497: loss = 6.6870 (0.514 sec/step)
I0404 20:27:08.847084 47978602034560 learning.py:507] global step 2498: loss = 6.4123 (0.518 sec/step)
I0404 20:27:09.391036 47978602034560 learning.py:507] global step 2499: loss = 6.4080 (0.541 sec/step)
I0404 20:27:09.935221 47978602034560 learning.py:507] global step 2500: loss = 6.2280 (0.542 sec/step)
I0404 20:27:10.477051 47978602034560 learning.py:507] global step 2501: loss = 5.9155 (0.539 sec/step)
I0404 20:27:10.989608 47978602034560 learning.py:507] global step 2502: loss = 5.4622 (0.511 sec/step)
I0404 20:27:11.493899 47978602034560 learning.py:507] global step 2503: loss = 7.5836 (0.503 sec/step)
I0404 20:27:12.025679 47978602034560 learning.py:507] global step 2504: loss = 6.6766 (0.530 sec/step)
I0404 20:27:12.534505 47978602034560 learning.py:507] global step 2505: loss = 6.0909 (0.507 sec/step)
I0404 20:27:13.051809 47978602034560 learning.py:507] global step 2506: loss = 6.0475 (0.516 sec/step)
I0404 20:27:13.583909 47978602034560 learning.py:507] global step 2507: loss = 5.5905 (0.530 sec/step)
I0404 20:27:14.095263 47978602034560 learning.py:507] global step 2508: loss = 5.3437 (0.508 sec/step)
I0404 20:27:14.603177 47978602034560 learning.py:507] global step 2509: loss = 6.2382 (0.505 sec/step)
I0404 20:27:15.121353 47978602034560 learning.py:507] global step 2510: loss = 6.2969 (0.517 sec/step)
I0404 20:27:15.626230 47978602034560 learning.py:507] global step 2511: loss = 6.7132 (0.502 sec/step)
I0404 20:27:16.134443 47978602034560 learning.py:507] global step 2512: loss = 7.0085 (0.505 sec/step)
I0404 20:27:16.642418 47978602034560 learning.py:507] global step 2513: loss = 6.9227 (0.506 sec/step)
I0404 20:27:17.033908 47983661975296 supervisor.py:1050] Recording summary at step 2513.
I0404 20:27:17.363724 47978602034560 learning.py:507] global step 2514: loss = 6.5387 (0.697 sec/step)
I0404 20:27:17.877060 47978602034560 learning.py:507] global step 2515: loss = 7.2897 (0.510 sec/step)
I0404 20:27:18.392811 47978602034560 learning.py:507] global step 2516: loss = 7.9600 (0.514 sec/step)
I0404 20:27:18.933204 47978602034560 learning.py:507] global step 2517: loss = 6.6198 (0.539 sec/step)
I0404 20:27:19.461810 47978602034560 learning.py:507] global step 2518: loss = 6.4045 (0.527 sec/step)
I0404 20:27:19.980771 47978602034560 learning.py:507] global step 2519: loss = 7.4684 (0.517 sec/step)
I0404 20:27:20.519990 47978602034560 learning.py:507] global step 2520: loss = 6.3396 (0.536 sec/step)
I0404 20:27:21.024523 47978602034560 learning.py:507] global step 2521: loss = 6.4857 (0.501 sec/step)
I0404 20:27:21.554212 47978602034560 learning.py:507] global step 2522: loss = 5.7564 (0.527 sec/step)
I0404 20:27:22.061525 47978602034560 learning.py:507] global step 2523: loss = 5.9228 (0.506 sec/step)
I0404 20:27:22.575927 47978602034560 learning.py:507] global step 2524: loss = 7.5235 (0.513 sec/step)
I0404 20:27:23.082727 47978602034560 learning.py:507] global step 2525: loss = 6.9382 (0.505 sec/step)
I0404 20:27:23.603094 47978602034560 learning.py:507] global step 2526: loss = 6.4769 (0.519 sec/step)
I0404 20:27:24.112294 47978602034560 learning.py:507] global step 2527: loss = 6.3841 (0.506 sec/step)
I0404 20:27:24.622324 47978602034560 learning.py:507] global step 2528: loss = 6.6906 (0.509 sec/step)
I0404 20:27:25.136178 47978602034560 learning.py:507] global step 2529: loss = 6.6628 (0.511 sec/step)
I0404 20:27:25.679848 47978602034560 learning.py:507] global step 2530: loss = 6.3123 (0.542 sec/step)
I0404 20:27:26.214533 47978602034560 learning.py:507] global step 2531: loss = 5.4928 (0.533 sec/step)
I0404 20:27:26.734341 47978602034560 learning.py:507] global step 2532: loss = 6.1238 (0.518 sec/step)
I0404 20:27:27.245894 47978602034560 learning.py:507] global step 2533: loss = 6.2367 (0.510 sec/step)
I0404 20:27:27.782870 47978602034560 learning.py:507] global step 2534: loss = 7.3679 (0.535 sec/step)
I0404 20:27:28.285676 47978602034560 learning.py:507] global step 2535: loss = 5.8784 (0.501 sec/step)
I0404 20:27:28.803697 47978602034560 learning.py:507] global step 2536: loss = 6.4187 (0.516 sec/step)
I0404 20:27:29.310760 47978602034560 learning.py:507] global step 2537: loss = 6.3191 (0.504 sec/step)
I0404 20:27:29.843728 47978602034560 learning.py:507] global step 2538: loss = 6.2367 (0.531 sec/step)
I0404 20:27:30.374928 47978602034560 learning.py:507] global step 2539: loss = 6.9090 (0.530 sec/step)
I0404 20:27:30.895497 47978602034560 learning.py:507] global step 2540: loss = 6.9620 (0.519 sec/step)
I0404 20:27:31.406216 47978602034560 learning.py:507] global step 2541: loss = 6.1606 (0.508 sec/step)
I0404 20:27:31.933260 47978602034560 learning.py:507] global step 2542: loss = 5.9454 (0.525 sec/step)
I0404 20:27:32.452315 47978602034560 learning.py:507] global step 2543: loss = 5.5975 (0.517 sec/step)
I0404 20:27:32.961109 47978602034560 learning.py:507] global step 2544: loss = 6.1963 (0.507 sec/step)
I0404 20:27:33.466242 47978602034560 learning.py:507] global step 2545: loss = 7.4958 (0.504 sec/step)
I0404 20:27:33.980052 47978602034560 learning.py:507] global step 2546: loss = 5.8291 (0.512 sec/step)
I0404 20:27:34.488249 47978602034560 learning.py:507] global step 2547: loss = 5.8589 (0.507 sec/step)
I0404 20:27:35.004690 47978602034560 learning.py:507] global step 2548: loss = 6.9851 (0.515 sec/step)
I0404 20:27:35.517530 47978602034560 learning.py:507] global step 2549: loss = 6.5754 (0.511 sec/step)
I0404 20:27:36.027043 47978602034560 learning.py:507] global step 2550: loss = 6.7972 (0.508 sec/step)
I0404 20:27:36.539022 47978602034560 learning.py:507] global step 2551: loss = 6.5142 (0.510 sec/step)
I0404 20:27:37.066802 47978602034560 learning.py:507] global step 2552: loss = 6.3992 (0.526 sec/step)
I0404 20:27:37.584024 47978602034560 learning.py:507] global step 2553: loss = 5.7861 (0.516 sec/step)
I0404 20:27:38.124015 47978602034560 learning.py:507] global step 2554: loss = 6.6035 (0.538 sec/step)
I0404 20:27:38.628371 47978602034560 learning.py:507] global step 2555: loss = 5.9963 (0.502 sec/step)
I0404 20:27:39.146204 47978602034560 learning.py:507] global step 2556: loss = 6.6305 (0.515 sec/step)
I0404 20:27:39.665360 47978602034560 learning.py:507] global step 2557: loss = 7.3250 (0.518 sec/step)
I0404 20:27:40.178825 47978602034560 learning.py:507] global step 2558: loss = 6.9038 (0.512 sec/step)
I0404 20:27:40.699140 47978602034560 learning.py:507] global step 2559: loss = 6.8590 (0.517 sec/step)
I0404 20:27:41.221995 47978602034560 learning.py:507] global step 2560: loss = 6.1339 (0.520 sec/step)
I0404 20:27:41.734532 47978602034560 learning.py:507] global step 2561: loss = 5.8810 (0.511 sec/step)
I0404 20:27:42.237949 47978602034560 learning.py:507] global step 2562: loss = 6.6842 (0.501 sec/step)
I0404 20:27:42.774115 47978602034560 learning.py:507] global step 2563: loss = 6.7074 (0.533 sec/step)
I0404 20:27:43.285509 47978602034560 learning.py:507] global step 2564: loss = 5.9078 (0.508 sec/step)
I0404 20:27:43.798278 47978602034560 learning.py:507] global step 2565: loss = 6.5311 (0.511 sec/step)
I0404 20:27:44.304064 47978602034560 learning.py:507] global step 2566: loss = 6.6886 (0.504 sec/step)
I0404 20:27:44.812080 47978602034560 learning.py:507] global step 2567: loss = 5.5280 (0.506 sec/step)
I0404 20:27:45.319564 47978602034560 learning.py:507] global step 2568: loss = 6.4515 (0.506 sec/step)
I0404 20:27:45.829400 47978602034560 learning.py:507] global step 2569: loss = 6.0141 (0.507 sec/step)
I0404 20:27:46.340448 47978602034560 learning.py:507] global step 2570: loss = 6.1774 (0.509 sec/step)
I0404 20:27:46.851006 47978602034560 learning.py:507] global step 2571: loss = 6.0338 (0.508 sec/step)
I0404 20:27:47.370044 47978602034560 learning.py:507] global step 2572: loss = 6.2268 (0.517 sec/step)
I0404 20:27:47.869835 47978602034560 learning.py:507] global step 2573: loss = 6.4555 (0.498 sec/step)
I0404 20:27:48.390801 47978602034560 learning.py:507] global step 2574: loss = 7.4679 (0.518 sec/step)
I0404 20:27:48.894412 47978602034560 learning.py:507] global step 2575: loss = 6.2184 (0.502 sec/step)
I0404 20:27:49.406592 47978602034560 learning.py:507] global step 2576: loss = 5.6444 (0.511 sec/step)
I0404 20:27:49.912671 47978602034560 learning.py:507] global step 2577: loss = 6.5128 (0.504 sec/step)
I0404 20:27:50.429297 47978602034560 learning.py:507] global step 2578: loss = 6.2141 (0.515 sec/step)
I0404 20:27:50.944591 47978602034560 learning.py:507] global step 2579: loss = 7.2500 (0.514 sec/step)
I0404 20:27:51.450012 47978602034560 learning.py:507] global step 2580: loss = 6.9090 (0.504 sec/step)
I0404 20:27:51.953671 47978602034560 learning.py:507] global step 2581: loss = 7.1012 (0.502 sec/step)
I0404 20:27:52.463485 47978602034560 learning.py:507] global step 2582: loss = 6.3304 (0.507 sec/step)
I0404 20:27:52.972654 47978602034560 learning.py:507] global step 2583: loss = 5.8472 (0.508 sec/step)
I0404 20:27:53.482635 47978602034560 learning.py:507] global step 2584: loss = 6.6734 (0.508 sec/step)
I0404 20:27:53.989457 47978602034560 learning.py:507] global step 2585: loss = 6.4320 (0.504 sec/step)
I0404 20:27:54.503117 47978602034560 learning.py:507] global step 2586: loss = 6.0397 (0.512 sec/step)
I0404 20:27:55.029001 47978602034560 learning.py:507] global step 2587: loss = 7.4189 (0.524 sec/step)
I0404 20:27:55.540560 47978602034560 learning.py:507] global step 2588: loss = 5.9634 (0.510 sec/step)
I0404 20:27:56.053203 47978602034560 learning.py:507] global step 2589: loss = 6.3862 (0.511 sec/step)
I0404 20:27:56.568812 47978602034560 learning.py:507] global step 2590: loss = 7.2689 (0.514 sec/step)
I0404 20:27:57.079507 47978602034560 learning.py:507] global step 2591: loss = 6.7253 (0.509 sec/step)
I0404 20:27:57.589283 47978602034560 learning.py:507] global step 2592: loss = 7.3613 (0.508 sec/step)
I0404 20:27:58.103148 47978602034560 learning.py:507] global step 2593: loss = 7.0594 (0.512 sec/step)
I0404 20:27:58.610008 47978602034560 learning.py:507] global step 2594: loss = 6.6289 (0.505 sec/step)
I0404 20:27:59.144838 47978602034560 learning.py:507] global step 2595: loss = 5.9303 (0.532 sec/step)
I0404 20:27:59.675383 47978602034560 learning.py:507] global step 2596: loss = 6.9449 (0.529 sec/step)
I0404 20:28:00.189770 47978602034560 learning.py:507] global step 2597: loss = 6.0932 (0.513 sec/step)
I0404 20:28:00.712577 47978602034560 learning.py:507] global step 2598: loss = 6.2815 (0.520 sec/step)
I0404 20:28:01.219016 47978602034560 learning.py:507] global step 2599: loss = 6.9431 (0.505 sec/step)
I0404 20:28:01.734247 47978602034560 learning.py:507] global step 2600: loss = 5.9348 (0.514 sec/step)
I0404 20:28:02.248281 47978602034560 learning.py:507] global step 2601: loss = 5.6605 (0.512 sec/step)
I0404 20:28:02.755592 47978602034560 learning.py:507] global step 2602: loss = 6.9788 (0.506 sec/step)
I0404 20:28:03.268648 47978602034560 learning.py:507] global step 2603: loss = 6.0409 (0.511 sec/step)
I0404 20:28:03.788456 47978602034560 learning.py:507] global step 2604: loss = 6.0827 (0.518 sec/step)
I0404 20:28:04.293169 47978602034560 learning.py:507] global step 2605: loss = 7.4382 (0.503 sec/step)
I0404 20:28:04.803771 47978602034560 learning.py:507] global step 2606: loss = 6.3719 (0.509 sec/step)
I0404 20:28:05.306791 47978602034560 learning.py:507] global step 2607: loss = 6.8546 (0.501 sec/step)
I0404 20:28:05.822647 47978602034560 learning.py:507] global step 2608: loss = 6.5775 (0.514 sec/step)
I0404 20:28:06.351837 47978602034560 learning.py:507] global step 2609: loss = 7.0527 (0.528 sec/step)
I0404 20:28:06.855162 47978602034560 learning.py:507] global step 2610: loss = 6.3558 (0.500 sec/step)
I0404 20:28:07.372307 47978602034560 learning.py:507] global step 2611: loss = 6.7615 (0.516 sec/step)
I0404 20:28:07.877511 47978602034560 learning.py:507] global step 2612: loss = 5.6971 (0.502 sec/step)
I0404 20:28:08.417480 47978602034560 learning.py:507] global step 2613: loss = 5.0970 (0.538 sec/step)
I0404 20:28:08.932964 47978602034560 learning.py:507] global step 2614: loss = 7.5232 (0.514 sec/step)
I0404 20:28:09.473745 47978602034560 learning.py:507] global step 2615: loss = 7.7728 (0.539 sec/step)
I0404 20:28:09.981117 47978602034560 learning.py:507] global step 2616: loss = 6.1772 (0.505 sec/step)
I0404 20:28:10.495964 47978602034560 learning.py:507] global step 2617: loss = 7.1499 (0.513 sec/step)
I0404 20:28:11.008188 47978602034560 learning.py:507] global step 2618: loss = 6.0290 (0.511 sec/step)
I0404 20:28:11.525002 47978602034560 learning.py:507] global step 2619: loss = 5.5411 (0.515 sec/step)
I0404 20:28:12.032961 47978602034560 learning.py:507] global step 2620: loss = 5.7472 (0.506 sec/step)
I0404 20:28:12.553734 47978602034560 learning.py:507] global step 2621: loss = 7.8492 (0.519 sec/step)
I0404 20:28:13.090095 47978602034560 learning.py:507] global step 2622: loss = 5.9477 (0.535 sec/step)
I0404 20:28:13.607417 47978602034560 learning.py:507] global step 2623: loss = 6.3127 (0.516 sec/step)
I0404 20:28:14.127842 47978602034560 learning.py:507] global step 2624: loss = 6.7491 (0.518 sec/step)
I0404 20:28:14.643226 47978602034560 learning.py:507] global step 2625: loss = 7.1267 (0.513 sec/step)
I0404 20:28:15.179296 47978602034560 learning.py:507] global step 2626: loss = 6.7461 (0.534 sec/step)
I0404 20:28:15.693933 47978602034560 learning.py:507] global step 2627: loss = 6.1746 (0.513 sec/step)
I0404 20:28:16.196543 47978602034560 learning.py:507] global step 2628: loss = 8.2401 (0.501 sec/step)
I0404 20:28:16.724992 47978602034560 learning.py:507] global step 2629: loss = 7.5167 (0.526 sec/step)
I0404 20:28:17.228889 47978602034560 learning.py:507] global step 2630: loss = 6.7829 (0.501 sec/step)
I0404 20:28:17.747409 47978602034560 learning.py:507] global step 2631: loss = 6.6903 (0.517 sec/step)
I0404 20:28:18.253993 47978602034560 learning.py:507] global step 2632: loss = 6.1199 (0.505 sec/step)
I0404 20:28:18.766561 47978602034560 learning.py:507] global step 2633: loss = 6.2387 (0.511 sec/step)
I0404 20:28:19.299560 47978602034560 learning.py:507] global step 2634: loss = 7.6926 (0.530 sec/step)
I0404 20:28:19.819991 47978602034560 learning.py:507] global step 2635: loss = 6.3395 (0.518 sec/step)
I0404 20:28:20.329991 47978602034560 learning.py:507] global step 2636: loss = 5.8680 (0.508 sec/step)
I0404 20:28:20.842800 47978602034560 learning.py:507] global step 2637: loss = 6.7287 (0.511 sec/step)
I0404 20:28:21.365136 47978602034560 learning.py:507] global step 2638: loss = 6.3869 (0.521 sec/step)
I0404 20:28:21.871227 47978602034560 learning.py:507] global step 2639: loss = 5.9316 (0.503 sec/step)
I0404 20:28:22.380315 47978602034560 learning.py:507] global step 2640: loss = 5.9398 (0.508 sec/step)
I0404 20:28:22.892219 47978602034560 learning.py:507] global step 2641: loss = 5.9754 (0.510 sec/step)
I0404 20:28:23.405920 47978602034560 learning.py:507] global step 2642: loss = 6.9603 (0.511 sec/step)
I0404 20:28:23.916875 47978602034560 learning.py:507] global step 2643: loss = 6.2177 (0.509 sec/step)
I0404 20:28:24.439342 47978602034560 learning.py:507] global step 2644: loss = 6.5153 (0.521 sec/step)
I0404 20:28:24.945606 47978602034560 learning.py:507] global step 2645: loss = 6.9915 (0.505 sec/step)
I0404 20:28:25.476383 47978602034560 learning.py:507] global step 2646: loss = 7.0721 (0.529 sec/step)
I0404 20:28:25.990210 47978602034560 learning.py:507] global step 2647: loss = 7.9376 (0.512 sec/step)
I0404 20:28:26.502053 47978602034560 learning.py:507] global step 2648: loss = 6.0328 (0.510 sec/step)
I0404 20:28:27.019993 47978602034560 learning.py:507] global step 2649: loss = 5.6698 (0.516 sec/step)
I0404 20:28:27.530850 47978602034560 learning.py:507] global step 2650: loss = 7.8440 (0.509 sec/step)
I0404 20:28:28.047965 47978602034560 learning.py:507] global step 2651: loss = 7.4853 (0.515 sec/step)
I0404 20:28:28.557158 47978602034560 learning.py:507] global step 2652: loss = 6.3230 (0.508 sec/step)
I0404 20:28:29.077678 47978602034560 learning.py:507] global step 2653: loss = 5.6342 (0.518 sec/step)
I0404 20:28:29.580956 47978602034560 learning.py:507] global step 2654: loss = 8.0025 (0.500 sec/step)
I0404 20:28:30.095288 47978602034560 learning.py:507] global step 2655: loss = 6.9626 (0.513 sec/step)
I0404 20:28:30.601297 47978602034560 learning.py:507] global step 2656: loss = 6.7628 (0.504 sec/step)
I0404 20:28:31.105111 47978602034560 learning.py:507] global step 2657: loss = 5.8454 (0.502 sec/step)
I0404 20:28:31.619786 47978602034560 learning.py:507] global step 2658: loss = 6.4004 (0.513 sec/step)
I0404 20:28:32.122074 47978602034560 learning.py:507] global step 2659: loss = 6.6427 (0.501 sec/step)
I0404 20:28:32.649243 47978602034560 learning.py:507] global step 2660: loss = 6.1990 (0.526 sec/step)
I0404 20:28:33.154051 47978602034560 learning.py:507] global step 2661: loss = 5.4518 (0.503 sec/step)
I0404 20:28:33.663866 47978602034560 learning.py:507] global step 2662: loss = 6.9708 (0.508 sec/step)
I0404 20:28:34.173151 47978602034560 learning.py:507] global step 2663: loss = 6.1492 (0.508 sec/step)
I0404 20:28:34.685806 47978602034560 learning.py:507] global step 2664: loss = 6.4768 (0.510 sec/step)
I0404 20:28:35.194208 47978602034560 learning.py:507] global step 2665: loss = 6.5759 (0.505 sec/step)
I0404 20:28:35.712155 47978602034560 learning.py:507] global step 2666: loss = 5.5437 (0.516 sec/step)
I0404 20:28:36.216924 47978602034560 learning.py:507] global step 2667: loss = 6.0453 (0.503 sec/step)
I0404 20:28:36.728075 47978602034560 learning.py:507] global step 2668: loss = 7.4244 (0.508 sec/step)
I0404 20:28:37.229525 47978602034560 learning.py:507] global step 2669: loss = 6.7965 (0.500 sec/step)
I0404 20:28:37.735525 47978602034560 learning.py:507] global step 2670: loss = 6.7026 (0.504 sec/step)
I0404 20:28:38.238424 47978602034560 learning.py:507] global step 2671: loss = 7.0570 (0.501 sec/step)
I0404 20:28:38.747082 47978602034560 learning.py:507] global step 2672: loss = 6.2354 (0.507 sec/step)
I0404 20:28:39.258131 47978602034560 learning.py:507] global step 2673: loss = 6.3811 (0.509 sec/step)
I0404 20:28:39.771238 47978602034560 learning.py:507] global step 2674: loss = 6.8420 (0.512 sec/step)
I0404 20:28:40.287121 47978602034560 learning.py:507] global step 2675: loss = 5.4893 (0.514 sec/step)
I0404 20:28:40.795326 47978602034560 learning.py:507] global step 2676: loss = 6.9503 (0.507 sec/step)
I0404 20:28:41.306001 47978602034560 learning.py:507] global step 2677: loss = 6.5787 (0.509 sec/step)
I0404 20:28:41.810896 47978602034560 learning.py:507] global step 2678: loss = 6.5417 (0.502 sec/step)
I0404 20:28:42.312718 47978602034560 learning.py:507] global step 2679: loss = 5.9452 (0.500 sec/step)
I0404 20:28:42.831870 47978602034560 learning.py:507] global step 2680: loss = 6.6071 (0.518 sec/step)
I0404 20:28:43.360278 47978602034560 learning.py:507] global step 2681: loss = 5.7142 (0.527 sec/step)
I0404 20:28:43.862539 47978602034560 learning.py:507] global step 2682: loss = 5.0990 (0.501 sec/step)
I0404 20:28:44.371420 47978602034560 learning.py:507] global step 2683: loss = 6.0223 (0.506 sec/step)
I0404 20:28:44.875792 47978602034560 learning.py:507] global step 2684: loss = 5.8994 (0.503 sec/step)
I0404 20:28:45.406967 47978602034560 learning.py:507] global step 2685: loss = 6.6529 (0.529 sec/step)
I0404 20:28:45.939111 47978602034560 learning.py:507] global step 2686: loss = 6.1875 (0.531 sec/step)
I0404 20:28:46.453126 47978602034560 learning.py:507] global step 2687: loss = 6.6491 (0.512 sec/step)
I0404 20:28:46.966425 47978602034560 learning.py:507] global step 2688: loss = 6.5593 (0.512 sec/step)
I0404 20:28:47.471653 47978602034560 learning.py:507] global step 2689: loss = 6.3322 (0.504 sec/step)
I0404 20:28:47.984977 47978602034560 learning.py:507] global step 2690: loss = 5.8977 (0.512 sec/step)
I0404 20:28:48.513663 47978602034560 learning.py:507] global step 2691: loss = 6.7823 (0.527 sec/step)
I0404 20:28:49.033194 47978602034560 learning.py:507] global step 2692: loss = 7.1290 (0.518 sec/step)
I0404 20:28:49.566296 47978602034560 learning.py:507] global step 2693: loss = 5.6563 (0.532 sec/step)
I0404 20:28:50.083693 47978602034560 learning.py:507] global step 2694: loss = 6.6279 (0.515 sec/step)
I0404 20:28:50.604144 47978602034560 learning.py:507] global step 2695: loss = 6.2685 (0.518 sec/step)
I0404 20:28:51.126116 47978602034560 learning.py:507] global step 2696: loss = 5.9768 (0.520 sec/step)
I0404 20:28:51.639738 47978602034560 learning.py:507] global step 2697: loss = 5.5748 (0.510 sec/step)
I0404 20:28:52.159040 47978602034560 learning.py:507] global step 2698: loss = 6.6183 (0.517 sec/step)
I0404 20:28:52.666464 47978602034560 learning.py:507] global step 2699: loss = 7.2042 (0.506 sec/step)
I0404 20:28:53.185865 47978602034560 learning.py:507] global step 2700: loss = 6.9538 (0.517 sec/step)
I0404 20:28:53.718813 47978602034560 learning.py:507] global step 2701: loss = 6.3039 (0.530 sec/step)
I0404 20:28:54.228849 47978602034560 learning.py:507] global step 2702: loss = 7.1674 (0.508 sec/step)
I0404 20:28:54.750684 47978602034560 learning.py:507] global step 2703: loss = 7.0216 (0.520 sec/step)
I0404 20:28:55.259013 47978602034560 learning.py:507] global step 2704: loss = 5.1605 (0.507 sec/step)
I0404 20:28:55.791182 47978602034560 learning.py:507] global step 2705: loss = 7.0828 (0.531 sec/step)
I0404 20:28:56.318086 47978602034560 learning.py:507] global step 2706: loss = 6.2327 (0.525 sec/step)
I0404 20:28:56.830285 47978602034560 learning.py:507] global step 2707: loss = 5.8563 (0.511 sec/step)
I0404 20:28:57.362224 47978602034560 learning.py:507] global step 2708: loss = 5.3886 (0.530 sec/step)
I0404 20:28:57.871402 47978602034560 learning.py:507] global step 2709: loss = 6.5074 (0.508 sec/step)
I0404 20:28:58.387903 47978602034560 learning.py:507] global step 2710: loss = 6.1549 (0.514 sec/step)
I0404 20:28:58.895350 47978602034560 learning.py:507] global step 2711: loss = 7.0410 (0.506 sec/step)
I0404 20:28:59.402944 47978602034560 learning.py:507] global step 2712: loss = 6.5781 (0.505 sec/step)
I0404 20:28:59.934091 47978602034560 learning.py:507] global step 2713: loss = 6.4151 (0.530 sec/step)
I0404 20:29:00.450238 47978602034560 learning.py:507] global step 2714: loss = 6.5736 (0.513 sec/step)
I0404 20:29:00.959384 47978602034560 learning.py:507] global step 2715: loss = 6.3281 (0.508 sec/step)
I0404 20:29:01.462547 47978602034560 learning.py:507] global step 2716: loss = 7.1772 (0.501 sec/step)
I0404 20:29:01.965209 47978602034560 learning.py:507] global step 2717: loss = 6.7928 (0.501 sec/step)
I0404 20:29:02.469487 47978602034560 learning.py:507] global step 2718: loss = 6.2325 (0.501 sec/step)
I0404 20:29:02.989904 47978602034560 learning.py:507] global step 2719: loss = 6.7220 (0.517 sec/step)
I0404 20:29:03.504042 47978602034560 learning.py:507] global step 2720: loss = 6.5965 (0.513 sec/step)
I0404 20:29:04.015048 47978602034560 learning.py:507] global step 2721: loss = 6.6171 (0.509 sec/step)
I0404 20:29:04.527007 47978602034560 learning.py:507] global step 2722: loss = 6.2106 (0.510 sec/step)
I0404 20:29:05.038878 47978602034560 learning.py:507] global step 2723: loss = 6.4610 (0.510 sec/step)
I0404 20:29:05.551643 47978602034560 learning.py:507] global step 2724: loss = 5.8504 (0.511 sec/step)
I0404 20:29:06.059727 47978602034560 learning.py:507] global step 2725: loss = 5.8922 (0.507 sec/step)
I0404 20:29:06.572160 47978602034560 learning.py:507] global step 2726: loss = 5.9006 (0.511 sec/step)
I0404 20:29:07.106302 47978602034560 learning.py:507] global step 2727: loss = 7.7135 (0.533 sec/step)
I0404 20:29:07.613255 47978602034560 learning.py:507] global step 2728: loss = 7.2271 (0.505 sec/step)
I0404 20:29:08.137778 47978602034560 learning.py:507] global step 2729: loss = 5.6812 (0.523 sec/step)
I0404 20:29:08.639342 47978602034560 learning.py:507] global step 2730: loss = 6.9808 (0.500 sec/step)
I0404 20:29:09.171693 47978602034560 learning.py:507] global step 2731: loss = 6.7506 (0.531 sec/step)
I0404 20:29:09.681060 47978602034560 learning.py:507] global step 2732: loss = 4.9105 (0.508 sec/step)
I0404 20:29:10.194078 47978602034560 learning.py:507] global step 2733: loss = 5.9524 (0.510 sec/step)
I0404 20:29:10.704436 47978602034560 learning.py:507] global step 2734: loss = 6.9958 (0.509 sec/step)
I0404 20:29:11.217060 47978602034560 learning.py:507] global step 2735: loss = 4.8644 (0.510 sec/step)
I0404 20:29:11.725231 47978602034560 learning.py:507] global step 2736: loss = 6.7667 (0.505 sec/step)
I0404 20:29:12.244146 47978602034560 learning.py:507] global step 2737: loss = 6.8323 (0.517 sec/step)
I0404 20:29:12.758705 47978602034560 learning.py:507] global step 2738: loss = 6.8451 (0.513 sec/step)
I0404 20:29:13.281851 47978602034560 learning.py:507] global step 2739: loss = 6.1337 (0.520 sec/step)
I0404 20:29:13.813663 47978602034560 learning.py:507] global step 2740: loss = 6.3113 (0.530 sec/step)
I0404 20:29:14.328841 47978602034560 learning.py:507] global step 2741: loss = 6.8566 (0.514 sec/step)
I0404 20:29:14.837863 47978602034560 learning.py:507] global step 2742: loss = 6.4861 (0.507 sec/step)
I0404 20:29:15.350080 47978602034560 learning.py:507] global step 2743: loss = 7.5830 (0.509 sec/step)
I0404 20:29:15.852491 47978602034560 learning.py:507] global step 2744: loss = 6.1791 (0.500 sec/step)
I0404 20:29:16.360801 47978602034560 learning.py:507] global step 2745: loss = 7.2785 (0.507 sec/step)
I0404 20:29:16.868911 47978602034560 learning.py:507] global step 2746: loss = 5.5962 (0.503 sec/step)
I0404 20:29:17.246803 47983661975296 supervisor.py:1050] Recording summary at step 2746.
I0404 20:29:17.561996 47978602034560 learning.py:507] global step 2747: loss = 6.9410 (0.684 sec/step)
I0404 20:29:18.088786 47978602034560 learning.py:507] global step 2748: loss = 6.8043 (0.524 sec/step)
I0404 20:29:18.621633 47978602034560 learning.py:507] global step 2749: loss = 6.3438 (0.531 sec/step)
I0404 20:29:19.133126 47978602034560 learning.py:507] global step 2750: loss = 5.7268 (0.510 sec/step)
I0404 20:29:19.639453 47978602034560 learning.py:507] global step 2751: loss = 6.6380 (0.503 sec/step)
I0404 20:29:20.155951 47978602034560 learning.py:507] global step 2752: loss = 6.3567 (0.515 sec/step)
I0404 20:29:20.690463 47978602034560 learning.py:507] global step 2753: loss = 6.3540 (0.532 sec/step)
I0404 20:29:21.202086 47978602034560 learning.py:507] global step 2754: loss = 6.9541 (0.510 sec/step)
I0404 20:29:21.719382 47978602034560 learning.py:507] global step 2755: loss = 5.9316 (0.516 sec/step)
I0404 20:29:22.261254 47978602034560 learning.py:507] global step 2756: loss = 6.4529 (0.540 sec/step)
I0404 20:29:22.792305 47978602034560 learning.py:507] global step 2757: loss = 6.0091 (0.529 sec/step)
I0404 20:29:23.325506 47978602034560 learning.py:507] global step 2758: loss = 6.7910 (0.530 sec/step)
I0404 20:29:23.841789 47978602034560 learning.py:507] global step 2759: loss = 7.0046 (0.513 sec/step)
I0404 20:29:24.358058 47978602034560 learning.py:507] global step 2760: loss = 5.6394 (0.515 sec/step)
I0404 20:29:24.875442 47978602034560 learning.py:507] global step 2761: loss = 7.6396 (0.516 sec/step)
I0404 20:29:25.393870 47978602034560 learning.py:507] global step 2762: loss = 6.3614 (0.517 sec/step)
I0404 20:29:25.904703 47978602034560 learning.py:507] global step 2763: loss = 7.7411 (0.509 sec/step)
I0404 20:29:26.415858 47978602034560 learning.py:507] global step 2764: loss = 7.3900 (0.508 sec/step)
I0404 20:29:26.930524 47978602034560 learning.py:507] global step 2765: loss = 6.2652 (0.513 sec/step)
I0404 20:29:27.436520 47978602034560 learning.py:507] global step 2766: loss = 5.8008 (0.503 sec/step)
I0404 20:29:27.936411 47978602034560 learning.py:507] global step 2767: loss = 6.1090 (0.498 sec/step)
I0404 20:29:28.456386 47978602034560 learning.py:507] global step 2768: loss = 6.5305 (0.518 sec/step)
I0404 20:29:28.988461 47978602034560 learning.py:507] global step 2769: loss = 5.5002 (0.531 sec/step)
I0404 20:29:29.494720 47978602034560 learning.py:507] global step 2770: loss = 6.1608 (0.503 sec/step)
I0404 20:29:30.015256 47978602034560 learning.py:507] global step 2771: loss = 6.7579 (0.518 sec/step)
I0404 20:29:30.523231 47978602034560 learning.py:507] global step 2772: loss = 6.8647 (0.506 sec/step)
I0404 20:29:31.060117 47978602034560 learning.py:507] global step 2773: loss = 6.5421 (0.535 sec/step)
I0404 20:29:31.569689 47978602034560 learning.py:507] global step 2774: loss = 6.2520 (0.508 sec/step)
I0404 20:29:32.082551 47978602034560 learning.py:507] global step 2775: loss = 5.4493 (0.511 sec/step)
I0404 20:29:32.602729 47978602034560 learning.py:507] global step 2776: loss = 6.8691 (0.519 sec/step)
I0404 20:29:33.109512 47978602034560 learning.py:507] global step 2777: loss = 5.9773 (0.505 sec/step)
I0404 20:29:33.645683 47978602034560 learning.py:507] global step 2778: loss = 6.9493 (0.534 sec/step)
I0404 20:29:34.156776 47978602034560 learning.py:507] global step 2779: loss = 5.9890 (0.510 sec/step)
I0404 20:29:34.660393 47978602034560 learning.py:507] global step 2780: loss = 6.3153 (0.501 sec/step)
I0404 20:29:35.163870 47978602034560 learning.py:507] global step 2781: loss = 7.2563 (0.501 sec/step)
I0404 20:29:35.676707 47978602034560 learning.py:507] global step 2782: loss = 6.2714 (0.510 sec/step)
I0404 20:29:36.197931 47978602034560 learning.py:507] global step 2783: loss = 7.0246 (0.520 sec/step)
I0404 20:29:36.712243 47978602034560 learning.py:507] global step 2784: loss = 7.0928 (0.513 sec/step)
I0404 20:29:37.229875 47978602034560 learning.py:507] global step 2785: loss = 5.9839 (0.516 sec/step)
I0404 20:29:37.734639 47978602034560 learning.py:507] global step 2786: loss = 6.6990 (0.503 sec/step)
I0404 20:29:38.254523 47978602034560 learning.py:507] global step 2787: loss = 7.0621 (0.517 sec/step)
I0404 20:29:38.766339 47978602034560 learning.py:507] global step 2788: loss = 8.1059 (0.510 sec/step)
I0404 20:29:39.299207 47978602034560 learning.py:507] global step 2789: loss = 7.5537 (0.531 sec/step)
I0404 20:29:39.827025 47978602034560 learning.py:507] global step 2790: loss = 7.2879 (0.525 sec/step)
I0404 20:29:40.335750 47978602034560 learning.py:507] global step 2791: loss = 7.1329 (0.506 sec/step)
I0404 20:29:40.848095 47978602034560 learning.py:507] global step 2792: loss = 5.9117 (0.511 sec/step)
I0404 20:29:41.386211 47978602034560 learning.py:507] global step 2793: loss = 6.3982 (0.537 sec/step)
I0404 20:29:41.906325 47978602034560 learning.py:507] global step 2794: loss = 6.7434 (0.518 sec/step)
I0404 20:29:42.416767 47978602034560 learning.py:507] global step 2795: loss = 6.7318 (0.509 sec/step)
I0404 20:29:42.938240 47978602034560 learning.py:507] global step 2796: loss = 6.6802 (0.520 sec/step)
I0404 20:29:43.441104 47978602034560 learning.py:507] global step 2797: loss = 7.1406 (0.501 sec/step)
I0404 20:29:43.948390 47978602034560 learning.py:507] global step 2798: loss = 6.6053 (0.506 sec/step)
I0404 20:29:44.486071 47978602034560 learning.py:507] global step 2799: loss = 5.9914 (0.536 sec/step)
I0404 20:29:45.002726 47978602034560 learning.py:507] global step 2800: loss = 5.9336 (0.515 sec/step)
I0404 20:29:45.539656 47978602034560 learning.py:507] global step 2801: loss = 5.9819 (0.535 sec/step)
I0404 20:29:46.044362 47978602034560 learning.py:507] global step 2802: loss = 6.9326 (0.503 sec/step)
I0404 20:29:46.556679 47978602034560 learning.py:507] global step 2803: loss = 5.3587 (0.511 sec/step)
I0404 20:29:47.061286 47978602034560 learning.py:507] global step 2804: loss = 6.9195 (0.502 sec/step)
I0404 20:29:47.579913 47978602034560 learning.py:507] global step 2805: loss = 6.1193 (0.517 sec/step)
I0404 20:29:48.085262 47978602034560 learning.py:507] global step 2806: loss = 6.2070 (0.503 sec/step)
I0404 20:29:48.626257 47978602034560 learning.py:507] global step 2807: loss = 7.0882 (0.539 sec/step)
I0404 20:29:49.136722 47978602034560 learning.py:507] global step 2808: loss = 5.4253 (0.508 sec/step)
I0404 20:29:49.664105 47978602034560 learning.py:507] global step 2809: loss = 6.5777 (0.524 sec/step)
I0404 20:29:50.195064 47978602034560 learning.py:507] global step 2810: loss = 7.9624 (0.529 sec/step)
I0404 20:29:50.707048 47978602034560 learning.py:507] global step 2811: loss = 6.6796 (0.510 sec/step)
I0404 20:29:51.240260 47978602034560 learning.py:507] global step 2812: loss = 6.9341 (0.532 sec/step)
I0404 20:29:51.767979 47978602034560 learning.py:507] global step 2813: loss = 5.1916 (0.526 sec/step)
I0404 20:29:52.269303 47978602034560 learning.py:507] global step 2814: loss = 6.0540 (0.498 sec/step)
I0404 20:29:52.777043 47978602034560 learning.py:507] global step 2815: loss = 6.3057 (0.506 sec/step)
I0404 20:29:53.325657 47978602034560 learning.py:507] global step 2816: loss = 6.0800 (0.547 sec/step)
I0404 20:29:53.864327 47978602034560 learning.py:507] global step 2817: loss = 5.6192 (0.537 sec/step)
I0404 20:29:54.400431 47978602034560 learning.py:507] global step 2818: loss = 5.0665 (0.533 sec/step)
I0404 20:29:54.900462 47978602034560 learning.py:507] global step 2819: loss = 5.9134 (0.498 sec/step)
I0404 20:29:55.429649 47978602034560 learning.py:507] global step 2820: loss = 5.6699 (0.528 sec/step)
I0404 20:29:55.946459 47978602034560 learning.py:507] global step 2821: loss = 6.0568 (0.515 sec/step)
I0404 20:29:56.452115 47978602034560 learning.py:507] global step 2822: loss = 6.8637 (0.504 sec/step)
I0404 20:29:56.954298 47978602034560 learning.py:507] global step 2823: loss = 5.5789 (0.501 sec/step)
I0404 20:29:57.458379 47978602034560 learning.py:507] global step 2824: loss = 6.3590 (0.503 sec/step)
I0404 20:29:57.998583 47978602034560 learning.py:507] global step 2825: loss = 6.1219 (0.538 sec/step)
I0404 20:29:58.499607 47978602034560 learning.py:507] global step 2826: loss = 6.2819 (0.499 sec/step)
I0404 20:29:59.012268 47978602034560 learning.py:507] global step 2827: loss = 6.4566 (0.511 sec/step)
I0404 20:29:59.531603 47978602034560 learning.py:507] global step 2828: loss = 6.0593 (0.518 sec/step)
I0404 20:30:00.038007 47978602034560 learning.py:507] global step 2829: loss = 7.0475 (0.505 sec/step)
I0404 20:30:00.557232 47978602034560 learning.py:507] global step 2830: loss = 6.4670 (0.518 sec/step)
I0404 20:30:01.067010 47978602034560 learning.py:507] global step 2831: loss = 6.2704 (0.508 sec/step)
I0404 20:30:01.582809 47978602034560 learning.py:507] global step 2832: loss = 6.4267 (0.514 sec/step)
I0404 20:30:02.117668 47978602034560 learning.py:507] global step 2833: loss = 6.7558 (0.533 sec/step)
I0404 20:30:02.622424 47978602034560 learning.py:507] global step 2834: loss = 6.3869 (0.502 sec/step)
I0404 20:30:03.135132 47978602034560 learning.py:507] global step 2835: loss = 6.7773 (0.510 sec/step)
I0404 20:30:03.663111 47978602034560 learning.py:507] global step 2836: loss = 6.6896 (0.526 sec/step)
I0404 20:30:04.175555 47978602034560 learning.py:507] global step 2837: loss = 7.1384 (0.511 sec/step)
I0404 20:30:04.688670 47978602034560 learning.py:507] global step 2838: loss = 6.5511 (0.510 sec/step)
I0404 20:30:05.230229 47978602034560 learning.py:507] global step 2839: loss = 7.5349 (0.538 sec/step)
I0404 20:30:05.745069 47978602034560 learning.py:507] global step 2840: loss = 6.6731 (0.513 sec/step)
I0404 20:30:06.260514 47978602034560 learning.py:507] global step 2841: loss = 7.6478 (0.514 sec/step)
I0404 20:30:06.790254 47978602034560 learning.py:507] global step 2842: loss = 5.9187 (0.528 sec/step)
I0404 20:30:07.299665 47978602034560 learning.py:507] global step 2843: loss = 6.4012 (0.507 sec/step)
I0404 20:30:07.815890 47978602034560 learning.py:507] global step 2844: loss = 7.2637 (0.515 sec/step)
I0404 20:30:08.322872 47978602034560 learning.py:507] global step 2845: loss = 6.0950 (0.505 sec/step)
I0404 20:30:08.861854 47978602034560 learning.py:507] global step 2846: loss = 6.2209 (0.537 sec/step)
I0404 20:30:09.364926 47978602034560 learning.py:507] global step 2847: loss = 7.3215 (0.501 sec/step)
I0404 20:30:09.874446 47978602034560 learning.py:507] global step 2848: loss = 6.3780 (0.508 sec/step)
I0404 20:30:10.391051 47978602034560 learning.py:507] global step 2849: loss = 6.5129 (0.514 sec/step)
I0404 20:30:10.925884 47978602034560 learning.py:507] global step 2850: loss = 6.1753 (0.533 sec/step)
I0404 20:30:11.432425 47978602034560 learning.py:507] global step 2851: loss = 5.9304 (0.505 sec/step)
I0404 20:30:11.943481 47978602034560 learning.py:507] global step 2852: loss = 6.0633 (0.510 sec/step)
I0404 20:30:12.448478 47978602034560 learning.py:507] global step 2853: loss = 5.3873 (0.503 sec/step)
I0404 20:30:12.966789 47978602034560 learning.py:507] global step 2854: loss = 5.5828 (0.515 sec/step)
I0404 20:30:13.494253 47978602034560 learning.py:507] global step 2855: loss = 6.1544 (0.526 sec/step)
I0404 20:30:13.996896 47978602034560 learning.py:507] global step 2856: loss = 5.4898 (0.501 sec/step)
I0404 20:30:14.525224 47978602034560 learning.py:507] global step 2857: loss = 6.6537 (0.525 sec/step)
I0404 20:30:15.044968 47978602034560 learning.py:507] global step 2858: loss = 6.3723 (0.518 sec/step)
I0404 20:30:15.567898 47978602034560 learning.py:507] global step 2859: loss = 6.5207 (0.521 sec/step)
I0404 20:30:16.079429 47978602034560 learning.py:507] global step 2860: loss = 6.2626 (0.510 sec/step)
I0404 20:30:16.609982 47978602034560 learning.py:507] global step 2861: loss = 6.4259 (0.528 sec/step)
I0404 20:30:17.123724 47978602034560 learning.py:507] global step 2862: loss = 8.2139 (0.511 sec/step)
I0404 20:30:17.637410 47978602034560 learning.py:507] global step 2863: loss = 6.2045 (0.512 sec/step)
I0404 20:30:18.144541 47978602034560 learning.py:507] global step 2864: loss = 6.9981 (0.504 sec/step)
I0404 20:30:18.651254 47978602034560 learning.py:507] global step 2865: loss = 5.9827 (0.505 sec/step)
I0404 20:30:19.191370 47978602034560 learning.py:507] global step 2866: loss = 6.6298 (0.539 sec/step)
I0404 20:30:19.738599 47978602034560 learning.py:507] global step 2867: loss = 6.6066 (0.546 sec/step)
I0404 20:30:20.247668 47978602034560 learning.py:507] global step 2868: loss = 6.0834 (0.506 sec/step)
I0404 20:30:20.785294 47978602034560 learning.py:507] global step 2869: loss = 6.3287 (0.536 sec/step)
I0404 20:30:21.293713 47978602034560 learning.py:507] global step 2870: loss = 6.1847 (0.506 sec/step)
I0404 20:30:21.820553 47978602034560 learning.py:507] global step 2871: loss = 7.0372 (0.525 sec/step)
I0404 20:30:22.356141 47978602034560 learning.py:507] global step 2872: loss = 6.7732 (0.534 sec/step)
I0404 20:30:22.877171 47978602034560 learning.py:507] global step 2873: loss = 6.3706 (0.518 sec/step)
I0404 20:30:23.387629 47978602034560 learning.py:507] global step 2874: loss = 6.3492 (0.509 sec/step)
I0404 20:30:23.896895 47978602034560 learning.py:507] global step 2875: loss = 7.0882 (0.508 sec/step)
I0404 20:30:24.412953 47978602034560 learning.py:507] global step 2876: loss = 7.1228 (0.514 sec/step)
I0404 20:30:24.924092 47978602034560 learning.py:507] global step 2877: loss = 7.3301 (0.510 sec/step)
I0404 20:30:25.459720 47978602034560 learning.py:507] global step 2878: loss = 6.4795 (0.534 sec/step)
I0404 20:30:25.973117 47978602034560 learning.py:507] global step 2879: loss = 5.5808 (0.512 sec/step)
I0404 20:30:26.481007 47978602034560 learning.py:507] global step 2880: loss = 6.3461 (0.506 sec/step)
I0404 20:30:26.988328 47978602034560 learning.py:507] global step 2881: loss = 5.6536 (0.506 sec/step)
I0404 20:30:27.505117 47978602034560 learning.py:507] global step 2882: loss = 6.4426 (0.515 sec/step)
I0404 20:30:28.009300 47978602034560 learning.py:507] global step 2883: loss = 7.6144 (0.503 sec/step)
I0404 20:30:28.529137 47978602034560 learning.py:507] global step 2884: loss = 6.0169 (0.517 sec/step)
I0404 20:30:29.037048 47978602034560 learning.py:507] global step 2885: loss = 7.1532 (0.506 sec/step)
I0404 20:30:29.569835 47978602034560 learning.py:507] global step 2886: loss = 7.0490 (0.531 sec/step)
I0404 20:30:30.101195 47978602034560 learning.py:507] global step 2887: loss = 6.3374 (0.530 sec/step)
I0404 20:30:30.613943 47978602034560 learning.py:507] global step 2888: loss = 6.6033 (0.511 sec/step)
I0404 20:30:31.114888 47978602034560 learning.py:507] global step 2889: loss = 6.8955 (0.499 sec/step)
I0404 20:30:31.631907 47978602034560 learning.py:507] global step 2890: loss = 6.4195 (0.515 sec/step)
I0404 20:30:32.140699 47978602034560 learning.py:507] global step 2891: loss = 6.0421 (0.507 sec/step)
I0404 20:30:32.651863 47978602034560 learning.py:507] global step 2892: loss = 6.0692 (0.508 sec/step)
I0404 20:30:33.161550 47978602034560 learning.py:507] global step 2893: loss = 6.2866 (0.508 sec/step)
I0404 20:30:33.690167 47978602034560 learning.py:507] global step 2894: loss = 6.1568 (0.527 sec/step)
I0404 20:30:34.211183 47978602034560 learning.py:507] global step 2895: loss = 7.3245 (0.518 sec/step)
I0404 20:30:34.715329 47978602034560 learning.py:507] global step 2896: loss = 6.8216 (0.503 sec/step)
I0404 20:30:35.226110 47978602034560 learning.py:507] global step 2897: loss = 6.2936 (0.509 sec/step)
I0404 20:30:35.732572 47978602034560 learning.py:507] global step 2898: loss = 6.9160 (0.504 sec/step)
I0404 20:30:36.247029 47978602034560 learning.py:507] global step 2899: loss = 5.8830 (0.512 sec/step)
I0404 20:30:36.757123 47978602034560 learning.py:507] global step 2900: loss = 6.8008 (0.507 sec/step)
I0404 20:30:37.294707 47978602034560 learning.py:507] global step 2901: loss = 6.7194 (0.536 sec/step)
I0404 20:30:37.797888 47978602034560 learning.py:507] global step 2902: loss = 7.5261 (0.500 sec/step)
I0404 20:30:38.299418 47978602034560 learning.py:507] global step 2903: loss = 8.5199 (0.500 sec/step)
I0404 20:30:38.810748 47978602034560 learning.py:507] global step 2904: loss = 5.8442 (0.510 sec/step)
I0404 20:30:39.321574 47978602034560 learning.py:507] global step 2905: loss = 6.5422 (0.508 sec/step)
I0404 20:30:39.860141 47978602034560 learning.py:507] global step 2906: loss = 7.9180 (0.537 sec/step)
I0404 20:30:40.372085 47978602034560 learning.py:507] global step 2907: loss = 6.4105 (0.510 sec/step)
I0404 20:30:40.879196 47978602034560 learning.py:507] global step 2908: loss = 7.6390 (0.504 sec/step)
I0404 20:30:41.410547 47978602034560 learning.py:507] global step 2909: loss = 8.0742 (0.528 sec/step)
I0404 20:30:41.914292 47978602034560 learning.py:507] global step 2910: loss = 5.7907 (0.502 sec/step)
I0404 20:30:42.418441 47978602034560 learning.py:507] global step 2911: loss = 6.9036 (0.503 sec/step)
I0404 20:30:42.954834 47978602034560 learning.py:507] global step 2912: loss = 5.8355 (0.535 sec/step)
I0404 20:30:43.475911 47978602034560 learning.py:507] global step 2913: loss = 6.2591 (0.518 sec/step)
I0404 20:30:43.982846 47978602034560 learning.py:507] global step 2914: loss = 6.2381 (0.504 sec/step)
I0404 20:30:44.488013 47978602034560 learning.py:507] global step 2915: loss = 6.9197 (0.504 sec/step)
I0404 20:30:44.993569 47978602034560 learning.py:507] global step 2916: loss = 5.8924 (0.504 sec/step)
I0404 20:30:45.527872 47978602034560 learning.py:507] global step 2917: loss = 6.3386 (0.531 sec/step)
I0404 20:30:46.035164 47978602034560 learning.py:507] global step 2918: loss = 7.0299 (0.506 sec/step)
I0404 20:30:46.540008 47978602034560 learning.py:507] global step 2919: loss = 7.1056 (0.503 sec/step)
I0404 20:30:47.070110 47978602034560 learning.py:507] global step 2920: loss = 7.4025 (0.528 sec/step)
I0404 20:30:47.583421 47978602034560 learning.py:507] global step 2921: loss = 6.6270 (0.512 sec/step)
I0404 20:30:48.094777 47978602034560 learning.py:507] global step 2922: loss = 7.3177 (0.510 sec/step)
I0404 20:30:48.631548 47978602034560 learning.py:507] global step 2923: loss = 6.3119 (0.534 sec/step)
I0404 20:30:49.162904 47978602034560 learning.py:507] global step 2924: loss = 6.1597 (0.530 sec/step)
I0404 20:30:49.665612 47978602034560 learning.py:507] global step 2925: loss = 5.5849 (0.501 sec/step)
I0404 20:30:50.176396 47978602034560 learning.py:507] global step 2926: loss = 6.9030 (0.509 sec/step)
I0404 20:30:50.704719 47978602034560 learning.py:507] global step 2927: loss = 5.9549 (0.525 sec/step)
I0404 20:30:51.215109 47978602034560 learning.py:507] global step 2928: loss = 5.9116 (0.507 sec/step)
I0404 20:30:51.749949 47978602034560 learning.py:507] global step 2929: loss = 5.6975 (0.533 sec/step)
I0404 20:30:52.267370 47978602034560 learning.py:507] global step 2930: loss = 6.2505 (0.516 sec/step)
I0404 20:30:52.792751 47978602034560 learning.py:507] global step 2931: loss = 5.7492 (0.524 sec/step)
I0404 20:30:53.297877 47978602034560 learning.py:507] global step 2932: loss = 5.9255 (0.504 sec/step)
I0404 20:30:53.801038 47978602034560 learning.py:507] global step 2933: loss = 6.3351 (0.502 sec/step)
I0404 20:30:54.332875 47978602034560 learning.py:507] global step 2934: loss = 6.9850 (0.530 sec/step)
I0404 20:30:54.843185 47978602034560 learning.py:507] global step 2935: loss = 6.9758 (0.509 sec/step)
I0404 20:30:55.363300 47978602034560 learning.py:507] global step 2936: loss = 6.4912 (0.519 sec/step)
I0404 20:30:55.874005 47978602034560 learning.py:507] global step 2937: loss = 5.5089 (0.509 sec/step)
I0404 20:30:56.376363 47978602034560 learning.py:507] global step 2938: loss = 7.2383 (0.499 sec/step)
I0404 20:30:56.897283 47978602034560 learning.py:507] global step 2939: loss = 6.1243 (0.519 sec/step)
I0404 20:30:57.406550 47978602034560 learning.py:507] global step 2940: loss = 6.2028 (0.506 sec/step)
I0404 20:30:57.931591 47978602034560 learning.py:507] global step 2941: loss = 6.5922 (0.522 sec/step)
I0404 20:30:58.449988 47978602034560 learning.py:507] global step 2942: loss = 5.3042 (0.517 sec/step)
I0404 20:30:58.958645 47978602034560 learning.py:507] global step 2943: loss = 5.7958 (0.507 sec/step)
I0404 20:30:59.499212 47978602034560 learning.py:507] global step 2944: loss = 5.2927 (0.539 sec/step)
I0404 20:31:00.033797 47978602034560 learning.py:507] global step 2945: loss = 5.7991 (0.533 sec/step)
I0404 20:31:00.566486 47978602034560 learning.py:507] global step 2946: loss = 4.8153 (0.530 sec/step)
I0404 20:31:01.073714 47978602034560 learning.py:507] global step 2947: loss = 6.5991 (0.504 sec/step)
I0404 20:31:01.592184 47978602034560 learning.py:507] global step 2948: loss = 6.4097 (0.517 sec/step)
I0404 20:31:02.106489 47978602034560 learning.py:507] global step 2949: loss = 6.5476 (0.511 sec/step)
I0404 20:31:02.620585 47978602034560 learning.py:507] global step 2950: loss = 7.3718 (0.513 sec/step)
I0404 20:31:03.132733 47978602034560 learning.py:507] global step 2951: loss = 7.0296 (0.509 sec/step)
I0404 20:31:03.662360 47978602034560 learning.py:507] global step 2952: loss = 6.6868 (0.528 sec/step)
I0404 20:31:04.171391 47978602034560 learning.py:507] global step 2953: loss = 6.5659 (0.506 sec/step)
I0404 20:31:04.685918 47978602034560 learning.py:507] global step 2954: loss = 6.8279 (0.512 sec/step)
I0404 20:31:05.190311 47978602034560 learning.py:507] global step 2955: loss = 6.6516 (0.503 sec/step)
I0404 20:31:05.702214 47978602034560 learning.py:507] global step 2956: loss = 6.9245 (0.510 sec/step)
I0404 20:31:06.213332 47978602034560 learning.py:507] global step 2957: loss = 7.1036 (0.508 sec/step)
I0404 20:31:06.732772 47978602034560 learning.py:507] global step 2958: loss = 6.5235 (0.518 sec/step)
I0404 20:31:07.265884 47978602034560 learning.py:507] global step 2959: loss = 6.0818 (0.532 sec/step)
I0404 20:31:07.786459 47978602034560 learning.py:507] global step 2960: loss = 6.7084 (0.519 sec/step)
I0404 20:31:08.299423 47978602034560 learning.py:507] global step 2961: loss = 7.9865 (0.511 sec/step)
I0404 20:31:08.807435 47978602034560 learning.py:507] global step 2962: loss = 6.4113 (0.505 sec/step)
I0404 20:31:09.308117 47978602034560 learning.py:507] global step 2963: loss = 7.8029 (0.499 sec/step)
I0404 20:31:09.824734 47978602034560 learning.py:507] global step 2964: loss = 6.6205 (0.515 sec/step)
I0404 20:31:10.336315 47978602034560 learning.py:507] global step 2965: loss = 6.2384 (0.510 sec/step)
I0404 20:31:10.868170 47978602034560 learning.py:507] global step 2966: loss = 6.5369 (0.530 sec/step)
I0404 20:31:11.380733 47978602034560 learning.py:507] global step 2967: loss = 5.8694 (0.511 sec/step)
I0404 20:31:11.887798 47978602034560 learning.py:507] global step 2968: loss = 6.6185 (0.505 sec/step)
I0404 20:31:12.401209 47978602034560 learning.py:507] global step 2969: loss = 6.5174 (0.512 sec/step)
I0404 20:31:12.909973 47978602034560 learning.py:507] global step 2970: loss = 6.6188 (0.507 sec/step)
I0404 20:31:13.416830 47978602034560 learning.py:507] global step 2971: loss = 7.0602 (0.504 sec/step)
I0404 20:31:13.937087 47978602034560 learning.py:507] global step 2972: loss = 5.8877 (0.519 sec/step)
I0404 20:31:14.444607 47978602034560 learning.py:507] global step 2973: loss = 6.4687 (0.505 sec/step)
I0404 20:31:14.950525 47978602034560 learning.py:507] global step 2974: loss = 5.4105 (0.504 sec/step)
I0404 20:31:15.477288 47978602034560 learning.py:507] global step 2975: loss = 6.0930 (0.525 sec/step)
I0404 20:31:15.995687 47978602034560 learning.py:507] global step 2976: loss = 6.1478 (0.517 sec/step)
I0404 20:31:16.521486 47978602034560 learning.py:507] global step 2977: loss = 6.5851 (0.524 sec/step)
I0404 20:31:17.202728 47978602034560 learning.py:507] global step 2978: loss = 7.0369 (0.678 sec/step)
I0404 20:31:17.294596 47983661975296 supervisor.py:1050] Recording summary at step 2978.
I0404 20:31:17.719364 47978602034560 learning.py:507] global step 2979: loss = 5.9243 (0.514 sec/step)
I0404 20:31:18.227166 47978602034560 learning.py:507] global step 2980: loss = 7.3187 (0.506 sec/step)
I0404 20:31:18.739810 47978602034560 learning.py:507] global step 2981: loss = 6.7116 (0.511 sec/step)
I0404 20:31:19.241818 47978602034560 learning.py:507] global step 2982: loss = 5.9960 (0.500 sec/step)
I0404 20:31:19.758315 47978602034560 learning.py:507] global step 2983: loss = 6.1017 (0.515 sec/step)
I0404 20:31:20.286076 47978602034560 learning.py:507] global step 2984: loss = 5.8034 (0.526 sec/step)
I0404 20:31:20.800200 47978602034560 learning.py:507] global step 2985: loss = 5.7395 (0.511 sec/step)
I0404 20:31:21.304296 47978602034560 learning.py:507] global step 2986: loss = 6.8821 (0.501 sec/step)
I0404 20:31:21.812610 47978602034560 learning.py:507] global step 2987: loss = 6.9924 (0.507 sec/step)
I0404 20:31:22.317419 47978602034560 learning.py:507] global step 2988: loss = 6.9753 (0.502 sec/step)
I0404 20:31:22.830379 47978602034560 learning.py:507] global step 2989: loss = 6.4482 (0.511 sec/step)
I0404 20:31:23.364674 47978602034560 learning.py:507] global step 2990: loss = 6.5527 (0.531 sec/step)
I0404 20:31:23.881448 47978602034560 learning.py:507] global step 2991: loss = 5.7316 (0.515 sec/step)
I0404 20:31:24.401591 47978602034560 learning.py:507] global step 2992: loss = 5.5221 (0.517 sec/step)
I0404 20:31:24.905374 47978602034560 learning.py:507] global step 2993: loss = 5.2487 (0.502 sec/step)
I0404 20:31:25.418423 47978602034560 learning.py:507] global step 2994: loss = 6.3526 (0.510 sec/step)
I0404 20:31:25.962013 47978602034560 learning.py:507] global step 2995: loss = 6.8743 (0.541 sec/step)
I0404 20:31:26.477849 47978602034560 learning.py:507] global step 2996: loss = 6.3989 (0.513 sec/step)
I0404 20:31:26.998016 47978602034560 learning.py:507] global step 2997: loss = 6.3177 (0.517 sec/step)
I0404 20:31:27.504337 47978602034560 learning.py:507] global step 2998: loss = 6.5610 (0.503 sec/step)
I0404 20:31:28.007671 47978602034560 learning.py:507] global step 2999: loss = 6.2564 (0.502 sec/step)
I0404 20:31:28.513988 47978602034560 learning.py:507] global step 3000: loss = 5.7969 (0.504 sec/step)
I0404 20:31:29.036695 47978602034560 learning.py:507] global step 3001: loss = 6.0027 (0.521 sec/step)
I0404 20:31:29.540249 47978602034560 learning.py:507] global step 3002: loss = 7.1979 (0.502 sec/step)
I0404 20:31:30.058228 47978602034560 learning.py:507] global step 3003: loss = 7.9266 (0.516 sec/step)
I0404 20:31:30.579338 47978602034560 learning.py:507] global step 3004: loss = 6.9665 (0.520 sec/step)
I0404 20:31:31.082917 47978602034560 learning.py:507] global step 3005: loss = 6.4372 (0.502 sec/step)
I0404 20:31:31.587544 47978602034560 learning.py:507] global step 3006: loss = 6.4551 (0.502 sec/step)
I0404 20:31:32.096724 47978602034560 learning.py:507] global step 3007: loss = 6.9896 (0.508 sec/step)
I0404 20:31:32.620245 47978602034560 learning.py:507] global step 3008: loss = 5.6894 (0.522 sec/step)
I0404 20:31:33.132012 47978602034560 learning.py:507] global step 3009: loss = 6.6639 (0.510 sec/step)
I0404 20:31:33.637184 47978602034560 learning.py:507] global step 3010: loss = 6.6981 (0.504 sec/step)
I0404 20:31:34.172994 47978602034560 learning.py:507] global step 3011: loss = 5.3455 (0.534 sec/step)
I0404 20:31:34.715361 47978602034560 learning.py:507] global step 3012: loss = 7.5403 (0.541 sec/step)
I0404 20:31:35.221128 47978602034560 learning.py:507] global step 3013: loss = 6.3823 (0.503 sec/step)
I0404 20:31:35.725838 47978602034560 learning.py:507] global step 3014: loss = 6.4205 (0.503 sec/step)
I0404 20:31:36.238541 47978602034560 learning.py:507] global step 3015: loss = 7.3178 (0.510 sec/step)
I0404 20:31:36.741998 47978602034560 learning.py:507] global step 3016: loss = 5.9841 (0.502 sec/step)
I0404 20:31:37.272053 47978602034560 learning.py:507] global step 3017: loss = 6.1700 (0.528 sec/step)
I0404 20:31:37.771838 47978602034560 learning.py:507] global step 3018: loss = 6.6178 (0.498 sec/step)
I0404 20:31:38.283370 47978602034560 learning.py:507] global step 3019: loss = 6.2279 (0.510 sec/step)
I0404 20:31:38.820630 47978602034560 learning.py:507] global step 3020: loss = 5.7681 (0.536 sec/step)
I0404 20:31:39.325223 47978602034560 learning.py:507] global step 3021: loss = 6.2542 (0.502 sec/step)
I0404 20:31:39.826256 47978602034560 learning.py:507] global step 3022: loss = 5.9688 (0.499 sec/step)
I0404 20:31:40.332804 47978602034560 learning.py:507] global step 3023: loss = 6.2514 (0.505 sec/step)
I0404 20:31:40.841040 47978602034560 learning.py:507] global step 3024: loss = 7.0455 (0.507 sec/step)
I0404 20:31:41.357428 47978602034560 learning.py:507] global step 3025: loss = 6.6764 (0.515 sec/step)
I0404 20:31:41.892829 47978602034560 learning.py:507] global step 3026: loss = 6.9930 (0.534 sec/step)
I0404 20:31:42.431182 47978602034560 learning.py:507] global step 3027: loss = 6.7521 (0.537 sec/step)
I0404 20:31:42.961590 47978602034560 learning.py:507] global step 3028: loss = 6.6493 (0.529 sec/step)
I0404 20:31:43.482509 47978602034560 learning.py:507] global step 3029: loss = 6.0225 (0.519 sec/step)
I0404 20:31:43.996154 47978602034560 learning.py:507] global step 3030: loss = 6.7737 (0.511 sec/step)
I0404 20:31:44.508328 47978602034560 learning.py:507] global step 3031: loss = 6.5102 (0.511 sec/step)
I0404 20:31:45.022327 47978602034560 learning.py:507] global step 3032: loss = 6.6317 (0.511 sec/step)
I0404 20:31:45.521943 47978602034560 learning.py:507] global step 3033: loss = 6.3419 (0.498 sec/step)
I0404 20:31:46.032927 47978602034560 learning.py:507] global step 3034: loss = 6.8606 (0.509 sec/step)
I0404 20:31:46.545420 47978602034560 learning.py:507] global step 3035: loss = 6.4298 (0.511 sec/step)
I0404 20:31:47.070897 47978602034560 learning.py:507] global step 3036: loss = 7.0704 (0.523 sec/step)
I0404 20:31:47.594413 47978602034560 learning.py:507] global step 3037: loss = 6.1242 (0.522 sec/step)
I0404 20:31:48.116040 47978602034560 learning.py:507] global step 3038: loss = 7.2832 (0.519 sec/step)
I0404 20:31:48.645009 47978602034560 learning.py:507] global step 3039: loss = 6.5767 (0.527 sec/step)
I0404 20:31:49.163132 47978602034560 learning.py:507] global step 3040: loss = 6.3120 (0.516 sec/step)
I0404 20:31:49.681402 47978602034560 learning.py:507] global step 3041: loss = 6.3373 (0.515 sec/step)
I0404 20:31:50.202816 47978602034560 learning.py:507] global step 3042: loss = 6.1436 (0.518 sec/step)
I0404 20:31:50.708424 47978602034560 learning.py:507] global step 3043: loss = 6.4758 (0.504 sec/step)
I0404 20:31:51.214195 47978602034560 learning.py:507] global step 3044: loss = 5.5623 (0.504 sec/step)
I0404 20:31:51.726433 47978602034560 learning.py:507] global step 3045: loss = 6.1047 (0.509 sec/step)
I0404 20:31:52.247048 47978602034560 learning.py:507] global step 3046: loss = 6.0957 (0.518 sec/step)
I0404 20:31:52.752500 47978602034560 learning.py:507] global step 3047: loss = 6.2047 (0.503 sec/step)
I0404 20:31:53.263301 47978602034560 learning.py:507] global step 3048: loss = 7.5148 (0.509 sec/step)
I0404 20:31:53.793529 47978602034560 learning.py:507] global step 3049: loss = 6.3185 (0.529 sec/step)
I0404 20:31:54.315719 47978602034560 learning.py:507] global step 3050: loss = 6.5297 (0.521 sec/step)
I0404 20:31:54.831319 47978602034560 learning.py:507] global step 3051: loss = 6.5031 (0.513 sec/step)
I0404 20:31:55.355215 47978602034560 learning.py:507] global step 3052: loss = 6.2550 (0.521 sec/step)
I0404 20:31:55.893687 47978602034560 learning.py:507] global step 3053: loss = 5.9390 (0.537 sec/step)
I0404 20:31:56.420635 47978602034560 learning.py:507] global step 3054: loss = 6.3318 (0.525 sec/step)
I0404 20:31:56.920193 47978602034560 learning.py:507] global step 3055: loss = 6.7458 (0.498 sec/step)
I0404 20:31:57.436725 47978602034560 learning.py:507] global step 3056: loss = 6.9878 (0.515 sec/step)
I0404 20:31:57.945595 47978602034560 learning.py:507] global step 3057: loss = 5.8665 (0.507 sec/step)
I0404 20:31:58.464876 47978602034560 learning.py:507] global step 3058: loss = 6.5369 (0.516 sec/step)
I0404 20:31:58.996846 47978602034560 learning.py:507] global step 3059: loss = 5.8301 (0.530 sec/step)
I0404 20:31:59.505820 47978602034560 learning.py:507] global step 3060: loss = 8.5482 (0.506 sec/step)
I0404 20:32:00.046737 47978602034560 learning.py:507] global step 3061: loss = 5.2476 (0.539 sec/step)
I0404 20:32:00.583759 47978602034560 learning.py:507] global step 3062: loss = 5.3942 (0.535 sec/step)
I0404 20:32:01.093100 47978602034560 learning.py:507] global step 3063: loss = 6.8691 (0.508 sec/step)
I0404 20:32:01.598242 47978602034560 learning.py:507] global step 3064: loss = 6.5172 (0.504 sec/step)
I0404 20:32:02.128741 47978602034560 learning.py:507] global step 3065: loss = 6.3315 (0.528 sec/step)
I0404 20:32:02.636445 47978602034560 learning.py:507] global step 3066: loss = 6.3839 (0.506 sec/step)
I0404 20:32:03.170305 47978602034560 learning.py:507] global step 3067: loss = 6.7129 (0.532 sec/step)
I0404 20:32:03.688597 47978602034560 learning.py:507] global step 3068: loss = 6.9962 (0.517 sec/step)
I0404 20:32:04.210116 47978602034560 learning.py:507] global step 3069: loss = 5.7607 (0.519 sec/step)
I0404 20:32:04.720183 47978602034560 learning.py:507] global step 3070: loss = 5.9944 (0.508 sec/step)
I0404 20:32:05.233259 47978602034560 learning.py:507] global step 3071: loss = 6.4902 (0.512 sec/step)
I0404 20:32:05.740081 47978602034560 learning.py:507] global step 3072: loss = 6.2009 (0.504 sec/step)
I0404 20:32:06.248739 47978602034560 learning.py:507] global step 3073: loss = 6.7295 (0.506 sec/step)
I0404 20:32:06.759280 47978602034560 learning.py:507] global step 3074: loss = 7.6432 (0.509 sec/step)
I0404 20:32:07.268082 47978602034560 learning.py:507] global step 3075: loss = 6.4790 (0.507 sec/step)
I0404 20:32:07.771648 47978602034560 learning.py:507] global step 3076: loss = 6.6102 (0.502 sec/step)
I0404 20:32:08.282869 47978602034560 learning.py:507] global step 3077: loss = 6.4535 (0.508 sec/step)
I0404 20:32:08.789098 47978602034560 learning.py:507] global step 3078: loss = 6.6681 (0.503 sec/step)
I0404 20:32:09.301232 47978602034560 learning.py:507] global step 3079: loss = 6.1195 (0.511 sec/step)
I0404 20:32:09.837247 47978602034560 learning.py:507] global step 3080: loss = 5.7974 (0.534 sec/step)
I0404 20:32:10.339148 47978602034560 learning.py:507] global step 3081: loss = 6.7861 (0.500 sec/step)
I0404 20:32:10.858545 47978602034560 learning.py:507] global step 3082: loss = 7.6692 (0.518 sec/step)
I0404 20:32:11.368511 47978602034560 learning.py:507] global step 3083: loss = 6.3671 (0.507 sec/step)
I0404 20:32:11.889681 47978602034560 learning.py:507] global step 3084: loss = 5.7764 (0.520 sec/step)
I0404 20:32:12.407587 47978602034560 learning.py:507] global step 3085: loss = 5.3870 (0.516 sec/step)
I0404 20:32:12.919291 47978602034560 learning.py:507] global step 3086: loss = 6.0499 (0.510 sec/step)
I0404 20:32:13.452222 47978602034560 learning.py:507] global step 3087: loss = 6.5597 (0.531 sec/step)
I0404 20:32:13.969158 47978602034560 learning.py:507] global step 3088: loss = 6.3440 (0.515 sec/step)
I0404 20:32:14.503834 47978602034560 learning.py:507] global step 3089: loss = 7.1669 (0.533 sec/step)
I0404 20:32:15.018888 47978602034560 learning.py:507] global step 3090: loss = 5.7921 (0.512 sec/step)
I0404 20:32:15.536260 47978602034560 learning.py:507] global step 3091: loss = 6.9211 (0.516 sec/step)
I0404 20:32:16.081753 47978602034560 learning.py:507] global step 3092: loss = 7.1437 (0.544 sec/step)
I0404 20:32:16.619153 47978602034560 learning.py:507] global step 3093: loss = 7.2874 (0.536 sec/step)
I0404 20:32:17.134996 47978602034560 learning.py:507] global step 3094: loss = 6.2579 (0.514 sec/step)
I0404 20:32:17.655143 47978602034560 learning.py:507] global step 3095: loss = 5.9491 (0.519 sec/step)
I0404 20:32:18.167264 47978602034560 learning.py:507] global step 3096: loss = 6.1778 (0.510 sec/step)
I0404 20:32:18.672292 47978602034560 learning.py:507] global step 3097: loss = 5.9278 (0.502 sec/step)
I0404 20:32:19.178328 47978602034560 learning.py:507] global step 3098: loss = 6.6023 (0.503 sec/step)
I0404 20:32:19.688259 47978602034560 learning.py:507] global step 3099: loss = 6.0322 (0.507 sec/step)
I0404 20:32:20.200044 47978602034560 learning.py:507] global step 3100: loss = 8.0077 (0.510 sec/step)
I0404 20:32:20.737996 47978602034560 learning.py:507] global step 3101: loss = 7.2159 (0.536 sec/step)
I0404 20:32:21.259093 47978602034560 learning.py:507] global step 3102: loss = 5.6685 (0.520 sec/step)
I0404 20:32:21.769345 47978602034560 learning.py:507] global step 3103: loss = 6.5032 (0.507 sec/step)
I0404 20:32:22.292542 47978602034560 learning.py:507] global step 3104: loss = 6.5459 (0.520 sec/step)
I0404 20:32:22.801398 47978602034560 learning.py:507] global step 3105: loss = 6.9982 (0.506 sec/step)
I0404 20:32:23.307662 47978602034560 learning.py:507] global step 3106: loss = 7.9473 (0.505 sec/step)
I0404 20:32:23.820032 47978602034560 learning.py:507] global step 3107: loss = 6.2151 (0.509 sec/step)
I0404 20:32:24.326240 47978602034560 learning.py:507] global step 3108: loss = 6.5958 (0.505 sec/step)
I0404 20:32:24.857102 47978602034560 learning.py:507] global step 3109: loss = 7.0401 (0.528 sec/step)
I0404 20:32:25.373554 47978602034560 learning.py:507] global step 3110: loss = 6.1769 (0.515 sec/step)
I0404 20:32:25.899633 47978602034560 learning.py:507] global step 3111: loss = 6.5562 (0.523 sec/step)
I0404 20:32:26.406779 47978602034560 learning.py:507] global step 3112: loss = 5.5898 (0.506 sec/step)
I0404 20:32:26.916285 47978602034560 learning.py:507] global step 3113: loss = 7.4006 (0.508 sec/step)
I0404 20:32:27.424343 47978602034560 learning.py:507] global step 3114: loss = 6.8635 (0.505 sec/step)
I0404 20:32:27.930869 47978602034560 learning.py:507] global step 3115: loss = 6.3124 (0.505 sec/step)
I0404 20:32:28.465082 47978602034560 learning.py:507] global step 3116: loss = 6.0501 (0.533 sec/step)
I0404 20:32:29.004140 47978602034560 learning.py:507] global step 3117: loss = 5.6852 (0.537 sec/step)
I0404 20:32:29.508397 47978602034560 learning.py:507] global step 3118: loss = 6.6814 (0.503 sec/step)
I0404 20:32:30.040963 47978602034560 learning.py:507] global step 3119: loss = 6.3628 (0.530 sec/step)
I0404 20:32:30.556516 47978602034560 learning.py:507] global step 3120: loss = 5.9477 (0.514 sec/step)
I0404 20:32:31.068604 47978602034560 learning.py:507] global step 3121: loss = 7.6344 (0.511 sec/step)
I0404 20:32:31.575943 47978602034560 learning.py:507] global step 3122: loss = 6.5446 (0.506 sec/step)
I0404 20:32:32.086321 47978602034560 learning.py:507] global step 3123: loss = 6.4052 (0.509 sec/step)
I0404 20:32:32.599094 47978602034560 learning.py:507] global step 3124: loss = 6.5588 (0.510 sec/step)
I0404 20:32:33.131540 47978602034560 learning.py:507] global step 3125: loss = 6.7708 (0.531 sec/step)
I0404 20:32:33.638949 47978602034560 learning.py:507] global step 3126: loss = 6.5691 (0.506 sec/step)
I0404 20:32:34.148947 47978602034560 learning.py:507] global step 3127: loss = 5.0352 (0.508 sec/step)
I0404 20:32:34.656985 47978602034560 learning.py:507] global step 3128: loss = 7.1816 (0.506 sec/step)
I0404 20:32:35.169878 47978602034560 learning.py:507] global step 3129: loss = 6.5278 (0.511 sec/step)
I0404 20:32:35.686056 47978602034560 learning.py:507] global step 3130: loss = 6.6847 (0.515 sec/step)
I0404 20:32:36.200767 47978602034560 learning.py:507] global step 3131: loss = 7.3974 (0.512 sec/step)
I0404 20:32:36.726502 47978602034560 learning.py:507] global step 3132: loss = 7.3616 (0.524 sec/step)
I0404 20:32:37.234799 47978602034560 learning.py:507] global step 3133: loss = 6.7572 (0.507 sec/step)
I0404 20:32:37.747188 47978602034560 learning.py:507] global step 3134: loss = 6.7856 (0.511 sec/step)
I0404 20:32:38.276285 47978602034560 learning.py:507] global step 3135: loss = 5.9076 (0.526 sec/step)
I0404 20:32:38.798999 47978602034560 learning.py:507] global step 3136: loss = 6.2324 (0.521 sec/step)
I0404 20:32:39.303666 47978602034560 learning.py:507] global step 3137: loss = 5.6481 (0.503 sec/step)
I0404 20:32:39.823728 47978602034560 learning.py:507] global step 3138: loss = 6.1653 (0.519 sec/step)
I0404 20:32:40.335180 47978602034560 learning.py:507] global step 3139: loss = 6.2107 (0.510 sec/step)
I0404 20:32:40.849777 47978602034560 learning.py:507] global step 3140: loss = 7.4957 (0.513 sec/step)
I0404 20:32:41.375133 47978602034560 learning.py:507] global step 3141: loss = 4.8890 (0.524 sec/step)
I0404 20:32:41.883801 47978602034560 learning.py:507] global step 3142: loss = 6.3013 (0.507 sec/step)
I0404 20:32:42.399252 47978602034560 learning.py:507] global step 3143: loss = 7.1901 (0.513 sec/step)
I0404 20:32:42.901238 47978602034560 learning.py:507] global step 3144: loss = 5.9820 (0.500 sec/step)
I0404 20:32:43.441362 47978602034560 learning.py:507] global step 3145: loss = 5.8899 (0.539 sec/step)
I0404 20:32:43.952822 47978602034560 learning.py:507] global step 3146: loss = 6.4177 (0.510 sec/step)
I0404 20:32:44.485203 47978602034560 learning.py:507] global step 3147: loss = 6.6126 (0.531 sec/step)
I0404 20:32:45.014101 47978602034560 learning.py:507] global step 3148: loss = 7.1041 (0.526 sec/step)
I0404 20:32:45.524228 47978602034560 learning.py:507] global step 3149: loss = 6.8915 (0.509 sec/step)
I0404 20:32:46.055346 47978602034560 learning.py:507] global step 3150: loss = 6.2341 (0.528 sec/step)
I0404 20:32:46.585671 47978602034560 learning.py:507] global step 3151: loss = 5.9206 (0.529 sec/step)
I0404 20:32:47.126133 47978602034560 learning.py:507] global step 3152: loss = 5.9792 (0.537 sec/step)
I0404 20:32:47.630419 47978602034560 learning.py:507] global step 3153: loss = 6.2629 (0.501 sec/step)
I0404 20:32:48.137360 47978602034560 learning.py:507] global step 3154: loss = 6.5636 (0.504 sec/step)
I0404 20:32:48.651385 47978602034560 learning.py:507] global step 3155: loss = 7.5959 (0.512 sec/step)
I0404 20:32:49.166056 47978602034560 learning.py:507] global step 3156: loss = 5.4445 (0.513 sec/step)
I0404 20:32:49.678824 47978602034560 learning.py:507] global step 3157: loss = 6.8522 (0.511 sec/step)
I0404 20:32:50.182861 47978602034560 learning.py:507] global step 3158: loss = 6.3954 (0.501 sec/step)
I0404 20:32:50.692168 47978602034560 learning.py:507] global step 3159: loss = 5.1420 (0.508 sec/step)
I0404 20:32:51.199460 47978602034560 learning.py:507] global step 3160: loss = 6.5917 (0.506 sec/step)
I0404 20:32:51.704267 47978602034560 learning.py:507] global step 3161: loss = 6.6208 (0.503 sec/step)
I0404 20:32:52.234837 47978602034560 learning.py:507] global step 3162: loss = 6.4184 (0.528 sec/step)
I0404 20:32:52.736318 47978602034560 learning.py:507] global step 3163: loss = 5.6991 (0.499 sec/step)
I0404 20:32:53.249996 47978602034560 learning.py:507] global step 3164: loss = 5.8815 (0.512 sec/step)
I0404 20:32:53.772756 47978602034560 learning.py:507] global step 3165: loss = 7.0200 (0.520 sec/step)
I0404 20:32:54.276544 47978602034560 learning.py:507] global step 3166: loss = 6.1276 (0.502 sec/step)
I0404 20:32:54.781510 47978602034560 learning.py:507] global step 3167: loss = 6.4034 (0.502 sec/step)
I0404 20:32:55.292416 47978602034560 learning.py:507] global step 3168: loss = 5.5661 (0.509 sec/step)
I0404 20:32:55.830522 47978602034560 learning.py:507] global step 3169: loss = 7.0588 (0.536 sec/step)
I0404 20:32:56.351355 47978602034560 learning.py:507] global step 3170: loss = 6.9788 (0.518 sec/step)
I0404 20:32:56.864277 47978602034560 learning.py:507] global step 3171: loss = 6.2901 (0.511 sec/step)
I0404 20:32:57.405433 47978602034560 learning.py:507] global step 3172: loss = 7.4969 (0.538 sec/step)
I0404 20:32:57.915775 47978602034560 learning.py:507] global step 3173: loss = 7.0834 (0.509 sec/step)
I0404 20:32:58.424439 47978602034560 learning.py:507] global step 3174: loss = 5.9947 (0.507 sec/step)
I0404 20:32:58.925515 47978602034560 learning.py:507] global step 3175: loss = 5.5859 (0.500 sec/step)
I0404 20:32:59.441742 47978602034560 learning.py:507] global step 3176: loss = 6.7656 (0.513 sec/step)
I0404 20:32:59.947991 47978602034560 learning.py:507] global step 3177: loss = 7.0725 (0.505 sec/step)
I0404 20:33:00.463757 47978602034560 learning.py:507] global step 3178: loss = 7.0843 (0.513 sec/step)
I0404 20:33:00.981048 47978602034560 learning.py:507] global step 3179: loss = 6.9039 (0.516 sec/step)
I0404 20:33:01.494860 47978602034560 learning.py:507] global step 3180: loss = 5.7957 (0.512 sec/step)
I0404 20:33:02.013526 47978602034560 learning.py:507] global step 3181: loss = 6.3285 (0.516 sec/step)
I0404 20:33:02.528666 47978602034560 learning.py:507] global step 3182: loss = 5.3798 (0.512 sec/step)
I0404 20:33:03.034741 47978602034560 learning.py:507] global step 3183: loss = 7.3947 (0.503 sec/step)
I0404 20:33:03.550107 47978602034560 learning.py:507] global step 3184: loss = 7.0856 (0.514 sec/step)
I0404 20:33:04.056544 47978602034560 learning.py:507] global step 3185: loss = 6.3447 (0.505 sec/step)
I0404 20:33:04.590631 47978602034560 learning.py:507] global step 3186: loss = 7.2958 (0.532 sec/step)
I0404 20:33:05.116055 47978602034560 learning.py:507] global step 3187: loss = 6.1377 (0.524 sec/step)
I0404 20:33:05.649710 47978602034560 learning.py:507] global step 3188: loss = 7.1256 (0.532 sec/step)
I0404 20:33:06.159554 47978602034560 learning.py:507] global step 3189: loss = 6.8980 (0.508 sec/step)
I0404 20:33:06.665630 47978602034560 learning.py:507] global step 3190: loss = 6.3608 (0.503 sec/step)
I0404 20:33:07.189398 47978602034560 learning.py:507] global step 3191: loss = 5.9620 (0.522 sec/step)
I0404 20:33:07.701074 47978602034560 learning.py:507] global step 3192: loss = 7.0740 (0.510 sec/step)
I0404 20:33:08.206053 47978602034560 learning.py:507] global step 3193: loss = 5.8988 (0.503 sec/step)
I0404 20:33:08.745204 47978602034560 learning.py:507] global step 3194: loss = 6.6598 (0.538 sec/step)
I0404 20:33:09.270370 47978602034560 learning.py:507] global step 3195: loss = 6.0891 (0.524 sec/step)
I0404 20:33:09.799823 47978602034560 learning.py:507] global step 3196: loss = 5.6796 (0.528 sec/step)
I0404 20:33:10.302899 47978602034560 learning.py:507] global step 3197: loss = 7.0446 (0.501 sec/step)
I0404 20:33:10.811264 47978602034560 learning.py:507] global step 3198: loss = 6.7989 (0.507 sec/step)
I0404 20:33:11.326596 47978602034560 learning.py:507] global step 3199: loss = 5.6676 (0.512 sec/step)
I0404 20:33:11.835004 47978602034560 learning.py:507] global step 3200: loss = 6.5618 (0.507 sec/step)
I0404 20:33:12.337190 47978602034560 learning.py:507] global step 3201: loss = 7.1537 (0.499 sec/step)
I0404 20:33:12.846390 47978602034560 learning.py:507] global step 3202: loss = 6.6588 (0.506 sec/step)
I0404 20:33:13.346372 47978602034560 learning.py:507] global step 3203: loss = 5.2901 (0.498 sec/step)
I0404 20:33:13.860809 47978602034560 learning.py:507] global step 3204: loss = 5.6583 (0.513 sec/step)
I0404 20:33:14.380661 47978602034560 learning.py:507] global step 3205: loss = 5.9333 (0.518 sec/step)
I0404 20:33:14.910895 47978602034560 learning.py:507] global step 3206: loss = 5.6615 (0.529 sec/step)
I0404 20:33:15.421555 47978602034560 learning.py:507] global step 3207: loss = 6.6313 (0.509 sec/step)
I0404 20:33:15.930478 47978602034560 learning.py:507] global step 3208: loss = 7.8618 (0.507 sec/step)
I0404 20:33:16.437351 47978602034560 learning.py:507] global step 3209: loss = 6.8481 (0.504 sec/step)
I0404 20:33:16.963891 47978602034560 learning.py:507] global step 3210: loss = 6.2744 (0.520 sec/step)
I0404 20:33:17.323986 47983661975296 supervisor.py:1050] Recording summary at step 3210.
I0404 20:33:17.643376 47978602034560 learning.py:507] global step 3211: loss = 6.5246 (0.667 sec/step)
I0404 20:33:18.157728 47978602034560 learning.py:507] global step 3212: loss = 6.5673 (0.513 sec/step)
I0404 20:33:18.665457 47978602034560 learning.py:507] global step 3213: loss = 7.2987 (0.506 sec/step)
I0404 20:33:19.172163 47978602034560 learning.py:507] global step 3214: loss = 5.6236 (0.504 sec/step)
I0404 20:33:19.683126 47978602034560 learning.py:507] global step 3215: loss = 6.4868 (0.508 sec/step)
I0404 20:33:20.194313 47978602034560 learning.py:507] global step 3216: loss = 6.6281 (0.510 sec/step)
I0404 20:33:20.735095 47978602034560 learning.py:507] global step 3217: loss = 5.8516 (0.539 sec/step)
I0404 20:33:21.244173 47978602034560 learning.py:507] global step 3218: loss = 6.2285 (0.507 sec/step)
I0404 20:33:21.753439 47978602034560 learning.py:507] global step 3219: loss = 5.3470 (0.506 sec/step)
I0404 20:33:22.261101 47978602034560 learning.py:507] global step 3220: loss = 7.1945 (0.506 sec/step)
I0404 20:33:22.767419 47978602034560 learning.py:507] global step 3221: loss = 6.5006 (0.503 sec/step)
I0404 20:33:23.298709 47978602034560 learning.py:507] global step 3222: loss = 6.1172 (0.528 sec/step)
I0404 20:33:23.829398 47978602034560 learning.py:507] global step 3223: loss = 5.9985 (0.529 sec/step)
I0404 20:33:24.358444 47978602034560 learning.py:507] global step 3224: loss = 5.8443 (0.528 sec/step)
I0404 20:33:24.870906 47978602034560 learning.py:507] global step 3225: loss = 6.0485 (0.511 sec/step)
I0404 20:33:25.375902 47978602034560 learning.py:507] global step 3226: loss = 6.2479 (0.503 sec/step)
I0404 20:33:25.887741 47978602034560 learning.py:507] global step 3227: loss = 5.6931 (0.510 sec/step)
I0404 20:33:26.404314 47978602034560 learning.py:507] global step 3228: loss = 5.0303 (0.514 sec/step)
I0404 20:33:26.918994 47978602034560 learning.py:507] global step 3229: loss = 7.2716 (0.512 sec/step)
I0404 20:33:27.427437 47978602034560 learning.py:507] global step 3230: loss = 5.9635 (0.507 sec/step)
I0404 20:33:27.937432 47978602034560 learning.py:507] global step 3231: loss = 6.1778 (0.508 sec/step)
I0404 20:33:28.470381 47978602034560 learning.py:507] global step 3232: loss = 7.0259 (0.530 sec/step)
I0404 20:33:28.980863 47978602034560 learning.py:507] global step 3233: loss = 5.7000 (0.508 sec/step)
I0404 20:33:29.489974 47978602034560 learning.py:507] global step 3234: loss = 6.2475 (0.506 sec/step)
I0404 20:33:29.999171 47978602034560 learning.py:507] global step 3235: loss = 5.7434 (0.508 sec/step)
I0404 20:33:30.508988 47978602034560 learning.py:507] global step 3236: loss = 5.1348 (0.507 sec/step)
I0404 20:33:31.025035 47978602034560 learning.py:507] global step 3237: loss = 7.3458 (0.514 sec/step)
I0404 20:33:31.540293 47978602034560 learning.py:507] global step 3238: loss = 5.8342 (0.514 sec/step)
I0404 20:33:32.067690 47978602034560 learning.py:507] global step 3239: loss = 7.7169 (0.526 sec/step)
I0404 20:33:32.574746 47978602034560 learning.py:507] global step 3240: loss = 6.1936 (0.506 sec/step)
I0404 20:33:33.082218 47978602034560 learning.py:507] global step 3241: loss = 5.9448 (0.506 sec/step)
I0404 20:33:33.621404 47978602034560 learning.py:507] global step 3242: loss = 6.0602 (0.538 sec/step)
I0404 20:33:34.138221 47978602034560 learning.py:507] global step 3243: loss = 6.2604 (0.515 sec/step)
I0404 20:33:34.643933 47978602034560 learning.py:507] global step 3244: loss = 6.8625 (0.504 sec/step)
I0404 20:33:35.149695 47978602034560 learning.py:507] global step 3245: loss = 7.3625 (0.503 sec/step)
I0404 20:33:35.684353 47978602034560 learning.py:507] global step 3246: loss = 6.9094 (0.532 sec/step)
I0404 20:33:36.189926 47978602034560 learning.py:507] global step 3247: loss = 6.4797 (0.504 sec/step)
I0404 20:33:36.712435 47978602034560 learning.py:507] global step 3248: loss = 6.2372 (0.521 sec/step)
I0404 20:33:37.229447 47978602034560 learning.py:507] global step 3249: loss = 6.0504 (0.515 sec/step)
I0404 20:33:37.733988 47978602034560 learning.py:507] global step 3250: loss = 7.0728 (0.502 sec/step)
I0404 20:33:38.253359 47978602034560 learning.py:507] global step 3251: loss = 6.3030 (0.518 sec/step)
I0404 20:33:38.755259 47978602034560 learning.py:507] global step 3252: loss = 7.1302 (0.499 sec/step)
I0404 20:33:39.288826 47978602034560 learning.py:507] global step 3253: loss = 6.6668 (0.531 sec/step)
I0404 20:33:39.807079 47978602034560 learning.py:507] global step 3254: loss = 7.1110 (0.517 sec/step)
I0404 20:33:40.306678 47978602034560 learning.py:507] global step 3255: loss = 6.2392 (0.498 sec/step)
I0404 20:33:40.815197 47978602034560 learning.py:507] global step 3256: loss = 7.2188 (0.507 sec/step)
I0404 20:33:41.320963 47978602034560 learning.py:507] global step 3257: loss = 6.8329 (0.503 sec/step)
I0404 20:33:41.849063 47978602034560 learning.py:507] global step 3258: loss = 6.9893 (0.527 sec/step)
I0404 20:33:42.355103 47978602034560 learning.py:507] global step 3259: loss = 6.1199 (0.505 sec/step)
I0404 20:33:42.889118 47978602034560 learning.py:507] global step 3260: loss = 7.0924 (0.532 sec/step)
I0404 20:33:43.400967 47978602034560 learning.py:507] global step 3261: loss = 6.1626 (0.509 sec/step)
I0404 20:33:43.917386 47978602034560 learning.py:507] global step 3262: loss = 6.3583 (0.515 sec/step)
I0404 20:33:44.431244 47978602034560 learning.py:507] global step 3263: loss = 6.2662 (0.511 sec/step)
I0404 20:33:44.947048 47978602034560 learning.py:507] global step 3264: loss = 6.2941 (0.514 sec/step)
I0404 20:33:45.473543 47978602034560 learning.py:507] global step 3265: loss = 5.5601 (0.525 sec/step)
I0404 20:33:45.981189 47978602034560 learning.py:507] global step 3266: loss = 6.6490 (0.506 sec/step)
I0404 20:33:46.517041 47978602034560 learning.py:507] global step 3267: loss = 6.9596 (0.533 sec/step)
I0404 20:33:47.035861 47978602034560 learning.py:507] global step 3268: loss = 5.4390 (0.517 sec/step)
I0404 20:33:47.541595 47978602034560 learning.py:507] global step 3269: loss = 6.8467 (0.504 sec/step)
I0404 20:33:48.071138 47978602034560 learning.py:507] global step 3270: loss = 6.2055 (0.528 sec/step)
I0404 20:33:48.580319 47978602034560 learning.py:507] global step 3271: loss = 6.4084 (0.506 sec/step)
I0404 20:33:49.099923 47978602034560 learning.py:507] global step 3272: loss = 6.2740 (0.518 sec/step)
I0404 20:33:49.631540 47978602034560 learning.py:507] global step 3273: loss = 6.5221 (0.530 sec/step)
I0404 20:33:50.142146 47978602034560 learning.py:507] global step 3274: loss = 6.3445 (0.509 sec/step)
I0404 20:33:50.655089 47978602034560 learning.py:507] global step 3275: loss = 6.9030 (0.511 sec/step)
I0404 20:33:51.158158 47978602034560 learning.py:507] global step 3276: loss = 5.6220 (0.502 sec/step)
I0404 20:33:51.668972 47978602034560 learning.py:507] global step 3277: loss = 6.5969 (0.509 sec/step)
I0404 20:33:52.179556 47978602034560 learning.py:507] global step 3278: loss = 7.0143 (0.509 sec/step)
I0404 20:33:52.723330 47978602034560 learning.py:507] global step 3279: loss = 7.4074 (0.541 sec/step)
I0404 20:33:53.243452 47978602034560 learning.py:507] global step 3280: loss = 6.4866 (0.518 sec/step)
I0404 20:33:53.760097 47978602034560 learning.py:507] global step 3281: loss = 6.8591 (0.515 sec/step)
I0404 20:33:54.273489 47978602034560 learning.py:507] global step 3282: loss = 6.5178 (0.512 sec/step)
I0404 20:33:54.811574 47978602034560 learning.py:507] global step 3283: loss = 5.4761 (0.537 sec/step)
I0404 20:33:55.321507 47978602034560 learning.py:507] global step 3284: loss = 6.1387 (0.508 sec/step)
I0404 20:33:55.849816 47978602034560 learning.py:507] global step 3285: loss = 7.1364 (0.527 sec/step)
I0404 20:33:56.380287 47978602034560 learning.py:507] global step 3286: loss = 5.0070 (0.528 sec/step)
I0404 20:33:56.889829 47978602034560 learning.py:507] global step 3287: loss = 6.6565 (0.508 sec/step)
I0404 20:33:57.400653 47978602034560 learning.py:507] global step 3288: loss = 6.7392 (0.509 sec/step)
I0404 20:33:57.914544 47978602034560 learning.py:507] global step 3289: loss = 4.8950 (0.512 sec/step)
I0404 20:33:58.431059 47978602034560 learning.py:507] global step 3290: loss = 5.7393 (0.515 sec/step)
I0404 20:33:58.958154 47978602034560 learning.py:507] global step 3291: loss = 6.1512 (0.526 sec/step)
I0404 20:33:59.471430 47978602034560 learning.py:507] global step 3292: loss = 5.4371 (0.510 sec/step)
I0404 20:33:59.983517 47978602034560 learning.py:507] global step 3293: loss = 5.4182 (0.511 sec/step)
I0404 20:34:00.498421 47978602034560 learning.py:507] global step 3294: loss = 7.1552 (0.513 sec/step)
I0404 20:34:01.033320 47978602034560 learning.py:507] global step 3295: loss = 6.3380 (0.532 sec/step)
I0404 20:34:01.547230 47978602034560 learning.py:507] global step 3296: loss = 6.0865 (0.512 sec/step)
I0404 20:34:02.060686 47978602034560 learning.py:507] global step 3297: loss = 6.3212 (0.512 sec/step)
I0404 20:34:02.592142 47978602034560 learning.py:507] global step 3298: loss = 6.6506 (0.529 sec/step)
I0404 20:34:03.103258 47978602034560 learning.py:507] global step 3299: loss = 6.5635 (0.510 sec/step)
I0404 20:34:03.616739 47978602034560 learning.py:507] global step 3300: loss = 5.6663 (0.512 sec/step)
I0404 20:34:04.129134 47978602034560 learning.py:507] global step 3301: loss = 5.5875 (0.510 sec/step)
I0404 20:34:04.666814 47978602034560 learning.py:507] global step 3302: loss = 5.5621 (0.536 sec/step)
I0404 20:34:05.186383 47978602034560 learning.py:507] global step 3303: loss = 6.1642 (0.518 sec/step)
I0404 20:34:05.691915 47978602034560 learning.py:507] global step 3304: loss = 6.1245 (0.504 sec/step)
I0404 20:34:06.201264 47978602034560 learning.py:507] global step 3305: loss = 5.7715 (0.508 sec/step)
I0404 20:34:06.712105 47978602034560 learning.py:507] global step 3306: loss = 6.2893 (0.509 sec/step)
I0404 20:34:07.223346 47978602034560 learning.py:507] global step 3307: loss = 6.2669 (0.510 sec/step)
I0404 20:34:07.733022 47978602034560 learning.py:507] global step 3308: loss = 6.0007 (0.508 sec/step)
I0404 20:34:08.253604 47978602034560 learning.py:507] global step 3309: loss = 6.1718 (0.519 sec/step)
I0404 20:34:08.771553 47978602034560 learning.py:507] global step 3310: loss = 6.5995 (0.515 sec/step)
I0404 20:34:09.288254 47978602034560 learning.py:507] global step 3311: loss = 6.5356 (0.514 sec/step)
I0404 20:34:09.830500 47978602034560 learning.py:507] global step 3312: loss = 5.9933 (0.541 sec/step)
I0404 20:34:10.340938 47978602034560 learning.py:507] global step 3313: loss = 5.6289 (0.509 sec/step)
I0404 20:34:10.853669 47978602034560 learning.py:507] global step 3314: loss = 7.6984 (0.510 sec/step)
I0404 20:34:11.401072 47978602034560 learning.py:507] global step 3315: loss = 6.3423 (0.546 sec/step)
I0404 20:34:11.907514 47978602034560 learning.py:507] global step 3316: loss = 6.1466 (0.505 sec/step)
I0404 20:34:12.421334 47978602034560 learning.py:507] global step 3317: loss = 6.2342 (0.511 sec/step)
I0404 20:34:12.927639 47978602034560 learning.py:507] global step 3318: loss = 6.9974 (0.505 sec/step)
I0404 20:34:13.439255 47978602034560 learning.py:507] global step 3319: loss = 7.3500 (0.510 sec/step)
I0404 20:34:13.945754 47978602034560 learning.py:507] global step 3320: loss = 6.7428 (0.505 sec/step)
I0404 20:34:14.487777 47978602034560 learning.py:507] global step 3321: loss = 6.0837 (0.539 sec/step)
I0404 20:34:14.998831 47978602034560 learning.py:507] global step 3322: loss = 6.4672 (0.509 sec/step)
I0404 20:34:15.502642 47978602034560 learning.py:507] global step 3323: loss = 7.1951 (0.501 sec/step)
I0404 20:34:16.012026 47978602034560 learning.py:507] global step 3324: loss = 6.4856 (0.508 sec/step)
I0404 20:34:16.522250 47978602034560 learning.py:507] global step 3325: loss = 7.0991 (0.508 sec/step)
I0404 20:34:17.029199 47978602034560 learning.py:507] global step 3326: loss = 5.6560 (0.505 sec/step)
I0404 20:34:17.551304 47978602034560 learning.py:507] global step 3327: loss = 7.2685 (0.519 sec/step)
I0404 20:34:18.057440 47978602034560 learning.py:507] global step 3328: loss = 6.7676 (0.504 sec/step)
I0404 20:34:18.588676 47978602034560 learning.py:507] global step 3329: loss = 5.8961 (0.530 sec/step)
I0404 20:34:19.107884 47978602034560 learning.py:507] global step 3330: loss = 5.4735 (0.516 sec/step)
I0404 20:34:19.621177 47978602034560 learning.py:507] global step 3331: loss = 6.5774 (0.510 sec/step)
I0404 20:34:20.155425 47978602034560 learning.py:507] global step 3332: loss = 6.6700 (0.531 sec/step)
I0404 20:34:20.688020 47978602034560 learning.py:507] global step 3333: loss = 5.1498 (0.531 sec/step)
I0404 20:34:21.193258 47978602034560 learning.py:507] global step 3334: loss = 6.1009 (0.504 sec/step)
I0404 20:34:21.696233 47978602034560 learning.py:507] global step 3335: loss = 5.6988 (0.501 sec/step)
I0404 20:34:22.207495 47978602034560 learning.py:507] global step 3336: loss = 5.9518 (0.508 sec/step)
I0404 20:34:22.742475 47978602034560 learning.py:507] global step 3337: loss = 6.6429 (0.532 sec/step)
I0404 20:34:23.255308 47978602034560 learning.py:507] global step 3338: loss = 6.5044 (0.511 sec/step)
I0404 20:34:23.789327 47978602034560 learning.py:507] global step 3339: loss = 6.1819 (0.532 sec/step)
I0404 20:34:24.300456 47978602034560 learning.py:507] global step 3340: loss = 6.6700 (0.508 sec/step)
I0404 20:34:24.838963 47978602034560 learning.py:507] global step 3341: loss = 7.5659 (0.537 sec/step)
I0404 20:34:25.353610 47978602034560 learning.py:507] global step 3342: loss = 6.5651 (0.513 sec/step)
I0404 20:34:25.866234 47978602034560 learning.py:507] global step 3343: loss = 6.9312 (0.511 sec/step)
I0404 20:34:26.374007 47978602034560 learning.py:507] global step 3344: loss = 7.1734 (0.505 sec/step)
I0404 20:34:26.880091 47978602034560 learning.py:507] global step 3345: loss = 6.3535 (0.503 sec/step)
I0404 20:34:27.386498 47978602034560 learning.py:507] global step 3346: loss = 5.8008 (0.503 sec/step)
I0404 20:34:27.900249 47978602034560 learning.py:507] global step 3347: loss = 7.3411 (0.512 sec/step)
I0404 20:34:28.424569 47978602034560 learning.py:507] global step 3348: loss = 5.6297 (0.523 sec/step)
I0404 20:34:28.956994 47978602034560 learning.py:507] global step 3349: loss = 5.8163 (0.531 sec/step)
I0404 20:34:29.478556 47978602034560 learning.py:507] global step 3350: loss = 5.8078 (0.520 sec/step)
I0404 20:34:29.991406 47978602034560 learning.py:507] global step 3351: loss = 6.5189 (0.510 sec/step)
I0404 20:34:30.498789 47978602034560 learning.py:507] global step 3352: loss = 5.6343 (0.505 sec/step)
I0404 20:34:31.005362 47978602034560 learning.py:507] global step 3353: loss = 6.4897 (0.504 sec/step)
I0404 20:34:31.520970 47978602034560 learning.py:507] global step 3354: loss = 5.8715 (0.514 sec/step)
I0404 20:34:32.048672 47978602034560 learning.py:507] global step 3355: loss = 5.0899 (0.526 sec/step)
I0404 20:34:32.564581 47978602034560 learning.py:507] global step 3356: loss = 6.5820 (0.514 sec/step)
I0404 20:34:33.072957 47978602034560 learning.py:507] global step 3357: loss = 6.7079 (0.505 sec/step)
I0404 20:34:33.587521 47978602034560 learning.py:507] global step 3358: loss = 6.0674 (0.513 sec/step)
I0404 20:34:34.115984 47978602034560 learning.py:507] global step 3359: loss = 5.9901 (0.527 sec/step)
I0404 20:34:34.629840 47978602034560 learning.py:507] global step 3360: loss = 5.9544 (0.512 sec/step)
I0404 20:34:35.142323 47978602034560 learning.py:507] global step 3361: loss = 6.8470 (0.510 sec/step)
I0404 20:34:35.657055 47978602034560 learning.py:507] global step 3362: loss = 6.5923 (0.513 sec/step)
I0404 20:34:36.189029 47978602034560 learning.py:507] global step 3363: loss = 6.5275 (0.530 sec/step)
I0404 20:34:36.730633 47978602034560 learning.py:507] global step 3364: loss = 5.6489 (0.540 sec/step)
I0404 20:34:37.248236 47978602034560 learning.py:507] global step 3365: loss = 6.6920 (0.516 sec/step)
I0404 20:34:37.750925 47978602034560 learning.py:507] global step 3366: loss = 6.0556 (0.501 sec/step)
I0404 20:34:38.286126 47978602034560 learning.py:507] global step 3367: loss = 6.6081 (0.532 sec/step)
I0404 20:34:38.788317 47978602034560 learning.py:507] global step 3368: loss = 6.4855 (0.501 sec/step)
I0404 20:34:39.292452 47978602034560 learning.py:507] global step 3369: loss = 6.9890 (0.503 sec/step)
I0404 20:34:39.806008 47978602034560 learning.py:507] global step 3370: loss = 6.3587 (0.512 sec/step)
I0404 20:34:40.326766 47978602034560 learning.py:507] global step 3371: loss = 6.6093 (0.519 sec/step)
I0404 20:34:40.837612 47978602034560 learning.py:507] global step 3372: loss = 6.3309 (0.508 sec/step)
I0404 20:34:41.345179 47978602034560 learning.py:507] global step 3373: loss = 5.0730 (0.505 sec/step)
I0404 20:34:41.846583 47978602034560 learning.py:507] global step 3374: loss = 5.9739 (0.500 sec/step)
I0404 20:34:42.379106 47978602034560 learning.py:507] global step 3375: loss = 6.4132 (0.530 sec/step)
I0404 20:34:42.891592 47978602034560 learning.py:507] global step 3376: loss = 5.6545 (0.510 sec/step)
I0404 20:34:43.420812 47978602034560 learning.py:507] global step 3377: loss = 6.8752 (0.528 sec/step)
I0404 20:34:43.939006 47978602034560 learning.py:507] global step 3378: loss = 7.0912 (0.517 sec/step)
I0404 20:34:44.453379 47978602034560 learning.py:507] global step 3379: loss = 7.0868 (0.513 sec/step)
I0404 20:34:44.961822 47978602034560 learning.py:507] global step 3380: loss = 6.7504 (0.506 sec/step)
I0404 20:34:45.475697 47978602034560 learning.py:507] global step 3381: loss = 6.1280 (0.512 sec/step)
I0404 20:34:45.978262 47978602034560 learning.py:507] global step 3382: loss = 6.5170 (0.500 sec/step)
I0404 20:34:46.497623 47978602034560 learning.py:507] global step 3383: loss = 5.8885 (0.518 sec/step)
I0404 20:34:47.003960 47978602034560 learning.py:507] global step 3384: loss = 6.2207 (0.504 sec/step)
I0404 20:34:47.518766 47978602034560 learning.py:507] global step 3385: loss = 5.8713 (0.513 sec/step)
I0404 20:34:48.035630 47978602034560 learning.py:507] global step 3386: loss = 5.7311 (0.514 sec/step)
I0404 20:34:48.552653 47978602034560 learning.py:507] global step 3387: loss = 6.6526 (0.514 sec/step)
I0404 20:34:49.074455 47978602034560 learning.py:507] global step 3388: loss = 6.6360 (0.520 sec/step)
I0404 20:34:49.583301 47978602034560 learning.py:507] global step 3389: loss = 6.9098 (0.507 sec/step)
I0404 20:34:50.097691 47978602034560 learning.py:507] global step 3390: loss = 6.0167 (0.513 sec/step)
I0404 20:34:50.611327 47978602034560 learning.py:507] global step 3391: loss = 6.3658 (0.512 sec/step)
I0404 20:34:51.118675 47978602034560 learning.py:507] global step 3392: loss = 5.8524 (0.506 sec/step)
I0404 20:34:51.624510 47978602034560 learning.py:507] global step 3393: loss = 7.5255 (0.504 sec/step)
I0404 20:34:52.133267 47978602034560 learning.py:507] global step 3394: loss = 7.1074 (0.507 sec/step)
I0404 20:34:52.669087 47978602034560 learning.py:507] global step 3395: loss = 6.1725 (0.534 sec/step)
I0404 20:34:53.180678 47978602034560 learning.py:507] global step 3396: loss = 5.8424 (0.510 sec/step)
I0404 20:34:53.703345 47978602034560 learning.py:507] global step 3397: loss = 5.4809 (0.521 sec/step)
I0404 20:34:54.211904 47978602034560 learning.py:507] global step 3398: loss = 7.3547 (0.506 sec/step)
I0404 20:34:54.740902 47978602034560 learning.py:507] global step 3399: loss = 6.4108 (0.527 sec/step)
I0404 20:34:55.255820 47978602034560 learning.py:507] global step 3400: loss = 6.6877 (0.513 sec/step)
I0404 20:34:55.757624 47978602034560 learning.py:507] global step 3401: loss = 6.0782 (0.500 sec/step)
I0404 20:34:56.277294 47978602034560 learning.py:507] global step 3402: loss = 6.5585 (0.518 sec/step)
I0404 20:34:56.785094 47978602034560 learning.py:507] global step 3403: loss = 5.5017 (0.506 sec/step)
I0404 20:34:57.301190 47978602034560 learning.py:507] global step 3404: loss = 6.8608 (0.514 sec/step)
I0404 20:34:57.835399 47978602034560 learning.py:507] global step 3405: loss = 5.8099 (0.533 sec/step)
I0404 20:34:58.343571 47978602034560 learning.py:507] global step 3406: loss = 6.5385 (0.507 sec/step)
I0404 20:34:58.852774 47978602034560 learning.py:507] global step 3407: loss = 7.8382 (0.508 sec/step)
I0404 20:34:59.362874 47978602034560 learning.py:507] global step 3408: loss = 6.4112 (0.509 sec/step)
I0404 20:34:59.865309 47978602034560 learning.py:507] global step 3409: loss = 6.6276 (0.501 sec/step)
I0404 20:35:00.382715 47978602034560 learning.py:507] global step 3410: loss = 7.3219 (0.515 sec/step)
I0404 20:35:00.887765 47978602034560 learning.py:507] global step 3411: loss = 6.4342 (0.502 sec/step)
I0404 20:35:01.408846 47978602034560 learning.py:507] global step 3412: loss = 6.5472 (0.519 sec/step)
I0404 20:35:01.913899 47978602034560 learning.py:507] global step 3413: loss = 6.7058 (0.504 sec/step)
I0404 20:35:02.419809 47978602034560 learning.py:507] global step 3414: loss = 5.9800 (0.504 sec/step)
I0404 20:35:02.929612 47978602034560 learning.py:507] global step 3415: loss = 5.8944 (0.508 sec/step)
I0404 20:35:03.452359 47978602034560 learning.py:507] global step 3416: loss = 6.0657 (0.521 sec/step)
I0404 20:35:03.961940 47978602034560 learning.py:507] global step 3417: loss = 6.6005 (0.507 sec/step)
I0404 20:35:04.477820 47978602034560 learning.py:507] global step 3418: loss = 5.3634 (0.514 sec/step)
I0404 20:35:04.988346 47978602034560 learning.py:507] global step 3419: loss = 6.6972 (0.508 sec/step)
I0404 20:35:05.510392 47978602034560 learning.py:507] global step 3420: loss = 5.9061 (0.519 sec/step)
I0404 20:35:06.018525 47978602034560 learning.py:507] global step 3421: loss = 6.5303 (0.505 sec/step)
I0404 20:35:06.549654 47978602034560 learning.py:507] global step 3422: loss = 6.4873 (0.530 sec/step)
I0404 20:35:07.085557 47978602034560 learning.py:507] global step 3423: loss = 6.1572 (0.534 sec/step)
I0404 20:35:07.594002 47978602034560 learning.py:507] global step 3424: loss = 7.2908 (0.507 sec/step)
I0404 20:35:08.104819 47978602034560 learning.py:507] global step 3425: loss = 6.1881 (0.508 sec/step)
I0404 20:35:08.614992 47978602034560 learning.py:507] global step 3426: loss = 6.1966 (0.509 sec/step)
I0404 20:35:09.123086 47978602034560 learning.py:507] global step 3427: loss = 6.3122 (0.505 sec/step)
I0404 20:35:09.644876 47978602034560 learning.py:507] global step 3428: loss = 6.3548 (0.520 sec/step)
I0404 20:35:10.186788 47978602034560 learning.py:507] global step 3429: loss = 6.0542 (0.540 sec/step)
I0404 20:35:10.723603 47978602034560 learning.py:507] global step 3430: loss = 6.3648 (0.535 sec/step)
I0404 20:35:11.231217 47978602034560 learning.py:507] global step 3431: loss = 7.0887 (0.506 sec/step)
I0404 20:35:11.753168 47978602034560 learning.py:507] global step 3432: loss = 6.0990 (0.520 sec/step)
I0404 20:35:12.270453 47978602034560 learning.py:507] global step 3433: loss = 6.1290 (0.516 sec/step)
I0404 20:35:12.779190 47978602034560 learning.py:507] global step 3434: loss = 5.7941 (0.507 sec/step)
I0404 20:35:13.286803 47978602034560 learning.py:507] global step 3435: loss = 6.7624 (0.506 sec/step)
I0404 20:35:13.812265 47978602034560 learning.py:507] global step 3436: loss = 6.0215 (0.524 sec/step)
I0404 20:35:14.337243 47978602034560 learning.py:507] global step 3437: loss = 6.1651 (0.523 sec/step)
I0404 20:35:14.848095 47978602034560 learning.py:507] global step 3438: loss = 5.5551 (0.509 sec/step)
I0404 20:35:15.356823 47978602034560 learning.py:507] global step 3439: loss = 6.2921 (0.507 sec/step)
I0404 20:35:15.869565 47978602034560 learning.py:507] global step 3440: loss = 5.5477 (0.511 sec/step)
I0404 20:35:16.383373 47978602034560 learning.py:507] global step 3441: loss = 6.8970 (0.512 sec/step)
I0404 20:35:16.636512 47983666177792 supervisor.py:1117] Saving checkpoint to path ../../trainingOutput/model.ckpt
I0404 20:35:17.008630 47978602034560 learning.py:507] global step 3442: loss = 6.2774 (0.511 sec/step)
I0404 20:35:17.301419 47983661975296 supervisor.py:1050] Recording summary at step 3442.
I0404 20:35:17.649511 47978602034560 learning.py:507] global step 3443: loss = 6.6259 (0.621 sec/step)
I0404 20:35:18.200518 47978602034560 learning.py:507] global step 3444: loss = 7.5395 (0.501 sec/step)
I0404 20:35:18.727061 47978602034560 learning.py:507] global step 3445: loss = 6.8966 (0.525 sec/step)
I0404 20:35:19.237392 47978602034560 learning.py:507] global step 3446: loss = 6.4779 (0.507 sec/step)
I0404 20:35:19.742833 47978602034560 learning.py:507] global step 3447: loss = 6.7584 (0.502 sec/step)
I0404 20:35:20.278112 47978602034560 learning.py:507] global step 3448: loss = 5.6407 (0.534 sec/step)
I0404 20:35:20.800021 47978602034560 learning.py:507] global step 3449: loss = 5.7954 (0.520 sec/step)
I0404 20:35:21.300344 47978602034560 learning.py:507] global step 3450: loss = 7.3969 (0.499 sec/step)
I0404 20:35:21.814029 47978602034560 learning.py:507] global step 3451: loss = 5.9688 (0.512 sec/step)
I0404 20:35:22.319250 47978602034560 learning.py:507] global step 3452: loss = 6.0072 (0.502 sec/step)
I0404 20:35:22.856879 47978602034560 learning.py:507] global step 3453: loss = 7.0660 (0.536 sec/step)
I0404 20:35:23.392408 47978602034560 learning.py:507] global step 3454: loss = 6.3660 (0.534 sec/step)
I0404 20:35:23.916516 47978602034560 learning.py:507] global step 3455: loss = 5.7797 (0.522 sec/step)
I0404 20:35:24.461905 47978602034560 learning.py:507] global step 3456: loss = 6.4775 (0.544 sec/step)
I0404 20:35:24.968496 47978602034560 learning.py:507] global step 3457: loss = 7.3504 (0.505 sec/step)
I0404 20:35:25.470124 47978602034560 learning.py:507] global step 3458: loss = 5.2968 (0.500 sec/step)
I0404 20:35:25.985247 47978602034560 learning.py:507] global step 3459: loss = 5.8732 (0.513 sec/step)
I0404 20:35:26.514087 47978602034560 learning.py:507] global step 3460: loss = 7.3903 (0.527 sec/step)
I0404 20:35:27.022853 47978602034560 learning.py:507] global step 3461: loss = 8.5937 (0.506 sec/step)
I0404 20:35:27.531383 47978602034560 learning.py:507] global step 3462: loss = 6.2389 (0.506 sec/step)
I0404 20:35:28.037925 47978602034560 learning.py:507] global step 3463: loss = 5.9640 (0.505 sec/step)
I0404 20:35:28.547229 47978602034560 learning.py:507] global step 3464: loss = 6.4127 (0.508 sec/step)
I0404 20:35:29.056418 47978602034560 learning.py:507] global step 3465: loss = 6.6746 (0.508 sec/step)
I0404 20:35:29.577382 47978602034560 learning.py:507] global step 3466: loss = 6.0075 (0.519 sec/step)
I0404 20:35:30.086258 47978602034560 learning.py:507] global step 3467: loss = 5.8038 (0.507 sec/step)
I0404 20:35:30.594295 47978602034560 learning.py:507] global step 3468: loss = 6.5621 (0.507 sec/step)
I0404 20:35:31.132232 47978602034560 learning.py:507] global step 3469: loss = 6.2718 (0.536 sec/step)
I0404 20:35:31.640976 47978602034560 learning.py:507] global step 3470: loss = 6.0791 (0.507 sec/step)
I0404 20:35:32.155491 47978602034560 learning.py:507] global step 3471: loss = 6.3321 (0.512 sec/step)
I0404 20:35:32.665669 47978602034560 learning.py:507] global step 3472: loss = 5.8103 (0.509 sec/step)
I0404 20:35:33.183824 47978602034560 learning.py:507] global step 3473: loss = 6.7962 (0.517 sec/step)
I0404 20:35:33.717613 47978602034560 learning.py:507] global step 3474: loss = 6.1241 (0.532 sec/step)
I0404 20:35:34.231944 47978602034560 learning.py:507] global step 3475: loss = 6.7600 (0.513 sec/step)
I0404 20:35:34.761212 47978602034560 learning.py:507] global step 3476: loss = 6.8789 (0.526 sec/step)
I0404 20:35:35.265509 47978602034560 learning.py:507] global step 3477: loss = 7.2563 (0.503 sec/step)
I0404 20:35:35.778638 47978602034560 learning.py:507] global step 3478: loss = 6.7056 (0.511 sec/step)
I0404 20:35:36.293243 47978602034560 learning.py:507] global step 3479: loss = 5.7375 (0.512 sec/step)
I0404 20:35:36.804849 47978602034560 learning.py:507] global step 3480: loss = 6.1060 (0.510 sec/step)
I0404 20:35:37.336483 47978602034560 learning.py:507] global step 3481: loss = 5.8090 (0.530 sec/step)
I0404 20:35:37.856882 47978602034560 learning.py:507] global step 3482: loss = 6.0173 (0.519 sec/step)
I0404 20:35:38.393182 47978602034560 learning.py:507] global step 3483: loss = 5.8819 (0.533 sec/step)
I0404 20:35:38.893416 47978602034560 learning.py:507] global step 3484: loss = 6.3108 (0.497 sec/step)
I0404 20:35:39.400357 47978602034560 learning.py:507] global step 3485: loss = 6.7996 (0.504 sec/step)
I0404 20:35:39.917376 47978602034560 learning.py:507] global step 3486: loss = 5.3618 (0.515 sec/step)
I0404 20:35:40.433871 47978602034560 learning.py:507] global step 3487: loss = 6.5457 (0.514 sec/step)
I0404 20:35:40.971148 47978602034560 learning.py:507] global step 3488: loss = 5.9443 (0.534 sec/step)
I0404 20:35:41.490617 47978602034560 learning.py:507] global step 3489: loss = 7.0177 (0.518 sec/step)
I0404 20:35:42.007799 47978602034560 learning.py:507] global step 3490: loss = 6.6276 (0.516 sec/step)
I0404 20:35:42.513034 47978602034560 learning.py:507] global step 3491: loss = 5.8611 (0.504 sec/step)
I0404 20:35:43.047783 47978602034560 learning.py:507] global step 3492: loss = 7.1118 (0.533 sec/step)
I0404 20:35:43.561551 47978602034560 learning.py:507] global step 3493: loss = 5.7526 (0.512 sec/step)
I0404 20:35:44.074590 47978602034560 learning.py:507] global step 3494: loss = 6.1863 (0.511 sec/step)
I0404 20:35:44.588117 47978602034560 learning.py:507] global step 3495: loss = 7.5231 (0.511 sec/step)
I0404 20:35:45.116353 47978602034560 learning.py:507] global step 3496: loss = 5.0171 (0.527 sec/step)
I0404 20:35:45.653267 47978602034560 learning.py:507] global step 3497: loss = 6.3840 (0.535 sec/step)
I0404 20:35:46.164683 47978602034560 learning.py:507] global step 3498: loss = 6.3881 (0.510 sec/step)
I0404 20:35:46.709137 47978602034560 learning.py:507] global step 3499: loss = 6.1946 (0.543 sec/step)
I0404 20:35:47.229636 47978602034560 learning.py:507] global step 3500: loss = 6.0626 (0.518 sec/step)
I0404 20:35:47.764806 47978602034560 learning.py:507] global step 3501: loss = 6.7599 (0.534 sec/step)
I0404 20:35:48.271037 47978602034560 learning.py:507] global step 3502: loss = 6.4211 (0.505 sec/step)
I0404 20:35:48.802327 47978602034560 learning.py:507] global step 3503: loss = 6.8810 (0.530 sec/step)
I0404 20:35:49.322382 47978602034560 learning.py:507] global step 3504: loss = 6.5296 (0.518 sec/step)
I0404 20:35:49.834544 47978602034560 learning.py:507] global step 3505: loss = 6.2743 (0.511 sec/step)
I0404 20:35:50.354468 47978602034560 learning.py:507] global step 3506: loss = 5.9745 (0.518 sec/step)
I0404 20:35:50.861591 47978602034560 learning.py:507] global step 3507: loss = 6.7036 (0.504 sec/step)
I0404 20:35:51.379085 47978602034560 learning.py:507] global step 3508: loss = 5.6099 (0.516 sec/step)
I0404 20:35:51.913888 47978602034560 learning.py:507] global step 3509: loss = 5.7329 (0.532 sec/step)
I0404 20:35:52.418458 47978602034560 learning.py:507] global step 3510: loss = 7.4696 (0.502 sec/step)
I0404 20:35:52.926634 47978602034560 learning.py:507] global step 3511: loss = 5.7576 (0.507 sec/step)
I0404 20:35:53.428198 47978602034560 learning.py:507] global step 3512: loss = 5.6279 (0.499 sec/step)
I0404 20:35:53.934620 47978602034560 learning.py:507] global step 3513: loss = 5.6481 (0.505 sec/step)
I0404 20:35:54.440321 47978602034560 learning.py:507] global step 3514: loss = 6.2935 (0.504 sec/step)
I0404 20:35:54.954488 47978602034560 learning.py:507] global step 3515: loss = 6.2317 (0.513 sec/step)
I0404 20:35:55.465113 47978602034560 learning.py:507] global step 3516: loss = 5.9081 (0.508 sec/step)
I0404 20:35:55.996330 47978602034560 learning.py:507] global step 3517: loss = 6.0667 (0.530 sec/step)
I0404 20:35:56.494030 47978602034560 learning.py:507] global step 3518: loss = 6.0282 (0.496 sec/step)
I0404 20:35:57.005352 47978602034560 learning.py:507] global step 3519: loss = 5.4598 (0.510 sec/step)
I0404 20:35:57.516051 47978602034560 learning.py:507] global step 3520: loss = 6.2911 (0.509 sec/step)
I0404 20:35:58.034557 47978602034560 learning.py:507] global step 3521: loss = 6.5456 (0.517 sec/step)
I0404 20:35:58.542113 47978602034560 learning.py:507] global step 3522: loss = 6.2561 (0.506 sec/step)
I0404 20:35:59.053068 47978602034560 learning.py:507] global step 3523: loss = 7.1570 (0.509 sec/step)
I0404 20:35:59.568334 47978602034560 learning.py:507] global step 3524: loss = 5.5703 (0.514 sec/step)
I0404 20:36:00.073358 47978602034560 learning.py:507] global step 3525: loss = 6.1879 (0.503 sec/step)
I0404 20:36:00.606438 47978602034560 learning.py:507] global step 3526: loss = 5.3022 (0.530 sec/step)
I0404 20:36:01.141127 47978602034560 learning.py:507] global step 3527: loss = 6.1584 (0.533 sec/step)
I0404 20:36:01.647234 47978602034560 learning.py:507] global step 3528: loss = 5.9644 (0.505 sec/step)
I0404 20:36:02.161919 47978602034560 learning.py:507] global step 3529: loss = 5.5857 (0.513 sec/step)
I0404 20:36:02.661050 47978602034560 learning.py:507] global step 3530: loss = 5.8400 (0.498 sec/step)
I0404 20:36:03.183837 47978602034560 learning.py:507] global step 3531: loss = 6.0876 (0.521 sec/step)
I0404 20:36:03.695650 47978602034560 learning.py:507] global step 3532: loss = 6.1179 (0.510 sec/step)
I0404 20:36:04.204063 47978602034560 learning.py:507] global step 3533: loss = 6.3604 (0.506 sec/step)
I0404 20:36:04.720160 47978602034560 learning.py:507] global step 3534: loss = 7.2385 (0.515 sec/step)
I0404 20:36:05.227010 47978602034560 learning.py:507] global step 3535: loss = 5.9890 (0.505 sec/step)
I0404 20:36:05.745409 47978602034560 learning.py:507] global step 3536: loss = 5.9797 (0.516 sec/step)
I0404 20:36:06.255656 47978602034560 learning.py:507] global step 3537: loss = 7.4073 (0.507 sec/step)
I0404 20:36:06.757524 47978602034560 learning.py:507] global step 3538: loss = 6.5756 (0.500 sec/step)
I0404 20:36:07.280786 47978602034560 learning.py:507] global step 3539: loss = 5.5961 (0.522 sec/step)
I0404 20:36:07.797229 47978602034560 learning.py:507] global step 3540: loss = 6.3763 (0.515 sec/step)
I0404 20:36:08.308619 47978602034560 learning.py:507] global step 3541: loss = 6.0208 (0.509 sec/step)
I0404 20:36:08.836109 47978602034560 learning.py:507] global step 3542: loss = 5.5721 (0.525 sec/step)
I0404 20:36:09.358010 47978602034560 learning.py:507] global step 3543: loss = 5.2881 (0.520 sec/step)
I0404 20:36:09.856734 47978602034560 learning.py:507] global step 3544: loss = 6.9656 (0.496 sec/step)
I0404 20:36:10.378208 47978602034560 learning.py:507] global step 3545: loss = 7.0302 (0.520 sec/step)
I0404 20:36:10.879974 47978602034560 learning.py:507] global step 3546: loss = 7.1322 (0.499 sec/step)
I0404 20:36:11.391906 47978602034560 learning.py:507] global step 3547: loss = 6.2001 (0.510 sec/step)
I0404 20:36:11.916290 47978602034560 learning.py:507] global step 3548: loss = 6.5522 (0.523 sec/step)
I0404 20:36:12.421893 47978602034560 learning.py:507] global step 3549: loss = 5.4285 (0.504 sec/step)
I0404 20:36:12.937087 47978602034560 learning.py:507] global step 3550: loss = 6.5946 (0.512 sec/step)
I0404 20:36:13.446596 47978602034560 learning.py:507] global step 3551: loss = 7.1982 (0.508 sec/step)
I0404 20:36:13.957921 47978602034560 learning.py:507] global step 3552: loss = 7.2355 (0.508 sec/step)
I0404 20:36:14.476872 47978602034560 learning.py:507] global step 3553: loss = 5.9675 (0.517 sec/step)
I0404 20:36:14.989606 47978602034560 learning.py:507] global step 3554: loss = 6.0896 (0.511 sec/step)
I0404 20:36:15.492427 47978602034560 learning.py:507] global step 3555: loss = 6.5647 (0.501 sec/step)
I0404 20:36:15.998027 47978602034560 learning.py:507] global step 3556: loss = 6.1894 (0.504 sec/step)
I0404 20:36:16.515003 47978602034560 learning.py:507] global step 3557: loss = 6.3924 (0.514 sec/step)
I0404 20:36:17.024062 47978602034560 learning.py:507] global step 3558: loss = 5.8779 (0.508 sec/step)
I0404 20:36:17.533619 47978602034560 learning.py:507] global step 3559: loss = 5.8449 (0.508 sec/step)
I0404 20:36:18.039558 47978602034560 learning.py:507] global step 3560: loss = 6.6529 (0.504 sec/step)
I0404 20:36:18.545249 47978602034560 learning.py:507] global step 3561: loss = 5.9500 (0.504 sec/step)
I0404 20:36:19.055657 47978602034560 learning.py:507] global step 3562: loss = 5.4502 (0.509 sec/step)
I0404 20:36:19.595178 47978602034560 learning.py:507] global step 3563: loss = 6.1865 (0.538 sec/step)
I0404 20:36:20.098366 47978602034560 learning.py:507] global step 3564: loss = 6.2007 (0.502 sec/step)
I0404 20:36:20.626834 47978602034560 learning.py:507] global step 3565: loss = 6.5700 (0.526 sec/step)
I0404 20:36:21.156733 47978602034560 learning.py:507] global step 3566: loss = 6.3986 (0.527 sec/step)
I0404 20:36:21.659719 47978602034560 learning.py:507] global step 3567: loss = 6.6996 (0.501 sec/step)
I0404 20:36:22.184046 47978602034560 learning.py:507] global step 3568: loss = 5.8745 (0.523 sec/step)
I0404 20:36:22.689934 47978602034560 learning.py:507] global step 3569: loss = 6.6956 (0.504 sec/step)
I0404 20:36:23.223595 47978602034560 learning.py:507] global step 3570: loss = 6.2216 (0.532 sec/step)
I0404 20:36:23.753611 47978602034560 learning.py:507] global step 3571: loss = 6.9755 (0.527 sec/step)
I0404 20:36:24.275941 47978602034560 learning.py:507] global step 3572: loss = 4.9869 (0.519 sec/step)
I0404 20:36:24.797455 47978602034560 learning.py:507] global step 3573: loss = 6.3920 (0.520 sec/step)
I0404 20:36:25.303896 47978602034560 learning.py:507] global step 3574: loss = 7.3939 (0.505 sec/step)
I0404 20:36:25.817732 47978602034560 learning.py:507] global step 3575: loss = 6.0702 (0.512 sec/step)
I0404 20:36:26.325987 47978602034560 learning.py:507] global step 3576: loss = 5.8961 (0.507 sec/step)
I0404 20:36:26.830444 47978602034560 learning.py:507] global step 3577: loss = 5.9121 (0.503 sec/step)
I0404 20:36:27.333383 47978602034560 learning.py:507] global step 3578: loss = 6.5420 (0.501 sec/step)
I0404 20:36:27.873187 47978602034560 learning.py:507] global step 3579: loss = 6.7620 (0.538 sec/step)
I0404 20:36:28.370421 47978602034560 learning.py:507] global step 3580: loss = 6.7486 (0.496 sec/step)
I0404 20:36:28.898281 47978602034560 learning.py:507] global step 3581: loss = 6.9941 (0.526 sec/step)
I0404 20:36:29.397220 47978602034560 learning.py:507] global step 3582: loss = 6.8462 (0.497 sec/step)
I0404 20:36:29.909665 47978602034560 learning.py:507] global step 3583: loss = 7.1265 (0.511 sec/step)
I0404 20:36:30.426774 47978602034560 learning.py:507] global step 3584: loss = 6.7218 (0.515 sec/step)
I0404 20:36:30.933671 47978602034560 learning.py:507] global step 3585: loss = 6.0856 (0.505 sec/step)
I0404 20:36:31.451210 47978602034560 learning.py:507] global step 3586: loss = 6.1584 (0.516 sec/step)
I0404 20:36:31.968296 47978602034560 learning.py:507] global step 3587: loss = 6.5928 (0.516 sec/step)
I0404 20:36:32.512135 47978602034560 learning.py:507] global step 3588: loss = 6.1599 (0.542 sec/step)
I0404 20:36:33.038100 47978602034560 learning.py:507] global step 3589: loss = 5.8411 (0.524 sec/step)
I0404 20:36:33.555119 47978602034560 learning.py:507] global step 3590: loss = 6.1224 (0.515 sec/step)
I0404 20:36:34.064685 47978602034560 learning.py:507] global step 3591: loss = 6.6560 (0.507 sec/step)
I0404 20:36:34.586372 47978602034560 learning.py:507] global step 3592: loss = 6.5626 (0.520 sec/step)
I0404 20:36:35.099193 47978602034560 learning.py:507] global step 3593: loss = 5.9712 (0.511 sec/step)
I0404 20:36:35.602715 47978602034560 learning.py:507] global step 3594: loss = 6.5550 (0.502 sec/step)
I0404 20:36:36.119688 47978602034560 learning.py:507] global step 3595: loss = 5.8856 (0.515 sec/step)
I0404 20:36:36.632371 47978602034560 learning.py:507] global step 3596: loss = 7.0167 (0.510 sec/step)
I0404 20:36:37.136723 47978602034560 learning.py:507] global step 3597: loss = 5.6876 (0.501 sec/step)
I0404 20:36:37.645548 47978602034560 learning.py:507] global step 3598: loss = 5.3162 (0.506 sec/step)
I0404 20:36:38.162514 47978602034560 learning.py:507] global step 3599: loss = 5.7303 (0.514 sec/step)
I0404 20:36:38.681329 47978602034560 learning.py:507] global step 3600: loss = 6.6808 (0.517 sec/step)
I0404 20:36:39.214489 47978602034560 learning.py:507] global step 3601: loss = 6.9877 (0.532 sec/step)
I0404 20:36:39.724782 47978602034560 learning.py:507] global step 3602: loss = 5.8190 (0.509 sec/step)
I0404 20:36:40.231255 47978602034560 learning.py:507] global step 3603: loss = 5.9685 (0.504 sec/step)
I0404 20:36:40.764257 47978602034560 learning.py:507] global step 3604: loss = 4.7742 (0.531 sec/step)
I0404 20:36:41.303586 47978602034560 learning.py:507] global step 3605: loss = 6.1096 (0.538 sec/step)
I0404 20:36:41.814961 47978602034560 learning.py:507] global step 3606: loss = 5.2126 (0.508 sec/step)
I0404 20:36:42.320482 47978602034560 learning.py:507] global step 3607: loss = 5.8984 (0.503 sec/step)
I0404 20:36:42.837408 47978602034560 learning.py:507] global step 3608: loss = 6.1328 (0.515 sec/step)
I0404 20:36:43.366790 47978602034560 learning.py:507] global step 3609: loss = 6.4334 (0.528 sec/step)
I0404 20:36:43.883084 47978602034560 learning.py:507] global step 3610: loss = 6.6149 (0.515 sec/step)
I0404 20:36:44.395142 47978602034560 learning.py:507] global step 3611: loss = 6.4636 (0.510 sec/step)
I0404 20:36:44.924892 47978602034560 learning.py:507] global step 3612: loss = 4.9317 (0.528 sec/step)
I0404 20:36:45.435717 47978602034560 learning.py:507] global step 3613: loss = 5.5341 (0.508 sec/step)
I0404 20:36:45.945807 47978602034560 learning.py:507] global step 3614: loss = 7.4031 (0.507 sec/step)
I0404 20:36:46.480809 47978602034560 learning.py:507] global step 3615: loss = 7.0153 (0.533 sec/step)
I0404 20:36:46.993220 47978602034560 learning.py:507] global step 3616: loss = 6.4260 (0.510 sec/step)
I0404 20:36:47.496389 47978602034560 learning.py:507] global step 3617: loss = 5.7243 (0.502 sec/step)
I0404 20:36:48.027095 47978602034560 learning.py:507] global step 3618: loss = 6.2364 (0.529 sec/step)
I0404 20:36:48.543677 47978602034560 learning.py:507] global step 3619: loss = 6.7260 (0.514 sec/step)
I0404 20:36:49.051200 47978602034560 learning.py:507] global step 3620: loss = 6.8755 (0.506 sec/step)
I0404 20:36:49.587803 47978602034560 learning.py:507] global step 3621: loss = 6.3810 (0.534 sec/step)
I0404 20:36:50.110451 47978602034560 learning.py:507] global step 3622: loss = 5.2740 (0.521 sec/step)
I0404 20:36:50.620228 47978602034560 learning.py:507] global step 3623: loss = 6.2448 (0.507 sec/step)
I0404 20:36:51.131189 47978602034560 learning.py:507] global step 3624: loss = 5.4024 (0.509 sec/step)
I0404 20:36:51.635663 47978602034560 learning.py:507] global step 3625: loss = 7.3740 (0.503 sec/step)
I0404 20:36:52.170969 47978602034560 learning.py:507] global step 3626: loss = 5.8699 (0.534 sec/step)
I0404 20:36:52.676757 47978602034560 learning.py:507] global step 3627: loss = 5.7536 (0.504 sec/step)
I0404 20:36:53.182949 47978602034560 learning.py:507] global step 3628: loss = 5.7189 (0.505 sec/step)
I0404 20:36:53.698911 47978602034560 learning.py:507] global step 3629: loss = 6.2677 (0.514 sec/step)
I0404 20:36:54.228267 47978602034560 learning.py:507] global step 3630: loss = 6.1647 (0.528 sec/step)
I0404 20:36:54.743687 47978602034560 learning.py:507] global step 3631: loss = 6.1118 (0.513 sec/step)
I0404 20:36:55.258954 47978602034560 learning.py:507] global step 3632: loss = 5.7831 (0.514 sec/step)
I0404 20:36:55.777467 47978602034560 learning.py:507] global step 3633: loss = 6.3509 (0.517 sec/step)
I0404 20:36:56.295812 47978602034560 learning.py:507] global step 3634: loss = 6.5529 (0.515 sec/step)
I0404 20:36:56.812045 47978602034560 learning.py:507] global step 3635: loss = 6.8136 (0.515 sec/step)
I0404 20:36:57.328283 47978602034560 learning.py:507] global step 3636: loss = 6.1745 (0.515 sec/step)
I0404 20:36:57.842769 47978602034560 learning.py:507] global step 3637: loss = 5.8761 (0.511 sec/step)
I0404 20:36:58.354325 47978602034560 learning.py:507] global step 3638: loss = 6.6914 (0.508 sec/step)
I0404 20:36:58.875235 47978602034560 learning.py:507] global step 3639: loss = 5.9183 (0.519 sec/step)
I0404 20:36:59.372927 47978602034560 learning.py:507] global step 3640: loss = 6.3885 (0.496 sec/step)
I0404 20:36:59.886198 47978602034560 learning.py:507] global step 3641: loss = 6.6748 (0.512 sec/step)
I0404 20:37:00.393755 47978602034560 learning.py:507] global step 3642: loss = 7.4193 (0.506 sec/step)
I0404 20:37:00.903282 47978602034560 learning.py:507] global step 3643: loss = 5.8010 (0.508 sec/step)
I0404 20:37:01.407263 47978602034560 learning.py:507] global step 3644: loss = 7.2179 (0.502 sec/step)
I0404 20:37:01.943629 47978602034560 learning.py:507] global step 3645: loss = 6.3577 (0.535 sec/step)
I0404 20:37:02.454112 47978602034560 learning.py:507] global step 3646: loss = 7.7727 (0.508 sec/step)
I0404 20:37:02.995715 47978602034560 learning.py:507] global step 3647: loss = 6.6262 (0.540 sec/step)
I0404 20:37:03.505091 47978602034560 learning.py:507] global step 3648: loss = 7.0645 (0.508 sec/step)
I0404 20:37:04.023895 47978602034560 learning.py:507] global step 3649: loss = 7.7301 (0.517 sec/step)
I0404 20:37:04.550439 47978602034560 learning.py:507] global step 3650: loss = 6.5604 (0.524 sec/step)
I0404 20:37:05.062788 47978602034560 learning.py:507] global step 3651: loss = 6.6962 (0.511 sec/step)
I0404 20:37:05.581915 47978602034560 learning.py:507] global step 3652: loss = 6.8804 (0.518 sec/step)
I0404 20:37:06.100423 47978602034560 learning.py:507] global step 3653: loss = 6.7638 (0.516 sec/step)
I0404 20:37:06.602729 47978602034560 learning.py:507] global step 3654: loss = 5.7262 (0.501 sec/step)
I0404 20:37:07.114616 47978602034560 learning.py:507] global step 3655: loss = 5.5957 (0.510 sec/step)
I0404 20:37:07.645588 47978602034560 learning.py:507] global step 3656: loss = 6.2000 (0.529 sec/step)
I0404 20:37:08.158036 47978602034560 learning.py:507] global step 3657: loss = 5.4242 (0.511 sec/step)
I0404 20:37:08.687840 47978602034560 learning.py:507] global step 3658: loss = 8.0068 (0.528 sec/step)
I0404 20:37:09.197517 47978602034560 learning.py:507] global step 3659: loss = 7.4455 (0.508 sec/step)
I0404 20:37:09.729681 47978602034560 learning.py:507] global step 3660: loss = 6.4363 (0.531 sec/step)
I0404 20:37:10.229377 47978602034560 learning.py:507] global step 3661: loss = 6.7373 (0.497 sec/step)
I0404 20:37:10.734386 47978602034560 learning.py:507] global step 3662: loss = 7.2335 (0.502 sec/step)
I0404 20:37:11.238060 47978602034560 learning.py:507] global step 3663: loss = 6.9375 (0.502 sec/step)
I0404 20:37:11.766256 47978602034560 learning.py:507] global step 3664: loss = 6.8186 (0.527 sec/step)
I0404 20:37:12.285692 47978602034560 learning.py:507] global step 3665: loss = 6.0781 (0.518 sec/step)
I0404 20:37:12.800466 47978602034560 learning.py:507] global step 3666: loss = 6.7072 (0.513 sec/step)
I0404 20:37:13.302135 47978602034560 learning.py:507] global step 3667: loss = 5.7878 (0.500 sec/step)
I0404 20:37:13.809158 47978602034560 learning.py:507] global step 3668: loss = 6.6173 (0.505 sec/step)
I0404 20:37:14.318353 47978602034560 learning.py:507] global step 3669: loss = 6.8228 (0.508 sec/step)
I0404 20:37:14.826446 47978602034560 learning.py:507] global step 3670: loss = 6.1476 (0.505 sec/step)
I0404 20:37:15.358498 47978602034560 learning.py:507] global step 3671: loss = 7.0638 (0.529 sec/step)
I0404 20:37:15.875068 47978602034560 learning.py:507] global step 3672: loss = 6.4140 (0.515 sec/step)
I0404 20:37:16.386052 47978602034560 learning.py:507] global step 3673: loss = 6.2457 (0.509 sec/step)
I0404 20:37:16.898496 47978602034560 learning.py:507] global step 3674: loss = 6.8176 (0.505 sec/step)
I0404 20:37:17.274879 47983661975296 supervisor.py:1050] Recording summary at step 3674.
I0404 20:37:17.604357 47978602034560 learning.py:507] global step 3675: loss = 6.9101 (0.699 sec/step)
I0404 20:37:18.123740 47978602034560 learning.py:507] global step 3676: loss = 5.7966 (0.518 sec/step)
I0404 20:37:18.643037 47978602034560 learning.py:507] global step 3677: loss = 6.4821 (0.518 sec/step)
I0404 20:37:19.167465 47978602034560 learning.py:507] global step 3678: loss = 6.2817 (0.522 sec/step)
I0404 20:37:19.679532 47978602034560 learning.py:507] global step 3679: loss = 6.5490 (0.509 sec/step)
I0404 20:37:20.185652 47978602034560 learning.py:507] global step 3680: loss = 5.2896 (0.505 sec/step)
I0404 20:37:20.696357 47978602034560 learning.py:507] global step 3681: loss = 5.8141 (0.509 sec/step)
I0404 20:37:21.200075 47978602034560 learning.py:507] global step 3682: loss = 6.2915 (0.501 sec/step)
I0404 20:37:21.703922 47978602034560 learning.py:507] global step 3683: loss = 6.2950 (0.502 sec/step)
I0404 20:37:22.231794 47978602034560 learning.py:507] global step 3684: loss = 7.0541 (0.526 sec/step)
I0404 20:37:22.738503 47978602034560 learning.py:507] global step 3685: loss = 8.3767 (0.505 sec/step)
I0404 20:37:23.241372 47978602034560 learning.py:507] global step 3686: loss = 7.0294 (0.501 sec/step)
I0404 20:37:23.746499 47978602034560 learning.py:507] global step 3687: loss = 6.5360 (0.502 sec/step)
I0404 20:37:24.256802 47978602034560 learning.py:507] global step 3688: loss = 5.8653 (0.509 sec/step)
I0404 20:37:24.765515 47978602034560 learning.py:507] global step 3689: loss = 7.2917 (0.506 sec/step)
I0404 20:37:25.269436 47978602034560 learning.py:507] global step 3690: loss = 6.2044 (0.502 sec/step)
I0404 20:37:25.798542 47978602034560 learning.py:507] global step 3691: loss = 6.5458 (0.528 sec/step)
I0404 20:37:26.330362 47978602034560 learning.py:507] global step 3692: loss = 6.7331 (0.530 sec/step)
I0404 20:37:26.856432 47978602034560 learning.py:507] global step 3693: loss = 5.7940 (0.525 sec/step)
I0404 20:37:27.367328 47978602034560 learning.py:507] global step 3694: loss = 6.3441 (0.509 sec/step)
I0404 20:37:27.897966 47978602034560 learning.py:507] global step 3695: loss = 6.6693 (0.529 sec/step)
I0404 20:37:28.437921 47978602034560 learning.py:507] global step 3696: loss = 5.6926 (0.538 sec/step)
I0404 20:37:28.953578 47978602034560 learning.py:507] global step 3697: loss = 6.0614 (0.514 sec/step)
I0404 20:37:29.460010 47978602034560 learning.py:507] global step 3698: loss = 6.0306 (0.504 sec/step)
I0404 20:37:29.972651 47978602034560 learning.py:507] global step 3699: loss = 5.4829 (0.510 sec/step)
I0404 20:37:30.486295 47978602034560 learning.py:507] global step 3700: loss = 5.6720 (0.511 sec/step)
I0404 20:37:30.999994 47978602034560 learning.py:507] global step 3701: loss = 6.0036 (0.511 sec/step)
I0404 20:37:31.511772 47978602034560 learning.py:507] global step 3702: loss = 6.8595 (0.510 sec/step)
I0404 20:37:32.021499 47978602034560 learning.py:507] global step 3703: loss = 6.1727 (0.508 sec/step)
I0404 20:37:32.529302 47978602034560 learning.py:507] global step 3704: loss = 6.5910 (0.506 sec/step)
I0404 20:37:33.042954 47978602034560 learning.py:507] global step 3705: loss = 5.2459 (0.511 sec/step)
I0404 20:37:33.567220 47978602034560 learning.py:507] global step 3706: loss = 6.0582 (0.523 sec/step)
I0404 20:37:34.099482 47978602034560 learning.py:507] global step 3707: loss = 6.5869 (0.529 sec/step)
I0404 20:37:34.611715 47978602034560 learning.py:507] global step 3708: loss = 6.0237 (0.511 sec/step)
I0404 20:37:35.136886 47978602034560 learning.py:507] global step 3709: loss = 6.5460 (0.524 sec/step)
I0404 20:37:35.643673 47978602034560 learning.py:507] global step 3710: loss = 6.7621 (0.504 sec/step)
I0404 20:37:36.151861 47978602034560 learning.py:507] global step 3711: loss = 5.8296 (0.507 sec/step)
I0404 20:37:36.679628 47978602034560 learning.py:507] global step 3712: loss = 5.8022 (0.526 sec/step)
I0404 20:37:37.193307 47978602034560 learning.py:507] global step 3713: loss = 5.2916 (0.512 sec/step)
I0404 20:37:37.702570 47978602034560 learning.py:507] global step 3714: loss = 7.5052 (0.506 sec/step)
I0404 20:37:38.231352 47978602034560 learning.py:507] global step 3715: loss = 7.1317 (0.527 sec/step)
I0404 20:37:38.745901 47978602034560 learning.py:507] global step 3716: loss = 6.2324 (0.513 sec/step)
I0404 20:37:39.288041 47978602034560 learning.py:507] global step 3717: loss = 7.5440 (0.541 sec/step)
I0404 20:37:39.810737 47978602034560 learning.py:507] global step 3718: loss = 6.5817 (0.521 sec/step)
I0404 20:37:40.319376 47978602034560 learning.py:507] global step 3719: loss = 5.7104 (0.507 sec/step)
I0404 20:37:40.835162 47978602034560 learning.py:507] global step 3720: loss = 6.4888 (0.514 sec/step)
I0404 20:37:41.341355 47978602034560 learning.py:507] global step 3721: loss = 6.3124 (0.505 sec/step)
I0404 20:37:41.844440 47978602034560 learning.py:507] global step 3722: loss = 6.4505 (0.501 sec/step)
I0404 20:37:42.354058 47978602034560 learning.py:507] global step 3723: loss = 6.6126 (0.508 sec/step)
I0404 20:37:42.864442 47978602034560 learning.py:507] global step 3724: loss = 5.6150 (0.507 sec/step)
I0404 20:37:43.377395 47978602034560 learning.py:507] global step 3725: loss = 6.7193 (0.511 sec/step)
I0404 20:37:43.921121 47978602034560 learning.py:507] global step 3726: loss = 6.1870 (0.542 sec/step)
I0404 20:37:44.458911 47978602034560 learning.py:507] global step 3727: loss = 6.7446 (0.535 sec/step)
I0404 20:37:44.958176 47978602034560 learning.py:507] global step 3728: loss = 5.6536 (0.498 sec/step)
I0404 20:37:45.467686 47978602034560 learning.py:507] global step 3729: loss = 5.9090 (0.508 sec/step)
I0404 20:37:45.969213 47978602034560 learning.py:507] global step 3730: loss = 7.2392 (0.500 sec/step)
I0404 20:37:46.478955 47978602034560 learning.py:507] global step 3731: loss = 5.4637 (0.507 sec/step)
I0404 20:37:47.010520 47978602034560 learning.py:507] global step 3732: loss = 6.2777 (0.530 sec/step)
I0404 20:37:47.526955 47978602034560 learning.py:507] global step 3733: loss = 7.6595 (0.515 sec/step)
I0404 20:37:48.058980 47978602034560 learning.py:507] global step 3734: loss = 6.3715 (0.531 sec/step)
I0404 20:37:48.565825 47978602034560 learning.py:507] global step 3735: loss = 7.0470 (0.505 sec/step)
I0404 20:37:49.096288 47978602034560 learning.py:507] global step 3736: loss = 6.0916 (0.528 sec/step)
I0404 20:37:49.619121 47978602034560 learning.py:507] global step 3737: loss = 6.2147 (0.520 sec/step)
I0404 20:37:50.127705 47978602034560 learning.py:507] global step 3738: loss = 7.1558 (0.507 sec/step)
I0404 20:37:50.640400 47978602034560 learning.py:507] global step 3739: loss = 7.2532 (0.510 sec/step)
I0404 20:37:51.162754 47978602034560 learning.py:507] global step 3740: loss = 6.3802 (0.519 sec/step)
I0404 20:37:51.679999 47978602034560 learning.py:507] global step 3741: loss = 5.4076 (0.514 sec/step)
I0404 20:37:52.190354 47978602034560 learning.py:507] global step 3742: loss = 6.3531 (0.509 sec/step)
I0404 20:37:52.692787 47978602034560 learning.py:507] global step 3743: loss = 6.6139 (0.501 sec/step)
I0404 20:37:53.194488 47978602034560 learning.py:507] global step 3744: loss = 6.8197 (0.499 sec/step)
I0404 20:37:53.699696 47978602034560 learning.py:507] global step 3745: loss = 7.1110 (0.504 sec/step)
I0404 20:37:54.211345 47978602034560 learning.py:507] global step 3746: loss = 6.4717 (0.509 sec/step)
I0404 20:37:54.725038 47978602034560 learning.py:507] global step 3747: loss = 6.7894 (0.512 sec/step)
I0404 20:37:55.253041 47978602034560 learning.py:507] global step 3748: loss = 6.0508 (0.525 sec/step)
I0404 20:37:55.770264 47978602034560 learning.py:507] global step 3749: loss = 6.3962 (0.516 sec/step)
I0404 20:37:56.281720 47978602034560 learning.py:507] global step 3750: loss = 6.1788 (0.510 sec/step)
I0404 20:37:56.789852 47978602034560 learning.py:507] global step 3751: loss = 5.3774 (0.507 sec/step)
I0404 20:37:57.316911 47978602034560 learning.py:507] global step 3752: loss = 5.8333 (0.525 sec/step)
I0404 20:37:57.822297 47978602034560 learning.py:507] global step 3753: loss = 5.6880 (0.504 sec/step)
I0404 20:37:58.331488 47978602034560 learning.py:507] global step 3754: loss = 5.7153 (0.508 sec/step)
I0404 20:37:58.844856 47978602034560 learning.py:507] global step 3755: loss = 5.0574 (0.510 sec/step)
I0404 20:37:59.356386 47978602034560 learning.py:507] global step 3756: loss = 6.1954 (0.509 sec/step)
I0404 20:37:59.868928 47978602034560 learning.py:507] global step 3757: loss = 6.0811 (0.511 sec/step)
I0404 20:38:00.386711 47978602034560 learning.py:507] global step 3758: loss = 7.1190 (0.516 sec/step)
I0404 20:38:00.927982 47978602034560 learning.py:507] global step 3759: loss = 6.1989 (0.540 sec/step)
I0404 20:38:01.433952 47978602034560 learning.py:507] global step 3760: loss = 5.4611 (0.504 sec/step)
I0404 20:38:01.943018 47978602034560 learning.py:507] global step 3761: loss = 6.5732 (0.508 sec/step)
I0404 20:38:02.463056 47978602034560 learning.py:507] global step 3762: loss = 6.7368 (0.518 sec/step)
I0404 20:38:02.991047 47978602034560 learning.py:507] global step 3763: loss = 6.5634 (0.525 sec/step)
I0404 20:38:03.521128 47978602034560 learning.py:507] global step 3764: loss = 6.3043 (0.527 sec/step)
I0404 20:38:04.028088 47978602034560 learning.py:507] global step 3765: loss = 6.4993 (0.504 sec/step)
I0404 20:38:04.535710 47978602034560 learning.py:507] global step 3766: loss = 8.2170 (0.505 sec/step)
I0404 20:38:05.042570 47978602034560 learning.py:507] global step 3767: loss = 6.1863 (0.505 sec/step)
I0404 20:38:05.539581 47978602034560 learning.py:507] global step 3768: loss = 6.5763 (0.496 sec/step)
I0404 20:38:06.042422 47978602034560 learning.py:507] global step 3769: loss = 7.4753 (0.501 sec/step)
I0404 20:38:06.554655 47978602034560 learning.py:507] global step 3770: loss = 6.9539 (0.511 sec/step)
I0404 20:38:07.061885 47978602034560 learning.py:507] global step 3771: loss = 5.8882 (0.506 sec/step)
I0404 20:38:07.584896 47978602034560 learning.py:507] global step 3772: loss = 5.4671 (0.521 sec/step)
I0404 20:38:08.115589 47978602034560 learning.py:507] global step 3773: loss = 6.3138 (0.529 sec/step)
I0404 20:38:08.647926 47978602034560 learning.py:507] global step 3774: loss = 6.2944 (0.531 sec/step)
I0404 20:38:09.156284 47978602034560 learning.py:507] global step 3775: loss = 6.8427 (0.507 sec/step)
I0404 20:38:09.667106 47978602034560 learning.py:507] global step 3776: loss = 6.5929 (0.508 sec/step)
I0404 20:38:10.172551 47978602034560 learning.py:507] global step 3777: loss = 5.8751 (0.504 sec/step)
I0404 20:38:10.678810 47978602034560 learning.py:507] global step 3778: loss = 7.2373 (0.503 sec/step)
I0404 20:38:11.214978 47978602034560 learning.py:507] global step 3779: loss = 7.5286 (0.535 sec/step)
I0404 20:38:11.749984 47978602034560 learning.py:507] global step 3780: loss = 7.9177 (0.533 sec/step)
I0404 20:38:12.279138 47978602034560 learning.py:507] global step 3781: loss = 5.3037 (0.528 sec/step)
I0404 20:38:12.794219 47978602034560 learning.py:507] global step 3782: loss = 6.3478 (0.514 sec/step)
I0404 20:38:13.310685 47978602034560 learning.py:507] global step 3783: loss = 5.7796 (0.514 sec/step)
I0404 20:38:13.840357 47978602034560 learning.py:507] global step 3784: loss = 7.1192 (0.527 sec/step)
I0404 20:38:14.378921 47978602034560 learning.py:507] global step 3785: loss = 6.3417 (0.537 sec/step)
I0404 20:38:14.892349 47978602034560 learning.py:507] global step 3786: loss = 5.9449 (0.512 sec/step)
I0404 20:38:15.411144 47978602034560 learning.py:507] global step 3787: loss = 5.9590 (0.517 sec/step)
I0404 20:38:15.916701 47978602034560 learning.py:507] global step 3788: loss = 6.6652 (0.503 sec/step)
I0404 20:38:16.449079 47978602034560 learning.py:507] global step 3789: loss = 6.1236 (0.531 sec/step)
I0404 20:38:16.961692 47978602034560 learning.py:507] global step 3790: loss = 5.7450 (0.511 sec/step)
I0404 20:38:17.474012 47978602034560 learning.py:507] global step 3791: loss = 5.8700 (0.509 sec/step)
I0404 20:38:17.989943 47978602034560 learning.py:507] global step 3792: loss = 7.8551 (0.514 sec/step)
I0404 20:38:18.530306 47978602034560 learning.py:507] global step 3793: loss = 5.8570 (0.539 sec/step)
I0404 20:38:19.061853 47978602034560 learning.py:507] global step 3794: loss = 5.0569 (0.530 sec/step)
I0404 20:38:19.577024 47978602034560 learning.py:507] global step 3795: loss = 5.7884 (0.514 sec/step)
I0404 20:38:20.090632 47978602034560 learning.py:507] global step 3796: loss = 5.8339 (0.512 sec/step)
I0404 20:38:20.601079 47978602034560 learning.py:507] global step 3797: loss = 5.5565 (0.508 sec/step)
I0404 20:38:21.104751 47978602034560 learning.py:507] global step 3798: loss = 5.9284 (0.502 sec/step)
I0404 20:38:21.605893 47978602034560 learning.py:507] global step 3799: loss = 7.0770 (0.498 sec/step)
I0404 20:38:22.112920 47978602034560 learning.py:507] global step 3800: loss = 5.3669 (0.505 sec/step)
I0404 20:38:22.646369 47978602034560 learning.py:507] global step 3801: loss = 5.9331 (0.532 sec/step)
I0404 20:38:23.155890 47978602034560 learning.py:507] global step 3802: loss = 6.2345 (0.508 sec/step)
I0404 20:38:23.675311 47978602034560 learning.py:507] global step 3803: loss = 5.6949 (0.518 sec/step)
I0404 20:38:24.200990 47978602034560 learning.py:507] global step 3804: loss = 7.2040 (0.524 sec/step)
I0404 20:38:24.721998 47978602034560 learning.py:507] global step 3805: loss = 6.4329 (0.519 sec/step)
I0404 20:38:25.231926 47978602034560 learning.py:507] global step 3806: loss = 5.3622 (0.507 sec/step)
I0404 20:38:25.766346 47978602034560 learning.py:507] global step 3807: loss = 6.5378 (0.533 sec/step)
I0404 20:38:26.284980 47978602034560 learning.py:507] global step 3808: loss = 6.7443 (0.517 sec/step)
I0404 20:38:26.797957 47978602034560 learning.py:507] global step 3809: loss = 6.4312 (0.511 sec/step)
I0404 20:38:27.309957 47978602034560 learning.py:507] global step 3810: loss = 5.8796 (0.509 sec/step)
I0404 20:38:27.816604 47978602034560 learning.py:507] global step 3811: loss = 7.6465 (0.504 sec/step)
I0404 20:38:28.324899 47978602034560 learning.py:507] global step 3812: loss = 5.6144 (0.505 sec/step)
I0404 20:38:28.834251 47978602034560 learning.py:507] global step 3813: loss = 6.9794 (0.506 sec/step)
I0404 20:38:29.355385 47978602034560 learning.py:507] global step 3814: loss = 5.7689 (0.520 sec/step)
I0404 20:38:29.888491 47978602034560 learning.py:507] global step 3815: loss = 5.8439 (0.532 sec/step)
I0404 20:38:30.416518 47978602034560 learning.py:507] global step 3816: loss = 6.4061 (0.526 sec/step)
I0404 20:38:30.924533 47978602034560 learning.py:507] global step 3817: loss = 6.1279 (0.505 sec/step)
I0404 20:38:31.442059 47978602034560 learning.py:507] global step 3818: loss = 6.1350 (0.515 sec/step)
I0404 20:38:31.951360 47978602034560 learning.py:507] global step 3819: loss = 5.8710 (0.508 sec/step)
I0404 20:38:32.493340 47978602034560 learning.py:507] global step 3820: loss = 5.8247 (0.539 sec/step)
I0404 20:38:33.015677 47978602034560 learning.py:507] global step 3821: loss = 6.0149 (0.520 sec/step)
I0404 20:38:33.523690 47978602034560 learning.py:507] global step 3822: loss = 6.0847 (0.505 sec/step)
I0404 20:38:34.039056 47978602034560 learning.py:507] global step 3823: loss = 7.1126 (0.514 sec/step)
I0404 20:38:34.550385 47978602034560 learning.py:507] global step 3824: loss = 6.6822 (0.510 sec/step)
I0404 20:38:35.076355 47978602034560 learning.py:507] global step 3825: loss = 5.9536 (0.524 sec/step)
I0404 20:38:35.586304 47978602034560 learning.py:507] global step 3826: loss = 7.2219 (0.508 sec/step)
I0404 20:38:36.120172 47978602034560 learning.py:507] global step 3827: loss = 6.1311 (0.532 sec/step)
I0404 20:38:36.626095 47978602034560 learning.py:507] global step 3828: loss = 6.2682 (0.503 sec/step)
I0404 20:38:37.133219 47978602034560 learning.py:507] global step 3829: loss = 6.2368 (0.506 sec/step)
I0404 20:38:37.660465 47978602034560 learning.py:507] global step 3830: loss = 5.7527 (0.526 sec/step)
I0404 20:38:38.170145 47978602034560 learning.py:507] global step 3831: loss = 6.0005 (0.508 sec/step)
I0404 20:38:38.673926 47978602034560 learning.py:507] global step 3832: loss = 5.6097 (0.502 sec/step)
I0404 20:38:39.186556 47978602034560 learning.py:507] global step 3833: loss = 5.6388 (0.511 sec/step)
I0404 20:38:39.721749 47978602034560 learning.py:507] global step 3834: loss = 5.7514 (0.534 sec/step)
I0404 20:38:40.239606 47978602034560 learning.py:507] global step 3835: loss = 7.1626 (0.516 sec/step)
I0404 20:38:40.778333 47978602034560 learning.py:507] global step 3836: loss = 6.0224 (0.537 sec/step)
I0404 20:38:41.285202 47978602034560 learning.py:507] global step 3837: loss = 6.8049 (0.505 sec/step)
I0404 20:38:41.795109 47978602034560 learning.py:507] global step 3838: loss = 7.0950 (0.508 sec/step)
I0404 20:38:42.327567 47978602034560 learning.py:507] global step 3839: loss = 6.2590 (0.531 sec/step)
I0404 20:38:42.855939 47978602034560 learning.py:507] global step 3840: loss = 5.2832 (0.525 sec/step)
I0404 20:38:43.370185 47978602034560 learning.py:507] global step 3841: loss = 6.3969 (0.511 sec/step)
I0404 20:38:43.902878 47978602034560 learning.py:507] global step 3842: loss = 5.3527 (0.531 sec/step)
I0404 20:38:44.437760 47978602034560 learning.py:507] global step 3843: loss = 5.5070 (0.532 sec/step)
I0404 20:38:44.946607 47978602034560 learning.py:507] global step 3844: loss = 5.8967 (0.506 sec/step)
I0404 20:38:45.453280 47978602034560 learning.py:507] global step 3845: loss = 6.0429 (0.505 sec/step)
I0404 20:38:45.962179 47978602034560 learning.py:507] global step 3846: loss = 6.9262 (0.507 sec/step)
I0404 20:38:46.496677 47978602034560 learning.py:507] global step 3847: loss = 5.2667 (0.533 sec/step)
I0404 20:38:47.000525 47978602034560 learning.py:507] global step 3848: loss = 5.2464 (0.502 sec/step)
I0404 20:38:47.508595 47978602034560 learning.py:507] global step 3849: loss = 6.6131 (0.506 sec/step)
I0404 20:38:48.021267 47978602034560 learning.py:507] global step 3850: loss = 5.7987 (0.511 sec/step)
I0404 20:38:48.530704 47978602034560 learning.py:507] global step 3851: loss = 5.9541 (0.507 sec/step)
I0404 20:38:49.047062 47978602034560 learning.py:507] global step 3852: loss = 6.5127 (0.515 sec/step)
I0404 20:38:49.557737 47978602034560 learning.py:507] global step 3853: loss = 5.5845 (0.509 sec/step)
I0404 20:38:50.072448 47978602034560 learning.py:507] global step 3854: loss = 6.1408 (0.512 sec/step)
I0404 20:38:50.575004 47978602034560 learning.py:507] global step 3855: loss = 5.2000 (0.501 sec/step)
I0404 20:38:51.100895 47978602034560 learning.py:507] global step 3856: loss = 6.6833 (0.523 sec/step)
I0404 20:38:51.607118 47978602034560 learning.py:507] global step 3857: loss = 6.6474 (0.505 sec/step)
I0404 20:38:52.118785 47978602034560 learning.py:507] global step 3858: loss = 6.3815 (0.509 sec/step)
I0404 20:38:52.631634 47978602034560 learning.py:507] global step 3859: loss = 6.0352 (0.511 sec/step)
I0404 20:38:53.144788 47978602034560 learning.py:507] global step 3860: loss = 6.2123 (0.512 sec/step)
I0404 20:38:53.649285 47978602034560 learning.py:507] global step 3861: loss = 6.3792 (0.502 sec/step)
I0404 20:38:54.178789 47978602034560 learning.py:507] global step 3862: loss = 5.2441 (0.527 sec/step)
I0404 20:38:54.683872 47978602034560 learning.py:507] global step 3863: loss = 6.3850 (0.502 sec/step)
I0404 20:38:55.192577 47978602034560 learning.py:507] global step 3864: loss = 6.0371 (0.506 sec/step)
I0404 20:38:55.706962 47978602034560 learning.py:507] global step 3865: loss = 5.7645 (0.513 sec/step)
I0404 20:38:56.225715 47978602034560 learning.py:507] global step 3866: loss = 6.3812 (0.516 sec/step)
I0404 20:38:56.733592 47978602034560 learning.py:507] global step 3867: loss = 5.3352 (0.506 sec/step)
I0404 20:38:57.250065 47978602034560 learning.py:507] global step 3868: loss = 6.2543 (0.515 sec/step)
I0404 20:38:57.786954 47978602034560 learning.py:507] global step 3869: loss = 6.8457 (0.535 sec/step)
I0404 20:38:58.317524 47978602034560 learning.py:507] global step 3870: loss = 5.3778 (0.529 sec/step)
I0404 20:38:58.835715 47978602034560 learning.py:507] global step 3871: loss = 6.6299 (0.517 sec/step)
I0404 20:38:59.357987 47978602034560 learning.py:507] global step 3872: loss = 5.9562 (0.521 sec/step)
I0404 20:38:59.875883 47978602034560 learning.py:507] global step 3873: loss = 5.9879 (0.516 sec/step)
I0404 20:39:00.381850 47978602034560 learning.py:507] global step 3874: loss = 5.6651 (0.504 sec/step)
I0404 20:39:00.885817 47978602034560 learning.py:507] global step 3875: loss = 6.0291 (0.502 sec/step)
I0404 20:39:01.410042 47978602034560 learning.py:507] global step 3876: loss = 6.5306 (0.521 sec/step)
I0404 20:39:01.945351 47978602034560 learning.py:507] global step 3877: loss = 5.5495 (0.534 sec/step)
I0404 20:39:02.446705 47978602034560 learning.py:507] global step 3878: loss = 5.8906 (0.500 sec/step)
I0404 20:39:02.953984 47978602034560 learning.py:507] global step 3879: loss = 7.8731 (0.504 sec/step)
I0404 20:39:03.468991 47978602034560 learning.py:507] global step 3880: loss = 6.9675 (0.513 sec/step)
I0404 20:39:03.987185 47978602034560 learning.py:507] global step 3881: loss = 6.2131 (0.517 sec/step)
I0404 20:39:04.498973 47978602034560 learning.py:507] global step 3882: loss = 5.7993 (0.510 sec/step)
I0404 20:39:05.006289 47978602034560 learning.py:507] global step 3883: loss = 5.7938 (0.506 sec/step)
I0404 20:39:05.516581 47978602034560 learning.py:507] global step 3884: loss = 6.2405 (0.507 sec/step)
I0404 20:39:06.027665 47978602034560 learning.py:507] global step 3885: loss = 5.7399 (0.510 sec/step)
I0404 20:39:06.559350 47978602034560 learning.py:507] global step 3886: loss = 5.4809 (0.530 sec/step)
I0404 20:39:07.082972 47978602034560 learning.py:507] global step 3887: loss = 6.9874 (0.522 sec/step)
I0404 20:39:07.594731 47978602034560 learning.py:507] global step 3888: loss = 6.2671 (0.510 sec/step)
I0404 20:39:08.106872 47978602034560 learning.py:507] global step 3889: loss = 6.5430 (0.509 sec/step)
I0404 20:39:08.615161 47978602034560 learning.py:507] global step 3890: loss = 6.4223 (0.507 sec/step)
I0404 20:39:09.127979 47978602034560 learning.py:507] global step 3891: loss = 6.3866 (0.510 sec/step)
I0404 20:39:09.639626 47978602034560 learning.py:507] global step 3892: loss = 7.6108 (0.509 sec/step)
I0404 20:39:10.157909 47978602034560 learning.py:507] global step 3893: loss = 6.0581 (0.515 sec/step)
I0404 20:39:10.672147 47978602034560 learning.py:507] global step 3894: loss = 5.4773 (0.513 sec/step)
I0404 20:39:11.193746 47978602034560 learning.py:507] global step 3895: loss = 4.9768 (0.520 sec/step)
I0404 20:39:11.698697 47978602034560 learning.py:507] global step 3896: loss = 6.6924 (0.502 sec/step)
I0404 20:39:12.203459 47978602034560 learning.py:507] global step 3897: loss = 5.5744 (0.503 sec/step)
I0404 20:39:12.733659 47978602034560 learning.py:507] global step 3898: loss = 6.5807 (0.527 sec/step)
I0404 20:39:13.260644 47978602034560 learning.py:507] global step 3899: loss = 6.3665 (0.525 sec/step)
I0404 20:39:13.765279 47978602034560 learning.py:507] global step 3900: loss = 6.7476 (0.502 sec/step)
I0404 20:39:14.301166 47978602034560 learning.py:507] global step 3901: loss = 6.3651 (0.534 sec/step)
I0404 20:39:14.814452 47978602034560 learning.py:507] global step 3902: loss = 6.0475 (0.512 sec/step)
I0404 20:39:15.330974 47978602034560 learning.py:507] global step 3903: loss = 6.0385 (0.515 sec/step)
I0404 20:39:15.847821 47978602034560 learning.py:507] global step 3904: loss = 5.7780 (0.515 sec/step)
I0404 20:39:16.360538 47978602034560 learning.py:507] global step 3905: loss = 6.0470 (0.510 sec/step)
I0404 20:39:16.872191 47978602034560 learning.py:507] global step 3906: loss = 6.1600 (0.495 sec/step)
I0404 20:39:17.567771 47983661975296 supervisor.py:1050] Recording summary at step 3907.
I0404 20:39:17.573374 47978602034560 learning.py:507] global step 3907: loss = 5.7018 (0.698 sec/step)
I0404 20:39:18.074569 47978602034560 learning.py:507] global step 3908: loss = 7.5705 (0.500 sec/step)
I0404 20:39:18.605207 47978602034560 learning.py:507] global step 3909: loss = 5.7806 (0.529 sec/step)
I0404 20:39:19.110220 47978602034560 learning.py:507] global step 3910: loss = 6.1514 (0.502 sec/step)
I0404 20:39:19.620277 47978602034560 learning.py:507] global step 3911: loss = 6.0513 (0.508 sec/step)
I0404 20:39:20.134808 47978602034560 learning.py:507] global step 3912: loss = 6.2740 (0.513 sec/step)
I0404 20:39:20.642421 47978602034560 learning.py:507] global step 3913: loss = 5.3066 (0.506 sec/step)
I0404 20:39:21.144592 47978602034560 learning.py:507] global step 3914: loss = 6.3146 (0.501 sec/step)
I0404 20:39:21.661324 47978602034560 learning.py:507] global step 3915: loss = 6.9277 (0.515 sec/step)
I0404 20:39:22.169484 47978602034560 learning.py:507] global step 3916: loss = 5.3175 (0.506 sec/step)
I0404 20:39:22.684114 47978602034560 learning.py:507] global step 3917: loss = 6.4727 (0.512 sec/step)
I0404 20:39:23.194165 47978602034560 learning.py:507] global step 3918: loss = 6.2245 (0.508 sec/step)
I0404 20:39:23.709308 47978602034560 learning.py:507] global step 3919: loss = 5.6901 (0.512 sec/step)
I0404 20:39:24.227519 47978602034560 learning.py:507] global step 3920: loss = 5.7213 (0.517 sec/step)
I0404 20:39:24.744351 47978602034560 learning.py:507] global step 3921: loss = 6.4119 (0.515 sec/step)
I0404 20:39:25.264555 47978602034560 learning.py:507] global step 3922: loss = 5.7720 (0.519 sec/step)
I0404 20:39:25.776383 47978602034560 learning.py:507] global step 3923: loss = 5.8276 (0.510 sec/step)
I0404 20:39:26.288428 47978602034560 learning.py:507] global step 3924: loss = 5.9868 (0.510 sec/step)
I0404 20:39:26.824547 47978602034560 learning.py:507] global step 3925: loss = 6.6688 (0.535 sec/step)
I0404 20:39:27.332782 47978602034560 learning.py:507] global step 3926: loss = 5.4195 (0.507 sec/step)
I0404 20:39:27.871453 47978602034560 learning.py:507] global step 3927: loss = 5.2845 (0.537 sec/step)
I0404 20:39:28.394672 47978602034560 learning.py:507] global step 3928: loss = 6.5689 (0.522 sec/step)
I0404 20:39:28.902006 47978602034560 learning.py:507] global step 3929: loss = 6.5307 (0.504 sec/step)
I0404 20:39:29.404333 47978602034560 learning.py:507] global step 3930: loss = 5.8644 (0.499 sec/step)
I0404 20:39:29.917253 47978602034560 learning.py:507] global step 3931: loss = 5.4383 (0.510 sec/step)
I0404 20:39:30.447117 47978602034560 learning.py:507] global step 3932: loss = 6.5600 (0.528 sec/step)
I0404 20:39:30.973838 47978602034560 learning.py:507] global step 3933: loss = 5.9273 (0.524 sec/step)
I0404 20:39:31.483989 47978602034560 learning.py:507] global step 3934: loss = 6.4459 (0.509 sec/step)
I0404 20:39:31.992740 47978602034560 learning.py:507] global step 3935: loss = 6.3938 (0.507 sec/step)
I0404 20:39:32.522036 47978602034560 learning.py:507] global step 3936: loss = 6.5566 (0.528 sec/step)
I0404 20:39:33.034579 47978602034560 learning.py:507] global step 3937: loss = 6.7108 (0.511 sec/step)
I0404 20:39:33.539961 47978602034560 learning.py:507] global step 3938: loss = 6.9441 (0.503 sec/step)
I0404 20:39:34.079247 47978602034560 learning.py:507] global step 3939: loss = 7.1923 (0.536 sec/step)
I0404 20:39:34.579090 47978602034560 learning.py:507] global step 3940: loss = 7.2357 (0.497 sec/step)
I0404 20:39:35.087943 47978602034560 learning.py:507] global step 3941: loss = 7.0964 (0.507 sec/step)
I0404 20:39:35.624896 47978602034560 learning.py:507] global step 3942: loss = 5.9801 (0.535 sec/step)
I0404 20:39:36.129915 47978602034560 learning.py:507] global step 3943: loss = 6.7239 (0.502 sec/step)
I0404 20:39:36.638288 47978602034560 learning.py:507] global step 3944: loss = 7.1435 (0.507 sec/step)
I0404 20:39:37.152075 47978602034560 learning.py:507] global step 3945: loss = 6.0135 (0.512 sec/step)
I0404 20:39:37.668627 47978602034560 learning.py:507] global step 3946: loss = 5.9720 (0.515 sec/step)
I0404 20:39:38.180691 47978602034560 learning.py:507] global step 3947: loss = 6.2444 (0.509 sec/step)
I0404 20:39:38.687993 47978602034560 learning.py:507] global step 3948: loss = 6.0608 (0.506 sec/step)
I0404 20:39:39.196808 47978602034560 learning.py:507] global step 3949: loss = 6.9473 (0.507 sec/step)
I0404 20:39:39.704586 47978602034560 learning.py:507] global step 3950: loss = 6.0508 (0.506 sec/step)
I0404 20:39:40.242124 47978602034560 learning.py:507] global step 3951: loss = 6.1620 (0.535 sec/step)
I0404 20:39:40.749285 47978602034560 learning.py:507] global step 3952: loss = 6.3212 (0.504 sec/step)
I0404 20:39:41.257062 47978602034560 learning.py:507] global step 3953: loss = 6.6529 (0.505 sec/step)
I0404 20:39:41.766053 47978602034560 learning.py:507] global step 3954: loss = 6.3490 (0.506 sec/step)
I0404 20:39:42.289632 47978602034560 learning.py:507] global step 3955: loss = 5.6159 (0.522 sec/step)
I0404 20:39:42.790733 47978602034560 learning.py:507] global step 3956: loss = 5.9267 (0.498 sec/step)
I0404 20:39:43.302415 47978602034560 learning.py:507] global step 3957: loss = 7.1903 (0.510 sec/step)
I0404 20:39:43.812829 47978602034560 learning.py:507] global step 3958: loss = 5.9378 (0.509 sec/step)
I0404 20:39:44.318946 47978602034560 learning.py:507] global step 3959: loss = 6.5435 (0.505 sec/step)
I0404 20:39:44.849852 47978602034560 learning.py:507] global step 3960: loss = 6.2098 (0.529 sec/step)
I0404 20:39:45.359856 47978602034560 learning.py:507] global step 3961: loss = 6.1999 (0.508 sec/step)
I0404 20:39:45.873373 47978602034560 learning.py:507] global step 3962: loss = 6.2773 (0.512 sec/step)
I0404 20:39:46.386767 47978602034560 learning.py:507] global step 3963: loss = 6.8016 (0.512 sec/step)
I0404 20:39:46.886575 47978602034560 learning.py:507] global step 3964: loss = 7.4529 (0.498 sec/step)
I0404 20:39:47.427165 47978602034560 learning.py:507] global step 3965: loss = 6.8688 (0.539 sec/step)
I0404 20:39:47.954137 47978602034560 learning.py:507] global step 3966: loss = 6.8924 (0.524 sec/step)
I0404 20:39:48.466303 47978602034560 learning.py:507] global step 3967: loss = 5.6743 (0.511 sec/step)
I0404 20:39:49.005005 47978602034560 learning.py:507] global step 3968: loss = 7.6403 (0.537 sec/step)
I0404 20:39:49.508201 47978602034560 learning.py:507] global step 3969: loss = 6.6267 (0.502 sec/step)
I0404 20:39:50.013983 47978602034560 learning.py:507] global step 3970: loss = 6.1697 (0.504 sec/step)
I0404 20:39:50.545027 47978602034560 learning.py:507] global step 3971: loss = 6.6639 (0.530 sec/step)
I0404 20:39:51.059849 47978602034560 learning.py:507] global step 3972: loss = 6.4914 (0.513 sec/step)
I0404 20:39:51.565212 47978602034560 learning.py:507] global step 3973: loss = 5.8612 (0.504 sec/step)
I0404 20:39:52.077207 47978602034560 learning.py:507] global step 3974: loss = 6.0036 (0.509 sec/step)
I0404 20:39:52.586819 47978602034560 learning.py:507] global step 3975: loss = 6.5512 (0.508 sec/step)
I0404 20:39:53.114448 47978602034560 learning.py:507] global step 3976: loss = 5.9663 (0.526 sec/step)
I0404 20:39:53.634545 47978602034560 learning.py:507] global step 3977: loss = 6.1669 (0.519 sec/step)
I0404 20:39:54.138389 47978602034560 learning.py:507] global step 3978: loss = 5.9858 (0.502 sec/step)
I0404 20:39:54.644182 47978602034560 learning.py:507] global step 3979: loss = 5.3669 (0.503 sec/step)
I0404 20:39:55.151541 47978602034560 learning.py:507] global step 3980: loss = 5.9695 (0.504 sec/step)
I0404 20:39:55.661584 47978602034560 learning.py:507] global step 3981: loss = 5.1207 (0.507 sec/step)
I0404 20:39:56.172182 47978602034560 learning.py:507] global step 3982: loss = 6.5588 (0.509 sec/step)
I0404 20:39:56.684635 47978602034560 learning.py:507] global step 3983: loss = 6.4254 (0.511 sec/step)
I0404 20:39:57.184947 47978602034560 learning.py:507] global step 3984: loss = 5.8189 (0.499 sec/step)
I0404 20:39:57.693401 47978602034560 learning.py:507] global step 3985: loss = 6.2556 (0.507 sec/step)
I0404 20:39:58.210659 47978602034560 learning.py:507] global step 3986: loss = 6.6130 (0.516 sec/step)
I0404 20:39:58.723684 47978602034560 learning.py:507] global step 3987: loss = 6.4265 (0.511 sec/step)
I0404 20:39:59.226669 47978602034560 learning.py:507] global step 3988: loss = 6.7520 (0.500 sec/step)
I0404 20:39:59.736909 47978602034560 learning.py:507] global step 3989: loss = 5.8339 (0.507 sec/step)
I0404 20:40:00.276347 47978602034560 learning.py:507] global step 3990: loss = 5.8567 (0.537 sec/step)
I0404 20:40:00.783398 47978602034560 learning.py:507] global step 3991: loss = 5.3759 (0.506 sec/step)
I0404 20:40:01.286713 47978602034560 learning.py:507] global step 3992: loss = 7.4859 (0.502 sec/step)
I0404 20:40:01.791451 47978602034560 learning.py:507] global step 3993: loss = 6.3660 (0.502 sec/step)
I0404 20:40:02.300917 47978602034560 learning.py:507] global step 3994: loss = 6.3797 (0.507 sec/step)
I0404 20:40:02.830616 47978602034560 learning.py:507] global step 3995: loss = 5.4406 (0.528 sec/step)
I0404 20:40:03.341278 47978602034560 learning.py:507] global step 3996: loss = 6.3334 (0.508 sec/step)
I0404 20:40:03.852890 47978602034560 learning.py:507] global step 3997: loss = 5.8089 (0.510 sec/step)
I0404 20:40:04.355595 47978602034560 learning.py:507] global step 3998: loss = 6.1950 (0.501 sec/step)
I0404 20:40:04.871558 47978602034560 learning.py:507] global step 3999: loss = 5.6575 (0.513 sec/step)
I0404 20:40:05.379845 47978602034560 learning.py:507] global step 4000: loss = 6.0893 (0.507 sec/step)
I0404 20:40:05.892414 47978602034560 learning.py:507] global step 4001: loss = 5.9141 (0.511 sec/step)
I0404 20:40:06.408813 47978602034560 learning.py:507] global step 4002: loss = 7.3321 (0.515 sec/step)
I0404 20:40:06.922538 47978602034560 learning.py:507] global step 4003: loss = 5.3620 (0.512 sec/step)
I0404 20:40:07.458744 47978602034560 learning.py:507] global step 4004: loss = 6.8809 (0.535 sec/step)
I0404 20:40:07.987495 47978602034560 learning.py:507] global step 4005: loss = 6.5080 (0.526 sec/step)
I0404 20:40:08.509136 47978602034560 learning.py:507] global step 4006: loss = 6.4846 (0.519 sec/step)
I0404 20:40:09.017533 47978602034560 learning.py:507] global step 4007: loss = 6.4298 (0.506 sec/step)
I0404 20:40:09.528514 47978602034560 learning.py:507] global step 4008: loss = 7.4459 (0.508 sec/step)
I0404 20:40:10.058668 47978602034560 learning.py:507] global step 4009: loss = 6.0500 (0.527 sec/step)
I0404 20:40:10.563910 47978602034560 learning.py:507] global step 4010: loss = 5.8694 (0.502 sec/step)
I0404 20:40:11.076342 47978602034560 learning.py:507] global step 4011: loss = 6.6508 (0.511 sec/step)
I0404 20:40:11.587629 47978602034560 learning.py:507] global step 4012: loss = 5.3780 (0.510 sec/step)
I0404 20:40:12.134087 47978602034560 learning.py:507] global step 4013: loss = 6.2650 (0.545 sec/step)
I0404 20:40:12.640537 47978602034560 learning.py:507] global step 4014: loss = 6.8529 (0.504 sec/step)
I0404 20:40:13.147566 47978602034560 learning.py:507] global step 4015: loss = 5.8324 (0.504 sec/step)
I0404 20:40:13.681907 47978602034560 learning.py:507] global step 4016: loss = 5.4972 (0.533 sec/step)
I0404 20:40:14.182986 47978602034560 learning.py:507] global step 4017: loss = 6.7796 (0.500 sec/step)
I0404 20:40:14.717220 47978602034560 learning.py:507] global step 4018: loss = 6.3192 (0.531 sec/step)
I0404 20:40:15.219958 47978602034560 learning.py:507] global step 4019: loss = 7.1617 (0.501 sec/step)
I0404 20:40:15.721507 47978602034560 learning.py:507] global step 4020: loss = 5.9134 (0.499 sec/step)
I0404 20:40:16.224990 47978602034560 learning.py:507] global step 4021: loss = 6.0020 (0.502 sec/step)
I0404 20:40:16.735090 47978602034560 learning.py:507] global step 4022: loss = 6.9308 (0.509 sec/step)
I0404 20:40:17.251233 47978602034560 learning.py:507] global step 4023: loss = 5.1969 (0.515 sec/step)
I0404 20:40:17.756368 47978602034560 learning.py:507] global step 4024: loss = 6.9276 (0.504 sec/step)
I0404 20:40:18.261567 47978602034560 learning.py:507] global step 4025: loss = 6.3433 (0.504 sec/step)
I0404 20:40:18.792493 47978602034560 learning.py:507] global step 4026: loss = 7.2929 (0.529 sec/step)
I0404 20:40:19.317815 47978602034560 learning.py:507] global step 4027: loss = 5.0343 (0.522 sec/step)
I0404 20:40:19.832401 47978602034560 learning.py:507] global step 4028: loss = 4.5960 (0.513 sec/step)
I0404 20:40:20.341145 47978602034560 learning.py:507] global step 4029: loss = 5.4743 (0.506 sec/step)
I0404 20:40:20.863719 47978602034560 learning.py:507] global step 4030: loss = 7.1195 (0.521 sec/step)
I0404 20:40:21.377801 47978602034560 learning.py:507] global step 4031: loss = 7.0711 (0.512 sec/step)
I0404 20:40:21.880652 47978602034560 learning.py:507] global step 4032: loss = 5.4972 (0.501 sec/step)
I0404 20:40:22.386822 47978602034560 learning.py:507] global step 4033: loss = 5.9154 (0.505 sec/step)
I0404 20:40:22.904563 47978602034560 learning.py:507] global step 4034: loss = 5.5882 (0.516 sec/step)
I0404 20:40:23.423426 47978602034560 learning.py:507] global step 4035: loss = 6.6399 (0.516 sec/step)
I0404 20:40:23.934903 47978602034560 learning.py:507] global step 4036: loss = 5.7211 (0.509 sec/step)
I0404 20:40:24.449648 47978602034560 learning.py:507] global step 4037: loss = 6.5212 (0.512 sec/step)
I0404 20:40:24.958906 47978602034560 learning.py:507] global step 4038: loss = 4.6195 (0.506 sec/step)
I0404 20:40:25.476120 47978602034560 learning.py:507] global step 4039: loss = 6.6912 (0.514 sec/step)
I0404 20:40:25.993996 47978602034560 learning.py:507] global step 4040: loss = 7.4870 (0.515 sec/step)
I0404 20:40:26.505641 47978602034560 learning.py:507] global step 4041: loss = 6.2718 (0.510 sec/step)
I0404 20:40:27.019235 47978602034560 learning.py:507] global step 4042: loss = 6.0920 (0.512 sec/step)
I0404 20:40:27.541757 47978602034560 learning.py:507] global step 4043: loss = 5.7403 (0.520 sec/step)
I0404 20:40:28.042722 47978602034560 learning.py:507] global step 4044: loss = 6.9587 (0.499 sec/step)
I0404 20:40:28.563609 47978602034560 learning.py:507] global step 4045: loss = 6.0826 (0.518 sec/step)
I0404 20:40:29.072581 47978602034560 learning.py:507] global step 4046: loss = 5.9867 (0.507 sec/step)
I0404 20:40:29.585813 47978602034560 learning.py:507] global step 4047: loss = 5.8383 (0.512 sec/step)
I0404 20:40:30.089894 47978602034560 learning.py:507] global step 4048: loss = 5.5715 (0.501 sec/step)
I0404 20:40:30.628837 47978602034560 learning.py:507] global step 4049: loss = 5.1640 (0.537 sec/step)
I0404 20:40:31.142964 47978602034560 learning.py:507] global step 4050: loss = 6.0566 (0.513 sec/step)
I0404 20:40:31.665909 47978602034560 learning.py:507] global step 4051: loss = 5.2375 (0.521 sec/step)
I0404 20:40:32.172901 47978602034560 learning.py:507] global step 4052: loss = 6.0655 (0.505 sec/step)
I0404 20:40:32.677304 47978602034560 learning.py:507] global step 4053: loss = 6.4429 (0.501 sec/step)
I0404 20:40:33.217725 47978602034560 learning.py:507] global step 4054: loss = 6.6957 (0.539 sec/step)
I0404 20:40:33.727126 47978602034560 learning.py:507] global step 4055: loss = 6.6956 (0.508 sec/step)
I0404 20:40:34.237192 47978602034560 learning.py:507] global step 4056: loss = 5.7314 (0.507 sec/step)
I0404 20:40:34.758065 47978602034560 learning.py:507] global step 4057: loss = 6.4320 (0.519 sec/step)
I0404 20:40:35.277225 47978602034560 learning.py:507] global step 4058: loss = 5.8767 (0.518 sec/step)
I0404 20:40:35.793163 47978602034560 learning.py:507] global step 4059: loss = 6.5146 (0.514 sec/step)
I0404 20:40:36.304197 47978602034560 learning.py:507] global step 4060: loss = 6.0962 (0.508 sec/step)
I0404 20:40:36.808346 47978602034560 learning.py:507] global step 4061: loss = 6.0554 (0.503 sec/step)
I0404 20:40:37.350911 47978602034560 learning.py:507] global step 4062: loss = 5.2155 (0.541 sec/step)
I0404 20:40:37.864319 47978602034560 learning.py:507] global step 4063: loss = 6.8059 (0.512 sec/step)
I0404 20:40:38.394638 47978602034560 learning.py:507] global step 4064: loss = 6.2902 (0.529 sec/step)
I0404 20:40:38.924513 47978602034560 learning.py:507] global step 4065: loss = 6.4445 (0.528 sec/step)
I0404 20:40:39.440352 47978602034560 learning.py:507] global step 4066: loss = 6.4491 (0.514 sec/step)
I0404 20:40:39.974580 47978602034560 learning.py:507] global step 4067: loss = 5.9849 (0.533 sec/step)
I0404 20:40:40.482098 47978602034560 learning.py:507] global step 4068: loss = 6.1049 (0.506 sec/step)
I0404 20:40:41.007492 47978602034560 learning.py:507] global step 4069: loss = 5.9815 (0.524 sec/step)
I0404 20:40:41.549524 47978602034560 learning.py:507] global step 4070: loss = 5.2937 (0.540 sec/step)
I0404 20:40:42.073104 47978602034560 learning.py:507] global step 4071: loss = 6.8900 (0.521 sec/step)
I0404 20:40:42.600486 47978602034560 learning.py:507] global step 4072: loss = 6.7768 (0.526 sec/step)
I0404 20:40:43.130309 47978602034560 learning.py:507] global step 4073: loss = 6.9759 (0.527 sec/step)
I0404 20:40:43.653794 47978602034560 learning.py:507] global step 4074: loss = 6.1415 (0.522 sec/step)
I0404 20:40:44.190898 47978602034560 learning.py:507] global step 4075: loss = 5.9819 (0.536 sec/step)
I0404 20:40:44.721466 47978602034560 learning.py:507] global step 4076: loss = 6.0392 (0.529 sec/step)
I0404 20:40:45.265362 47978602034560 learning.py:507] global step 4077: loss = 5.9128 (0.542 sec/step)
I0404 20:40:45.782047 47978602034560 learning.py:507] global step 4078: loss = 4.7766 (0.514 sec/step)
I0404 20:40:46.285960 47978602034560 learning.py:507] global step 4079: loss = 6.1199 (0.502 sec/step)
I0404 20:40:46.802253 47978602034560 learning.py:507] global step 4080: loss = 6.6323 (0.513 sec/step)
I0404 20:40:47.310199 47978602034560 learning.py:507] global step 4081: loss = 5.6688 (0.506 sec/step)
I0404 20:40:47.833448 47978602034560 learning.py:507] global step 4082: loss = 6.4105 (0.522 sec/step)
I0404 20:40:48.354637 47978602034560 learning.py:507] global step 4083: loss = 6.0551 (0.518 sec/step)
I0404 20:40:48.900238 47978602034560 learning.py:507] global step 4084: loss = 5.8606 (0.543 sec/step)
I0404 20:40:49.408563 47978602034560 learning.py:507] global step 4085: loss = 5.4616 (0.507 sec/step)
I0404 20:40:49.938692 47978602034560 learning.py:507] global step 4086: loss = 6.0450 (0.529 sec/step)
I0404 20:40:50.450140 47978602034560 learning.py:507] global step 4087: loss = 6.2076 (0.510 sec/step)
I0404 20:40:50.960128 47978602034560 learning.py:507] global step 4088: loss = 6.9717 (0.508 sec/step)
I0404 20:40:51.468476 47978602034560 learning.py:507] global step 4089: loss = 6.0311 (0.507 sec/step)
I0404 20:40:51.975906 47978602034560 learning.py:507] global step 4090: loss = 6.3436 (0.506 sec/step)
I0404 20:40:52.479996 47978602034560 learning.py:507] global step 4091: loss = 7.1962 (0.501 sec/step)
I0404 20:40:52.998187 47978602034560 learning.py:507] global step 4092: loss = 7.0862 (0.517 sec/step)
I0404 20:40:53.501671 47978602034560 learning.py:507] global step 4093: loss = 6.0005 (0.502 sec/step)
I0404 20:40:54.005196 47978602034560 learning.py:507] global step 4094: loss = 6.9960 (0.502 sec/step)
I0404 20:40:54.520242 47978602034560 learning.py:507] global step 4095: loss = 6.9705 (0.512 sec/step)
I0404 20:40:55.035521 47978602034560 learning.py:507] global step 4096: loss = 6.2108 (0.512 sec/step)
I0404 20:40:55.539875 47978602034560 learning.py:507] global step 4097: loss = 6.7212 (0.503 sec/step)
I0404 20:40:56.047026 47978602034560 learning.py:507] global step 4098: loss = 6.6253 (0.504 sec/step)
I0404 20:40:56.572136 47978602034560 learning.py:507] global step 4099: loss = 5.9630 (0.524 sec/step)
I0404 20:40:57.084624 47978602034560 learning.py:507] global step 4100: loss = 5.6160 (0.511 sec/step)
I0404 20:40:57.597731 47978602034560 learning.py:507] global step 4101: loss = 6.5993 (0.512 sec/step)
I0404 20:40:58.107028 47978602034560 learning.py:507] global step 4102: loss = 6.7412 (0.506 sec/step)
I0404 20:40:58.613104 47978602034560 learning.py:507] global step 4103: loss = 5.0380 (0.505 sec/step)
I0404 20:40:59.130738 47978602034560 learning.py:507] global step 4104: loss = 6.3253 (0.515 sec/step)
I0404 20:40:59.652775 47978602034560 learning.py:507] global step 4105: loss = 6.1286 (0.520 sec/step)
I0404 20:41:00.158678 47978602034560 learning.py:507] global step 4106: loss = 6.8868 (0.503 sec/step)
I0404 20:41:00.659574 47978602034560 learning.py:507] global step 4107: loss = 5.4197 (0.498 sec/step)
I0404 20:41:01.161266 47978602034560 learning.py:507] global step 4108: loss = 6.4480 (0.500 sec/step)
I0404 20:41:01.685991 47978602034560 learning.py:507] global step 4109: loss = 6.6954 (0.523 sec/step)
I0404 20:41:02.183256 47978602034560 learning.py:507] global step 4110: loss = 5.8776 (0.496 sec/step)
I0404 20:41:02.714745 47978602034560 learning.py:507] global step 4111: loss = 5.7102 (0.529 sec/step)
I0404 20:41:03.217676 47978602034560 learning.py:507] global step 4112: loss = 5.6564 (0.501 sec/step)
I0404 20:41:03.748249 47978602034560 learning.py:507] global step 4113: loss = 6.4913 (0.529 sec/step)
I0404 20:41:04.278495 47978602034560 learning.py:507] global step 4114: loss = 6.5487 (0.527 sec/step)
I0404 20:41:04.786703 47978602034560 learning.py:507] global step 4115: loss = 6.7786 (0.505 sec/step)
I0404 20:41:05.307118 47978602034560 learning.py:507] global step 4116: loss = 5.7446 (0.519 sec/step)
I0404 20:41:05.820751 47978602034560 learning.py:507] global step 4117: loss = 6.5220 (0.512 sec/step)
I0404 20:41:06.332818 47978602034560 learning.py:507] global step 4118: loss = 6.4330 (0.510 sec/step)
I0404 20:41:06.837323 47978602034560 learning.py:507] global step 4119: loss = 6.3526 (0.503 sec/step)
I0404 20:41:07.345428 47978602034560 learning.py:507] global step 4120: loss = 6.1647 (0.505 sec/step)
I0404 20:41:07.868881 47978602034560 learning.py:507] global step 4121: loss = 6.5740 (0.522 sec/step)
I0404 20:41:08.374111 47978602034560 learning.py:507] global step 4122: loss = 7.0060 (0.502 sec/step)
I0404 20:41:08.881306 47978602034560 learning.py:507] global step 4123: loss = 6.5814 (0.506 sec/step)
I0404 20:41:09.394970 47978602034560 learning.py:507] global step 4124: loss = 5.9010 (0.512 sec/step)
I0404 20:41:09.905993 47978602034560 learning.py:507] global step 4125: loss = 5.6576 (0.508 sec/step)
I0404 20:41:10.430795 47978602034560 learning.py:507] global step 4126: loss = 6.1466 (0.522 sec/step)
I0404 20:41:10.960421 47978602034560 learning.py:507] global step 4127: loss = 6.3641 (0.528 sec/step)
I0404 20:41:11.472840 47978602034560 learning.py:507] global step 4128: loss = 5.0542 (0.511 sec/step)
I0404 20:41:11.992554 47978602034560 learning.py:507] global step 4129: loss = 6.8469 (0.518 sec/step)
I0404 20:41:12.511960 47978602034560 learning.py:507] global step 4130: loss = 6.7900 (0.518 sec/step)
I0404 20:41:13.026437 47978602034560 learning.py:507] global step 4131: loss = 6.3963 (0.512 sec/step)
I0404 20:41:13.539688 47978602034560 learning.py:507] global step 4132: loss = 5.7411 (0.510 sec/step)
I0404 20:41:14.054579 47978602034560 learning.py:507] global step 4133: loss = 6.2211 (0.513 sec/step)
I0404 20:41:14.587031 47978602034560 learning.py:507] global step 4134: loss = 5.8687 (0.531 sec/step)
I0404 20:41:15.099667 47978602034560 learning.py:507] global step 4135: loss = 5.7447 (0.511 sec/step)
I0404 20:41:15.611574 47978602034560 learning.py:507] global step 4136: loss = 6.7673 (0.509 sec/step)
I0404 20:41:16.139610 47978602034560 learning.py:507] global step 4137: loss = 5.5640 (0.525 sec/step)
I0404 20:41:16.663442 47978602034560 learning.py:507] global step 4138: loss = 6.4940 (0.512 sec/step)
I0404 20:41:17.037097 47983661975296 supervisor.py:1050] Recording summary at step 4138.
I0404 20:41:17.372725 47978602034560 learning.py:507] global step 4139: loss = 5.7082 (0.702 sec/step)
I0404 20:41:17.888538 47978602034560 learning.py:507] global step 4140: loss = 6.8093 (0.514 sec/step)
I0404 20:41:18.403542 47978602034560 learning.py:507] global step 4141: loss = 7.0742 (0.513 sec/step)
I0404 20:41:18.911317 47978602034560 learning.py:507] global step 4142: loss = 5.8300 (0.506 sec/step)
I0404 20:41:19.414061 47978602034560 learning.py:507] global step 4143: loss = 5.3674 (0.500 sec/step)
I0404 20:41:19.934466 47978602034560 learning.py:507] global step 4144: loss = 5.8955 (0.519 sec/step)
I0404 20:41:20.443247 47978602034560 learning.py:507] global step 4145: loss = 5.7334 (0.506 sec/step)
I0404 20:41:20.964781 47978602034560 learning.py:507] global step 4146: loss = 6.5932 (0.520 sec/step)
I0404 20:41:21.475548 47978602034560 learning.py:507] global step 4147: loss = 6.2339 (0.509 sec/step)
I0404 20:41:22.006314 47978602034560 learning.py:507] global step 4148: loss = 6.1019 (0.529 sec/step)
I0404 20:41:22.526019 47978602034560 learning.py:507] global step 4149: loss = 6.3276 (0.518 sec/step)
I0404 20:41:23.040331 47978602034560 learning.py:507] global step 4150: loss = 6.4309 (0.513 sec/step)
I0404 20:41:23.563925 47978602034560 learning.py:507] global step 4151: loss = 6.4653 (0.522 sec/step)
I0404 20:41:24.075369 47978602034560 learning.py:507] global step 4152: loss = 6.3718 (0.510 sec/step)
I0404 20:41:24.588336 47978602034560 learning.py:507] global step 4153: loss = 6.3726 (0.511 sec/step)
I0404 20:41:25.095292 47978602034560 learning.py:507] global step 4154: loss = 6.9057 (0.505 sec/step)
I0404 20:41:25.628996 47978602034560 learning.py:507] global step 4155: loss = 6.6138 (0.532 sec/step)
I0404 20:41:26.164284 47978602034560 learning.py:507] global step 4156: loss = 5.9436 (0.534 sec/step)
I0404 20:41:26.674101 47978602034560 learning.py:507] global step 4157: loss = 6.4373 (0.508 sec/step)
I0404 20:41:27.204858 47978602034560 learning.py:507] global step 4158: loss = 7.1152 (0.529 sec/step)
I0404 20:41:27.741747 47978602034560 learning.py:507] global step 4159: loss = 5.6891 (0.535 sec/step)
I0404 20:41:28.257720 47978602034560 learning.py:507] global step 4160: loss = 6.1257 (0.513 sec/step)
I0404 20:41:28.787171 47978602034560 learning.py:507] global step 4161: loss = 6.3796 (0.528 sec/step)
I0404 20:41:29.292606 47978602034560 learning.py:507] global step 4162: loss = 6.6977 (0.504 sec/step)
I0404 20:41:29.806974 47978602034560 learning.py:507] global step 4163: loss = 6.3000 (0.513 sec/step)
I0404 20:41:30.324589 47978602034560 learning.py:507] global step 4164: loss = 6.8474 (0.515 sec/step)
I0404 20:41:30.825811 47978602034560 learning.py:507] global step 4165: loss = 5.7405 (0.500 sec/step)
I0404 20:41:31.337997 47978602034560 learning.py:507] global step 4166: loss = 5.6287 (0.511 sec/step)
I0404 20:41:31.858806 47978602034560 learning.py:507] global step 4167: loss = 5.4904 (0.519 sec/step)
I0404 20:41:32.377374 47978602034560 learning.py:507] global step 4168: loss = 5.8021 (0.517 sec/step)
I0404 20:41:32.901309 47978602034560 learning.py:507] global step 4169: loss = 6.3103 (0.522 sec/step)
I0404 20:41:33.422649 47978602034560 learning.py:507] global step 4170: loss = 5.9174 (0.520 sec/step)
I0404 20:41:33.926421 47978602034560 learning.py:507] global step 4171: loss = 7.4095 (0.502 sec/step)
I0404 20:41:34.443050 47978602034560 learning.py:507] global step 4172: loss = 5.5716 (0.514 sec/step)
I0404 20:41:34.959109 47978602034560 learning.py:507] global step 4173: loss = 6.1112 (0.513 sec/step)
I0404 20:41:35.473877 47978602034560 learning.py:507] global step 4174: loss = 7.5170 (0.513 sec/step)
I0404 20:41:35.995236 47978602034560 learning.py:507] global step 4175: loss = 6.5313 (0.520 sec/step)
I0404 20:41:36.530714 47978602034560 learning.py:507] global step 4176: loss = 6.5295 (0.532 sec/step)
I0404 20:41:37.047312 47978602034560 learning.py:507] global step 4177: loss = 6.6298 (0.514 sec/step)
I0404 20:41:37.559039 47978602034560 learning.py:507] global step 4178: loss = 5.3132 (0.510 sec/step)
I0404 20:41:38.077187 47978602034560 learning.py:507] global step 4179: loss = 5.6970 (0.517 sec/step)
I0404 20:41:38.597741 47978602034560 learning.py:507] global step 4180: loss = 6.6915 (0.519 sec/step)
I0404 20:41:39.112347 47978602034560 learning.py:507] global step 4181: loss = 5.7465 (0.513 sec/step)
I0404 20:41:39.643941 47978602034560 learning.py:507] global step 4182: loss = 6.3297 (0.530 sec/step)
I0404 20:41:40.158117 47978602034560 learning.py:507] global step 4183: loss = 6.7890 (0.513 sec/step)
I0404 20:41:40.665311 47978602034560 learning.py:507] global step 4184: loss = 5.2931 (0.506 sec/step)
I0404 20:41:41.195865 47978602034560 learning.py:507] global step 4185: loss = 6.9041 (0.528 sec/step)
I0404 20:41:41.699862 47978602034560 learning.py:507] global step 4186: loss = 6.2478 (0.501 sec/step)
I0404 20:41:42.215872 47978602034560 learning.py:507] global step 4187: loss = 6.4735 (0.514 sec/step)
I0404 20:41:42.733845 47978602034560 learning.py:507] global step 4188: loss = 6.1707 (0.516 sec/step)
I0404 20:41:43.236753 47978602034560 learning.py:507] global step 4189: loss = 7.2219 (0.500 sec/step)
I0404 20:41:43.756535 47978602034560 learning.py:507] global step 4190: loss = 6.8723 (0.518 sec/step)
I0404 20:41:44.264408 47978602034560 learning.py:507] global step 4191: loss = 6.5631 (0.505 sec/step)
I0404 20:41:44.768717 47978602034560 learning.py:507] global step 4192: loss = 5.5618 (0.501 sec/step)
I0404 20:41:45.304763 47978602034560 learning.py:507] global step 4193: loss = 6.3829 (0.534 sec/step)
I0404 20:41:45.817632 47978602034560 learning.py:507] global step 4194: loss = 5.6657 (0.511 sec/step)
I0404 20:41:46.326241 47978602034560 learning.py:507] global step 4195: loss = 5.7184 (0.507 sec/step)
I0404 20:41:46.848498 47978602034560 learning.py:507] global step 4196: loss = 6.6201 (0.521 sec/step)
I0404 20:41:47.356494 47978602034560 learning.py:507] global step 4197: loss = 7.0288 (0.506 sec/step)
I0404 20:41:47.861516 47978602034560 learning.py:507] global step 4198: loss = 6.8406 (0.502 sec/step)
I0404 20:41:48.380663 47978602034560 learning.py:507] global step 4199: loss = 5.3544 (0.518 sec/step)
I0404 20:41:48.888970 47978602034560 learning.py:507] global step 4200: loss = 6.2113 (0.507 sec/step)
I0404 20:41:49.389794 47978602034560 learning.py:507] global step 4201: loss = 6.3856 (0.498 sec/step)
I0404 20:41:49.890514 47978602034560 learning.py:507] global step 4202: loss = 5.9465 (0.499 sec/step)
I0404 20:41:50.397461 47978602034560 learning.py:507] global step 4203: loss = 5.6679 (0.505 sec/step)
I0404 20:41:50.907752 47978602034560 learning.py:507] global step 4204: loss = 5.5369 (0.509 sec/step)
I0404 20:41:51.427790 47978602034560 learning.py:507] global step 4205: loss = 5.9922 (0.518 sec/step)
I0404 20:41:51.947624 47978602034560 learning.py:507] global step 4206: loss = 6.2259 (0.517 sec/step)
I0404 20:41:52.454072 47978602034560 learning.py:507] global step 4207: loss = 6.6146 (0.504 sec/step)
I0404 20:41:52.966663 47978602034560 learning.py:507] global step 4208: loss = 5.5397 (0.511 sec/step)
I0404 20:41:53.477152 47978602034560 learning.py:507] global step 4209: loss = 6.4356 (0.509 sec/step)
I0404 20:41:53.988291 47978602034560 learning.py:507] global step 4210: loss = 5.6589 (0.510 sec/step)
I0404 20:41:54.507836 47978602034560 learning.py:507] global step 4211: loss = 5.3885 (0.518 sec/step)
I0404 20:41:55.016614 47978602034560 learning.py:507] global step 4212: loss = 6.0713 (0.507 sec/step)
I0404 20:41:55.518675 47978602034560 learning.py:507] global step 4213: loss = 6.5580 (0.501 sec/step)
I0404 20:41:56.029013 47978602034560 learning.py:507] global step 4214: loss = 5.7350 (0.509 sec/step)
I0404 20:41:56.543154 47978602034560 learning.py:507] global step 4215: loss = 5.0742 (0.513 sec/step)
I0404 20:41:57.054536 47978602034560 learning.py:507] global step 4216: loss = 5.9431 (0.510 sec/step)
I0404 20:41:57.564926 47978602034560 learning.py:507] global step 4217: loss = 6.0300 (0.508 sec/step)
I0404 20:41:58.076041 47978602034560 learning.py:507] global step 4218: loss = 5.8751 (0.510 sec/step)
I0404 20:41:58.599715 47978602034560 learning.py:507] global step 4219: loss = 6.1133 (0.522 sec/step)
I0404 20:41:59.108018 47978602034560 learning.py:507] global step 4220: loss = 6.6309 (0.507 sec/step)
I0404 20:41:59.629020 47978602034560 learning.py:507] global step 4221: loss = 7.3028 (0.518 sec/step)
I0404 20:42:00.137003 47978602034560 learning.py:507] global step 4222: loss = 7.3917 (0.506 sec/step)
I0404 20:42:00.645848 47978602034560 learning.py:507] global step 4223: loss = 5.8836 (0.506 sec/step)
I0404 20:42:01.152258 47978602034560 learning.py:507] global step 4224: loss = 6.0854 (0.505 sec/step)
I0404 20:42:01.695005 47978602034560 learning.py:507] global step 4225: loss = 6.2031 (0.541 sec/step)
I0404 20:42:02.209689 47978602034560 learning.py:507] global step 4226: loss = 6.6047 (0.513 sec/step)
I0404 20:42:02.729537 47978602034560 learning.py:507] global step 4227: loss = 6.0088 (0.518 sec/step)
I0404 20:42:03.246535 47978602034560 learning.py:507] global step 4228: loss = 5.8639 (0.515 sec/step)
I0404 20:42:03.760129 47978602034560 learning.py:507] global step 4229: loss = 6.5882 (0.511 sec/step)
I0404 20:42:04.278581 47978602034560 learning.py:507] global step 4230: loss = 6.1976 (0.517 sec/step)
I0404 20:42:04.795598 47978602034560 learning.py:507] global step 4231: loss = 6.2857 (0.515 sec/step)
I0404 20:42:05.295212 47978602034560 learning.py:507] global step 4232: loss = 5.1369 (0.498 sec/step)
I0404 20:42:05.813462 47978602034560 learning.py:507] global step 4233: loss = 7.8411 (0.515 sec/step)
I0404 20:42:06.317880 47978602034560 learning.py:507] global step 4234: loss = 5.5587 (0.503 sec/step)
I0404 20:42:06.851682 47978602034560 learning.py:507] global step 4235: loss = 5.8782 (0.532 sec/step)
I0404 20:42:07.387162 47978602034560 learning.py:507] global step 4236: loss = 6.1441 (0.534 sec/step)
I0404 20:42:07.897754 47978602034560 learning.py:507] global step 4237: loss = 5.7854 (0.509 sec/step)
I0404 20:42:08.411739 47978602034560 learning.py:507] global step 4238: loss = 5.8421 (0.512 sec/step)
I0404 20:42:08.952288 47978602034560 learning.py:507] global step 4239: loss = 5.9258 (0.539 sec/step)
I0404 20:42:09.488513 47978602034560 learning.py:507] global step 4240: loss = 6.1305 (0.535 sec/step)
I0404 20:42:09.987234 47978602034560 learning.py:507] global step 4241: loss = 6.2597 (0.497 sec/step)
I0404 20:42:10.491996 47978602034560 learning.py:507] global step 4242: loss = 7.2358 (0.503 sec/step)
I0404 20:42:11.003135 47978602034560 learning.py:507] global step 4243: loss = 5.9310 (0.510 sec/step)
I0404 20:42:11.515820 47978602034560 learning.py:507] global step 4244: loss = 5.3414 (0.511 sec/step)
I0404 20:42:12.044375 47978602034560 learning.py:507] global step 4245: loss = 5.1976 (0.527 sec/step)
I0404 20:42:12.566664 47978602034560 learning.py:507] global step 4246: loss = 6.2702 (0.521 sec/step)
I0404 20:42:13.076252 47978602034560 learning.py:507] global step 4247: loss = 7.3311 (0.507 sec/step)
I0404 20:42:13.585699 47978602034560 learning.py:507] global step 4248: loss = 7.0615 (0.508 sec/step)
I0404 20:42:14.091189 47978602034560 learning.py:507] global step 4249: loss = 6.5759 (0.504 sec/step)
I0404 20:42:14.602822 47978602034560 learning.py:507] global step 4250: loss = 6.0397 (0.510 sec/step)
I0404 20:42:15.138649 47978602034560 learning.py:507] global step 4251: loss = 6.0884 (0.534 sec/step)
I0404 20:42:15.651487 47978602034560 learning.py:507] global step 4252: loss = 6.0831 (0.510 sec/step)
I0404 20:42:16.195141 47978602034560 learning.py:507] global step 4253: loss = 6.2763 (0.542 sec/step)
I0404 20:42:16.704216 47978602034560 learning.py:507] global step 4254: loss = 5.8634 (0.506 sec/step)
I0404 20:42:17.209733 47978602034560 learning.py:507] global step 4255: loss = 7.3747 (0.504 sec/step)
I0404 20:42:17.713333 47978602034560 learning.py:507] global step 4256: loss = 7.9832 (0.502 sec/step)
I0404 20:42:18.240386 47978602034560 learning.py:507] global step 4257: loss = 6.3961 (0.526 sec/step)
I0404 20:42:18.759328 47978602034560 learning.py:507] global step 4258: loss = 6.8014 (0.517 sec/step)
I0404 20:42:19.269179 47978602034560 learning.py:507] global step 4259: loss = 5.8166 (0.508 sec/step)
I0404 20:42:19.777602 47978602034560 learning.py:507] global step 4260: loss = 7.9411 (0.507 sec/step)
I0404 20:42:20.314989 47978602034560 learning.py:507] global step 4261: loss = 7.5290 (0.534 sec/step)
I0404 20:42:20.818191 47978602034560 learning.py:507] global step 4262: loss = 6.1967 (0.502 sec/step)
I0404 20:42:21.339103 47978602034560 learning.py:507] global step 4263: loss = 5.7716 (0.518 sec/step)
I0404 20:42:21.850161 47978602034560 learning.py:507] global step 4264: loss = 6.2749 (0.510 sec/step)
I0404 20:42:22.365992 47978602034560 learning.py:507] global step 4265: loss = 5.2000 (0.514 sec/step)
I0404 20:42:22.877537 47978602034560 learning.py:507] global step 4266: loss = 6.9237 (0.510 sec/step)
I0404 20:42:23.390408 47978602034560 learning.py:507] global step 4267: loss = 6.3004 (0.511 sec/step)
I0404 20:42:23.908032 47978602034560 learning.py:507] global step 4268: loss = 6.8451 (0.515 sec/step)
I0404 20:42:24.420009 47978602034560 learning.py:507] global step 4269: loss = 4.9688 (0.510 sec/step)
I0404 20:42:24.933234 47978602034560 learning.py:507] global step 4270: loss = 5.6039 (0.512 sec/step)
I0404 20:42:25.471402 47978602034560 learning.py:507] global step 4271: loss = 5.4300 (0.537 sec/step)
I0404 20:42:25.982495 47978602034560 learning.py:507] global step 4272: loss = 6.7237 (0.510 sec/step)
I0404 20:42:26.505250 47978602034560 learning.py:507] global step 4273: loss = 5.8868 (0.521 sec/step)
I0404 20:42:27.003509 47978602034560 learning.py:507] global step 4274: loss = 6.2229 (0.497 sec/step)
I0404 20:42:27.519044 47978602034560 learning.py:507] global step 4275: loss = 5.8341 (0.514 sec/step)
I0404 20:42:28.041773 47978602034560 learning.py:507] global step 4276: loss = 6.3140 (0.520 sec/step)
I0404 20:42:28.551126 47978602034560 learning.py:507] global step 4277: loss = 6.0817 (0.506 sec/step)
I0404 20:42:29.089579 47978602034560 learning.py:507] global step 4278: loss = 6.1712 (0.537 sec/step)
I0404 20:42:29.609075 47978602034560 learning.py:507] global step 4279: loss = 5.2089 (0.518 sec/step)
I0404 20:42:30.117009 47978602034560 learning.py:507] global step 4280: loss = 7.5178 (0.506 sec/step)
I0404 20:42:30.620706 47978602034560 learning.py:507] global step 4281: loss = 6.4442 (0.501 sec/step)
I0404 20:42:31.133136 47978602034560 learning.py:507] global step 4282: loss = 6.0887 (0.509 sec/step)
I0404 20:42:31.639688 47978602034560 learning.py:507] global step 4283: loss = 6.2928 (0.505 sec/step)
I0404 20:42:32.182630 47978602034560 learning.py:507] global step 4284: loss = 6.4434 (0.541 sec/step)
I0404 20:42:32.706210 47978602034560 learning.py:507] global step 4285: loss = 6.3494 (0.522 sec/step)
I0404 20:42:33.214386 47978602034560 learning.py:507] global step 4286: loss = 5.7713 (0.505 sec/step)
I0404 20:42:33.734583 47978602034560 learning.py:507] global step 4287: loss = 7.3659 (0.519 sec/step)
I0404 20:42:34.231819 47978602034560 learning.py:507] global step 4288: loss = 5.6213 (0.496 sec/step)
I0404 20:42:34.756740 47978602034560 learning.py:507] global step 4289: loss = 6.2403 (0.523 sec/step)
I0404 20:42:35.268156 47978602034560 learning.py:507] global step 4290: loss = 5.9116 (0.510 sec/step)
I0404 20:42:35.805435 47978602034560 learning.py:507] global step 4291: loss = 6.2552 (0.536 sec/step)
I0404 20:42:36.307844 47978602034560 learning.py:507] global step 4292: loss = 6.5976 (0.501 sec/step)
I0404 20:42:36.835586 47978602034560 learning.py:507] global step 4293: loss = 6.4235 (0.526 sec/step)
I0404 20:42:37.345282 47978602034560 learning.py:507] global step 4294: loss = 5.9596 (0.508 sec/step)
I0404 20:42:37.881843 47978602034560 learning.py:507] global step 4295: loss = 6.1483 (0.535 sec/step)
I0404 20:42:38.388645 47978602034560 learning.py:507] global step 4296: loss = 6.7485 (0.505 sec/step)
I0404 20:42:38.893301 47978602034560 learning.py:507] global step 4297: loss = 5.8498 (0.503 sec/step)
I0404 20:42:39.408702 47978602034560 learning.py:507] global step 4298: loss = 6.8698 (0.514 sec/step)
I0404 20:42:39.914865 47978602034560 learning.py:507] global step 4299: loss = 5.1371 (0.505 sec/step)
I0404 20:42:40.419344 47978602034560 learning.py:507] global step 4300: loss = 5.9045 (0.502 sec/step)
I0404 20:42:40.925609 47978602034560 learning.py:507] global step 4301: loss = 5.7060 (0.505 sec/step)
I0404 20:42:41.455769 47978602034560 learning.py:507] global step 4302: loss = 6.0682 (0.529 sec/step)
I0404 20:42:41.991197 47978602034560 learning.py:507] global step 4303: loss = 5.8328 (0.534 sec/step)
I0404 20:42:42.500195 47978602034560 learning.py:507] global step 4304: loss = 6.8248 (0.507 sec/step)
I0404 20:42:43.024678 47978602034560 learning.py:507] global step 4305: loss = 6.2183 (0.522 sec/step)
I0404 20:42:43.553295 47978602034560 learning.py:507] global step 4306: loss = 5.2033 (0.526 sec/step)
I0404 20:42:44.054424 47978602034560 learning.py:507] global step 4307: loss = 5.0769 (0.500 sec/step)
I0404 20:42:44.567220 47978602034560 learning.py:507] global step 4308: loss = 6.3425 (0.511 sec/step)
I0404 20:42:45.082356 47978602034560 learning.py:507] global step 4309: loss = 6.0920 (0.514 sec/step)
I0404 20:42:45.590477 47978602034560 learning.py:507] global step 4310: loss = 6.0046 (0.507 sec/step)
I0404 20:42:46.113205 47978602034560 learning.py:507] global step 4311: loss = 5.6764 (0.521 sec/step)
I0404 20:42:46.629506 47978602034560 learning.py:507] global step 4312: loss = 6.0712 (0.515 sec/step)
I0404 20:42:47.153004 47978602034560 learning.py:507] global step 4313: loss = 6.0901 (0.521 sec/step)
I0404 20:42:47.665027 47978602034560 learning.py:507] global step 4314: loss = 5.8673 (0.510 sec/step)
I0404 20:42:48.176689 47978602034560 learning.py:507] global step 4315: loss = 5.0447 (0.510 sec/step)
I0404 20:42:48.685722 47978602034560 learning.py:507] global step 4316: loss = 5.6932 (0.507 sec/step)
I0404 20:42:49.214240 47978602034560 learning.py:507] global step 4317: loss = 6.3798 (0.527 sec/step)
I0404 20:42:49.718086 47978602034560 learning.py:507] global step 4318: loss = 6.9119 (0.502 sec/step)
I0404 20:42:50.244815 47978602034560 learning.py:507] global step 4319: loss = 5.9753 (0.525 sec/step)
I0404 20:42:50.758521 47978602034560 learning.py:507] global step 4320: loss = 6.3260 (0.511 sec/step)
I0404 20:42:51.261948 47978602034560 learning.py:507] global step 4321: loss = 5.8087 (0.500 sec/step)
I0404 20:42:51.788875 47978602034560 learning.py:507] global step 4322: loss = 6.4515 (0.524 sec/step)
I0404 20:42:52.320085 47978602034560 learning.py:507] global step 4323: loss = 6.3689 (0.530 sec/step)
I0404 20:42:52.859858 47978602034560 learning.py:507] global step 4324: loss = 5.6792 (0.537 sec/step)
I0404 20:42:53.388305 47978602034560 learning.py:507] global step 4325: loss = 6.5350 (0.526 sec/step)
I0404 20:42:53.894366 47978602034560 learning.py:507] global step 4326: loss = 5.7768 (0.503 sec/step)
I0404 20:42:54.406507 47978602034560 learning.py:507] global step 4327: loss = 6.9727 (0.509 sec/step)
I0404 20:42:54.941020 47978602034560 learning.py:507] global step 4328: loss = 5.1417 (0.533 sec/step)
I0404 20:42:55.452986 47978602034560 learning.py:507] global step 4329: loss = 7.3857 (0.509 sec/step)
I0404 20:42:55.962014 47978602034560 learning.py:507] global step 4330: loss = 5.1169 (0.507 sec/step)
I0404 20:42:56.475535 47978602034560 learning.py:507] global step 4331: loss = 6.4514 (0.512 sec/step)
I0404 20:42:56.985579 47978602034560 learning.py:507] global step 4332: loss = 5.8605 (0.507 sec/step)
I0404 20:42:57.489272 47978602034560 learning.py:507] global step 4333: loss = 6.4789 (0.501 sec/step)
I0404 20:42:58.008260 47978602034560 learning.py:507] global step 4334: loss = 6.5627 (0.516 sec/step)
I0404 20:42:58.521775 47978602034560 learning.py:507] global step 4335: loss = 5.1320 (0.510 sec/step)
I0404 20:42:59.041413 47978602034560 learning.py:507] global step 4336: loss = 5.7706 (0.518 sec/step)
I0404 20:42:59.553703 47978602034560 learning.py:507] global step 4337: loss = 6.1546 (0.511 sec/step)
I0404 20:43:00.068720 47978602034560 learning.py:507] global step 4338: loss = 6.7804 (0.513 sec/step)
I0404 20:43:00.582610 47978602034560 learning.py:507] global step 4339: loss = 6.0626 (0.511 sec/step)
I0404 20:43:01.098119 47978602034560 learning.py:507] global step 4340: loss = 6.9855 (0.514 sec/step)
I0404 20:43:01.608616 47978602034560 learning.py:507] global step 4341: loss = 6.2132 (0.508 sec/step)
I0404 20:43:02.122288 47978602034560 learning.py:507] global step 4342: loss = 6.2756 (0.512 sec/step)
I0404 20:43:02.660525 47978602034560 learning.py:507] global step 4343: loss = 5.7836 (0.537 sec/step)
I0404 20:43:03.191070 47978602034560 learning.py:507] global step 4344: loss = 6.0631 (0.529 sec/step)
I0404 20:43:03.694821 47978602034560 learning.py:507] global step 4345: loss = 6.8427 (0.502 sec/step)
I0404 20:43:04.200874 47978602034560 learning.py:507] global step 4346: loss = 5.8892 (0.504 sec/step)
I0404 20:43:04.705312 47978602034560 learning.py:507] global step 4347: loss = 7.1674 (0.503 sec/step)
I0404 20:43:05.243822 47978602034560 learning.py:507] global step 4348: loss = 6.9717 (0.537 sec/step)
I0404 20:43:05.749117 47978602034560 learning.py:507] global step 4349: loss = 7.0553 (0.504 sec/step)
I0404 20:43:06.267415 47978602034560 learning.py:507] global step 4350: loss = 7.1895 (0.517 sec/step)
I0404 20:43:06.785449 47978602034560 learning.py:507] global step 4351: loss = 5.7773 (0.516 sec/step)
I0404 20:43:07.297052 47978602034560 learning.py:507] global step 4352: loss = 6.5741 (0.509 sec/step)
I0404 20:43:07.801931 47978602034560 learning.py:507] global step 4353: loss = 6.9057 (0.503 sec/step)
I0404 20:43:08.317632 47978602034560 learning.py:507] global step 4354: loss = 6.3856 (0.513 sec/step)
I0404 20:43:08.827227 47978602034560 learning.py:507] global step 4355: loss = 6.8389 (0.508 sec/step)
I0404 20:43:09.348111 47978602034560 learning.py:507] global step 4356: loss = 6.0207 (0.519 sec/step)
I0404 20:43:09.857717 47978602034560 learning.py:507] global step 4357: loss = 7.5071 (0.508 sec/step)
I0404 20:43:10.367990 47978602034560 learning.py:507] global step 4358: loss = 6.9215 (0.509 sec/step)
I0404 20:43:10.878372 47978602034560 learning.py:507] global step 4359: loss = 6.5598 (0.509 sec/step)
I0404 20:43:11.386385 47978602034560 learning.py:507] global step 4360: loss = 6.7972 (0.505 sec/step)
I0404 20:43:11.890623 47978602034560 learning.py:507] global step 4361: loss = 6.4800 (0.501 sec/step)
I0404 20:43:12.429110 47978602034560 learning.py:507] global step 4362: loss = 6.0559 (0.537 sec/step)
I0404 20:43:12.946379 47978602034560 learning.py:507] global step 4363: loss = 6.0238 (0.514 sec/step)
I0404 20:43:13.483913 47978602034560 learning.py:507] global step 4364: loss = 5.9656 (0.535 sec/step)
I0404 20:43:13.987045 47978602034560 learning.py:507] global step 4365: loss = 7.5873 (0.502 sec/step)
I0404 20:43:14.502993 47978602034560 learning.py:507] global step 4366: loss = 6.9079 (0.514 sec/step)
I0404 20:43:15.005774 47978602034560 learning.py:507] global step 4367: loss = 5.9844 (0.500 sec/step)
I0404 20:43:15.517145 47978602034560 learning.py:507] global step 4368: loss = 6.9442 (0.510 sec/step)
I0404 20:43:16.043081 47978602034560 learning.py:507] global step 4369: loss = 7.3393 (0.524 sec/step)
I0404 20:43:16.571681 47978602034560 learning.py:507] global step 4370: loss = 6.6618 (0.527 sec/step)
I0404 20:43:17.267641 47978602034560 learning.py:507] global step 4371: loss = 6.2817 (0.694 sec/step)
I0404 20:43:17.269100 47983661975296 supervisor.py:1050] Recording summary at step 4371.
I0404 20:43:17.779574 47978602034560 learning.py:507] global step 4372: loss = 5.9353 (0.510 sec/step)
I0404 20:43:18.300695 47978602034560 learning.py:507] global step 4373: loss = 6.4867 (0.518 sec/step)
I0404 20:43:18.821227 47978602034560 learning.py:507] global step 4374: loss = 6.2716 (0.518 sec/step)
I0404 20:43:19.336646 47978602034560 learning.py:507] global step 4375: loss = 7.4707 (0.513 sec/step)
I0404 20:43:19.847424 47978602034560 learning.py:507] global step 4376: loss = 6.6278 (0.508 sec/step)
I0404 20:43:20.381356 47978602034560 learning.py:507] global step 4377: loss = 6.0490 (0.532 sec/step)
I0404 20:43:20.884446 47978602034560 learning.py:507] global step 4378: loss = 6.6656 (0.502 sec/step)
I0404 20:43:21.404130 47978602034560 learning.py:507] global step 4379: loss = 5.1593 (0.518 sec/step)
I0404 20:43:21.913984 47978602034560 learning.py:507] global step 4380: loss = 6.6568 (0.507 sec/step)
I0404 20:43:22.426787 47978602034560 learning.py:507] global step 4381: loss = 6.1498 (0.511 sec/step)
I0404 20:43:22.930588 47978602034560 learning.py:507] global step 4382: loss = 6.6466 (0.502 sec/step)
I0404 20:43:23.447248 47978602034560 learning.py:507] global step 4383: loss = 5.4787 (0.514 sec/step)
I0404 20:43:23.961202 47978602034560 learning.py:507] global step 4384: loss = 6.1729 (0.512 sec/step)
I0404 20:43:24.477585 47978602034560 learning.py:507] global step 4385: loss = 6.6280 (0.515 sec/step)
I0404 20:43:24.985861 47978602034560 learning.py:507] global step 4386: loss = 6.2783 (0.507 sec/step)
I0404 20:43:25.494293 47978602034560 learning.py:507] global step 4387: loss = 6.2129 (0.506 sec/step)
I0404 20:43:26.020019 47978602034560 learning.py:507] global step 4388: loss = 5.8511 (0.524 sec/step)
I0404 20:43:26.538391 47978602034560 learning.py:507] global step 4389: loss = 6.9945 (0.517 sec/step)
I0404 20:43:27.053452 47978602034560 learning.py:507] global step 4390: loss = 6.3885 (0.512 sec/step)
I0404 20:43:27.566526 47978602034560 learning.py:507] global step 4391: loss = 5.8832 (0.511 sec/step)
I0404 20:43:28.094430 47978602034560 learning.py:507] global step 4392: loss = 6.1102 (0.526 sec/step)
I0404 20:43:28.605140 47978602034560 learning.py:507] global step 4393: loss = 7.2895 (0.509 sec/step)
I0404 20:43:29.147157 47978602034560 learning.py:507] global step 4394: loss = 6.1131 (0.540 sec/step)
I0404 20:43:29.650848 47978602034560 learning.py:507] global step 4395: loss = 6.2264 (0.501 sec/step)
I0404 20:43:30.170368 47978602034560 learning.py:507] global step 4396: loss = 5.4677 (0.517 sec/step)
I0404 20:43:30.687494 47978602034560 learning.py:507] global step 4397: loss = 7.4009 (0.516 sec/step)
I0404 20:43:31.214387 47978602034560 learning.py:507] global step 4398: loss = 6.2228 (0.525 sec/step)
I0404 20:43:31.727944 47978602034560 learning.py:507] global step 4399: loss = 5.8111 (0.512 sec/step)
I0404 20:43:32.260581 47978602034560 learning.py:507] global step 4400: loss = 5.8087 (0.530 sec/step)
I0404 20:43:32.778899 47978602034560 learning.py:507] global step 4401: loss = 4.9595 (0.517 sec/step)
I0404 20:43:33.284609 47978602034560 learning.py:507] global step 4402: loss = 6.0468 (0.503 sec/step)
I0404 20:43:33.814370 47978602034560 learning.py:507] global step 4403: loss = 5.5342 (0.527 sec/step)
I0404 20:43:34.329219 47978602034560 learning.py:507] global step 4404: loss = 5.8329 (0.513 sec/step)
I0404 20:43:34.838831 47978602034560 learning.py:507] global step 4405: loss = 5.4174 (0.508 sec/step)
I0404 20:43:35.346179 47978602034560 learning.py:507] global step 4406: loss = 5.0763 (0.506 sec/step)
I0404 20:43:35.846634 47978602034560 learning.py:507] global step 4407: loss = 4.9997 (0.498 sec/step)
I0404 20:43:36.379632 47978602034560 learning.py:507] global step 4408: loss = 5.9104 (0.530 sec/step)
I0404 20:43:36.889549 47978602034560 learning.py:507] global step 4409: loss = 5.7246 (0.508 sec/step)
I0404 20:43:37.402936 47978602034560 learning.py:507] global step 4410: loss = 6.7203 (0.511 sec/step)
I0404 20:43:37.913816 47978602034560 learning.py:507] global step 4411: loss = 6.4969 (0.508 sec/step)
I0404 20:43:38.424440 47978602034560 learning.py:507] global step 4412: loss = 6.5439 (0.509 sec/step)
I0404 20:43:38.928435 47978602034560 learning.py:507] global step 4413: loss = 5.2176 (0.502 sec/step)
I0404 20:43:39.458698 47978602034560 learning.py:507] global step 4414: loss = 6.0961 (0.529 sec/step)
I0404 20:43:39.966905 47978602034560 learning.py:507] global step 4415: loss = 6.2154 (0.507 sec/step)
I0404 20:43:40.480957 47978602034560 learning.py:507] global step 4416: loss = 5.6084 (0.512 sec/step)
I0404 20:43:41.012165 47978602034560 learning.py:507] global step 4417: loss = 7.0149 (0.530 sec/step)
I0404 20:43:41.525591 47978602034560 learning.py:507] global step 4418: loss = 6.5858 (0.512 sec/step)
I0404 20:43:42.044633 47978602034560 learning.py:507] global step 4419: loss = 6.4486 (0.518 sec/step)
I0404 20:43:42.552374 47978602034560 learning.py:507] global step 4420: loss = 6.3482 (0.505 sec/step)
I0404 20:43:43.061812 47978602034560 learning.py:507] global step 4421: loss = 5.9198 (0.508 sec/step)
I0404 20:43:43.568957 47978602034560 learning.py:507] global step 4422: loss = 6.1248 (0.506 sec/step)
I0404 20:43:44.082632 47978602034560 learning.py:507] global step 4423: loss = 6.5275 (0.512 sec/step)
I0404 20:43:44.611076 47978602034560 learning.py:507] global step 4424: loss = 6.2133 (0.527 sec/step)
I0404 20:43:45.117519 47978602034560 learning.py:507] global step 4425: loss = 5.6869 (0.504 sec/step)
I0404 20:43:45.628877 47978602034560 learning.py:507] global step 4426: loss = 5.0319 (0.510 sec/step)
I0404 20:43:46.137541 47978602034560 learning.py:507] global step 4427: loss = 6.7098 (0.507 sec/step)
I0404 20:43:46.669191 47978602034560 learning.py:507] global step 4428: loss = 6.6470 (0.530 sec/step)
I0404 20:43:47.189960 47978602034560 learning.py:507] global step 4429: loss = 6.8891 (0.519 sec/step)
I0404 20:43:47.710222 47978602034560 learning.py:507] global step 4430: loss = 5.7654 (0.519 sec/step)
I0404 20:43:48.229279 47978602034560 learning.py:507] global step 4431: loss = 5.6363 (0.517 sec/step)
I0404 20:43:48.736133 47978602034560 learning.py:507] global step 4432: loss = 6.3423 (0.505 sec/step)
I0404 20:43:49.251136 47978602034560 learning.py:507] global step 4433: loss = 5.2135 (0.513 sec/step)
I0404 20:43:49.758104 47978602034560 learning.py:507] global step 4434: loss = 5.1093 (0.504 sec/step)
I0404 20:43:50.288929 47978602034560 learning.py:507] global step 4435: loss = 6.0587 (0.529 sec/step)
I0404 20:43:50.789772 47978602034560 learning.py:507] global step 4436: loss = 6.5237 (0.498 sec/step)
I0404 20:43:51.300707 47978602034560 learning.py:507] global step 4437: loss = 5.6810 (0.508 sec/step)
I0404 20:43:51.831018 47978602034560 learning.py:507] global step 4438: loss = 6.1068 (0.527 sec/step)
I0404 20:43:52.334038 47978602034560 learning.py:507] global step 4439: loss = 5.5340 (0.501 sec/step)
I0404 20:43:52.842537 47978602034560 learning.py:507] global step 4440: loss = 7.1143 (0.505 sec/step)
I0404 20:43:53.356788 47978602034560 learning.py:507] global step 4441: loss = 6.2925 (0.513 sec/step)
I0404 20:43:53.878107 47978602034560 learning.py:507] global step 4442: loss = 5.2493 (0.518 sec/step)
I0404 20:43:54.388605 47978602034560 learning.py:507] global step 4443: loss = 6.6982 (0.508 sec/step)
I0404 20:43:54.920537 47978602034560 learning.py:507] global step 4444: loss = 5.8082 (0.529 sec/step)
I0404 20:43:55.433760 47978602034560 learning.py:507] global step 4445: loss = 6.3175 (0.510 sec/step)
I0404 20:43:55.945164 47978602034560 learning.py:507] global step 4446: loss = 5.5007 (0.508 sec/step)
I0404 20:43:56.479663 47978602034560 learning.py:507] global step 4447: loss = 5.7286 (0.531 sec/step)
I0404 20:43:56.995552 47978602034560 learning.py:507] global step 4448: loss = 5.4120 (0.514 sec/step)
I0404 20:43:57.522720 47978602034560 learning.py:507] global step 4449: loss = 6.2227 (0.526 sec/step)
I0404 20:43:58.021095 47978602034560 learning.py:507] global step 4450: loss = 6.1890 (0.497 sec/step)
I0404 20:43:58.527880 47978602034560 learning.py:507] global step 4451: loss = 7.8908 (0.505 sec/step)
I0404 20:43:59.045716 47978602034560 learning.py:507] global step 4452: loss = 7.1764 (0.516 sec/step)
I0404 20:43:59.546914 47978602034560 learning.py:507] global step 4453: loss = 7.6478 (0.500 sec/step)
I0404 20:44:00.057335 47978602034560 learning.py:507] global step 4454: loss = 6.2328 (0.509 sec/step)
I0404 20:44:00.564107 47978602034560 learning.py:507] global step 4455: loss = 6.6737 (0.504 sec/step)
I0404 20:44:01.099975 47978602034560 learning.py:507] global step 4456: loss = 5.3810 (0.534 sec/step)
I0404 20:44:01.613219 47978602034560 learning.py:507] global step 4457: loss = 5.6027 (0.510 sec/step)
I0404 20:44:02.144067 47978602034560 learning.py:507] global step 4458: loss = 5.9977 (0.528 sec/step)
I0404 20:44:02.644978 47978602034560 learning.py:507] global step 4459: loss = 6.6465 (0.499 sec/step)
I0404 20:44:03.152282 47978602034560 learning.py:507] global step 4460: loss = 7.1880 (0.506 sec/step)
I0404 20:44:03.668565 47978602034560 learning.py:507] global step 4461: loss = 5.5946 (0.515 sec/step)
I0404 20:44:04.182088 47978602034560 learning.py:507] global step 4462: loss = 6.7361 (0.512 sec/step)
I0404 20:44:04.684610 47978602034560 learning.py:507] global step 4463: loss = 7.3541 (0.501 sec/step)
I0404 20:44:05.203479 47978602034560 learning.py:507] global step 4464: loss = 6.3213 (0.516 sec/step)
I0404 20:44:05.709144 47978602034560 learning.py:507] global step 4465: loss = 5.3791 (0.504 sec/step)
I0404 20:44:06.234226 47978602034560 learning.py:507] global step 4466: loss = 4.9745 (0.523 sec/step)
I0404 20:44:06.740768 47978602034560 learning.py:507] global step 4467: loss = 6.1459 (0.505 sec/step)
I0404 20:44:07.241312 47978602034560 learning.py:507] global step 4468: loss = 5.5780 (0.498 sec/step)
I0404 20:44:07.749034 47978602034560 learning.py:507] global step 4469: loss = 6.8696 (0.506 sec/step)
I0404 20:44:08.260790 47978602034560 learning.py:507] global step 4470: loss = 6.4725 (0.509 sec/step)
I0404 20:44:08.778792 47978602034560 learning.py:507] global step 4471: loss = 5.5849 (0.515 sec/step)
I0404 20:44:09.290354 47978602034560 learning.py:507] global step 4472: loss = 5.0291 (0.509 sec/step)
I0404 20:44:09.826699 47978602034560 learning.py:507] global step 4473: loss = 5.9879 (0.535 sec/step)
I0404 20:44:10.340249 47978602034560 learning.py:507] global step 4474: loss = 6.4882 (0.512 sec/step)
I0404 20:44:10.837369 47978602034560 learning.py:507] global step 4475: loss = 5.5384 (0.494 sec/step)
I0404 20:44:11.351969 47978602034560 learning.py:507] global step 4476: loss = 6.0421 (0.512 sec/step)
I0404 20:44:11.854290 47978602034560 learning.py:507] global step 4477: loss = 5.3282 (0.501 sec/step)
I0404 20:44:12.367711 47978602034560 learning.py:507] global step 4478: loss = 5.6354 (0.512 sec/step)
I0404 20:44:12.875278 47978602034560 learning.py:507] global step 4479: loss = 4.7857 (0.505 sec/step)
I0404 20:44:13.377264 47978602034560 learning.py:507] global step 4480: loss = 7.3797 (0.499 sec/step)
I0404 20:44:13.883377 47978602034560 learning.py:507] global step 4481: loss = 6.5328 (0.505 sec/step)
I0404 20:44:14.394023 47978602034560 learning.py:507] global step 4482: loss = 7.1986 (0.509 sec/step)
I0404 20:44:14.910608 47978602034560 learning.py:507] global step 4483: loss = 6.3254 (0.515 sec/step)
I0404 20:44:15.413713 47978602034560 learning.py:507] global step 4484: loss = 6.5125 (0.502 sec/step)
I0404 20:44:15.921375 47978602034560 learning.py:507] global step 4485: loss = 5.8034 (0.505 sec/step)
I0404 20:44:16.434610 47978602034560 learning.py:507] global step 4486: loss = 6.4419 (0.510 sec/step)
I0404 20:44:16.939484 47978602034560 learning.py:507] global step 4487: loss = 6.2007 (0.503 sec/step)
I0404 20:44:17.471479 47978602034560 learning.py:507] global step 4488: loss = 7.0496 (0.530 sec/step)
I0404 20:44:17.977274 47978602034560 learning.py:507] global step 4489: loss = 5.8135 (0.504 sec/step)
I0404 20:44:18.485059 47978602034560 learning.py:507] global step 4490: loss = 5.8593 (0.506 sec/step)
I0404 20:44:18.988755 47978602034560 learning.py:507] global step 4491: loss = 5.9488 (0.501 sec/step)
I0404 20:44:19.515715 47978602034560 learning.py:507] global step 4492: loss = 6.2701 (0.525 sec/step)
I0404 20:44:20.040203 47978602034560 learning.py:507] global step 4493: loss = 5.7023 (0.523 sec/step)
I0404 20:44:20.551960 47978602034560 learning.py:507] global step 4494: loss = 6.5280 (0.510 sec/step)
I0404 20:44:21.059652 47978602034560 learning.py:507] global step 4495: loss = 5.2050 (0.506 sec/step)
I0404 20:44:21.573307 47978602034560 learning.py:507] global step 4496: loss = 6.6670 (0.512 sec/step)
I0404 20:44:22.090142 47978602034560 learning.py:507] global step 4497: loss = 6.1301 (0.515 sec/step)
I0404 20:44:22.606204 47978602034560 learning.py:507] global step 4498: loss = 5.5042 (0.514 sec/step)
I0404 20:44:23.106634 47978602034560 learning.py:507] global step 4499: loss = 5.7671 (0.499 sec/step)
I0404 20:44:23.612871 47978602034560 learning.py:507] global step 4500: loss = 5.7003 (0.505 sec/step)
I0404 20:44:24.119313 47978602034560 learning.py:507] global step 4501: loss = 5.4609 (0.505 sec/step)
I0404 20:44:24.632014 47978602034560 learning.py:507] global step 4502: loss = 6.8982 (0.511 sec/step)
I0404 20:44:25.145759 47978602034560 learning.py:507] global step 4503: loss = 5.4612 (0.512 sec/step)
I0404 20:44:25.661461 47978602034560 learning.py:507] global step 4504: loss = 5.9447 (0.514 sec/step)
I0404 20:44:26.174903 47978602034560 learning.py:507] global step 4505: loss = 5.9320 (0.512 sec/step)
I0404 20:44:26.705525 47978602034560 learning.py:507] global step 4506: loss = 6.7961 (0.529 sec/step)
I0404 20:44:27.218562 47978602034560 learning.py:507] global step 4507: loss = 6.3752 (0.511 sec/step)
I0404 20:44:27.723353 47978602034560 learning.py:507] global step 4508: loss = 6.4397 (0.503 sec/step)
I0404 20:44:28.229559 47978602034560 learning.py:507] global step 4509: loss = 5.7931 (0.505 sec/step)
I0404 20:44:28.731873 47978602034560 learning.py:507] global step 4510: loss = 5.3442 (0.499 sec/step)
I0404 20:44:29.236776 47978602034560 learning.py:507] global step 4511: loss = 5.8171 (0.503 sec/step)
I0404 20:44:29.751380 47978602034560 learning.py:507] global step 4512: loss = 6.0307 (0.513 sec/step)
I0404 20:44:30.262779 47978602034560 learning.py:507] global step 4513: loss = 6.4321 (0.510 sec/step)
I0404 20:44:30.774184 47978602034560 learning.py:507] global step 4514: loss = 7.2177 (0.510 sec/step)
I0404 20:44:31.310413 47978602034560 learning.py:507] global step 4515: loss = 6.2178 (0.535 sec/step)
I0404 20:44:31.814161 47978602034560 learning.py:507] global step 4516: loss = 6.7398 (0.502 sec/step)
I0404 20:44:32.321299 47978602034560 learning.py:507] global step 4517: loss = 6.3604 (0.506 sec/step)
I0404 20:44:32.837174 47978602034560 learning.py:507] global step 4518: loss = 5.7741 (0.513 sec/step)
I0404 20:44:33.346583 47978602034560 learning.py:507] global step 4519: loss = 6.1647 (0.508 sec/step)
I0404 20:44:33.881036 47978602034560 learning.py:507] global step 4520: loss = 5.9381 (0.533 sec/step)
I0404 20:44:34.387650 47978602034560 learning.py:507] global step 4521: loss = 6.2399 (0.504 sec/step)
I0404 20:44:34.897068 47978602034560 learning.py:507] global step 4522: loss = 6.1058 (0.507 sec/step)
I0404 20:44:35.406706 47978602034560 learning.py:507] global step 4523: loss = 5.6980 (0.507 sec/step)
I0404 20:44:35.924832 47978602034560 learning.py:507] global step 4524: loss = 6.0203 (0.515 sec/step)
I0404 20:44:36.435038 47978602034560 learning.py:507] global step 4525: loss = 6.2001 (0.509 sec/step)
I0404 20:44:36.965291 47978602034560 learning.py:507] global step 4526: loss = 6.2742 (0.529 sec/step)
I0404 20:44:37.473257 47978602034560 learning.py:507] global step 4527: loss = 6.6309 (0.506 sec/step)
I0404 20:44:37.984064 47978602034560 learning.py:507] global step 4528: loss = 6.8987 (0.508 sec/step)
I0404 20:44:38.494421 47978602034560 learning.py:507] global step 4529: loss = 5.7719 (0.509 sec/step)
I0404 20:44:39.009963 47978602034560 learning.py:507] global step 4530: loss = 5.3716 (0.514 sec/step)
I0404 20:44:39.520750 47978602034560 learning.py:507] global step 4531: loss = 6.9377 (0.509 sec/step)
I0404 20:44:40.025757 47978602034560 learning.py:507] global step 4532: loss = 6.2652 (0.503 sec/step)
I0404 20:44:40.561685 47978602034560 learning.py:507] global step 4533: loss = 6.1305 (0.534 sec/step)
I0404 20:44:41.071643 47978602034560 learning.py:507] global step 4534: loss = 5.5563 (0.508 sec/step)
I0404 20:44:41.580107 47978602034560 learning.py:507] global step 4535: loss = 6.0777 (0.507 sec/step)
I0404 20:44:42.082993 47978602034560 learning.py:507] global step 4536: loss = 6.2736 (0.501 sec/step)
I0404 20:44:42.594634 47978602034560 learning.py:507] global step 4537: loss = 6.0516 (0.510 sec/step)
I0404 20:44:43.106269 47978602034560 learning.py:507] global step 4538: loss = 5.6181 (0.509 sec/step)
I0404 20:44:43.615755 47978602034560 learning.py:507] global step 4539: loss = 5.7147 (0.508 sec/step)
I0404 20:44:44.126641 47978602034560 learning.py:507] global step 4540: loss = 5.7053 (0.508 sec/step)
I0404 20:44:44.645750 47978602034560 learning.py:507] global step 4541: loss = 5.3547 (0.517 sec/step)
I0404 20:44:45.152570 47978602034560 learning.py:507] global step 4542: loss = 7.2602 (0.504 sec/step)
I0404 20:44:45.689422 47978602034560 learning.py:507] global step 4543: loss = 6.1879 (0.535 sec/step)
I0404 20:44:46.206038 47978602034560 learning.py:507] global step 4544: loss = 6.9701 (0.515 sec/step)
I0404 20:44:46.719147 47978602034560 learning.py:507] global step 4545: loss = 5.1789 (0.512 sec/step)
I0404 20:44:47.229797 47978602034560 learning.py:507] global step 4546: loss = 5.8736 (0.509 sec/step)
I0404 20:44:47.733191 47978602034560 learning.py:507] global step 4547: loss = 6.6417 (0.502 sec/step)
I0404 20:44:48.236600 47978602034560 learning.py:507] global step 4548: loss = 6.0750 (0.502 sec/step)
I0404 20:44:48.780394 47978602034560 learning.py:507] global step 4549: loss = 6.5722 (0.542 sec/step)
I0404 20:44:49.288183 47978602034560 learning.py:507] global step 4550: loss = 5.6601 (0.505 sec/step)
I0404 20:44:49.802904 47978602034560 learning.py:507] global step 4551: loss = 6.3193 (0.512 sec/step)
I0404 20:44:50.304006 47978602034560 learning.py:507] global step 4552: loss = 6.6883 (0.498 sec/step)
I0404 20:44:50.808882 47978602034560 learning.py:507] global step 4553: loss = 5.6179 (0.502 sec/step)
I0404 20:44:51.341078 47978602034560 learning.py:507] global step 4554: loss = 5.2281 (0.531 sec/step)
I0404 20:44:51.876484 47978602034560 learning.py:507] global step 4555: loss = 6.0681 (0.534 sec/step)
I0404 20:44:52.384832 47978602034560 learning.py:507] global step 4556: loss = 5.9440 (0.507 sec/step)
I0404 20:44:52.904868 47978602034560 learning.py:507] global step 4557: loss = 5.6512 (0.517 sec/step)
I0404 20:44:53.413201 47978602034560 learning.py:507] global step 4558: loss = 5.2526 (0.505 sec/step)
I0404 20:44:53.914030 47978602034560 learning.py:507] global step 4559: loss = 6.2579 (0.499 sec/step)
I0404 20:44:54.420184 47978602034560 learning.py:507] global step 4560: loss = 6.1034 (0.503 sec/step)
I0404 20:44:54.923628 47978602034560 learning.py:507] global step 4561: loss = 6.8255 (0.502 sec/step)
I0404 20:44:55.460690 47978602034560 learning.py:507] global step 4562: loss = 6.2019 (0.535 sec/step)
I0404 20:44:55.988966 47978602034560 learning.py:507] global step 4563: loss = 5.7311 (0.527 sec/step)
I0404 20:44:56.506706 47978602034560 learning.py:507] global step 4564: loss = 6.0751 (0.516 sec/step)
I0404 20:44:57.045393 47978602034560 learning.py:507] global step 4565: loss = 5.1406 (0.537 sec/step)
I0404 20:44:57.561706 47978602034560 learning.py:507] global step 4566: loss = 5.9920 (0.515 sec/step)
I0404 20:44:58.069883 47978602034560 learning.py:507] global step 4567: loss = 6.0387 (0.507 sec/step)
I0404 20:44:58.579867 47978602034560 learning.py:507] global step 4568: loss = 7.0840 (0.508 sec/step)
I0404 20:44:59.084627 47978602034560 learning.py:507] global step 4569: loss = 5.8624 (0.502 sec/step)
I0404 20:44:59.588445 47978602034560 learning.py:507] global step 4570: loss = 6.3187 (0.502 sec/step)
I0404 20:45:00.094863 47978602034560 learning.py:507] global step 4571: loss = 6.1514 (0.505 sec/step)
I0404 20:45:00.621683 47978602034560 learning.py:507] global step 4572: loss = 6.1302 (0.524 sec/step)
I0404 20:45:01.139055 47978602034560 learning.py:507] global step 4573: loss = 7.0151 (0.516 sec/step)
I0404 20:45:01.671114 47978602034560 learning.py:507] global step 4574: loss = 7.5582 (0.529 sec/step)
I0404 20:45:02.178615 47978602034560 learning.py:507] global step 4575: loss = 5.7485 (0.506 sec/step)
I0404 20:45:02.688039 47978602034560 learning.py:507] global step 4576: loss = 5.5964 (0.508 sec/step)
I0404 20:45:03.192934 47978602034560 learning.py:507] global step 4577: loss = 5.6831 (0.503 sec/step)
I0404 20:45:03.711813 47978602034560 learning.py:507] global step 4578: loss = 5.3127 (0.517 sec/step)
I0404 20:45:04.226015 47978602034560 learning.py:507] global step 4579: loss = 5.3263 (0.513 sec/step)
I0404 20:45:04.731509 47978602034560 learning.py:507] global step 4580: loss = 5.6584 (0.504 sec/step)
I0404 20:45:05.247776 47978602034560 learning.py:507] global step 4581: loss = 5.1779 (0.515 sec/step)
I0404 20:45:05.751854 47978602034560 learning.py:507] global step 4582: loss = 6.7119 (0.501 sec/step)
I0404 20:45:06.269602 47978602034560 learning.py:507] global step 4583: loss = 5.5373 (0.515 sec/step)
I0404 20:45:06.778303 47978602034560 learning.py:507] global step 4584: loss = 6.8690 (0.506 sec/step)
I0404 20:45:07.292299 47978602034560 learning.py:507] global step 4585: loss = 5.0476 (0.512 sec/step)
I0404 20:45:07.796506 47978602034560 learning.py:507] global step 4586: loss = 6.3219 (0.501 sec/step)
I0404 20:45:08.308540 47978602034560 learning.py:507] global step 4587: loss = 5.2710 (0.509 sec/step)
I0404 20:45:08.819633 47978602034560 learning.py:507] global step 4588: loss = 7.2338 (0.510 sec/step)
I0404 20:45:09.343481 47978602034560 learning.py:507] global step 4589: loss = 7.0869 (0.522 sec/step)
I0404 20:45:09.859065 47978602034560 learning.py:507] global step 4590: loss = 6.0282 (0.514 sec/step)
I0404 20:45:10.377200 47978602034560 learning.py:507] global step 4591: loss = 6.7623 (0.515 sec/step)
I0404 20:45:10.887525 47978602034560 learning.py:507] global step 4592: loss = 5.8680 (0.509 sec/step)
I0404 20:45:11.412739 47978602034560 learning.py:507] global step 4593: loss = 5.6129 (0.524 sec/step)
I0404 20:45:11.922207 47978602034560 learning.py:507] global step 4594: loss = 5.7642 (0.508 sec/step)
I0404 20:45:12.441359 47978602034560 learning.py:507] global step 4595: loss = 5.9144 (0.516 sec/step)
I0404 20:45:12.945535 47978602034560 learning.py:507] global step 4596: loss = 6.8238 (0.503 sec/step)
I0404 20:45:13.448343 47978602034560 learning.py:507] global step 4597: loss = 5.0607 (0.501 sec/step)
I0404 20:45:13.953136 47978602034560 learning.py:507] global step 4598: loss = 6.1044 (0.503 sec/step)
I0404 20:45:14.489560 47978602034560 learning.py:507] global step 4599: loss = 6.5241 (0.535 sec/step)
I0404 20:45:14.996803 47978602034560 learning.py:507] global step 4600: loss = 6.1842 (0.506 sec/step)
I0404 20:45:15.508493 47978602034560 learning.py:507] global step 4601: loss = 7.2582 (0.510 sec/step)
I0404 20:45:16.022097 47978602034560 learning.py:507] global step 4602: loss = 5.6781 (0.511 sec/step)
I0404 20:45:16.531100 47978602034560 learning.py:507] global step 4603: loss = 7.3515 (0.507 sec/step)
I0404 20:45:16.636528 47983666177792 supervisor.py:1117] Saving checkpoint to path ../../trainingOutput/model.ckpt
I0404 20:45:17.240886 47983661975296 supervisor.py:1050] Recording summary at step 4604.
I0404 20:45:17.251609 47978602034560 learning.py:507] global step 4604: loss = 5.7221 (0.709 sec/step)
I0404 20:45:17.901001 47978602034560 learning.py:507] global step 4605: loss = 5.8548 (0.568 sec/step)
I0404 20:45:18.430593 47978602034560 learning.py:507] global step 4606: loss = 6.6521 (0.525 sec/step)
I0404 20:45:18.935172 47978602034560 learning.py:507] global step 4607: loss = 4.9532 (0.503 sec/step)
I0404 20:45:19.441797 47978602034560 learning.py:507] global step 4608: loss = 5.7702 (0.505 sec/step)
I0404 20:45:19.968659 47978602034560 learning.py:507] global step 4609: loss = 5.4920 (0.525 sec/step)
I0404 20:45:20.501250 47978602034560 learning.py:507] global step 4610: loss = 5.9436 (0.531 sec/step)
I0404 20:45:21.014969 47978602034560 learning.py:507] global step 4611: loss = 5.9371 (0.512 sec/step)
I0404 20:45:21.548565 47978602034560 learning.py:507] global step 4612: loss = 7.5208 (0.532 sec/step)
I0404 20:45:22.054729 47978602034560 learning.py:507] global step 4613: loss = 5.6650 (0.505 sec/step)
I0404 20:45:22.585981 47978602034560 learning.py:507] global step 4614: loss = 7.0650 (0.528 sec/step)
I0404 20:45:23.097021 47978602034560 learning.py:507] global step 4615: loss = 6.5519 (0.509 sec/step)
I0404 20:45:23.618579 47978602034560 learning.py:507] global step 4616: loss = 5.3189 (0.520 sec/step)
I0404 20:45:24.139262 47978602034560 learning.py:507] global step 4617: loss = 5.1254 (0.519 sec/step)
I0404 20:45:24.641326 47978602034560 learning.py:507] global step 4618: loss = 6.4450 (0.501 sec/step)
I0404 20:45:25.182631 47978602034560 learning.py:507] global step 4619: loss = 6.4030 (0.538 sec/step)
I0404 20:45:25.696546 47978602034560 learning.py:507] global step 4620: loss = 5.6879 (0.512 sec/step)
I0404 20:45:26.205607 47978602034560 learning.py:507] global step 4621: loss = 5.9774 (0.506 sec/step)
I0404 20:45:26.715785 47978602034560 learning.py:507] global step 4622: loss = 6.9645 (0.508 sec/step)
I0404 20:45:27.221459 47978602034560 learning.py:507] global step 4623: loss = 6.4223 (0.504 sec/step)
I0404 20:45:27.727060 47978602034560 learning.py:507] global step 4624: loss = 5.2320 (0.503 sec/step)
I0404 20:45:28.240738 47978602034560 learning.py:507] global step 4625: loss = 6.3624 (0.511 sec/step)
I0404 20:45:28.762137 47978602034560 learning.py:507] global step 4626: loss = 6.6703 (0.518 sec/step)
I0404 20:45:29.299368 47978602034560 learning.py:507] global step 4627: loss = 6.4201 (0.536 sec/step)
I0404 20:45:29.833672 47978602034560 learning.py:507] global step 4628: loss = 6.1697 (0.533 sec/step)
I0404 20:45:30.359060 47978602034560 learning.py:507] global step 4629: loss = 5.6354 (0.524 sec/step)
I0404 20:45:30.859876 47978602034560 learning.py:507] global step 4630: loss = 6.0591 (0.499 sec/step)
I0404 20:45:31.363438 47978602034560 learning.py:507] global step 4631: loss = 5.2448 (0.502 sec/step)
I0404 20:45:31.884859 47978602034560 learning.py:507] global step 4632: loss = 6.2886 (0.520 sec/step)
I0404 20:45:32.385699 47978602034560 learning.py:507] global step 4633: loss = 7.1775 (0.499 sec/step)
I0404 20:45:32.898991 47978602034560 learning.py:507] global step 4634: loss = 5.9273 (0.512 sec/step)
I0404 20:45:33.414431 47978602034560 learning.py:507] global step 4635: loss = 6.3827 (0.514 sec/step)
I0404 20:45:33.924606 47978602034560 learning.py:507] global step 4636: loss = 6.9604 (0.507 sec/step)
I0404 20:45:34.432338 47978602034560 learning.py:507] global step 4637: loss = 6.6314 (0.505 sec/step)
I0404 20:45:34.939141 47978602034560 learning.py:507] global step 4638: loss = 7.0572 (0.505 sec/step)
I0404 20:45:35.447715 47978602034560 learning.py:507] global step 4639: loss = 5.8423 (0.507 sec/step)
I0404 20:45:35.957777 47978602034560 learning.py:507] global step 4640: loss = 5.9719 (0.508 sec/step)
I0404 20:45:36.471506 47978602034560 learning.py:507] global step 4641: loss = 5.6088 (0.511 sec/step)
I0404 20:45:36.974330 47978602034560 learning.py:507] global step 4642: loss = 7.3171 (0.501 sec/step)
I0404 20:45:37.477870 47978602034560 learning.py:507] global step 4643: loss = 6.7092 (0.502 sec/step)
I0404 20:45:37.988754 47978602034560 learning.py:507] global step 4644: loss = 5.8722 (0.509 sec/step)
I0404 20:45:38.503693 47978602034560 learning.py:507] global step 4645: loss = 5.6183 (0.513 sec/step)
I0404 20:45:39.018049 47978602034560 learning.py:507] global step 4646: loss = 6.1728 (0.513 sec/step)
I0404 20:45:39.541019 47978602034560 learning.py:507] global step 4647: loss = 5.9808 (0.521 sec/step)
I0404 20:45:40.072032 47978602034560 learning.py:507] global step 4648: loss = 7.2420 (0.529 sec/step)
I0404 20:45:40.607489 47978602034560 learning.py:507] global step 4649: loss = 5.6811 (0.534 sec/step)
I0404 20:45:41.113647 47978602034560 learning.py:507] global step 4650: loss = 5.7073 (0.503 sec/step)
I0404 20:45:41.627699 47978602034560 learning.py:507] global step 4651: loss = 6.3578 (0.512 sec/step)
I0404 20:45:42.151179 47978602034560 learning.py:507] global step 4652: loss = 5.9792 (0.521 sec/step)
I0404 20:45:42.656532 47978602034560 learning.py:507] global step 4653: loss = 6.0052 (0.502 sec/step)
I0404 20:45:43.158953 47978602034560 learning.py:507] global step 4654: loss = 6.8845 (0.501 sec/step)
I0404 20:45:43.676024 47978602034560 learning.py:507] global step 4655: loss = 7.9003 (0.514 sec/step)
I0404 20:45:44.177147 47978602034560 learning.py:507] global step 4656: loss = 5.5244 (0.499 sec/step)
I0404 20:45:44.691013 47978602034560 learning.py:507] global step 4657: loss = 6.4252 (0.512 sec/step)
I0404 20:45:45.195407 47978602034560 learning.py:507] global step 4658: loss = 5.4193 (0.501 sec/step)
I0404 20:45:45.726942 47978602034560 learning.py:507] global step 4659: loss = 6.9562 (0.530 sec/step)
I0404 20:45:46.237425 47978602034560 learning.py:507] global step 4660: loss = 5.8415 (0.508 sec/step)
I0404 20:45:46.746958 47978602034560 learning.py:507] global step 4661: loss = 5.7828 (0.507 sec/step)
I0404 20:45:47.262010 47978602034560 learning.py:507] global step 4662: loss = 6.9948 (0.513 sec/step)
I0404 20:45:47.775780 47978602034560 learning.py:507] global step 4663: loss = 5.6154 (0.512 sec/step)
I0404 20:45:48.278055 47978602034560 learning.py:507] global step 4664: loss = 6.5780 (0.501 sec/step)
I0404 20:45:48.803278 47978602034560 learning.py:507] global step 4665: loss = 5.9026 (0.522 sec/step)
I0404 20:45:49.310119 47978602034560 learning.py:507] global step 4666: loss = 5.7075 (0.505 sec/step)
I0404 20:45:49.845070 47978602034560 learning.py:507] global step 4667: loss = 5.5878 (0.533 sec/step)
I0404 20:45:50.383439 47978602034560 learning.py:507] global step 4668: loss = 6.4022 (0.537 sec/step)
I0404 20:45:50.912186 47978602034560 learning.py:507] global step 4669: loss = 5.6922 (0.527 sec/step)
I0404 20:45:51.426187 47978602034560 learning.py:507] global step 4670: loss = 5.9084 (0.511 sec/step)
I0404 20:45:51.942355 47978602034560 learning.py:507] global step 4671: loss = 6.8422 (0.513 sec/step)
I0404 20:45:52.447800 47978602034560 learning.py:507] global step 4672: loss = 6.8586 (0.504 sec/step)
I0404 20:45:52.961730 47978602034560 learning.py:507] global step 4673: loss = 6.7167 (0.511 sec/step)
I0404 20:45:53.480417 47978602034560 learning.py:507] global step 4674: loss = 5.3996 (0.517 sec/step)
I0404 20:45:53.994180 47978602034560 learning.py:507] global step 4675: loss = 6.4500 (0.512 sec/step)
I0404 20:45:54.531698 47978602034560 learning.py:507] global step 4676: loss = 6.3776 (0.535 sec/step)
I0404 20:45:55.036594 47978602034560 learning.py:507] global step 4677: loss = 6.1884 (0.503 sec/step)
I0404 20:45:55.543302 47978602034560 learning.py:507] global step 4678: loss = 5.7305 (0.504 sec/step)
I0404 20:45:56.064154 47978602034560 learning.py:507] global step 4679: loss = 6.1892 (0.519 sec/step)
I0404 20:45:56.574012 47978602034560 learning.py:507] global step 4680: loss = 6.3492 (0.508 sec/step)
I0404 20:45:57.081602 47978602034560 learning.py:507] global step 4681: loss = 6.1888 (0.506 sec/step)
I0404 20:45:57.588706 47978602034560 learning.py:507] global step 4682: loss = 7.7943 (0.505 sec/step)
I0404 20:45:58.110947 47978602034560 learning.py:507] global step 4683: loss = 6.4510 (0.521 sec/step)
I0404 20:45:58.614171 47978602034560 learning.py:507] global step 4684: loss = 7.1348 (0.500 sec/step)
I0404 20:45:59.126577 47978602034560 learning.py:507] global step 4685: loss = 5.6036 (0.511 sec/step)
I0404 20:45:59.664735 47978602034560 learning.py:507] global step 4686: loss = 6.4879 (0.537 sec/step)
I0404 20:46:00.168559 47978602034560 learning.py:507] global step 4687: loss = 6.4512 (0.502 sec/step)
I0404 20:46:00.709910 47978602034560 learning.py:507] global step 4688: loss = 7.1087 (0.540 sec/step)
I0404 20:46:01.228549 47978602034560 learning.py:507] global step 4689: loss = 6.1018 (0.517 sec/step)
I0404 20:46:01.747837 47978602034560 learning.py:507] global step 4690: loss = 5.9035 (0.518 sec/step)
I0404 20:46:02.276637 47978602034560 learning.py:507] global step 4691: loss = 7.2526 (0.527 sec/step)
I0404 20:46:02.800935 47978602034560 learning.py:507] global step 4692: loss = 6.5084 (0.523 sec/step)
I0404 20:46:03.332163 47978602034560 learning.py:507] global step 4693: loss = 6.0171 (0.530 sec/step)
I0404 20:46:03.838101 47978602034560 learning.py:507] global step 4694: loss = 4.8912 (0.504 sec/step)
I0404 20:46:04.379727 47978602034560 learning.py:507] global step 4695: loss = 5.3363 (0.540 sec/step)
I0404 20:46:04.892857 47978602034560 learning.py:507] global step 4696: loss = 5.8190 (0.510 sec/step)
I0404 20:46:05.394239 47978602034560 learning.py:507] global step 4697: loss = 5.7775 (0.499 sec/step)
I0404 20:46:05.899382 47978602034560 learning.py:507] global step 4698: loss = 5.3265 (0.504 sec/step)
I0404 20:46:06.410435 47978602034560 learning.py:507] global step 4699: loss = 6.4644 (0.510 sec/step)
I0404 20:46:06.943305 47978602034560 learning.py:507] global step 4700: loss = 6.0296 (0.531 sec/step)
I0404 20:46:07.453420 47978602034560 learning.py:507] global step 4701: loss = 6.1281 (0.509 sec/step)
I0404 20:46:07.967125 47978602034560 learning.py:507] global step 4702: loss = 5.2075 (0.512 sec/step)
I0404 20:46:08.470149 47978602034560 learning.py:507] global step 4703: loss = 4.8786 (0.501 sec/step)
I0404 20:46:08.977379 47978602034560 learning.py:507] global step 4704: loss = 6.4254 (0.504 sec/step)
I0404 20:46:09.479268 47978602034560 learning.py:507] global step 4705: loss = 6.7146 (0.499 sec/step)
I0404 20:46:09.982284 47978602034560 learning.py:507] global step 4706: loss = 6.1088 (0.501 sec/step)
I0404 20:46:10.496822 47978602034560 learning.py:507] global step 4707: loss = 5.2404 (0.513 sec/step)
I0404 20:46:10.999746 47978602034560 learning.py:507] global step 4708: loss = 7.0672 (0.501 sec/step)
I0404 20:46:11.545429 47978602034560 learning.py:507] global step 4709: loss = 6.3326 (0.543 sec/step)
I0404 20:46:12.064153 47978602034560 learning.py:507] global step 4710: loss = 6.6547 (0.517 sec/step)
I0404 20:46:12.574169 47978602034560 learning.py:507] global step 4711: loss = 5.9010 (0.508 sec/step)
I0404 20:46:13.087739 47978602034560 learning.py:507] global step 4712: loss = 6.4232 (0.512 sec/step)
I0404 20:46:13.593511 47978602034560 learning.py:507] global step 4713: loss = 6.0440 (0.504 sec/step)
I0404 20:46:14.110826 47978602034560 learning.py:507] global step 4714: loss = 6.3741 (0.516 sec/step)
I0404 20:46:14.627612 47978602034560 learning.py:507] global step 4715: loss = 6.8663 (0.515 sec/step)
I0404 20:46:15.135199 47978602034560 learning.py:507] global step 4716: loss = 5.4789 (0.506 sec/step)
I0404 20:46:15.668064 47978602034560 learning.py:507] global step 4717: loss = 5.9004 (0.531 sec/step)
I0404 20:46:16.177666 47978602034560 learning.py:507] global step 4718: loss = 6.1592 (0.508 sec/step)
I0404 20:46:16.684543 47978602034560 learning.py:507] global step 4719: loss = 6.2043 (0.504 sec/step)
I0404 20:46:17.191103 47978602034560 learning.py:507] global step 4720: loss = 6.0494 (0.505 sec/step)
I0404 20:46:17.726493 47978602034560 learning.py:507] global step 4721: loss = 6.7798 (0.534 sec/step)
I0404 20:46:18.239554 47978602034560 learning.py:507] global step 4722: loss = 5.5592 (0.512 sec/step)
I0404 20:46:18.743168 47978602034560 learning.py:507] global step 4723: loss = 5.1774 (0.502 sec/step)
I0404 20:46:19.266076 47978602034560 learning.py:507] global step 4724: loss = 6.0242 (0.521 sec/step)
I0404 20:46:19.767290 47978602034560 learning.py:507] global step 4725: loss = 6.2008 (0.498 sec/step)
I0404 20:46:20.278238 47978602034560 learning.py:507] global step 4726: loss = 6.4567 (0.509 sec/step)
I0404 20:46:20.792114 47978602034560 learning.py:507] global step 4727: loss = 5.5937 (0.512 sec/step)
I0404 20:46:21.299057 47978602034560 learning.py:507] global step 4728: loss = 6.7161 (0.504 sec/step)
I0404 20:46:21.804248 47978602034560 learning.py:507] global step 4729: loss = 7.3013 (0.504 sec/step)
I0404 20:46:22.309369 47978602034560 learning.py:507] global step 4730: loss = 6.3359 (0.504 sec/step)
I0404 20:46:22.843905 47978602034560 learning.py:507] global step 4731: loss = 6.3365 (0.533 sec/step)
I0404 20:46:23.361643 47978602034560 learning.py:507] global step 4732: loss = 6.3156 (0.516 sec/step)
I0404 20:46:23.881851 47978602034560 learning.py:507] global step 4733: loss = 5.5826 (0.519 sec/step)
I0404 20:46:24.391538 47978602034560 learning.py:507] global step 4734: loss = 6.5843 (0.507 sec/step)
I0404 20:46:24.921007 47978602034560 learning.py:507] global step 4735: loss = 4.9776 (0.528 sec/step)
I0404 20:46:25.426963 47978602034560 learning.py:507] global step 4736: loss = 5.6957 (0.503 sec/step)
I0404 20:46:25.931948 47978602034560 learning.py:507] global step 4737: loss = 6.1259 (0.502 sec/step)
I0404 20:46:26.462167 47978602034560 learning.py:507] global step 4738: loss = 5.2170 (0.527 sec/step)
I0404 20:46:26.963762 47978602034560 learning.py:507] global step 4739: loss = 5.8182 (0.500 sec/step)
I0404 20:46:27.485058 47978602034560 learning.py:507] global step 4740: loss = 5.6940 (0.520 sec/step)
I0404 20:46:27.997494 47978602034560 learning.py:507] global step 4741: loss = 6.2208 (0.510 sec/step)
I0404 20:46:28.504359 47978602034560 learning.py:507] global step 4742: loss = 6.4597 (0.505 sec/step)
I0404 20:46:29.010637 47978602034560 learning.py:507] global step 4743: loss = 6.7492 (0.505 sec/step)
I0404 20:46:29.525605 47978602034560 learning.py:507] global step 4744: loss = 6.1138 (0.513 sec/step)
I0404 20:46:30.041272 47978602034560 learning.py:507] global step 4745: loss = 5.7198 (0.513 sec/step)
I0404 20:46:30.565889 47978602034560 learning.py:507] global step 4746: loss = 6.0857 (0.523 sec/step)
I0404 20:46:31.074221 47978602034560 learning.py:507] global step 4747: loss = 5.4914 (0.507 sec/step)
I0404 20:46:31.573813 47978602034560 learning.py:507] global step 4748: loss = 5.2948 (0.498 sec/step)
I0404 20:46:32.082497 47978602034560 learning.py:507] global step 4749: loss = 5.8322 (0.506 sec/step)
I0404 20:46:32.619248 47978602034560 learning.py:507] global step 4750: loss = 5.9051 (0.535 sec/step)
I0404 20:46:33.152617 47978602034560 learning.py:507] global step 4751: loss = 6.3009 (0.532 sec/step)
I0404 20:46:33.696199 47978602034560 learning.py:507] global step 4752: loss = 6.7419 (0.542 sec/step)
I0404 20:46:34.201726 47978602034560 learning.py:507] global step 4753: loss = 6.5710 (0.504 sec/step)
I0404 20:46:34.713059 47978602034560 learning.py:507] global step 4754: loss = 5.7351 (0.510 sec/step)
I0404 20:46:35.253293 47978602034560 learning.py:507] global step 4755: loss = 6.6354 (0.539 sec/step)
I0404 20:46:35.755563 47978602034560 learning.py:507] global step 4756: loss = 6.1141 (0.499 sec/step)
I0404 20:46:36.280718 47978602034560 learning.py:507] global step 4757: loss = 5.5300 (0.524 sec/step)
I0404 20:46:36.801613 47978602034560 learning.py:507] global step 4758: loss = 6.5120 (0.519 sec/step)
I0404 20:46:37.315706 47978602034560 learning.py:507] global step 4759: loss = 5.9904 (0.512 sec/step)
I0404 20:46:37.830678 47978602034560 learning.py:507] global step 4760: loss = 5.9335 (0.513 sec/step)
I0404 20:46:38.364503 47978602034560 learning.py:507] global step 4761: loss = 5.5133 (0.532 sec/step)
I0404 20:46:38.874425 47978602034560 learning.py:507] global step 4762: loss = 6.4452 (0.508 sec/step)
I0404 20:46:39.417432 47978602034560 learning.py:507] global step 4763: loss = 5.7447 (0.540 sec/step)
I0404 20:46:39.941684 47978602034560 learning.py:507] global step 4764: loss = 5.4861 (0.523 sec/step)
I0404 20:46:40.455100 47978602034560 learning.py:507] global step 4765: loss = 7.2867 (0.511 sec/step)
I0404 20:46:40.968076 47978602034560 learning.py:507] global step 4766: loss = 5.6069 (0.510 sec/step)
I0404 20:46:41.498732 47978602034560 learning.py:507] global step 4767: loss = 6.0008 (0.529 sec/step)
I0404 20:46:41.998902 47978602034560 learning.py:507] global step 4768: loss = 5.1982 (0.499 sec/step)
I0404 20:46:42.509167 47978602034560 learning.py:507] global step 4769: loss = 5.6287 (0.507 sec/step)
I0404 20:46:43.048626 47978602034560 learning.py:507] global step 4770: loss = 5.8815 (0.538 sec/step)
I0404 20:46:43.560610 47978602034560 learning.py:507] global step 4771: loss = 5.4010 (0.510 sec/step)
I0404 20:46:44.073148 47978602034560 learning.py:507] global step 4772: loss = 5.7640 (0.510 sec/step)
I0404 20:46:44.588719 47978602034560 learning.py:507] global step 4773: loss = 7.3685 (0.514 sec/step)
I0404 20:46:45.099188 47978602034560 learning.py:507] global step 4774: loss = 5.5858 (0.509 sec/step)
I0404 20:46:45.609577 47978602034560 learning.py:507] global step 4775: loss = 6.3907 (0.508 sec/step)
I0404 20:46:46.127002 47978602034560 learning.py:507] global step 4776: loss = 7.2727 (0.516 sec/step)
I0404 20:46:46.661638 47978602034560 learning.py:507] global step 4777: loss = 7.0736 (0.532 sec/step)
I0404 20:46:47.177964 47978602034560 learning.py:507] global step 4778: loss = 5.4568 (0.513 sec/step)
I0404 20:46:47.686352 47978602034560 learning.py:507] global step 4779: loss = 6.3953 (0.506 sec/step)
I0404 20:46:48.214187 47978602034560 learning.py:507] global step 4780: loss = 5.9827 (0.525 sec/step)
I0404 20:46:48.728242 47978602034560 learning.py:507] global step 4781: loss = 5.1600 (0.512 sec/step)
I0404 20:46:49.239101 47978602034560 learning.py:507] global step 4782: loss = 6.6056 (0.509 sec/step)
I0404 20:46:49.744747 47978602034560 learning.py:507] global step 4783: loss = 6.1326 (0.504 sec/step)
I0404 20:46:50.260060 47978602034560 learning.py:507] global step 4784: loss = 6.1009 (0.512 sec/step)
I0404 20:46:50.766198 47978602034560 learning.py:507] global step 4785: loss = 6.5420 (0.504 sec/step)
I0404 20:46:51.280347 47978602034560 learning.py:507] global step 4786: loss = 7.1780 (0.512 sec/step)
I0404 20:46:51.792333 47978602034560 learning.py:507] global step 4787: loss = 5.7419 (0.510 sec/step)
I0404 20:46:52.299086 47978602034560 learning.py:507] global step 4788: loss = 5.4595 (0.505 sec/step)
I0404 20:46:52.834661 47978602034560 learning.py:507] global step 4789: loss = 6.3506 (0.533 sec/step)
I0404 20:46:53.352797 47978602034560 learning.py:507] global step 4790: loss = 5.6498 (0.517 sec/step)
I0404 20:46:53.862443 47978602034560 learning.py:507] global step 4791: loss = 6.2662 (0.508 sec/step)
I0404 20:46:54.372085 47978602034560 learning.py:507] global step 4792: loss = 5.8651 (0.508 sec/step)
I0404 20:46:54.894311 47978602034560 learning.py:507] global step 4793: loss = 6.2512 (0.521 sec/step)
I0404 20:46:55.428946 47978602034560 learning.py:507] global step 4794: loss = 6.2352 (0.533 sec/step)
I0404 20:46:55.930460 47978602034560 learning.py:507] global step 4795: loss = 5.8079 (0.500 sec/step)
I0404 20:46:56.457889 47978602034560 learning.py:507] global step 4796: loss = 6.4036 (0.524 sec/step)
I0404 20:46:57.001120 47978602034560 learning.py:507] global step 4797: loss = 5.4674 (0.542 sec/step)
I0404 20:46:57.511628 47978602034560 learning.py:507] global step 4798: loss = 4.8380 (0.509 sec/step)
I0404 20:46:58.040331 47978602034560 learning.py:507] global step 4799: loss = 5.2895 (0.527 sec/step)
I0404 20:46:58.550172 47978602034560 learning.py:507] global step 4800: loss = 5.6210 (0.508 sec/step)
I0404 20:46:59.087389 47978602034560 learning.py:507] global step 4801: loss = 7.1995 (0.536 sec/step)
I0404 20:46:59.599213 47978602034560 learning.py:507] global step 4802: loss = 6.7565 (0.509 sec/step)
I0404 20:47:00.108796 47978602034560 learning.py:507] global step 4803: loss = 6.9036 (0.508 sec/step)
I0404 20:47:00.615027 47978602034560 learning.py:507] global step 4804: loss = 5.9810 (0.505 sec/step)
I0404 20:47:01.125906 47978602034560 learning.py:507] global step 4805: loss = 4.9003 (0.509 sec/step)
I0404 20:47:01.645733 47978602034560 learning.py:507] global step 4806: loss = 6.1500 (0.518 sec/step)
I0404 20:47:02.166368 47978602034560 learning.py:507] global step 4807: loss = 6.4680 (0.519 sec/step)
I0404 20:47:02.688768 47978602034560 learning.py:507] global step 4808: loss = 4.7522 (0.521 sec/step)
I0404 20:47:03.189026 47978602034560 learning.py:507] global step 4809: loss = 6.0054 (0.499 sec/step)
I0404 20:47:03.690966 47978602034560 learning.py:507] global step 4810: loss = 6.5659 (0.499 sec/step)
I0404 20:47:04.212838 47978602034560 learning.py:507] global step 4811: loss = 6.0420 (0.520 sec/step)
I0404 20:47:04.721105 47978602034560 learning.py:507] global step 4812: loss = 5.6179 (0.507 sec/step)
I0404 20:47:05.232808 47978602034560 learning.py:507] global step 4813: loss = 5.6950 (0.510 sec/step)
I0404 20:47:05.749749 47978602034560 learning.py:507] global step 4814: loss = 5.8266 (0.515 sec/step)
I0404 20:47:06.250084 47978602034560 learning.py:507] global step 4815: loss = 5.5012 (0.499 sec/step)
I0404 20:47:06.773537 47978602034560 learning.py:507] global step 4816: loss = 6.3100 (0.520 sec/step)
I0404 20:47:07.280334 47978602034560 learning.py:507] global step 4817: loss = 6.9482 (0.504 sec/step)
I0404 20:47:07.826631 47978602034560 learning.py:507] global step 4818: loss = 5.5754 (0.543 sec/step)
I0404 20:47:08.343068 47978602034560 learning.py:507] global step 4819: loss = 6.5438 (0.515 sec/step)
I0404 20:47:08.856864 47978602034560 learning.py:507] global step 4820: loss = 5.9216 (0.511 sec/step)
I0404 20:47:09.368026 47978602034560 learning.py:507] global step 4821: loss = 5.8397 (0.508 sec/step)
I0404 20:47:09.881196 47978602034560 learning.py:507] global step 4822: loss = 5.5328 (0.512 sec/step)
I0404 20:47:10.390828 47978602034560 learning.py:507] global step 4823: loss = 5.4665 (0.508 sec/step)
I0404 20:47:10.930727 47978602034560 learning.py:507] global step 4824: loss = 5.9691 (0.537 sec/step)
I0404 20:47:11.442959 47978602034560 learning.py:507] global step 4825: loss = 7.1301 (0.510 sec/step)
I0404 20:47:11.949300 47978602034560 learning.py:507] global step 4826: loss = 6.7078 (0.504 sec/step)
I0404 20:47:12.483406 47978602034560 learning.py:507] global step 4827: loss = 5.5386 (0.531 sec/step)
I0404 20:47:13.023306 47978602034560 learning.py:507] global step 4828: loss = 6.2371 (0.538 sec/step)
I0404 20:47:13.539653 47978602034560 learning.py:507] global step 4829: loss = 5.9926 (0.515 sec/step)
I0404 20:47:14.060774 47978602034560 learning.py:507] global step 4830: loss = 6.1275 (0.520 sec/step)
I0404 20:47:14.564358 47978602034560 learning.py:507] global step 4831: loss = 6.4002 (0.502 sec/step)
I0404 20:47:15.070984 47978602034560 learning.py:507] global step 4832: loss = 5.8062 (0.505 sec/step)
I0404 20:47:15.574672 47978602034560 learning.py:507] global step 4833: loss = 6.3835 (0.502 sec/step)
I0404 20:47:16.095112 47978602034560 learning.py:507] global step 4834: loss = 6.8822 (0.519 sec/step)
I0404 20:47:16.606363 47978602034560 learning.py:507] global step 4835: loss = 5.8531 (0.510 sec/step)
I0404 20:47:17.304286 47978602034560 learning.py:507] global step 4836: loss = 6.4230 (0.695 sec/step)
I0404 20:47:17.305955 47983661975296 supervisor.py:1050] Recording summary at step 4836.
I0404 20:47:17.820518 47978602034560 learning.py:507] global step 4837: loss = 6.2269 (0.511 sec/step)
I0404 20:47:18.359843 47978602034560 learning.py:507] global step 4838: loss = 6.3726 (0.538 sec/step)
I0404 20:47:18.891342 47978602034560 learning.py:507] global step 4839: loss = 5.1510 (0.530 sec/step)
I0404 20:47:19.414227 47978602034560 learning.py:507] global step 4840: loss = 5.3785 (0.520 sec/step)
I0404 20:47:19.928037 47978602034560 learning.py:507] global step 4841: loss = 7.3135 (0.511 sec/step)
I0404 20:47:20.434997 47978602034560 learning.py:507] global step 4842: loss = 5.6086 (0.505 sec/step)
I0404 20:47:20.947700 47978602034560 learning.py:507] global step 4843: loss = 6.4738 (0.511 sec/step)
I0404 20:47:21.454173 47978602034560 learning.py:507] global step 4844: loss = 6.8561 (0.505 sec/step)
I0404 20:47:21.973941 47978602034560 learning.py:507] global step 4845: loss = 5.5735 (0.518 sec/step)
I0404 20:47:22.496695 47978602034560 learning.py:507] global step 4846: loss = 5.6720 (0.521 sec/step)
I0404 20:47:23.011266 47978602034560 learning.py:507] global step 4847: loss = 5.8845 (0.513 sec/step)
I0404 20:47:23.520730 47978602034560 learning.py:507] global step 4848: loss = 6.0272 (0.508 sec/step)
I0404 20:47:24.051388 47978602034560 learning.py:507] global step 4849: loss = 6.0831 (0.529 sec/step)
I0404 20:47:24.562319 47978602034560 learning.py:507] global step 4850: loss = 5.8921 (0.509 sec/step)
I0404 20:47:25.070065 47978602034560 learning.py:507] global step 4851: loss = 6.1815 (0.506 sec/step)
I0404 20:47:25.605414 47978602034560 learning.py:507] global step 4852: loss = 7.8134 (0.532 sec/step)
I0404 20:47:26.146212 47978602034560 learning.py:507] global step 4853: loss = 5.7552 (0.538 sec/step)
I0404 20:47:26.673773 47978602034560 learning.py:507] global step 4854: loss = 5.7278 (0.526 sec/step)
I0404 20:47:27.202115 47978602034560 learning.py:507] global step 4855: loss = 5.9071 (0.527 sec/step)
I0404 20:47:27.717390 47978602034560 learning.py:507] global step 4856: loss = 5.7249 (0.514 sec/step)
I0404 20:47:28.238303 47978602034560 learning.py:507] global step 4857: loss = 6.3602 (0.518 sec/step)
I0404 20:47:28.765787 47978602034560 learning.py:507] global step 4858: loss = 5.3852 (0.526 sec/step)
I0404 20:47:29.272466 47978602034560 learning.py:507] global step 4859: loss = 6.0268 (0.504 sec/step)
I0404 20:47:29.782249 47978602034560 learning.py:507] global step 4860: loss = 6.8861 (0.508 sec/step)
I0404 20:47:30.294987 47978602034560 learning.py:507] global step 4861: loss = 6.7648 (0.511 sec/step)
I0404 20:47:30.796409 47978602034560 learning.py:507] global step 4862: loss = 5.8572 (0.500 sec/step)
I0404 20:47:31.326007 47978602034560 learning.py:507] global step 4863: loss = 5.9159 (0.528 sec/step)
I0404 20:47:31.856494 47978602034560 learning.py:507] global step 4864: loss = 5.7665 (0.529 sec/step)
I0404 20:47:32.376039 47978602034560 learning.py:507] global step 4865: loss = 6.2196 (0.518 sec/step)
I0404 20:47:32.889210 47978602034560 learning.py:507] global step 4866: loss = 6.5846 (0.512 sec/step)
I0404 20:47:33.420379 47978602034560 learning.py:507] global step 4867: loss = 6.8088 (0.528 sec/step)
I0404 20:47:33.937255 47978602034560 learning.py:507] global step 4868: loss = 5.7790 (0.515 sec/step)
I0404 20:47:34.450386 47978602034560 learning.py:507] global step 4869: loss = 5.8425 (0.510 sec/step)
I0404 20:47:34.958094 47978602034560 learning.py:507] global step 4870: loss = 6.0709 (0.506 sec/step)
I0404 20:47:35.465851 47978602034560 learning.py:507] global step 4871: loss = 6.5601 (0.506 sec/step)
I0404 20:47:35.976876 47978602034560 learning.py:507] global step 4872: loss = 5.5056 (0.508 sec/step)
I0404 20:47:36.481131 47978602034560 learning.py:507] global step 4873: loss = 6.5415 (0.503 sec/step)
I0404 20:47:36.985065 47978602034560 learning.py:507] global step 4874: loss = 6.0019 (0.502 sec/step)
I0404 20:47:37.510850 47978602034560 learning.py:507] global step 4875: loss = 7.3780 (0.524 sec/step)
I0404 20:47:38.021858 47978602034560 learning.py:507] global step 4876: loss = 5.3937 (0.509 sec/step)
I0404 20:47:38.523597 47978602034560 learning.py:507] global step 4877: loss = 7.0849 (0.500 sec/step)
I0404 20:47:39.061280 47978602034560 learning.py:507] global step 4878: loss = 6.5681 (0.535 sec/step)
I0404 20:47:39.564387 47978602034560 learning.py:507] global step 4879: loss = 5.8626 (0.500 sec/step)
I0404 20:47:40.081296 47978602034560 learning.py:507] global step 4880: loss = 6.5234 (0.514 sec/step)
I0404 20:47:40.588093 47978602034560 learning.py:507] global step 4881: loss = 6.7380 (0.504 sec/step)
I0404 20:47:41.100248 47978602034560 learning.py:507] global step 4882: loss = 6.8177 (0.511 sec/step)
I0404 20:47:41.630636 47978602034560 learning.py:507] global step 4883: loss = 6.2559 (0.529 sec/step)
I0404 20:47:42.143463 47978602034560 learning.py:507] global step 4884: loss = 5.6735 (0.510 sec/step)
I0404 20:47:42.657377 47978602034560 learning.py:507] global step 4885: loss = 6.1441 (0.512 sec/step)
I0404 20:47:43.197890 47978602034560 learning.py:507] global step 4886: loss = 6.3312 (0.539 sec/step)
I0404 20:47:43.708978 47978602034560 learning.py:507] global step 4887: loss = 6.3700 (0.510 sec/step)
I0404 20:47:44.237788 47978602034560 learning.py:507] global step 4888: loss = 6.7801 (0.527 sec/step)
I0404 20:47:44.740351 47978602034560 learning.py:507] global step 4889: loss = 5.8049 (0.501 sec/step)
I0404 20:47:45.245458 47978602034560 learning.py:507] global step 4890: loss = 5.3154 (0.504 sec/step)
I0404 20:47:45.778828 47978602034560 learning.py:507] global step 4891: loss = 5.5444 (0.532 sec/step)
I0404 20:47:46.286324 47978602034560 learning.py:507] global step 4892: loss = 5.0278 (0.506 sec/step)
I0404 20:47:46.824732 47978602034560 learning.py:507] global step 4893: loss = 7.2615 (0.536 sec/step)
I0404 20:47:47.332815 47978602034560 learning.py:507] global step 4894: loss = 5.1545 (0.506 sec/step)
I0404 20:47:47.840599 47978602034560 learning.py:507] global step 4895: loss = 5.9747 (0.505 sec/step)
I0404 20:47:48.380599 47978602034560 learning.py:507] global step 4896: loss = 6.1841 (0.538 sec/step)
I0404 20:47:48.910233 47978602034560 learning.py:507] global step 4897: loss = 6.3939 (0.527 sec/step)
I0404 20:47:49.422444 47978602034560 learning.py:507] global step 4898: loss = 5.7946 (0.511 sec/step)
I0404 20:47:49.935813 47978602034560 learning.py:507] global step 4899: loss = 6.0209 (0.510 sec/step)
I0404 20:47:50.455699 47978602034560 learning.py:507] global step 4900: loss = 4.9808 (0.518 sec/step)
I0404 20:47:50.960565 47978602034560 learning.py:507] global step 4901: loss = 5.4615 (0.503 sec/step)
I0404 20:47:51.462874 47978602034560 learning.py:507] global step 4902: loss = 7.2986 (0.501 sec/step)
I0404 20:47:51.977601 47978602034560 learning.py:507] global step 4903: loss = 5.8480 (0.512 sec/step)
I0404 20:47:52.512639 47978602034560 learning.py:507] global step 4904: loss = 5.6817 (0.533 sec/step)
I0404 20:47:53.016795 47978602034560 learning.py:507] global step 4905: loss = 6.0736 (0.503 sec/step)
I0404 20:47:53.526494 47978602034560 learning.py:507] global step 4906: loss = 5.4510 (0.508 sec/step)
I0404 20:47:54.032688 47978602034560 learning.py:507] global step 4907: loss = 6.1035 (0.503 sec/step)
I0404 20:47:54.549409 47978602034560 learning.py:507] global step 4908: loss = 5.8545 (0.515 sec/step)
I0404 20:47:55.060178 47978602034560 learning.py:507] global step 4909: loss = 7.0617 (0.508 sec/step)
I0404 20:47:55.602221 47978602034560 learning.py:507] global step 4910: loss = 6.1405 (0.540 sec/step)
I0404 20:47:56.136914 47978602034560 learning.py:507] global step 4911: loss = 6.3963 (0.533 sec/step)
I0404 20:47:56.645252 47978602034560 learning.py:507] global step 4912: loss = 6.2791 (0.507 sec/step)
I0404 20:47:57.150666 47978602034560 learning.py:507] global step 4913: loss = 6.3429 (0.503 sec/step)
I0404 20:47:57.670048 47978602034560 learning.py:507] global step 4914: loss = 6.0192 (0.518 sec/step)
I0404 20:47:58.199649 47978602034560 learning.py:507] global step 4915: loss = 5.2983 (0.527 sec/step)
I0404 20:47:58.704990 47978602034560 learning.py:507] global step 4916: loss = 6.4827 (0.503 sec/step)
I0404 20:47:59.228754 47978602034560 learning.py:507] global step 4917: loss = 5.5146 (0.521 sec/step)
I0404 20:47:59.748320 47978602034560 learning.py:507] global step 4918: loss = 5.6711 (0.518 sec/step)
I0404 20:48:00.257802 47978602034560 learning.py:507] global step 4919: loss = 5.5786 (0.507 sec/step)
I0404 20:48:00.766116 47978602034560 learning.py:507] global step 4920: loss = 7.1645 (0.507 sec/step)
I0404 20:48:01.279252 47978602034560 learning.py:507] global step 4921: loss = 5.4891 (0.512 sec/step)
I0404 20:48:01.793349 47978602034560 learning.py:507] global step 4922: loss = 6.5817 (0.513 sec/step)
I0404 20:48:02.310817 47978602034560 learning.py:507] global step 4923: loss = 6.3483 (0.515 sec/step)
I0404 20:48:02.815193 47978602034560 learning.py:507] global step 4924: loss = 6.0861 (0.503 sec/step)
I0404 20:48:03.334711 47978602034560 learning.py:507] global step 4925: loss = 5.7199 (0.518 sec/step)
I0404 20:48:03.850392 47978602034560 learning.py:507] global step 4926: loss = 6.3227 (0.514 sec/step)
I0404 20:48:04.353043 47978602034560 learning.py:507] global step 4927: loss = 6.5128 (0.501 sec/step)
I0404 20:48:04.859384 47978602034560 learning.py:507] global step 4928: loss = 5.8320 (0.505 sec/step)
I0404 20:48:05.361849 47978602034560 learning.py:507] global step 4929: loss = 5.6314 (0.501 sec/step)
I0404 20:48:05.868534 47978602034560 learning.py:507] global step 4930: loss = 6.7993 (0.504 sec/step)
I0404 20:48:06.372942 47978602034560 learning.py:507] global step 4931: loss = 6.8200 (0.502 sec/step)
I0404 20:48:06.916092 47978602034560 learning.py:507] global step 4932: loss = 5.7605 (0.542 sec/step)
I0404 20:48:07.432588 47978602034560 learning.py:507] global step 4933: loss = 6.5692 (0.515 sec/step)
I0404 20:48:07.942270 47978602034560 learning.py:507] global step 4934: loss = 5.8669 (0.508 sec/step)
I0404 20:48:08.468229 47978602034560 learning.py:507] global step 4935: loss = 5.7771 (0.524 sec/step)
I0404 20:48:08.971310 47978602034560 learning.py:507] global step 4936: loss = 6.5564 (0.502 sec/step)
I0404 20:48:09.482751 47978602034560 learning.py:507] global step 4937: loss = 6.5216 (0.510 sec/step)
I0404 20:48:09.999167 47978602034560 learning.py:507] global step 4938: loss = 5.8615 (0.515 sec/step)
I0404 20:48:10.517530 47978602034560 learning.py:507] global step 4939: loss = 6.4622 (0.515 sec/step)
I0404 20:48:11.024048 47978602034560 learning.py:507] global step 4940: loss = 6.9469 (0.505 sec/step)
I0404 20:48:11.530317 47978602034560 learning.py:507] global step 4941: loss = 6.1502 (0.505 sec/step)
I0404 20:48:12.038192 47978602034560 learning.py:507] global step 4942: loss = 5.8579 (0.506 sec/step)
I0404 20:48:12.575866 47978602034560 learning.py:507] global step 4943: loss = 6.2563 (0.536 sec/step)
I0404 20:48:13.118498 47978602034560 learning.py:507] global step 4944: loss = 6.0844 (0.540 sec/step)
I0404 20:48:13.620900 47978602034560 learning.py:507] global step 4945: loss = 4.5204 (0.499 sec/step)
I0404 20:48:14.153214 47978602034560 learning.py:507] global step 4946: loss = 7.4419 (0.531 sec/step)
I0404 20:48:14.653903 47978602034560 learning.py:507] global step 4947: loss = 5.7998 (0.499 sec/step)
I0404 20:48:15.172574 47978602034560 learning.py:507] global step 4948: loss = 6.9196 (0.517 sec/step)
I0404 20:48:15.682650 47978602034560 learning.py:507] global step 4949: loss = 6.3029 (0.509 sec/step)
I0404 20:48:16.196609 47978602034560 learning.py:507] global step 4950: loss = 5.7978 (0.511 sec/step)
I0404 20:48:16.706903 47978602034560 learning.py:507] global step 4951: loss = 5.3967 (0.509 sec/step)
I0404 20:48:17.244385 47978602034560 learning.py:507] global step 4952: loss = 6.0462 (0.536 sec/step)
I0404 20:48:17.755713 47978602034560 learning.py:507] global step 4953: loss = 6.5301 (0.510 sec/step)
I0404 20:48:18.261340 47978602034560 learning.py:507] global step 4954: loss = 6.0070 (0.504 sec/step)
I0404 20:48:18.774155 47978602034560 learning.py:507] global step 4955: loss = 6.3148 (0.510 sec/step)
I0404 20:48:19.309480 47978602034560 learning.py:507] global step 4956: loss = 5.3525 (0.532 sec/step)
I0404 20:48:19.815088 47978602034560 learning.py:507] global step 4957: loss = 5.7116 (0.504 sec/step)
I0404 20:48:20.330071 47978602034560 learning.py:507] global step 4958: loss = 6.3336 (0.513 sec/step)
I0404 20:48:20.842188 47978602034560 learning.py:507] global step 4959: loss = 6.4631 (0.511 sec/step)
I0404 20:48:21.377702 47978602034560 learning.py:507] global step 4960: loss = 5.7080 (0.533 sec/step)
I0404 20:48:21.882044 47978602034560 learning.py:507] global step 4961: loss = 6.4698 (0.502 sec/step)
I0404 20:48:22.391398 47978602034560 learning.py:507] global step 4962: loss = 5.5930 (0.508 sec/step)
I0404 20:48:22.896831 47978602034560 learning.py:507] global step 4963: loss = 6.0959 (0.504 sec/step)
I0404 20:48:23.413214 47978602034560 learning.py:507] global step 4964: loss = 5.5904 (0.514 sec/step)
I0404 20:48:23.925589 47978602034560 learning.py:507] global step 4965: loss = 6.0913 (0.510 sec/step)
I0404 20:48:24.464409 47978602034560 learning.py:507] global step 4966: loss = 6.2041 (0.535 sec/step)
I0404 20:48:25.002030 47978602034560 learning.py:507] global step 4967: loss = 5.7233 (0.535 sec/step)
I0404 20:48:25.525008 47978602034560 learning.py:507] global step 4968: loss = 7.1402 (0.520 sec/step)
I0404 20:48:26.038918 47978602034560 learning.py:507] global step 4969: loss = 5.4184 (0.512 sec/step)
I0404 20:48:26.541529 47978602034560 learning.py:507] global step 4970: loss = 5.5242 (0.501 sec/step)
I0404 20:48:27.051403 47978602034560 learning.py:507] global step 4971: loss = 6.2227 (0.508 sec/step)
I0404 20:48:27.590809 47978602034560 learning.py:507] global step 4972: loss = 6.1395 (0.537 sec/step)
I0404 20:48:28.104038 47978602034560 learning.py:507] global step 4973: loss = 5.4553 (0.512 sec/step)
I0404 20:48:28.615168 47978602034560 learning.py:507] global step 4974: loss = 6.4774 (0.508 sec/step)
I0404 20:48:29.122097 47978602034560 learning.py:507] global step 4975: loss = 6.1205 (0.505 sec/step)
I0404 20:48:29.639284 47978602034560 learning.py:507] global step 4976: loss = 5.8904 (0.516 sec/step)
I0404 20:48:30.151368 47978602034560 learning.py:507] global step 4977: loss = 6.4878 (0.511 sec/step)
I0404 20:48:30.696498 47978602034560 learning.py:507] global step 4978: loss = 5.3521 (0.544 sec/step)
I0404 20:48:31.234700 47978602034560 learning.py:507] global step 4979: loss = 6.1941 (0.535 sec/step)
I0404 20:48:31.749059 47978602034560 learning.py:507] global step 4980: loss = 5.5913 (0.513 sec/step)
I0404 20:48:32.262590 47978602034560 learning.py:507] global step 4981: loss = 6.5475 (0.512 sec/step)
I0404 20:48:32.770939 47978602034560 learning.py:507] global step 4982: loss = 5.9946 (0.505 sec/step)
I0404 20:48:33.292283 47978602034560 learning.py:507] global step 4983: loss = 6.3840 (0.520 sec/step)
I0404 20:48:33.820838 47978602034560 learning.py:507] global step 4984: loss = 5.8291 (0.527 sec/step)
I0404 20:48:34.328534 47978602034560 learning.py:507] global step 4985: loss = 6.3065 (0.506 sec/step)
I0404 20:48:34.834948 47978602034560 learning.py:507] global step 4986: loss = 6.1095 (0.505 sec/step)
I0404 20:48:35.355832 47978602034560 learning.py:507] global step 4987: loss = 5.7992 (0.519 sec/step)
I0404 20:48:35.858977 47978602034560 learning.py:507] global step 4988: loss = 6.0561 (0.500 sec/step)
I0404 20:48:36.359069 47978602034560 learning.py:507] global step 4989: loss = 7.2164 (0.498 sec/step)
I0404 20:48:36.858024 47978602034560 learning.py:507] global step 4990: loss = 6.1567 (0.497 sec/step)
I0404 20:48:37.372382 47978602034560 learning.py:507] global step 4991: loss = 5.9467 (0.511 sec/step)
I0404 20:48:37.887635 47978602034560 learning.py:507] global step 4992: loss = 5.9904 (0.512 sec/step)
I0404 20:48:38.389732 47978602034560 learning.py:507] global step 4993: loss = 6.3592 (0.501 sec/step)
I0404 20:48:38.896406 47978602034560 learning.py:507] global step 4994: loss = 5.8732 (0.505 sec/step)
I0404 20:48:39.430864 47978602034560 learning.py:507] global step 4995: loss = 5.5555 (0.533 sec/step)
I0404 20:48:39.967593 47978602034560 learning.py:507] global step 4996: loss = 4.8623 (0.535 sec/step)
I0404 20:48:40.492222 47978602034560 learning.py:507] global step 4997: loss = 6.6710 (0.523 sec/step)
I0404 20:48:41.006787 47978602034560 learning.py:507] global step 4998: loss = 5.9647 (0.513 sec/step)
I0404 20:48:41.519653 47978602034560 learning.py:507] global step 4999: loss = 5.7828 (0.510 sec/step)
I0404 20:48:42.036395 47978602034560 learning.py:507] global step 5000: loss = 6.1738 (0.515 sec/step)
I0404 20:48:42.549976 47978602034560 learning.py:507] global step 5001: loss = 5.6711 (0.511 sec/step)
I0404 20:48:43.059965 47978602034560 learning.py:507] global step 5002: loss = 5.2008 (0.507 sec/step)
I0404 20:48:43.596561 47978602034560 learning.py:507] global step 5003: loss = 5.4741 (0.535 sec/step)
I0404 20:48:44.103237 47978602034560 learning.py:507] global step 5004: loss = 7.7077 (0.504 sec/step)
I0404 20:48:44.614449 47978602034560 learning.py:507] global step 5005: loss = 5.8804 (0.510 sec/step)
I0404 20:48:45.121865 47978602034560 learning.py:507] global step 5006: loss = 5.3300 (0.505 sec/step)
I0404 20:48:45.634983 47978602034560 learning.py:507] global step 5007: loss = 5.9438 (0.512 sec/step)
I0404 20:48:46.159401 47978602034560 learning.py:507] global step 5008: loss = 7.9735 (0.523 sec/step)
I0404 20:48:46.677371 47978602034560 learning.py:507] global step 5009: loss = 5.8617 (0.516 sec/step)
I0404 20:48:47.179678 47978602034560 learning.py:507] global step 5010: loss = 6.2891 (0.499 sec/step)
I0404 20:48:47.689929 47978602034560 learning.py:507] global step 5011: loss = 6.6416 (0.509 sec/step)
I0404 20:48:48.211187 47978602034560 learning.py:507] global step 5012: loss = 4.9519 (0.520 sec/step)
I0404 20:48:48.718322 47978602034560 learning.py:507] global step 5013: loss = 5.7294 (0.506 sec/step)
I0404 20:48:49.226968 47978602034560 learning.py:507] global step 5014: loss = 5.6685 (0.506 sec/step)
I0404 20:48:49.740311 47978602034560 learning.py:507] global step 5015: loss = 6.4876 (0.512 sec/step)
I0404 20:48:50.255959 47978602034560 learning.py:507] global step 5016: loss = 7.5022 (0.514 sec/step)
I0404 20:48:50.762656 47978602034560 learning.py:507] global step 5017: loss = 6.3560 (0.505 sec/step)
I0404 20:48:51.266810 47978602034560 learning.py:507] global step 5018: loss = 6.5678 (0.501 sec/step)
I0404 20:48:51.774695 47978602034560 learning.py:507] global step 5019: loss = 6.3707 (0.505 sec/step)
I0404 20:48:52.285243 47978602034560 learning.py:507] global step 5020: loss = 5.6350 (0.508 sec/step)
I0404 20:48:52.802005 47978602034560 learning.py:507] global step 5021: loss = 5.5725 (0.514 sec/step)
I0404 20:48:53.315108 47978602034560 learning.py:507] global step 5022: loss = 6.2284 (0.511 sec/step)
I0404 20:48:53.831815 47978602034560 learning.py:507] global step 5023: loss = 5.8100 (0.515 sec/step)
I0404 20:48:54.339240 47978602034560 learning.py:507] global step 5024: loss = 5.5536 (0.506 sec/step)
I0404 20:48:54.854835 47978602034560 learning.py:507] global step 5025: loss = 5.3128 (0.513 sec/step)
I0404 20:48:55.360274 47978602034560 learning.py:507] global step 5026: loss = 5.4895 (0.504 sec/step)
I0404 20:48:55.892033 47978602034560 learning.py:507] global step 5027: loss = 6.4926 (0.530 sec/step)
I0404 20:48:56.412988 47978602034560 learning.py:507] global step 5028: loss = 6.2620 (0.518 sec/step)
I0404 20:48:56.929132 47978602034560 learning.py:507] global step 5029: loss = 6.1276 (0.515 sec/step)
I0404 20:48:57.441992 47978602034560 learning.py:507] global step 5030: loss = 5.8947 (0.511 sec/step)
I0404 20:48:57.962688 47978602034560 learning.py:507] global step 5031: loss = 6.9466 (0.518 sec/step)
I0404 20:48:58.502312 47978602034560 learning.py:507] global step 5032: loss = 5.1749 (0.538 sec/step)
I0404 20:48:59.005617 47978602034560 learning.py:507] global step 5033: loss = 5.9897 (0.502 sec/step)
I0404 20:48:59.511851 47978602034560 learning.py:507] global step 5034: loss = 5.7140 (0.503 sec/step)
I0404 20:49:00.025401 47978602034560 learning.py:507] global step 5035: loss = 5.6466 (0.511 sec/step)
I0404 20:49:00.532735 47978602034560 learning.py:507] global step 5036: loss = 5.8682 (0.506 sec/step)
I0404 20:49:01.047088 47978602034560 learning.py:507] global step 5037: loss = 5.9129 (0.513 sec/step)
I0404 20:49:01.564882 47978602034560 learning.py:507] global step 5038: loss = 5.8872 (0.516 sec/step)
I0404 20:49:02.083449 47978602034560 learning.py:507] global step 5039: loss = 5.5226 (0.517 sec/step)
I0404 20:49:02.613876 47978602034560 learning.py:507] global step 5040: loss = 6.3175 (0.528 sec/step)
I0404 20:49:03.136729 47978602034560 learning.py:507] global step 5041: loss = 6.3149 (0.521 sec/step)
I0404 20:49:03.648361 47978602034560 learning.py:507] global step 5042: loss = 5.0079 (0.510 sec/step)
I0404 20:49:04.151239 47978602034560 learning.py:507] global step 5043: loss = 5.4601 (0.501 sec/step)
I0404 20:49:04.657237 47978602034560 learning.py:507] global step 5044: loss = 6.7163 (0.504 sec/step)
I0404 20:49:05.189512 47978602034560 learning.py:507] global step 5045: loss = 6.7415 (0.531 sec/step)
I0404 20:49:05.697036 47978602034560 learning.py:507] global step 5046: loss = 5.7015 (0.506 sec/step)
I0404 20:49:06.204065 47978602034560 learning.py:507] global step 5047: loss = 5.6916 (0.505 sec/step)
I0404 20:49:06.708195 47978602034560 learning.py:507] global step 5048: loss = 5.4116 (0.502 sec/step)
I0404 20:49:07.219003 47978602034560 learning.py:507] global step 5049: loss = 6.8169 (0.509 sec/step)
I0404 20:49:07.726813 47978602034560 learning.py:507] global step 5050: loss = 5.3045 (0.506 sec/step)
I0404 20:49:08.257625 47978602034560 learning.py:507] global step 5051: loss = 6.0638 (0.529 sec/step)
I0404 20:49:08.809025 47978602034560 learning.py:507] global step 5052: loss = 6.3981 (0.550 sec/step)
I0404 20:49:09.313547 47978602034560 learning.py:507] global step 5053: loss = 5.4901 (0.503 sec/step)
I0404 20:49:09.828181 47978602034560 learning.py:507] global step 5054: loss = 6.1233 (0.512 sec/step)
I0404 20:49:10.366516 47978602034560 learning.py:507] global step 5055: loss = 6.4331 (0.535 sec/step)
I0404 20:49:10.874682 47978602034560 learning.py:507] global step 5056: loss = 6.3809 (0.507 sec/step)
I0404 20:49:11.401244 47978602034560 learning.py:507] global step 5057: loss = 5.7522 (0.524 sec/step)
I0404 20:49:11.912353 47978602034560 learning.py:507] global step 5058: loss = 6.0804 (0.510 sec/step)
I0404 20:49:12.433040 47978602034560 learning.py:507] global step 5059: loss = 6.1054 (0.519 sec/step)
I0404 20:49:12.935204 47978602034560 learning.py:507] global step 5060: loss = 5.9561 (0.499 sec/step)
I0404 20:49:13.435818 47978602034560 learning.py:507] global step 5061: loss = 6.1873 (0.499 sec/step)
I0404 20:49:13.942094 47978602034560 learning.py:507] global step 5062: loss = 5.6309 (0.505 sec/step)
I0404 20:49:14.455517 47978602034560 learning.py:507] global step 5063: loss = 6.7490 (0.512 sec/step)
I0404 20:49:14.993248 47978602034560 learning.py:507] global step 5064: loss = 5.6044 (0.536 sec/step)
I0404 20:49:15.494853 47978602034560 learning.py:507] global step 5065: loss = 5.1427 (0.499 sec/step)
I0404 20:49:16.011675 47978602034560 learning.py:507] global step 5066: loss = 5.3275 (0.515 sec/step)
I0404 20:49:16.525349 47978602034560 learning.py:507] global step 5067: loss = 6.3600 (0.511 sec/step)
I0404 20:49:17.218845 47978602034560 learning.py:507] global step 5068: loss = 5.6791 (0.690 sec/step)
I0404 20:49:17.234620 47983661975296 supervisor.py:1050] Recording summary at step 5068.
I0404 20:49:17.733200 47978602034560 learning.py:507] global step 5069: loss = 5.3562 (0.513 sec/step)
I0404 20:49:18.234351 47978602034560 learning.py:507] global step 5070: loss = 5.9641 (0.500 sec/step)
I0404 20:49:18.744633 47978602034560 learning.py:507] global step 5071: loss = 5.4872 (0.509 sec/step)
I0404 20:49:19.253097 47978602034560 learning.py:507] global step 5072: loss = 6.4440 (0.507 sec/step)
I0404 20:49:19.778541 47978602034560 learning.py:507] global step 5073: loss = 5.4739 (0.524 sec/step)
I0404 20:49:20.287652 47978602034560 learning.py:507] global step 5074: loss = 6.2211 (0.508 sec/step)
I0404 20:49:20.822388 47978602034560 learning.py:507] global step 5075: loss = 5.8601 (0.532 sec/step)
I0404 20:49:21.334017 47978602034560 learning.py:507] global step 5076: loss = 5.9650 (0.509 sec/step)
I0404 20:49:21.850521 47978602034560 learning.py:507] global step 5077: loss = 6.5565 (0.514 sec/step)
I0404 20:49:22.361961 47978602034560 learning.py:507] global step 5078: loss = 7.0681 (0.509 sec/step)
I0404 20:49:22.867889 47978602034560 learning.py:507] global step 5079: loss = 5.4203 (0.504 sec/step)
I0404 20:49:23.381874 47978602034560 learning.py:507] global step 5080: loss = 5.3828 (0.512 sec/step)
I0404 20:49:23.893973 47978602034560 learning.py:507] global step 5081: loss = 6.1686 (0.510 sec/step)
I0404 20:49:24.404399 47978602034560 learning.py:507] global step 5082: loss = 5.5657 (0.508 sec/step)
I0404 20:49:24.914514 47978602034560 learning.py:507] global step 5083: loss = 6.4559 (0.509 sec/step)
I0404 20:49:25.418304 47978602034560 learning.py:507] global step 5084: loss = 5.5981 (0.502 sec/step)
I0404 20:49:25.953207 47978602034560 learning.py:507] global step 5085: loss = 5.8368 (0.532 sec/step)
I0404 20:49:26.459727 47978602034560 learning.py:507] global step 5086: loss = 6.6710 (0.505 sec/step)
I0404 20:49:26.971268 47978602034560 learning.py:507] global step 5087: loss = 5.1882 (0.510 sec/step)
I0404 20:49:27.480646 47978602034560 learning.py:507] global step 5088: loss = 5.7095 (0.508 sec/step)
I0404 20:49:28.001549 47978602034560 learning.py:507] global step 5089: loss = 5.9650 (0.518 sec/step)
I0404 20:49:28.539586 47978602034560 learning.py:507] global step 5090: loss = 6.5982 (0.535 sec/step)
I0404 20:49:29.053506 47978602034560 learning.py:507] global step 5091: loss = 5.6295 (0.512 sec/step)
I0404 20:49:29.575807 47978602034560 learning.py:507] global step 5092: loss = 5.5882 (0.521 sec/step)
I0404 20:49:30.074621 47978602034560 learning.py:507] global step 5093: loss = 6.1839 (0.497 sec/step)
I0404 20:49:30.582201 47978602034560 learning.py:507] global step 5094: loss = 6.9340 (0.505 sec/step)
I0404 20:49:31.085286 47978602034560 learning.py:507] global step 5095: loss = 5.4654 (0.500 sec/step)
I0404 20:49:31.593033 47978602034560 learning.py:507] global step 5096: loss = 5.8991 (0.506 sec/step)
I0404 20:49:32.102998 47978602034560 learning.py:507] global step 5097: loss = 6.4896 (0.507 sec/step)
I0404 20:49:32.636324 47978602034560 learning.py:507] global step 5098: loss = 6.7741 (0.532 sec/step)
I0404 20:49:33.151656 47978602034560 learning.py:507] global step 5099: loss = 6.1909 (0.514 sec/step)
I0404 20:49:33.666563 47978602034560 learning.py:507] global step 5100: loss = 6.4470 (0.513 sec/step)
I0404 20:49:34.181778 47978602034560 learning.py:507] global step 5101: loss = 4.9665 (0.514 sec/step)
I0404 20:49:34.690204 47978602034560 learning.py:507] global step 5102: loss = 6.0356 (0.507 sec/step)
I0404 20:49:35.201386 47978602034560 learning.py:507] global step 5103: loss = 5.4462 (0.510 sec/step)
I0404 20:49:35.706256 47978602034560 learning.py:507] global step 5104: loss = 4.8003 (0.503 sec/step)
I0404 20:49:36.210112 47978602034560 learning.py:507] global step 5105: loss = 6.5934 (0.501 sec/step)
I0404 20:49:36.712248 47978602034560 learning.py:507] global step 5106: loss = 4.7552 (0.499 sec/step)
I0404 20:49:37.214057 47978602034560 learning.py:507] global step 5107: loss = 5.8276 (0.500 sec/step)
I0404 20:49:37.715143 47978602034560 learning.py:507] global step 5108: loss = 6.6947 (0.499 sec/step)
I0404 20:49:38.252549 47978602034560 learning.py:507] global step 5109: loss = 5.1363 (0.535 sec/step)
I0404 20:49:38.765193 47978602034560 learning.py:507] global step 5110: loss = 6.2435 (0.510 sec/step)
I0404 20:49:39.280514 47978602034560 learning.py:507] global step 5111: loss = 7.0261 (0.514 sec/step)
I0404 20:49:39.794732 47978602034560 learning.py:507] global step 5112: loss = 7.4780 (0.513 sec/step)
I0404 20:49:40.307592 47978602034560 learning.py:507] global step 5113: loss = 6.5343 (0.511 sec/step)
I0404 20:49:40.826300 47978602034560 learning.py:507] global step 5114: loss = 5.6899 (0.516 sec/step)
I0404 20:49:41.359454 47978602034560 learning.py:507] global step 5115: loss = 5.6580 (0.532 sec/step)
I0404 20:49:41.868813 47978602034560 learning.py:507] global step 5116: loss = 8.2410 (0.508 sec/step)
I0404 20:49:42.389815 47978602034560 learning.py:507] global step 5117: loss = 6.0281 (0.519 sec/step)
I0404 20:49:42.903511 47978602034560 learning.py:507] global step 5118: loss = 6.0278 (0.511 sec/step)
I0404 20:49:43.408881 47978602034560 learning.py:507] global step 5119: loss = 6.2912 (0.504 sec/step)
I0404 20:49:43.927762 47978602034560 learning.py:507] global step 5120: loss = 6.9435 (0.517 sec/step)
I0404 20:49:44.462956 47978602034560 learning.py:507] global step 5121: loss = 5.6253 (0.534 sec/step)
I0404 20:49:45.004218 47978602034560 learning.py:507] global step 5122: loss = 5.6894 (0.538 sec/step)
I0404 20:49:45.510933 47978602034560 learning.py:507] global step 5123: loss = 6.5854 (0.504 sec/step)
I0404 20:49:46.017044 47978602034560 learning.py:507] global step 5124: loss = 6.8355 (0.505 sec/step)
I0404 20:49:46.526541 47978602034560 learning.py:507] global step 5125: loss = 5.4212 (0.508 sec/step)
I0404 20:49:47.043455 47978602034560 learning.py:507] global step 5126: loss = 6.7856 (0.515 sec/step)
I0404 20:49:47.567388 47978602034560 learning.py:507] global step 5127: loss = 6.3163 (0.522 sec/step)
I0404 20:49:48.079621 47978602034560 learning.py:507] global step 5128: loss = 5.5215 (0.511 sec/step)
I0404 20:49:48.590942 47978602034560 learning.py:507] global step 5129: loss = 5.2782 (0.510 sec/step)
I0404 20:49:49.099245 47978602034560 learning.py:507] global step 5130: loss = 5.8150 (0.507 sec/step)
I0404 20:49:49.613091 47978602034560 learning.py:507] global step 5131: loss = 5.8983 (0.512 sec/step)
I0404 20:49:50.113459 47978602034560 learning.py:507] global step 5132: loss = 5.7998 (0.499 sec/step)
I0404 20:49:50.624062 47978602034560 learning.py:507] global step 5133: loss = 4.7255 (0.509 sec/step)
I0404 20:49:51.132206 47978602034560 learning.py:507] global step 5134: loss = 5.7965 (0.505 sec/step)
I0404 20:49:51.635524 47978602034560 learning.py:507] global step 5135: loss = 6.8201 (0.502 sec/step)
I0404 20:49:52.138477 47978602034560 learning.py:507] global step 5136: loss = 5.0982 (0.501 sec/step)
I0404 20:49:52.651721 47978602034560 learning.py:507] global step 5137: loss = 6.0956 (0.512 sec/step)
I0404 20:49:53.164033 47978602034560 learning.py:507] global step 5138: loss = 6.6140 (0.511 sec/step)
I0404 20:49:53.673189 47978602034560 learning.py:507] global step 5139: loss = 6.0896 (0.506 sec/step)
I0404 20:49:54.188294 47978602034560 learning.py:507] global step 5140: loss = 6.1295 (0.513 sec/step)
I0404 20:49:54.699355 47978602034560 learning.py:507] global step 5141: loss = 5.1204 (0.510 sec/step)
I0404 20:49:55.210770 47978602034560 learning.py:507] global step 5142: loss = 5.5277 (0.509 sec/step)
I0404 20:49:55.724111 47978602034560 learning.py:507] global step 5143: loss = 6.8209 (0.510 sec/step)
I0404 20:49:56.229768 47978602034560 learning.py:507] global step 5144: loss = 5.6767 (0.503 sec/step)
I0404 20:49:56.743388 47978602034560 learning.py:507] global step 5145: loss = 5.3832 (0.511 sec/step)
I0404 20:49:57.256825 47978602034560 learning.py:507] global step 5146: loss = 5.8965 (0.512 sec/step)
I0404 20:49:57.780098 47978602034560 learning.py:507] global step 5147: loss = 5.6431 (0.520 sec/step)
I0404 20:49:58.312674 47978602034560 learning.py:507] global step 5148: loss = 6.0536 (0.531 sec/step)
I0404 20:49:58.812906 47978602034560 learning.py:507] global step 5149: loss = 6.2106 (0.499 sec/step)
I0404 20:49:59.327760 47978602034560 learning.py:507] global step 5150: loss = 6.2809 (0.513 sec/step)
I0404 20:49:59.837982 47978602034560 learning.py:507] global step 5151: loss = 5.9415 (0.507 sec/step)
I0404 20:50:00.357984 47978602034560 learning.py:507] global step 5152: loss = 5.8978 (0.518 sec/step)
I0404 20:50:00.891726 47978602034560 learning.py:507] global step 5153: loss = 6.1109 (0.532 sec/step)
I0404 20:50:01.423758 47978602034560 learning.py:507] global step 5154: loss = 6.1178 (0.530 sec/step)
I0404 20:50:01.930355 47978602034560 learning.py:507] global step 5155: loss = 6.4555 (0.504 sec/step)
I0404 20:50:02.460681 47978602034560 learning.py:507] global step 5156: loss = 6.3413 (0.528 sec/step)
I0404 20:50:02.970838 47978602034560 learning.py:507] global step 5157: loss = 6.2718 (0.509 sec/step)
I0404 20:50:03.480784 47978602034560 learning.py:507] global step 5158: loss = 5.6255 (0.507 sec/step)
I0404 20:50:03.998625 47978602034560 learning.py:507] global step 5159: loss = 5.5482 (0.515 sec/step)
I0404 20:50:04.512542 47978602034560 learning.py:507] global step 5160: loss = 6.1809 (0.512 sec/step)
I0404 20:50:05.054771 47978602034560 learning.py:507] global step 5161: loss = 7.1986 (0.541 sec/step)
I0404 20:50:05.558238 47978602034560 learning.py:507] global step 5162: loss = 5.6793 (0.502 sec/step)
I0404 20:50:06.071600 47978602034560 learning.py:507] global step 5163: loss = 6.0688 (0.510 sec/step)
I0404 20:50:06.578902 47978602034560 learning.py:507] global step 5164: loss = 6.5472 (0.504 sec/step)
I0404 20:50:07.109480 47978602034560 learning.py:507] global step 5165: loss = 5.7555 (0.529 sec/step)
I0404 20:50:07.609216 47978602034560 learning.py:507] global step 5166: loss = 6.1462 (0.498 sec/step)
I0404 20:50:08.121850 47978602034560 learning.py:507] global step 5167: loss = 6.2736 (0.511 sec/step)
I0404 20:50:08.629818 47978602034560 learning.py:507] global step 5168: loss = 5.7728 (0.505 sec/step)
I0404 20:50:09.135515 47978602034560 learning.py:507] global step 5169: loss = 6.2479 (0.504 sec/step)
I0404 20:50:09.661392 47978602034560 learning.py:507] global step 5170: loss = 6.6602 (0.524 sec/step)
I0404 20:50:10.172132 47978602034560 learning.py:507] global step 5171: loss = 6.3616 (0.509 sec/step)
I0404 20:50:10.699417 47978602034560 learning.py:507] global step 5172: loss = 6.0883 (0.526 sec/step)
I0404 20:50:11.207171 47978602034560 learning.py:507] global step 5173: loss = 6.7945 (0.506 sec/step)
I0404 20:50:11.736546 47978602034560 learning.py:507] global step 5174: loss = 6.2148 (0.528 sec/step)
I0404 20:50:12.253492 47978602034560 learning.py:507] global step 5175: loss = 6.2875 (0.515 sec/step)
I0404 20:50:12.755491 47978602034560 learning.py:507] global step 5176: loss = 6.5132 (0.500 sec/step)
I0404 20:50:13.282158 47978602034560 learning.py:507] global step 5177: loss = 6.3816 (0.525 sec/step)
I0404 20:50:13.790390 47978602034560 learning.py:507] global step 5178: loss = 6.2117 (0.505 sec/step)
I0404 20:50:14.322433 47978602034560 learning.py:507] global step 5179: loss = 6.6159 (0.529 sec/step)
I0404 20:50:14.827065 47978602034560 learning.py:507] global step 5180: loss = 4.7788 (0.502 sec/step)
I0404 20:50:15.336304 47978602034560 learning.py:507] global step 5181: loss = 5.6212 (0.508 sec/step)
I0404 20:50:15.849946 47978602034560 learning.py:507] global step 5182: loss = 5.9472 (0.512 sec/step)
I0404 20:50:16.366733 47978602034560 learning.py:507] global step 5183: loss = 6.5638 (0.515 sec/step)
I0404 20:50:16.873463 47978602034560 learning.py:507] global step 5184: loss = 7.0467 (0.505 sec/step)
I0404 20:50:17.387117 47978602034560 learning.py:507] global step 5185: loss = 5.8147 (0.511 sec/step)
I0404 20:50:17.892922 47978602034560 learning.py:507] global step 5186: loss = 5.9786 (0.503 sec/step)
I0404 20:50:18.394411 47978602034560 learning.py:507] global step 5187: loss = 6.0398 (0.499 sec/step)
I0404 20:50:18.910783 47978602034560 learning.py:507] global step 5188: loss = 5.7613 (0.515 sec/step)
I0404 20:50:19.426784 47978602034560 learning.py:507] global step 5189: loss = 6.3690 (0.513 sec/step)
I0404 20:50:19.935559 47978602034560 learning.py:507] global step 5190: loss = 7.5562 (0.506 sec/step)
I0404 20:50:20.447300 47978602034560 learning.py:507] global step 5191: loss = 6.4105 (0.509 sec/step)
I0404 20:50:20.952491 47978602034560 learning.py:507] global step 5192: loss = 5.4838 (0.504 sec/step)
I0404 20:50:21.460017 47978602034560 learning.py:507] global step 5193: loss = 6.6123 (0.505 sec/step)
I0404 20:50:21.977684 47978602034560 learning.py:507] global step 5194: loss = 6.0632 (0.515 sec/step)
I0404 20:50:22.485106 47978602034560 learning.py:507] global step 5195: loss = 7.1206 (0.505 sec/step)
I0404 20:50:23.000748 47978602034560 learning.py:507] global step 5196: loss = 5.9452 (0.514 sec/step)
I0404 20:50:23.514286 47978602034560 learning.py:507] global step 5197: loss = 6.3087 (0.512 sec/step)
I0404 20:50:24.036129 47978602034560 learning.py:507] global step 5198: loss = 5.7715 (0.519 sec/step)
I0404 20:50:24.547015 47978602034560 learning.py:507] global step 5199: loss = 5.1072 (0.508 sec/step)
I0404 20:50:25.050827 47978602034560 learning.py:507] global step 5200: loss = 5.9564 (0.501 sec/step)
I0404 20:50:25.563462 47978602034560 learning.py:507] global step 5201: loss = 4.9195 (0.511 sec/step)
I0404 20:50:26.084601 47978602034560 learning.py:507] global step 5202: loss = 7.0779 (0.520 sec/step)
I0404 20:50:26.629101 47978602034560 learning.py:507] global step 5203: loss = 5.4356 (0.543 sec/step)
I0404 20:50:27.136755 47978602034560 learning.py:507] global step 5204: loss = 7.4725 (0.506 sec/step)
I0404 20:50:27.638068 47978602034560 learning.py:507] global step 5205: loss = 6.2478 (0.498 sec/step)
I0404 20:50:28.148658 47978602034560 learning.py:507] global step 5206: loss = 6.2436 (0.508 sec/step)
I0404 20:50:28.662849 47978602034560 learning.py:507] global step 5207: loss = 6.1529 (0.513 sec/step)
I0404 20:50:29.175623 47978602034560 learning.py:507] global step 5208: loss = 7.0561 (0.510 sec/step)
I0404 20:50:29.681090 47978602034560 learning.py:507] global step 5209: loss = 6.2880 (0.504 sec/step)
I0404 20:50:30.198404 47978602034560 learning.py:507] global step 5210: loss = 6.4431 (0.516 sec/step)
I0404 20:50:30.719672 47978602034560 learning.py:507] global step 5211: loss = 5.8479 (0.518 sec/step)
I0404 20:50:31.232988 47978602034560 learning.py:507] global step 5212: loss = 6.6981 (0.512 sec/step)
I0404 20:50:31.746382 47978602034560 learning.py:507] global step 5213: loss = 6.7017 (0.512 sec/step)
I0404 20:50:32.280612 47978602034560 learning.py:507] global step 5214: loss = 5.8810 (0.533 sec/step)
I0404 20:50:32.789736 47978602034560 learning.py:507] global step 5215: loss = 6.3261 (0.506 sec/step)
I0404 20:50:33.291233 47978602034560 learning.py:507] global step 5216: loss = 5.6445 (0.500 sec/step)
I0404 20:50:33.811782 47978602034560 learning.py:507] global step 5217: loss = 5.8665 (0.519 sec/step)
I0404 20:50:34.319140 47978602034560 learning.py:507] global step 5218: loss = 5.6763 (0.506 sec/step)
I0404 20:50:34.835237 47978602034560 learning.py:507] global step 5219: loss = 7.1188 (0.513 sec/step)
I0404 20:50:35.354460 47978602034560 learning.py:507] global step 5220: loss = 6.1511 (0.518 sec/step)
I0404 20:50:35.888126 47978602034560 learning.py:507] global step 5221: loss = 6.6108 (0.531 sec/step)
I0404 20:50:36.403450 47978602034560 learning.py:507] global step 5222: loss = 5.4372 (0.514 sec/step)
I0404 20:50:36.912053 47978602034560 learning.py:507] global step 5223: loss = 6.3467 (0.507 sec/step)
I0404 20:50:37.419460 47978602034560 learning.py:507] global step 5224: loss = 6.4289 (0.506 sec/step)
I0404 20:50:37.923485 47978602034560 learning.py:507] global step 5225: loss = 5.9969 (0.502 sec/step)
I0404 20:50:38.425784 47978602034560 learning.py:507] global step 5226: loss = 6.0327 (0.501 sec/step)
I0404 20:50:38.935678 47978602034560 learning.py:507] global step 5227: loss = 5.3305 (0.508 sec/step)
I0404 20:50:39.444078 47978602034560 learning.py:507] global step 5228: loss = 5.2269 (0.507 sec/step)
I0404 20:50:39.954949 47978602034560 learning.py:507] global step 5229: loss = 5.8334 (0.509 sec/step)
I0404 20:50:40.462729 47978602034560 learning.py:507] global step 5230: loss = 6.0071 (0.506 sec/step)
I0404 20:50:40.972971 47978602034560 learning.py:507] global step 5231: loss = 5.8779 (0.509 sec/step)
I0404 20:50:41.483379 47978602034560 learning.py:507] global step 5232: loss = 6.5144 (0.509 sec/step)
I0404 20:50:41.991786 47978602034560 learning.py:507] global step 5233: loss = 6.5917 (0.506 sec/step)
I0404 20:50:42.512592 47978602034560 learning.py:507] global step 5234: loss = 5.5693 (0.519 sec/step)
I0404 20:50:43.051361 47978602034560 learning.py:507] global step 5235: loss = 5.8202 (0.536 sec/step)
I0404 20:50:43.566156 47978602034560 learning.py:507] global step 5236: loss = 5.9770 (0.513 sec/step)
I0404 20:50:44.073597 47978602034560 learning.py:507] global step 5237: loss = 6.3822 (0.505 sec/step)
I0404 20:50:44.589319 47978602034560 learning.py:507] global step 5238: loss = 7.1111 (0.514 sec/step)
I0404 20:50:45.116071 47978602034560 learning.py:507] global step 5239: loss = 6.1134 (0.525 sec/step)
I0404 20:50:45.618018 47978602034560 learning.py:507] global step 5240: loss = 6.2805 (0.500 sec/step)
I0404 20:50:46.129132 47978602034560 learning.py:507] global step 5241: loss = 4.8164 (0.510 sec/step)
I0404 20:50:46.635609 47978602034560 learning.py:507] global step 5242: loss = 6.1290 (0.504 sec/step)
I0404 20:50:47.143806 47978602034560 learning.py:507] global step 5243: loss = 6.7288 (0.507 sec/step)
I0404 20:50:47.681942 47978602034560 learning.py:507] global step 5244: loss = 6.0382 (0.536 sec/step)
I0404 20:50:48.200484 47978602034560 learning.py:507] global step 5245: loss = 6.4936 (0.516 sec/step)
I0404 20:50:48.705491 47978602034560 learning.py:507] global step 5246: loss = 6.5798 (0.503 sec/step)
I0404 20:50:49.208139 47978602034560 learning.py:507] global step 5247: loss = 5.6235 (0.501 sec/step)
I0404 20:50:49.724333 47978602034560 learning.py:507] global step 5248: loss = 7.2598 (0.515 sec/step)
I0404 20:50:50.238390 47978602034560 learning.py:507] global step 5249: loss = 5.4958 (0.513 sec/step)
I0404 20:50:50.749981 47978602034560 learning.py:507] global step 5250: loss = 7.1478 (0.510 sec/step)
I0404 20:50:51.256916 47978602034560 learning.py:507] global step 5251: loss = 5.4464 (0.505 sec/step)
I0404 20:50:51.772808 47978602034560 learning.py:507] global step 5252: loss = 5.6364 (0.514 sec/step)
I0404 20:50:52.291405 47978602034560 learning.py:507] global step 5253: loss = 5.3285 (0.517 sec/step)
I0404 20:50:52.795465 47978602034560 learning.py:507] global step 5254: loss = 6.8227 (0.501 sec/step)
I0404 20:50:53.306940 47978602034560 learning.py:507] global step 5255: loss = 5.8360 (0.509 sec/step)
I0404 20:50:53.824575 47978602034560 learning.py:507] global step 5256: loss = 6.3902 (0.516 sec/step)
I0404 20:50:54.338484 47978602034560 learning.py:507] global step 5257: loss = 6.0004 (0.512 sec/step)
I0404 20:50:54.838221 47978602034560 learning.py:507] global step 5258: loss = 5.8213 (0.498 sec/step)
I0404 20:50:55.355180 47978602034560 learning.py:507] global step 5259: loss = 6.3584 (0.515 sec/step)
I0404 20:50:55.864887 47978602034560 learning.py:507] global step 5260: loss = 6.6192 (0.507 sec/step)
I0404 20:50:56.378892 47978602034560 learning.py:507] global step 5261: loss = 6.8155 (0.511 sec/step)
I0404 20:50:56.879299 47978602034560 learning.py:507] global step 5262: loss = 6.8231 (0.499 sec/step)
I0404 20:50:57.386047 47978602034560 learning.py:507] global step 5263: loss = 5.3046 (0.505 sec/step)
I0404 20:50:57.907456 47978602034560 learning.py:507] global step 5264: loss = 4.9859 (0.520 sec/step)
I0404 20:50:58.410516 47978602034560 learning.py:507] global step 5265: loss = 6.9042 (0.500 sec/step)
I0404 20:50:58.914911 47978602034560 learning.py:507] global step 5266: loss = 7.0311 (0.502 sec/step)
I0404 20:50:59.451210 47978602034560 learning.py:507] global step 5267: loss = 5.6457 (0.535 sec/step)
I0404 20:50:59.966701 47978602034560 learning.py:507] global step 5268: loss = 5.1496 (0.514 sec/step)
I0404 20:51:00.507592 47978602034560 learning.py:507] global step 5269: loss = 5.2845 (0.538 sec/step)
I0404 20:51:01.029197 47978602034560 learning.py:507] global step 5270: loss = 5.8453 (0.519 sec/step)
I0404 20:51:01.541911 47978602034560 learning.py:507] global step 5271: loss = 5.0336 (0.511 sec/step)
I0404 20:51:02.050437 47978602034560 learning.py:507] global step 5272: loss = 6.1771 (0.507 sec/step)
I0404 20:51:02.566143 47978602034560 learning.py:507] global step 5273: loss = 5.3340 (0.514 sec/step)
I0404 20:51:03.075337 47978602034560 learning.py:507] global step 5274: loss = 5.3565 (0.508 sec/step)
I0404 20:51:03.590643 47978602034560 learning.py:507] global step 5275: loss = 6.1543 (0.514 sec/step)
I0404 20:51:04.106618 47978602034560 learning.py:507] global step 5276: loss = 6.5678 (0.513 sec/step)
I0404 20:51:04.629833 47978602034560 learning.py:507] global step 5277: loss = 6.5737 (0.520 sec/step)
I0404 20:51:05.134162 47978602034560 learning.py:507] global step 5278: loss = 5.6099 (0.501 sec/step)
I0404 20:51:05.639427 47978602034560 learning.py:507] global step 5279: loss = 6.3894 (0.504 sec/step)
I0404 20:51:06.155234 47978602034560 learning.py:507] global step 5280: loss = 6.7285 (0.513 sec/step)
I0404 20:51:06.699379 47978602034560 learning.py:507] global step 5281: loss = 5.4712 (0.543 sec/step)
I0404 20:51:07.229688 47978602034560 learning.py:507] global step 5282: loss = 6.0241 (0.529 sec/step)
I0404 20:51:07.745048 47978602034560 learning.py:507] global step 5283: loss = 5.2064 (0.514 sec/step)
I0404 20:51:08.256369 47978602034560 learning.py:507] global step 5284: loss = 6.0357 (0.508 sec/step)
I0404 20:51:08.788078 47978602034560 learning.py:507] global step 5285: loss = 6.2074 (0.529 sec/step)
I0404 20:51:09.317759 47978602034560 learning.py:507] global step 5286: loss = 6.8129 (0.528 sec/step)
I0404 20:51:09.860332 47978602034560 learning.py:507] global step 5287: loss = 7.3231 (0.541 sec/step)
I0404 20:51:10.395529 47978602034560 learning.py:507] global step 5288: loss = 6.5879 (0.534 sec/step)
I0404 20:51:10.898235 47978602034560 learning.py:507] global step 5289: loss = 5.9382 (0.501 sec/step)
I0404 20:51:11.423367 47978602034560 learning.py:507] global step 5290: loss = 6.1146 (0.524 sec/step)
I0404 20:51:11.961556 47978602034560 learning.py:507] global step 5291: loss = 6.2870 (0.535 sec/step)
I0404 20:51:12.486935 47978602034560 learning.py:507] global step 5292: loss = 5.9717 (0.523 sec/step)
I0404 20:51:12.993175 47978602034560 learning.py:507] global step 5293: loss = 5.7911 (0.505 sec/step)
I0404 20:51:13.505842 47978602034560 learning.py:507] global step 5294: loss = 6.4908 (0.510 sec/step)
I0404 20:51:14.011689 47978602034560 learning.py:507] global step 5295: loss = 6.0346 (0.504 sec/step)
I0404 20:51:14.548922 47978602034560 learning.py:507] global step 5296: loss = 6.7599 (0.536 sec/step)
I0404 20:51:15.057157 47978602034560 learning.py:507] global step 5297: loss = 7.0863 (0.507 sec/step)
I0404 20:51:15.578417 47978602034560 learning.py:507] global step 5298: loss = 5.7501 (0.518 sec/step)
I0404 20:51:16.099997 47978602034560 learning.py:507] global step 5299: loss = 5.9608 (0.520 sec/step)
I0404 20:51:16.610256 47978602034560 learning.py:507] global step 5300: loss = 5.3697 (0.507 sec/step)
I0404 20:51:17.307009 47978602034560 learning.py:507] global step 5301: loss = 6.3168 (0.691 sec/step)
I0404 20:51:17.430703 47983661975296 supervisor.py:1050] Recording summary at step 5301.
I0404 20:51:17.815908 47978602034560 learning.py:507] global step 5302: loss = 6.2661 (0.507 sec/step)
I0404 20:51:18.320967 47978602034560 learning.py:507] global step 5303: loss = 6.6855 (0.503 sec/step)
I0404 20:51:18.830741 47978602034560 learning.py:507] global step 5304: loss = 5.5520 (0.508 sec/step)
I0404 20:51:19.348704 47978602034560 learning.py:507] global step 5305: loss = 6.0429 (0.516 sec/step)
I0404 20:51:19.864865 47978602034560 learning.py:507] global step 5306: loss = 6.6329 (0.515 sec/step)
I0404 20:51:20.397731 47978602034560 learning.py:507] global step 5307: loss = 6.4318 (0.531 sec/step)
I0404 20:51:20.906831 47978602034560 learning.py:507] global step 5308: loss = 6.9573 (0.506 sec/step)
I0404 20:51:21.420853 47978602034560 learning.py:507] global step 5309: loss = 6.1705 (0.512 sec/step)
I0404 20:51:21.943310 47978602034560 learning.py:507] global step 5310: loss = 6.1707 (0.521 sec/step)
I0404 20:51:22.455222 47978602034560 learning.py:507] global step 5311: loss = 7.0014 (0.509 sec/step)
I0404 20:51:22.958334 47978602034560 learning.py:507] global step 5312: loss = 5.8124 (0.502 sec/step)
I0404 20:51:23.469254 47978602034560 learning.py:507] global step 5313: loss = 5.4485 (0.508 sec/step)
I0404 20:51:23.979955 47978602034560 learning.py:507] global step 5314: loss = 6.1941 (0.509 sec/step)
I0404 20:51:24.499051 47978602034560 learning.py:507] global step 5315: loss = 6.2119 (0.518 sec/step)
I0404 20:51:25.003431 47978602034560 learning.py:507] global step 5316: loss = 6.0077 (0.503 sec/step)
I0404 20:51:25.503746 47978602034560 learning.py:507] global step 5317: loss = 5.7012 (0.499 sec/step)
I0404 20:51:26.002653 47978602034560 learning.py:507] global step 5318: loss = 5.9821 (0.497 sec/step)
I0404 20:51:26.510909 47978602034560 learning.py:507] global step 5319: loss = 5.9566 (0.505 sec/step)
I0404 20:51:27.022516 47978602034560 learning.py:507] global step 5320: loss = 6.3575 (0.509 sec/step)
I0404 20:51:27.543039 47978602034560 learning.py:507] global step 5321: loss = 5.7689 (0.519 sec/step)
I0404 20:51:28.072942 47978602034560 learning.py:507] global step 5322: loss = 6.9584 (0.528 sec/step)
I0404 20:51:28.581568 47978602034560 learning.py:507] global step 5323: loss = 5.7503 (0.506 sec/step)
I0404 20:51:29.100026 47978602034560 learning.py:507] global step 5324: loss = 6.4691 (0.517 sec/step)
I0404 20:51:29.605173 47978602034560 learning.py:507] global step 5325: loss = 6.2222 (0.502 sec/step)
I0404 20:51:30.131026 47978602034560 learning.py:507] global step 5326: loss = 5.7395 (0.524 sec/step)
I0404 20:51:30.669875 47978602034560 learning.py:507] global step 5327: loss = 5.8885 (0.536 sec/step)
I0404 20:51:31.175240 47978602034560 learning.py:507] global step 5328: loss = 5.7591 (0.504 sec/step)
I0404 20:51:31.703046 47978602034560 learning.py:507] global step 5329: loss = 6.4807 (0.526 sec/step)
I0404 20:51:32.208262 47978602034560 learning.py:507] global step 5330: loss = 5.7375 (0.504 sec/step)
I0404 20:51:32.752054 47978602034560 learning.py:507] global step 5331: loss = 6.0502 (0.542 sec/step)
I0404 20:51:33.296440 47978602034560 learning.py:507] global step 5332: loss = 5.9611 (0.542 sec/step)
I0404 20:51:33.818228 47978602034560 learning.py:507] global step 5333: loss = 7.2418 (0.519 sec/step)
I0404 20:51:34.325056 47978602034560 learning.py:507] global step 5334: loss = 6.2556 (0.505 sec/step)
I0404 20:51:34.842450 47978602034560 learning.py:507] global step 5335: loss = 6.3677 (0.516 sec/step)
I0404 20:51:35.350885 47978602034560 learning.py:507] global step 5336: loss = 5.4873 (0.507 sec/step)
I0404 20:51:35.870462 47978602034560 learning.py:507] global step 5337: loss = 6.0268 (0.517 sec/step)
I0404 20:51:36.378209 47978602034560 learning.py:507] global step 5338: loss = 7.4614 (0.506 sec/step)
I0404 20:51:36.885038 47978602034560 learning.py:507] global step 5339: loss = 5.9925 (0.504 sec/step)
I0404 20:51:37.384433 47978602034560 learning.py:507] global step 5340: loss = 6.6619 (0.498 sec/step)
I0404 20:51:37.894890 47978602034560 learning.py:507] global step 5341: loss = 6.1115 (0.508 sec/step)
I0404 20:51:38.398083 47978602034560 learning.py:507] global step 5342: loss = 6.0669 (0.502 sec/step)
I0404 20:51:38.905479 47978602034560 learning.py:507] global step 5343: loss = 5.8648 (0.506 sec/step)
I0404 20:51:39.410388 47978602034560 learning.py:507] global step 5344: loss = 6.6683 (0.503 sec/step)
I0404 20:51:39.915438 47978602034560 learning.py:507] global step 5345: loss = 6.3363 (0.503 sec/step)
I0404 20:51:40.425747 47978602034560 learning.py:507] global step 5346: loss = 5.8241 (0.509 sec/step)
I0404 20:51:40.935467 47978602034560 learning.py:507] global step 5347: loss = 5.9821 (0.508 sec/step)
I0404 20:51:41.442894 47978602034560 learning.py:507] global step 5348: loss = 5.5399 (0.506 sec/step)
I0404 20:51:41.948902 47978602034560 learning.py:507] global step 5349: loss = 5.7776 (0.504 sec/step)
I0404 20:51:42.472074 47978602034560 learning.py:507] global step 5350: loss = 5.1067 (0.520 sec/step)
I0404 20:51:42.980682 47978602034560 learning.py:507] global step 5351: loss = 6.1053 (0.507 sec/step)
I0404 20:51:43.498864 47978602034560 learning.py:507] global step 5352: loss = 5.6910 (0.517 sec/step)
I0404 20:51:44.011901 47978602034560 learning.py:507] global step 5353: loss = 5.8726 (0.511 sec/step)
I0404 20:51:44.530493 47978602034560 learning.py:507] global step 5354: loss = 5.3921 (0.517 sec/step)
I0404 20:51:45.034537 47978602034560 learning.py:507] global step 5355: loss = 6.0477 (0.501 sec/step)
I0404 20:51:45.542781 47978602034560 learning.py:507] global step 5356: loss = 6.9226 (0.505 sec/step)
I0404 20:51:46.074800 47978602034560 learning.py:507] global step 5357: loss = 6.2701 (0.529 sec/step)
I0404 20:51:46.583210 47978602034560 learning.py:507] global step 5358: loss = 5.7675 (0.506 sec/step)
I0404 20:51:47.102953 47978602034560 learning.py:507] global step 5359: loss = 6.5336 (0.518 sec/step)
I0404 20:51:47.612478 47978602034560 learning.py:507] global step 5360: loss = 5.1608 (0.508 sec/step)
I0404 20:51:48.146697 47978602034560 learning.py:507] global step 5361: loss = 5.6246 (0.533 sec/step)
I0404 20:51:48.650358 47978602034560 learning.py:507] global step 5362: loss = 6.1808 (0.502 sec/step)
I0404 20:51:49.156582 47978602034560 learning.py:507] global step 5363: loss = 6.1138 (0.505 sec/step)
I0404 20:51:49.672845 47978602034560 learning.py:507] global step 5364: loss = 5.1909 (0.515 sec/step)
I0404 20:51:50.181101 47978602034560 learning.py:507] global step 5365: loss = 6.2900 (0.507 sec/step)
I0404 20:51:50.683850 47978602034560 learning.py:507] global step 5366: loss = 6.0022 (0.500 sec/step)
I0404 20:51:51.199897 47978602034560 learning.py:507] global step 5367: loss = 6.2063 (0.514 sec/step)
I0404 20:51:51.709846 47978602034560 learning.py:507] global step 5368: loss = 5.0675 (0.508 sec/step)
I0404 20:51:52.212333 47978602034560 learning.py:507] global step 5369: loss = 5.8711 (0.501 sec/step)
I0404 20:51:52.720874 47978602034560 learning.py:507] global step 5370: loss = 6.9063 (0.506 sec/step)
I0404 20:51:53.250356 47978602034560 learning.py:507] global step 5371: loss = 5.2742 (0.527 sec/step)
I0404 20:51:53.769800 47978602034560 learning.py:507] global step 5372: loss = 6.1154 (0.518 sec/step)
I0404 20:51:54.288856 47978602034560 learning.py:507] global step 5373: loss = 7.2219 (0.518 sec/step)
I0404 20:51:54.800702 47978602034560 learning.py:507] global step 5374: loss = 6.2092 (0.510 sec/step)
I0404 20:51:55.308278 47978602034560 learning.py:507] global step 5375: loss = 6.0531 (0.506 sec/step)
I0404 20:51:55.817269 47978602034560 learning.py:507] global step 5376: loss = 7.7390 (0.506 sec/step)
I0404 20:51:56.360060 47978602034560 learning.py:507] global step 5377: loss = 6.0116 (0.541 sec/step)
I0404 20:51:56.894477 47978602034560 learning.py:507] global step 5378: loss = 6.4320 (0.533 sec/step)
I0404 20:51:57.400806 47978602034560 learning.py:507] global step 5379: loss = 5.5808 (0.505 sec/step)
I0404 20:51:57.913509 47978602034560 learning.py:507] global step 5380: loss = 5.7458 (0.510 sec/step)
I0404 20:51:58.416311 47978602034560 learning.py:507] global step 5381: loss = 6.4639 (0.501 sec/step)
I0404 20:51:58.929908 47978602034560 learning.py:507] global step 5382: loss = 5.0025 (0.512 sec/step)
I0404 20:51:59.445332 47978602034560 learning.py:507] global step 5383: loss = 6.3478 (0.513 sec/step)
I0404 20:51:59.977811 47978602034560 learning.py:507] global step 5384: loss = 5.0179 (0.530 sec/step)
I0404 20:52:00.479744 47978602034560 learning.py:507] global step 5385: loss = 5.8677 (0.500 sec/step)
I0404 20:52:01.008983 47978602034560 learning.py:507] global step 5386: loss = 6.8671 (0.526 sec/step)
I0404 20:52:01.516818 47978602034560 learning.py:507] global step 5387: loss = 6.2937 (0.506 sec/step)
I0404 20:52:02.049417 47978602034560 learning.py:507] global step 5388: loss = 5.6094 (0.531 sec/step)
I0404 20:52:02.560461 47978602034560 learning.py:507] global step 5389: loss = 5.7808 (0.509 sec/step)
I0404 20:52:03.095062 47978602034560 learning.py:507] global step 5390: loss = 6.7763 (0.533 sec/step)
I0404 20:52:03.626758 47978602034560 learning.py:507] global step 5391: loss = 5.7007 (0.530 sec/step)
I0404 20:52:04.139426 47978602034560 learning.py:507] global step 5392: loss = 6.3506 (0.511 sec/step)
I0404 20:52:04.683238 47978602034560 learning.py:507] global step 5393: loss = 6.7477 (0.542 sec/step)
I0404 20:52:05.198524 47978602034560 learning.py:507] global step 5394: loss = 5.6420 (0.514 sec/step)
I0404 20:52:05.712741 47978602034560 learning.py:507] global step 5395: loss = 5.8533 (0.513 sec/step)
I0404 20:52:06.230807 47978602034560 learning.py:507] global step 5396: loss = 5.8366 (0.516 sec/step)
I0404 20:52:06.746656 47978602034560 learning.py:507] global step 5397: loss = 6.0336 (0.514 sec/step)
I0404 20:52:07.260005 47978602034560 learning.py:507] global step 5398: loss = 5.6008 (0.512 sec/step)
I0404 20:52:07.770459 47978602034560 learning.py:507] global step 5399: loss = 5.6179 (0.509 sec/step)
I0404 20:52:08.284253 47978602034560 learning.py:507] global step 5400: loss = 6.8958 (0.512 sec/step)
I0404 20:52:08.792967 47978602034560 learning.py:507] global step 5401: loss = 5.2399 (0.507 sec/step)
I0404 20:52:09.330765 47978602034560 learning.py:507] global step 5402: loss = 6.0906 (0.536 sec/step)
I0404 20:52:09.874457 47978602034560 learning.py:507] global step 5403: loss = 6.3176 (0.542 sec/step)
I0404 20:52:10.386722 47978602034560 learning.py:507] global step 5404: loss = 6.7146 (0.511 sec/step)
I0404 20:52:10.914573 47978602034560 learning.py:507] global step 5405: loss = 5.7939 (0.526 sec/step)
I0404 20:52:11.426906 47978602034560 learning.py:507] global step 5406: loss = 5.4712 (0.509 sec/step)
I0404 20:52:11.934925 47978602034560 learning.py:507] global step 5407: loss = 6.1292 (0.505 sec/step)
I0404 20:52:12.470981 47978602034560 learning.py:507] global step 5408: loss = 5.6972 (0.534 sec/step)
I0404 20:52:12.987333 47978602034560 learning.py:507] global step 5409: loss = 6.3696 (0.513 sec/step)
I0404 20:52:13.501914 47978602034560 learning.py:507] global step 5410: loss = 6.4920 (0.513 sec/step)
I0404 20:52:14.040761 47978602034560 learning.py:507] global step 5411: loss = 5.6019 (0.536 sec/step)
I0404 20:52:14.548230 47978602034560 learning.py:507] global step 5412: loss = 6.0780 (0.505 sec/step)
I0404 20:52:15.092598 47978602034560 learning.py:507] global step 5413: loss = 5.6022 (0.543 sec/step)
I0404 20:52:15.604630 47978602034560 learning.py:507] global step 5414: loss = 5.9971 (0.510 sec/step)
I0404 20:52:16.118298 47978602034560 learning.py:507] global step 5415: loss = 5.1813 (0.511 sec/step)
I0404 20:52:16.653205 47978602034560 learning.py:507] global step 5416: loss = 5.5507 (0.533 sec/step)
I0404 20:52:17.196636 47978602034560 learning.py:507] global step 5417: loss = 6.0942 (0.542 sec/step)
I0404 20:52:17.701848 47978602034560 learning.py:507] global step 5418: loss = 5.2701 (0.502 sec/step)
I0404 20:52:18.214026 47978602034560 learning.py:507] global step 5419: loss = 6.7574 (0.511 sec/step)
I0404 20:52:18.758184 47978602034560 learning.py:507] global step 5420: loss = 6.3027 (0.543 sec/step)
I0404 20:52:19.287434 47978602034560 learning.py:507] global step 5421: loss = 5.3770 (0.526 sec/step)
I0404 20:52:19.827176 47978602034560 learning.py:507] global step 5422: loss = 5.6856 (0.537 sec/step)
I0404 20:52:20.344911 47978602034560 learning.py:507] global step 5423: loss = 5.0617 (0.515 sec/step)
I0404 20:52:20.856695 47978602034560 learning.py:507] global step 5424: loss = 6.3776 (0.510 sec/step)
I0404 20:52:21.375746 47978602034560 learning.py:507] global step 5425: loss = 6.5881 (0.518 sec/step)
I0404 20:52:21.894151 47978602034560 learning.py:507] global step 5426: loss = 6.3271 (0.517 sec/step)
I0404 20:52:22.405617 47978602034560 learning.py:507] global step 5427: loss = 5.5802 (0.510 sec/step)
I0404 20:52:22.914234 47978602034560 learning.py:507] global step 5428: loss = 6.2359 (0.507 sec/step)
I0404 20:52:23.452802 47978602034560 learning.py:507] global step 5429: loss = 6.4925 (0.537 sec/step)
I0404 20:52:23.962334 47978602034560 learning.py:507] global step 5430: loss = 6.2583 (0.507 sec/step)
I0404 20:52:24.479418 47978602034560 learning.py:507] global step 5431: loss = 6.5195 (0.514 sec/step)
I0404 20:52:24.985932 47978602034560 learning.py:507] global step 5432: loss = 6.8405 (0.505 sec/step)
I0404 20:52:25.516038 47978602034560 learning.py:507] global step 5433: loss = 6.7555 (0.529 sec/step)
I0404 20:52:26.019241 47978602034560 learning.py:507] global step 5434: loss = 5.7643 (0.500 sec/step)
I0404 20:52:26.547744 47978602034560 learning.py:507] global step 5435: loss = 4.8903 (0.526 sec/step)
I0404 20:52:27.053048 47978602034560 learning.py:507] global step 5436: loss = 5.9085 (0.504 sec/step)
I0404 20:52:27.569190 47978602034560 learning.py:507] global step 5437: loss = 5.4158 (0.515 sec/step)
I0404 20:52:28.097368 47978602034560 learning.py:507] global step 5438: loss = 5.7048 (0.527 sec/step)
I0404 20:52:28.617660 47978602034560 learning.py:507] global step 5439: loss = 6.3631 (0.519 sec/step)
I0404 20:52:29.136420 47978602034560 learning.py:507] global step 5440: loss = 5.1511 (0.517 sec/step)
I0404 20:52:29.649694 47978602034560 learning.py:507] global step 5441: loss = 5.4976 (0.512 sec/step)
I0404 20:52:30.152509 47978602034560 learning.py:507] global step 5442: loss = 6.3983 (0.501 sec/step)
I0404 20:52:30.670020 47978602034560 learning.py:507] global step 5443: loss = 6.1018 (0.516 sec/step)
I0404 20:52:31.186218 47978602034560 learning.py:507] global step 5444: loss = 6.4061 (0.515 sec/step)
I0404 20:52:31.700767 47978602034560 learning.py:507] global step 5445: loss = 6.7789 (0.513 sec/step)
I0404 20:52:32.216535 47978602034560 learning.py:507] global step 5446: loss = 5.5334 (0.514 sec/step)
I0404 20:52:32.722701 47978602034560 learning.py:507] global step 5447: loss = 5.6059 (0.503 sec/step)
I0404 20:52:33.254181 47978602034560 learning.py:507] global step 5448: loss = 5.9273 (0.530 sec/step)
I0404 20:52:33.762197 47978602034560 learning.py:507] global step 5449: loss = 5.8210 (0.506 sec/step)
I0404 20:52:34.298919 47978602034560 learning.py:507] global step 5450: loss = 6.3002 (0.535 sec/step)
I0404 20:52:34.810967 47978602034560 learning.py:507] global step 5451: loss = 6.4876 (0.510 sec/step)
I0404 20:52:35.328245 47978602034560 learning.py:507] global step 5452: loss = 6.8967 (0.516 sec/step)
I0404 20:52:35.841193 47978602034560 learning.py:507] global step 5453: loss = 5.9174 (0.510 sec/step)
I0404 20:52:36.351171 47978602034560 learning.py:507] global step 5454: loss = 6.3726 (0.508 sec/step)
I0404 20:52:36.866082 47978602034560 learning.py:507] global step 5455: loss = 5.7922 (0.512 sec/step)
I0404 20:52:37.399846 47978602034560 learning.py:507] global step 5456: loss = 5.7016 (0.531 sec/step)
I0404 20:52:37.907827 47978602034560 learning.py:507] global step 5457: loss = 6.8176 (0.505 sec/step)
I0404 20:52:38.411844 47978602034560 learning.py:507] global step 5458: loss = 6.5776 (0.502 sec/step)
I0404 20:52:38.934390 47978602034560 learning.py:507] global step 5459: loss = 5.7420 (0.520 sec/step)
I0404 20:52:39.444253 47978602034560 learning.py:507] global step 5460: loss = 5.1161 (0.508 sec/step)
I0404 20:52:39.953284 47978602034560 learning.py:507] global step 5461: loss = 6.7786 (0.507 sec/step)
I0404 20:52:40.459000 47978602034560 learning.py:507] global step 5462: loss = 6.2156 (0.503 sec/step)
I0404 20:52:40.966485 47978602034560 learning.py:507] global step 5463: loss = 6.5018 (0.504 sec/step)
I0404 20:52:41.476450 47978602034560 learning.py:507] global step 5464: loss = 6.9961 (0.508 sec/step)
I0404 20:52:41.988355 47978602034560 learning.py:507] global step 5465: loss = 5.9610 (0.509 sec/step)
I0404 20:52:42.515003 47978602034560 learning.py:507] global step 5466: loss = 6.4514 (0.525 sec/step)
I0404 20:52:43.026479 47978602034560 learning.py:507] global step 5467: loss = 7.5511 (0.510 sec/step)
I0404 20:52:43.539656 47978602034560 learning.py:507] global step 5468: loss = 6.3613 (0.510 sec/step)
I0404 20:52:44.048044 47978602034560 learning.py:507] global step 5469: loss = 6.6677 (0.507 sec/step)
I0404 20:52:44.550900 47978602034560 learning.py:507] global step 5470: loss = 5.6447 (0.501 sec/step)
I0404 20:52:45.054043 47978602034560 learning.py:507] global step 5471: loss = 6.0769 (0.502 sec/step)
I0404 20:52:45.572219 47978602034560 learning.py:507] global step 5472: loss = 6.2415 (0.517 sec/step)
I0404 20:52:46.093145 47978602034560 learning.py:507] global step 5473: loss = 7.0411 (0.519 sec/step)
I0404 20:52:46.606982 47978602034560 learning.py:507] global step 5474: loss = 5.7196 (0.512 sec/step)
I0404 20:52:47.120617 47978602034560 learning.py:507] global step 5475: loss = 5.7714 (0.512 sec/step)
I0404 20:52:47.626279 47978602034560 learning.py:507] global step 5476: loss = 6.1999 (0.503 sec/step)
I0404 20:52:48.137159 47978602034560 learning.py:507] global step 5477: loss = 6.0655 (0.508 sec/step)
I0404 20:52:48.650231 47978602034560 learning.py:507] global step 5478: loss = 5.3685 (0.511 sec/step)
I0404 20:52:49.160094 47978602034560 learning.py:507] global step 5479: loss = 4.8913 (0.508 sec/step)
I0404 20:52:49.671108 47978602034560 learning.py:507] global step 5480: loss = 6.4635 (0.508 sec/step)
I0404 20:52:50.211376 47978602034560 learning.py:507] global step 5481: loss = 7.3239 (0.539 sec/step)
I0404 20:52:50.725262 47978602034560 learning.py:507] global step 5482: loss = 6.5403 (0.512 sec/step)
I0404 20:52:51.232293 47978602034560 learning.py:507] global step 5483: loss = 7.5047 (0.505 sec/step)
I0404 20:52:51.770956 47978602034560 learning.py:507] global step 5484: loss = 5.9609 (0.537 sec/step)
I0404 20:52:52.283163 47978602034560 learning.py:507] global step 5485: loss = 5.9443 (0.511 sec/step)
I0404 20:52:52.816701 47978602034560 learning.py:507] global step 5486: loss = 6.0316 (0.532 sec/step)
I0404 20:52:53.340858 47978602034560 learning.py:507] global step 5487: loss = 6.7553 (0.521 sec/step)
I0404 20:52:53.851498 47978602034560 learning.py:507] global step 5488: loss = 5.2358 (0.509 sec/step)
I0404 20:52:54.353651 47978602034560 learning.py:507] global step 5489: loss = 4.9199 (0.499 sec/step)
I0404 20:52:54.860788 47978602034560 learning.py:507] global step 5490: loss = 6.6316 (0.505 sec/step)
I0404 20:52:55.378088 47978602034560 learning.py:507] global step 5491: loss = 6.5514 (0.516 sec/step)
I0404 20:52:55.893288 47978602034560 learning.py:507] global step 5492: loss = 6.0515 (0.514 sec/step)
I0404 20:52:56.395313 47978602034560 learning.py:507] global step 5493: loss = 6.4063 (0.500 sec/step)
I0404 20:52:56.927287 47978602034560 learning.py:507] global step 5494: loss = 5.3361 (0.530 sec/step)
I0404 20:52:57.435483 47978602034560 learning.py:507] global step 5495: loss = 7.0695 (0.507 sec/step)
I0404 20:52:57.939877 47978602034560 learning.py:507] global step 5496: loss = 6.9759 (0.502 sec/step)
I0404 20:52:58.454425 47978602034560 learning.py:507] global step 5497: loss = 6.4806 (0.512 sec/step)
I0404 20:52:58.966840 47978602034560 learning.py:507] global step 5498: loss = 5.7325 (0.510 sec/step)
I0404 20:52:59.478966 47978602034560 learning.py:507] global step 5499: loss = 5.7212 (0.511 sec/step)
I0404 20:52:59.986315 47978602034560 learning.py:507] global step 5500: loss = 6.4942 (0.506 sec/step)
I0404 20:53:00.499943 47978602034560 learning.py:507] global step 5501: loss = 5.5025 (0.512 sec/step)
I0404 20:53:01.027128 47978602034560 learning.py:507] global step 5502: loss = 6.2772 (0.526 sec/step)
I0404 20:53:01.534485 47978602034560 learning.py:507] global step 5503: loss = 7.0610 (0.506 sec/step)
I0404 20:53:02.041461 47978602034560 learning.py:507] global step 5504: loss = 6.2065 (0.505 sec/step)
I0404 20:53:02.563712 47978602034560 learning.py:507] global step 5505: loss = 6.2281 (0.519 sec/step)
I0404 20:53:03.086101 47978602034560 learning.py:507] global step 5506: loss = 6.2418 (0.519 sec/step)
I0404 20:53:03.592141 47978602034560 learning.py:507] global step 5507: loss = 6.5210 (0.504 sec/step)
I0404 20:53:04.111646 47978602034560 learning.py:507] global step 5508: loss = 6.5955 (0.518 sec/step)
I0404 20:53:04.624993 47978602034560 learning.py:507] global step 5509: loss = 6.5122 (0.512 sec/step)
I0404 20:53:05.134939 47978602034560 learning.py:507] global step 5510: loss = 6.0203 (0.508 sec/step)
I0404 20:53:05.653144 47978602034560 learning.py:507] global step 5511: loss = 6.9757 (0.517 sec/step)
I0404 20:53:06.162925 47978602034560 learning.py:507] global step 5512: loss = 6.1929 (0.507 sec/step)
I0404 20:53:06.667222 47978602034560 learning.py:507] global step 5513: loss = 6.9701 (0.503 sec/step)
I0404 20:53:07.197811 47978602034560 learning.py:507] global step 5514: loss = 5.2289 (0.529 sec/step)
I0404 20:53:07.715621 47978602034560 learning.py:507] global step 5515: loss = 5.3335 (0.516 sec/step)
I0404 20:53:08.246347 47978602034560 learning.py:507] global step 5516: loss = 5.9787 (0.529 sec/step)
I0404 20:53:08.760209 47978602034560 learning.py:507] global step 5517: loss = 6.1688 (0.512 sec/step)
I0404 20:53:09.272558 47978602034560 learning.py:507] global step 5518: loss = 6.0286 (0.511 sec/step)
I0404 20:53:09.779311 47978602034560 learning.py:507] global step 5519: loss = 6.0289 (0.505 sec/step)
I0404 20:53:10.281581 47978602034560 learning.py:507] global step 5520: loss = 5.6812 (0.501 sec/step)
I0404 20:53:10.785500 47978602034560 learning.py:507] global step 5521: loss = 5.8804 (0.501 sec/step)
I0404 20:53:11.295612 47978602034560 learning.py:507] global step 5522: loss = 6.4687 (0.509 sec/step)
I0404 20:53:11.808868 47978602034560 learning.py:507] global step 5523: loss = 5.2988 (0.510 sec/step)
I0404 20:53:12.327601 47978602034560 learning.py:507] global step 5524: loss = 6.6055 (0.517 sec/step)
I0404 20:53:12.845165 47978602034560 learning.py:507] global step 5525: loss = 5.3841 (0.516 sec/step)
I0404 20:53:13.361254 47978602034560 learning.py:507] global step 5526: loss = 4.4952 (0.514 sec/step)
I0404 20:53:13.864177 47978602034560 learning.py:507] global step 5527: loss = 4.6735 (0.501 sec/step)
I0404 20:53:14.373190 47978602034560 learning.py:507] global step 5528: loss = 5.6860 (0.507 sec/step)
I0404 20:53:14.896059 47978602034560 learning.py:507] global step 5529: loss = 6.1876 (0.521 sec/step)
I0404 20:53:15.411144 47978602034560 learning.py:507] global step 5530: loss = 6.4131 (0.513 sec/step)
I0404 20:53:15.919669 47978602034560 learning.py:507] global step 5531: loss = 6.0137 (0.506 sec/step)
I0404 20:53:16.429705 47978602034560 learning.py:507] global step 5532: loss = 5.1537 (0.508 sec/step)
I0404 20:53:16.944244 47978602034560 learning.py:507] global step 5533: loss = 6.7106 (0.511 sec/step)
I0404 20:53:17.306865 47983661975296 supervisor.py:1050] Recording summary at step 5533.
I0404 20:53:17.628988 47978602034560 learning.py:507] global step 5534: loss = 5.9520 (0.681 sec/step)
I0404 20:53:18.142165 47978602034560 learning.py:507] global step 5535: loss = 6.6957 (0.510 sec/step)
I0404 20:53:18.645908 47978602034560 learning.py:507] global step 5536: loss = 6.1071 (0.502 sec/step)
I0404 20:53:19.171196 47978602034560 learning.py:507] global step 5537: loss = 5.4803 (0.524 sec/step)
I0404 20:53:19.702193 47978602034560 learning.py:507] global step 5538: loss = 7.1804 (0.529 sec/step)
I0404 20:53:20.228212 47978602034560 learning.py:507] global step 5539: loss = 5.2074 (0.523 sec/step)
I0404 20:53:20.737783 47978602034560 learning.py:507] global step 5540: loss = 5.4029 (0.508 sec/step)
I0404 20:53:21.272552 47978602034560 learning.py:507] global step 5541: loss = 6.5049 (0.533 sec/step)
I0404 20:53:21.781875 47978602034560 learning.py:507] global step 5542: loss = 5.2687 (0.506 sec/step)
I0404 20:53:22.290682 47978602034560 learning.py:507] global step 5543: loss = 6.4987 (0.507 sec/step)
I0404 20:53:22.796130 47978602034560 learning.py:507] global step 5544: loss = 5.8585 (0.503 sec/step)
I0404 20:53:23.300870 47978602034560 learning.py:507] global step 5545: loss = 6.8759 (0.503 sec/step)
I0404 20:53:23.803501 47978602034560 learning.py:507] global step 5546: loss = 6.5179 (0.500 sec/step)
I0404 20:53:24.312949 47978602034560 learning.py:507] global step 5547: loss = 5.4275 (0.508 sec/step)
I0404 20:53:24.826956 47978602034560 learning.py:507] global step 5548: loss = 5.2939 (0.512 sec/step)
I0404 20:53:25.367260 47978602034560 learning.py:507] global step 5549: loss = 6.8964 (0.539 sec/step)
I0404 20:53:25.870020 47978602034560 learning.py:507] global step 5550: loss = 7.2095 (0.501 sec/step)
I0404 20:53:26.406255 47978602034560 learning.py:507] global step 5551: loss = 5.8868 (0.535 sec/step)
I0404 20:53:26.934902 47978602034560 learning.py:507] global step 5552: loss = 6.7407 (0.526 sec/step)
I0404 20:53:27.442459 47978602034560 learning.py:507] global step 5553: loss = 6.2619 (0.505 sec/step)
I0404 20:53:27.961057 47978602034560 learning.py:507] global step 5554: loss = 6.4055 (0.517 sec/step)
I0404 20:53:28.480296 47978602034560 learning.py:507] global step 5555: loss = 6.8841 (0.518 sec/step)
I0404 20:53:28.988652 47978602034560 learning.py:507] global step 5556: loss = 6.3087 (0.507 sec/step)
I0404 20:53:29.526674 47978602034560 learning.py:507] global step 5557: loss = 4.8802 (0.536 sec/step)
I0404 20:53:30.033237 47978602034560 learning.py:507] global step 5558: loss = 5.6443 (0.505 sec/step)
I0404 20:53:30.538672 47978602034560 learning.py:507] global step 5559: loss = 5.2834 (0.504 sec/step)
I0404 20:53:31.057643 47978602034560 learning.py:507] global step 5560: loss = 6.1004 (0.516 sec/step)
I0404 20:53:31.563549 47978602034560 learning.py:507] global step 5561: loss = 5.2117 (0.503 sec/step)
I0404 20:53:32.072973 47978602034560 learning.py:507] global step 5562: loss = 5.8971 (0.508 sec/step)
I0404 20:53:32.586204 47978602034560 learning.py:507] global step 5563: loss = 5.0712 (0.510 sec/step)
I0404 20:53:33.093503 47978602034560 learning.py:507] global step 5564: loss = 5.2425 (0.506 sec/step)
I0404 20:53:33.597576 47978602034560 learning.py:507] global step 5565: loss = 6.4548 (0.501 sec/step)
I0404 20:53:34.102860 47978602034560 learning.py:507] global step 5566: loss = 7.7648 (0.504 sec/step)
I0404 20:53:34.638170 47978602034560 learning.py:507] global step 5567: loss = 5.6187 (0.534 sec/step)
I0404 20:53:35.155508 47978602034560 learning.py:507] global step 5568: loss = 5.6007 (0.514 sec/step)
I0404 20:53:35.665410 47978602034560 learning.py:507] global step 5569: loss = 6.2511 (0.508 sec/step)
I0404 20:53:36.199502 47978602034560 learning.py:507] global step 5570: loss = 6.4039 (0.532 sec/step)
I0404 20:53:36.737414 47978602034560 learning.py:507] global step 5571: loss = 6.4797 (0.536 sec/step)
I0404 20:53:37.269971 47978602034560 learning.py:507] global step 5572: loss = 6.7841 (0.531 sec/step)
I0404 20:53:37.772966 47978602034560 learning.py:507] global step 5573: loss = 5.8076 (0.501 sec/step)
I0404 20:53:38.300737 47978602034560 learning.py:507] global step 5574: loss = 5.6972 (0.525 sec/step)
I0404 20:53:38.841259 47978602034560 learning.py:507] global step 5575: loss = 5.0653 (0.539 sec/step)
I0404 20:53:39.348380 47978602034560 learning.py:507] global step 5576: loss = 6.5050 (0.506 sec/step)
I0404 20:53:39.887208 47978602034560 learning.py:507] global step 5577: loss = 5.6685 (0.537 sec/step)
I0404 20:53:40.406278 47978602034560 learning.py:507] global step 5578: loss = 5.2096 (0.517 sec/step)
I0404 20:53:40.920689 47978602034560 learning.py:507] global step 5579: loss = 5.4869 (0.513 sec/step)
I0404 20:53:41.420045 47978602034560 learning.py:507] global step 5580: loss = 5.4271 (0.498 sec/step)
I0404 20:53:41.932006 47978602034560 learning.py:507] global step 5581: loss = 5.7421 (0.510 sec/step)
I0404 20:53:42.453820 47978602034560 learning.py:507] global step 5582: loss = 5.6168 (0.520 sec/step)
I0404 20:53:42.961566 47978602034560 learning.py:507] global step 5583: loss = 6.3601 (0.506 sec/step)
I0404 20:53:43.494858 47978602034560 learning.py:507] global step 5584: loss = 5.5990 (0.530 sec/step)
I0404 20:53:44.003842 47978602034560 learning.py:507] global step 5585: loss = 5.3537 (0.507 sec/step)
I0404 20:53:44.509099 47978602034560 learning.py:507] global step 5586: loss = 5.7089 (0.504 sec/step)
I0404 20:53:45.036585 47978602034560 learning.py:507] global step 5587: loss = 5.4190 (0.525 sec/step)
I0404 20:53:45.567035 47978602034560 learning.py:507] global step 5588: loss = 5.3330 (0.528 sec/step)
I0404 20:53:46.096670 47978602034560 learning.py:507] global step 5589: loss = 5.4219 (0.527 sec/step)
I0404 20:53:46.618063 47978602034560 learning.py:507] global step 5590: loss = 4.9280 (0.520 sec/step)
I0404 20:53:47.129875 47978602034560 learning.py:507] global step 5591: loss = 5.8504 (0.510 sec/step)
I0404 20:53:47.658622 47978602034560 learning.py:507] global step 5592: loss = 4.7427 (0.527 sec/step)
I0404 20:53:48.160734 47978602034560 learning.py:507] global step 5593: loss = 6.3928 (0.501 sec/step)
I0404 20:53:48.683229 47978602034560 learning.py:507] global step 5594: loss = 7.0877 (0.521 sec/step)
I0404 20:53:49.209249 47978602034560 learning.py:507] global step 5595: loss = 6.2097 (0.524 sec/step)
I0404 20:53:49.707873 47978602034560 learning.py:507] global step 5596: loss = 5.3868 (0.497 sec/step)
I0404 20:53:50.227388 47978602034560 learning.py:507] global step 5597: loss = 6.1034 (0.518 sec/step)
I0404 20:53:50.746678 47978602034560 learning.py:507] global step 5598: loss = 5.9132 (0.516 sec/step)
I0404 20:53:51.259917 47978602034560 learning.py:507] global step 5599: loss = 5.8825 (0.512 sec/step)
I0404 20:53:51.768242 47978602034560 learning.py:507] global step 5600: loss = 6.5968 (0.507 sec/step)
I0404 20:53:52.283764 47978602034560 learning.py:507] global step 5601: loss = 5.1429 (0.514 sec/step)
I0404 20:53:52.810833 47978602034560 learning.py:507] global step 5602: loss = 7.0411 (0.524 sec/step)
I0404 20:53:53.308765 47978602034560 learning.py:507] global step 5603: loss = 5.9754 (0.496 sec/step)
I0404 20:53:53.840144 47978602034560 learning.py:507] global step 5604: loss = 7.0034 (0.528 sec/step)
I0404 20:53:54.346655 47978602034560 learning.py:507] global step 5605: loss = 5.9261 (0.505 sec/step)
I0404 20:53:54.865543 47978602034560 learning.py:507] global step 5606: loss = 5.6539 (0.516 sec/step)
I0404 20:53:55.369316 47978602034560 learning.py:507] global step 5607: loss = 5.6562 (0.502 sec/step)
I0404 20:53:55.885058 47978602034560 learning.py:507] global step 5608: loss = 5.6905 (0.513 sec/step)
I0404 20:53:56.390874 47978602034560 learning.py:507] global step 5609: loss = 5.3654 (0.503 sec/step)
I0404 20:53:56.908465 47978602034560 learning.py:507] global step 5610: loss = 6.5205 (0.516 sec/step)
I0404 20:53:57.429709 47978602034560 learning.py:507] global step 5611: loss = 6.0487 (0.518 sec/step)
I0404 20:53:57.937361 47978602034560 learning.py:507] global step 5612: loss = 5.8033 (0.505 sec/step)
I0404 20:53:58.444934 47978602034560 learning.py:507] global step 5613: loss = 5.3459 (0.505 sec/step)
I0404 20:53:58.955723 47978602034560 learning.py:507] global step 5614: loss = 5.4299 (0.509 sec/step)
I0404 20:53:59.467641 47978602034560 learning.py:507] global step 5615: loss = 5.7745 (0.510 sec/step)
I0404 20:54:00.002189 47978602034560 learning.py:507] global step 5616: loss = 5.3508 (0.533 sec/step)
I0404 20:54:00.516669 47978602034560 learning.py:507] global step 5617: loss = 5.9209 (0.511 sec/step)
I0404 20:54:01.027205 47978602034560 learning.py:507] global step 5618: loss = 4.8599 (0.508 sec/step)
I0404 20:54:01.557716 47978602034560 learning.py:507] global step 5619: loss = 7.2158 (0.528 sec/step)
I0404 20:54:02.064559 47978602034560 learning.py:507] global step 5620: loss = 5.1188 (0.505 sec/step)
I0404 20:54:02.597687 47978602034560 learning.py:507] global step 5621: loss = 6.0433 (0.531 sec/step)
I0404 20:54:03.111427 47978602034560 learning.py:507] global step 5622: loss = 6.1420 (0.511 sec/step)
I0404 20:54:03.641946 47978602034560 learning.py:507] global step 5623: loss = 5.9969 (0.529 sec/step)
I0404 20:54:04.146210 47978602034560 learning.py:507] global step 5624: loss = 5.4332 (0.503 sec/step)
I0404 20:54:04.664433 47978602034560 learning.py:507] global step 5625: loss = 6.1386 (0.515 sec/step)
I0404 20:54:05.174113 47978602034560 learning.py:507] global step 5626: loss = 5.7576 (0.508 sec/step)
I0404 20:54:05.694889 47978602034560 learning.py:507] global step 5627: loss = 5.5919 (0.519 sec/step)
I0404 20:54:06.205284 47978602034560 learning.py:507] global step 5628: loss = 5.9377 (0.508 sec/step)
I0404 20:54:06.711239 47978602034560 learning.py:507] global step 5629: loss = 5.3925 (0.504 sec/step)
I0404 20:54:07.230032 47978602034560 learning.py:507] global step 5630: loss = 6.1771 (0.517 sec/step)
I0404 20:54:07.740083 47978602034560 learning.py:507] global step 5631: loss = 6.2621 (0.507 sec/step)
I0404 20:54:08.268019 47978602034560 learning.py:507] global step 5632: loss = 5.9837 (0.526 sec/step)
I0404 20:54:08.805150 47978602034560 learning.py:507] global step 5633: loss = 5.7106 (0.536 sec/step)
I0404 20:54:09.309285 47978602034560 learning.py:507] global step 5634: loss = 6.4399 (0.501 sec/step)
I0404 20:54:09.816095 47978602034560 learning.py:507] global step 5635: loss = 5.5286 (0.505 sec/step)
I0404 20:54:10.352600 47978602034560 learning.py:507] global step 5636: loss = 6.4772 (0.535 sec/step)
I0404 20:54:10.880957 47978602034560 learning.py:507] global step 5637: loss = 5.7643 (0.527 sec/step)
I0404 20:54:11.386522 47978602034560 learning.py:507] global step 5638: loss = 5.8871 (0.504 sec/step)
I0404 20:54:11.901422 47978602034560 learning.py:507] global step 5639: loss = 5.5485 (0.513 sec/step)
I0404 20:54:12.426674 47978602034560 learning.py:507] global step 5640: loss = 6.5243 (0.524 sec/step)
I0404 20:54:12.938251 47978602034560 learning.py:507] global step 5641: loss = 5.9658 (0.510 sec/step)
I0404 20:54:13.473845 47978602034560 learning.py:507] global step 5642: loss = 5.9690 (0.533 sec/step)
I0404 20:54:13.983451 47978602034560 learning.py:507] global step 5643: loss = 5.4436 (0.508 sec/step)
I0404 20:54:14.518451 47978602034560 learning.py:507] global step 5644: loss = 5.6421 (0.533 sec/step)
I0404 20:54:15.027857 47978602034560 learning.py:507] global step 5645: loss = 6.3501 (0.508 sec/step)
I0404 20:54:15.565905 47978602034560 learning.py:507] global step 5646: loss = 5.7769 (0.536 sec/step)
I0404 20:54:16.081343 47978602034560 learning.py:507] global step 5647: loss = 5.7228 (0.514 sec/step)
I0404 20:54:16.590827 47978602034560 learning.py:507] global step 5648: loss = 6.0220 (0.508 sec/step)
I0404 20:54:17.109310 47978602034560 learning.py:507] global step 5649: loss = 5.5897 (0.517 sec/step)
I0404 20:54:17.614011 47978602034560 learning.py:507] global step 5650: loss = 5.9055 (0.503 sec/step)
I0404 20:54:18.119599 47978602034560 learning.py:507] global step 5651: loss = 6.1323 (0.504 sec/step)
I0404 20:54:18.624872 47978602034560 learning.py:507] global step 5652: loss = 6.7313 (0.504 sec/step)
I0404 20:54:19.137893 47978602034560 learning.py:507] global step 5653: loss = 6.3653 (0.511 sec/step)
I0404 20:54:19.680296 47978602034560 learning.py:507] global step 5654: loss = 7.0007 (0.541 sec/step)
I0404 20:54:20.215502 47978602034560 learning.py:507] global step 5655: loss = 6.1007 (0.534 sec/step)
I0404 20:54:20.753920 47978602034560 learning.py:507] global step 5656: loss = 5.7047 (0.536 sec/step)
I0404 20:54:21.274697 47978602034560 learning.py:507] global step 5657: loss = 6.4141 (0.519 sec/step)
I0404 20:54:21.794105 47978602034560 learning.py:507] global step 5658: loss = 5.9263 (0.518 sec/step)
I0404 20:54:22.304009 47978602034560 learning.py:507] global step 5659: loss = 6.0594 (0.508 sec/step)
I0404 20:54:22.819676 47978602034560 learning.py:507] global step 5660: loss = 5.7310 (0.514 sec/step)
I0404 20:54:23.330173 47978602034560 learning.py:507] global step 5661: loss = 6.3156 (0.508 sec/step)
I0404 20:54:23.840457 47978602034560 learning.py:507] global step 5662: loss = 5.2699 (0.507 sec/step)
I0404 20:54:24.350864 47978602034560 learning.py:507] global step 5663: loss = 6.6166 (0.509 sec/step)
I0404 20:54:24.860271 47978602034560 learning.py:507] global step 5664: loss = 5.7507 (0.508 sec/step)
I0404 20:54:25.372484 47978602034560 learning.py:507] global step 5665: loss = 6.1794 (0.511 sec/step)
I0404 20:54:25.888907 47978602034560 learning.py:507] global step 5666: loss = 6.3654 (0.514 sec/step)
I0404 20:54:26.414910 47978602034560 learning.py:507] global step 5667: loss = 6.8049 (0.524 sec/step)
I0404 20:54:26.922580 47978602034560 learning.py:507] global step 5668: loss = 5.3503 (0.506 sec/step)
I0404 20:54:27.454841 47978602034560 learning.py:507] global step 5669: loss = 5.3893 (0.529 sec/step)
I0404 20:54:27.961770 47978602034560 learning.py:507] global step 5670: loss = 6.0139 (0.504 sec/step)
I0404 20:54:28.478842 47978602034560 learning.py:507] global step 5671: loss = 6.2553 (0.515 sec/step)
I0404 20:54:29.015257 47978602034560 learning.py:507] global step 5672: loss = 6.2704 (0.535 sec/step)
I0404 20:54:29.544723 47978602034560 learning.py:507] global step 5673: loss = 6.3823 (0.528 sec/step)
I0404 20:54:30.044008 47978602034560 learning.py:507] global step 5674: loss = 6.0436 (0.498 sec/step)
I0404 20:54:30.545341 47978602034560 learning.py:507] global step 5675: loss = 5.9997 (0.500 sec/step)
I0404 20:54:31.048103 47978602034560 learning.py:507] global step 5676: loss = 6.6183 (0.500 sec/step)
I0404 20:54:31.585488 47978602034560 learning.py:507] global step 5677: loss = 5.6411 (0.535 sec/step)
I0404 20:54:32.095217 47978602034560 learning.py:507] global step 5678: loss = 6.2052 (0.507 sec/step)
I0404 20:54:32.609726 47978602034560 learning.py:507] global step 5679: loss = 5.5732 (0.512 sec/step)
I0404 20:54:33.136832 47978602034560 learning.py:507] global step 5680: loss = 5.7081 (0.526 sec/step)
I0404 20:54:33.654237 47978602034560 learning.py:507] global step 5681: loss = 5.2286 (0.516 sec/step)
I0404 20:54:34.169906 47978602034560 learning.py:507] global step 5682: loss = 5.3510 (0.514 sec/step)
I0404 20:54:34.674644 47978602034560 learning.py:507] global step 5683: loss = 6.2760 (0.503 sec/step)
I0404 20:54:35.210949 47978602034560 learning.py:507] global step 5684: loss = 6.9984 (0.535 sec/step)
I0404 20:54:35.745980 47978602034560 learning.py:507] global step 5685: loss = 5.5795 (0.533 sec/step)
I0404 20:54:36.292992 47978602034560 learning.py:507] global step 5686: loss = 6.1018 (0.545 sec/step)
I0404 20:54:36.798633 47978602034560 learning.py:507] global step 5687: loss = 6.4872 (0.504 sec/step)
I0404 20:54:37.302447 47978602034560 learning.py:507] global step 5688: loss = 7.2080 (0.502 sec/step)
I0404 20:54:37.808743 47978602034560 learning.py:507] global step 5689: loss = 6.0236 (0.503 sec/step)
I0404 20:54:38.317498 47978602034560 learning.py:507] global step 5690: loss = 6.0407 (0.506 sec/step)
I0404 20:54:38.823527 47978602034560 learning.py:507] global step 5691: loss = 6.8992 (0.503 sec/step)
I0404 20:54:39.326140 47978602034560 learning.py:507] global step 5692: loss = 5.6626 (0.500 sec/step)
I0404 20:54:39.860213 47978602034560 learning.py:507] global step 5693: loss = 5.3922 (0.533 sec/step)
I0404 20:54:40.362024 47978602034560 learning.py:507] global step 5694: loss = 6.2623 (0.500 sec/step)
I0404 20:54:40.874543 47978602034560 learning.py:507] global step 5695: loss = 6.2426 (0.510 sec/step)
I0404 20:54:41.408336 47978602034560 learning.py:507] global step 5696: loss = 5.9160 (0.532 sec/step)
I0404 20:54:41.915815 47978602034560 learning.py:507] global step 5697: loss = 5.8585 (0.506 sec/step)
I0404 20:54:42.423832 47978602034560 learning.py:507] global step 5698: loss = 6.5407 (0.506 sec/step)
I0404 20:54:42.941430 47978602034560 learning.py:507] global step 5699: loss = 5.9042 (0.515 sec/step)
I0404 20:54:43.451520 47978602034560 learning.py:507] global step 5700: loss = 7.2088 (0.509 sec/step)
I0404 20:54:43.994322 47978602034560 learning.py:507] global step 5701: loss = 6.3608 (0.540 sec/step)
I0404 20:54:44.512592 47978602034560 learning.py:507] global step 5702: loss = 5.0442 (0.515 sec/step)
I0404 20:54:45.057320 47978602034560 learning.py:507] global step 5703: loss = 5.6306 (0.543 sec/step)
I0404 20:54:45.560732 47978602034560 learning.py:507] global step 5704: loss = 7.2055 (0.502 sec/step)
I0404 20:54:46.074538 47978602034560 learning.py:507] global step 5705: loss = 6.6521 (0.512 sec/step)
I0404 20:54:46.583592 47978602034560 learning.py:507] global step 5706: loss = 7.5891 (0.508 sec/step)
I0404 20:54:47.090010 47978602034560 learning.py:507] global step 5707: loss = 5.0157 (0.505 sec/step)
I0404 20:54:47.602055 47978602034560 learning.py:507] global step 5708: loss = 6.3045 (0.510 sec/step)
I0404 20:54:48.105812 47978602034560 learning.py:507] global step 5709: loss = 6.9792 (0.502 sec/step)
I0404 20:54:48.628819 47978602034560 learning.py:507] global step 5710: loss = 5.7255 (0.520 sec/step)
I0404 20:54:49.142837 47978602034560 learning.py:507] global step 5711: loss = 6.8913 (0.511 sec/step)
I0404 20:54:49.645011 47978602034560 learning.py:507] global step 5712: loss = 6.6523 (0.501 sec/step)
I0404 20:54:50.156824 47978602034560 learning.py:507] global step 5713: loss = 6.0369 (0.510 sec/step)
I0404 20:54:50.674098 47978602034560 learning.py:507] global step 5714: loss = 6.3187 (0.516 sec/step)
I0404 20:54:51.203736 47978602034560 learning.py:507] global step 5715: loss = 6.0347 (0.528 sec/step)
I0404 20:54:51.719374 47978602034560 learning.py:507] global step 5716: loss = 6.0166 (0.514 sec/step)
I0404 20:54:52.228466 47978602034560 learning.py:507] global step 5717: loss = 5.6244 (0.508 sec/step)
I0404 20:54:52.738604 47978602034560 learning.py:507] global step 5718: loss = 6.4521 (0.509 sec/step)
I0404 20:54:53.244934 47978602034560 learning.py:507] global step 5719: loss = 6.7773 (0.503 sec/step)
I0404 20:54:53.757685 47978602034560 learning.py:507] global step 5720: loss = 5.4247 (0.510 sec/step)
I0404 20:54:54.265562 47978602034560 learning.py:507] global step 5721: loss = 5.1562 (0.506 sec/step)
I0404 20:54:54.771950 47978602034560 learning.py:507] global step 5722: loss = 5.3405 (0.505 sec/step)
I0404 20:54:55.288733 47978602034560 learning.py:507] global step 5723: loss = 5.9508 (0.515 sec/step)
I0404 20:54:55.800076 47978602034560 learning.py:507] global step 5724: loss = 6.1293 (0.510 sec/step)
I0404 20:54:56.311669 47978602034560 learning.py:507] global step 5725: loss = 6.1543 (0.509 sec/step)
I0404 20:54:56.818131 47978602034560 learning.py:507] global step 5726: loss = 6.1935 (0.505 sec/step)
I0404 20:54:57.339622 47978602034560 learning.py:507] global step 5727: loss = 5.4049 (0.520 sec/step)
I0404 20:54:57.845267 47978602034560 learning.py:507] global step 5728: loss = 5.6344 (0.504 sec/step)
I0404 20:54:58.359360 47978602034560 learning.py:507] global step 5729: loss = 6.1034 (0.512 sec/step)
I0404 20:54:58.879957 47978602034560 learning.py:507] global step 5730: loss = 5.8838 (0.518 sec/step)
I0404 20:54:59.384814 47978602034560 learning.py:507] global step 5731: loss = 5.2715 (0.503 sec/step)
I0404 20:54:59.901965 47978602034560 learning.py:507] global step 5732: loss = 5.9669 (0.516 sec/step)
I0404 20:55:00.407464 47978602034560 learning.py:507] global step 5733: loss = 5.9378 (0.504 sec/step)
I0404 20:55:00.925744 47978602034560 learning.py:507] global step 5734: loss = 6.2176 (0.515 sec/step)
I0404 20:55:01.457188 47978602034560 learning.py:507] global step 5735: loss = 5.3549 (0.530 sec/step)
I0404 20:55:01.993027 47978602034560 learning.py:507] global step 5736: loss = 5.7472 (0.534 sec/step)
I0404 20:55:02.520040 47978602034560 learning.py:507] global step 5737: loss = 5.8858 (0.525 sec/step)
I0404 20:55:03.030154 47978602034560 learning.py:507] global step 5738: loss = 5.6588 (0.507 sec/step)
I0404 20:55:03.532747 47978602034560 learning.py:507] global step 5739: loss = 5.9450 (0.501 sec/step)
I0404 20:55:04.055914 47978602034560 learning.py:507] global step 5740: loss = 6.4275 (0.522 sec/step)
I0404 20:55:04.564552 47978602034560 learning.py:507] global step 5741: loss = 5.4804 (0.507 sec/step)
I0404 20:55:05.106720 47978602034560 learning.py:507] global step 5742: loss = 6.1163 (0.541 sec/step)
I0404 20:55:05.636197 47978602034560 learning.py:507] global step 5743: loss = 5.3817 (0.528 sec/step)
I0404 20:55:06.140838 47978602034560 learning.py:507] global step 5744: loss = 5.8460 (0.503 sec/step)
I0404 20:55:06.658243 47978602034560 learning.py:507] global step 5745: loss = 5.6580 (0.515 sec/step)
I0404 20:55:07.166434 47978602034560 learning.py:507] global step 5746: loss = 6.4041 (0.507 sec/step)
I0404 20:55:07.675527 47978602034560 learning.py:507] global step 5747: loss = 5.8585 (0.507 sec/step)
I0404 20:55:08.198441 47978602034560 learning.py:507] global step 5748: loss = 5.8762 (0.521 sec/step)
I0404 20:55:08.709450 47978602034560 learning.py:507] global step 5749: loss = 5.8656 (0.509 sec/step)
I0404 20:55:09.238054 47978602034560 learning.py:507] global step 5750: loss = 5.4983 (0.527 sec/step)
I0404 20:55:09.751223 47978602034560 learning.py:507] global step 5751: loss = 6.0744 (0.512 sec/step)
I0404 20:55:10.260578 47978602034560 learning.py:507] global step 5752: loss = 6.3430 (0.508 sec/step)
I0404 20:55:10.771234 47978602034560 learning.py:507] global step 5753: loss = 6.5095 (0.508 sec/step)
I0404 20:55:11.277842 47978602034560 learning.py:507] global step 5754: loss = 6.9447 (0.505 sec/step)
I0404 20:55:11.797266 47978602034560 learning.py:507] global step 5755: loss = 6.1335 (0.518 sec/step)
I0404 20:55:12.301453 47978602034560 learning.py:507] global step 5756: loss = 6.0510 (0.503 sec/step)
I0404 20:55:12.839815 47978602034560 learning.py:507] global step 5757: loss = 5.5791 (0.536 sec/step)
I0404 20:55:13.349905 47978602034560 learning.py:507] global step 5758: loss = 6.4877 (0.507 sec/step)
I0404 20:55:13.872507 47978602034560 learning.py:507] global step 5759: loss = 5.4741 (0.521 sec/step)
I0404 20:55:14.388726 47978602034560 learning.py:507] global step 5760: loss = 5.0544 (0.515 sec/step)
I0404 20:55:14.899265 47978602034560 learning.py:507] global step 5761: loss = 6.0077 (0.509 sec/step)
I0404 20:55:15.419728 47978602034560 learning.py:507] global step 5762: loss = 6.7930 (0.518 sec/step)
I0404 20:55:15.924184 47978602034560 learning.py:507] global step 5763: loss = 6.6094 (0.502 sec/step)
I0404 20:55:16.430974 47978602034560 learning.py:507] global step 5764: loss = 6.3397 (0.504 sec/step)
I0404 20:55:16.636948 47983666177792 supervisor.py:1117] Saving checkpoint to path ../../trainingOutput/model.ckpt
I0404 20:55:16.953385 47978602034560 learning.py:507] global step 5765: loss = 7.3424 (0.519 sec/step)
W0404 20:55:17.183397 47983666177792 deprecation.py:323] From /home-1/cpaolic1@jhu.edu/.conda/envs/LPEnvironment/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
I0404 20:55:17.320305 47983661975296 supervisor.py:1050] Recording summary at step 5765.
I0404 20:55:17.660888 47978602034560 learning.py:507] global step 5766: loss = 4.5842 (0.684 sec/step)
I0404 20:55:18.256782 47978602034560 learning.py:507] global step 5767: loss = 5.7452 (0.548 sec/step)
I0404 20:55:18.766696 47978602034560 learning.py:507] global step 5768: loss = 5.6203 (0.505 sec/step)
I0404 20:55:19.270939 47978602034560 learning.py:507] global step 5769: loss = 6.6607 (0.503 sec/step)
I0404 20:55:19.791792 47978602034560 learning.py:507] global step 5770: loss = 5.9767 (0.519 sec/step)
I0404 20:55:20.298958 47978602034560 learning.py:507] global step 5771: loss = 5.7610 (0.505 sec/step)
I0404 20:55:20.828541 47978602034560 learning.py:507] global step 5772: loss = 7.4511 (0.527 sec/step)
I0404 20:55:21.342860 47978602034560 learning.py:507] global step 5773: loss = 8.2973 (0.513 sec/step)
I0404 20:55:21.853329 47978602034560 learning.py:507] global step 5774: loss = 6.4368 (0.509 sec/step)
I0404 20:55:22.364006 47978602034560 learning.py:507] global step 5775: loss = 6.1449 (0.508 sec/step)
I0404 20:55:22.874200 47978602034560 learning.py:507] global step 5776: loss = 5.8770 (0.509 sec/step)
I0404 20:55:23.402495 47978602034560 learning.py:507] global step 5777: loss = 6.0715 (0.527 sec/step)
I0404 20:55:23.929507 47978602034560 learning.py:507] global step 5778: loss = 6.0594 (0.525 sec/step)
I0404 20:55:24.451988 47978602034560 learning.py:507] global step 5779: loss = 6.2568 (0.520 sec/step)
I0404 20:55:24.966021 47978602034560 learning.py:507] global step 5780: loss = 5.8795 (0.511 sec/step)
I0404 20:55:25.497688 47978602034560 learning.py:507] global step 5781: loss = 5.5757 (0.530 sec/step)
I0404 20:55:26.034944 47978602034560 learning.py:507] global step 5782: loss = 6.7057 (0.534 sec/step)
I0404 20:55:26.556593 47978602034560 learning.py:507] global step 5783: loss = 5.9246 (0.520 sec/step)
I0404 20:55:27.067430 47978602034560 learning.py:507] global step 5784: loss = 6.2159 (0.509 sec/step)
I0404 20:55:27.568258 47978602034560 learning.py:507] global step 5785: loss = 6.5021 (0.499 sec/step)
I0404 20:55:28.071358 47978602034560 learning.py:507] global step 5786: loss = 6.4720 (0.500 sec/step)
I0404 20:55:28.591646 47978602034560 learning.py:507] global step 5787: loss = 7.2454 (0.519 sec/step)
I0404 20:55:29.099256 47978602034560 learning.py:507] global step 5788: loss = 5.5586 (0.505 sec/step)
I0404 20:55:29.609909 47978602034560 learning.py:507] global step 5789: loss = 6.2524 (0.509 sec/step)
I0404 20:55:30.121775 47978602034560 learning.py:507] global step 5790: loss = 6.2497 (0.510 sec/step)
I0404 20:55:30.624526 47978602034560 learning.py:507] global step 5791: loss = 6.3256 (0.501 sec/step)
I0404 20:55:31.160630 47978602034560 learning.py:507] global step 5792: loss = 6.5118 (0.535 sec/step)
I0404 20:55:31.688916 47978602034560 learning.py:507] global step 5793: loss = 5.9924 (0.525 sec/step)
I0404 20:55:32.201061 47978602034560 learning.py:507] global step 5794: loss = 5.8591 (0.511 sec/step)
I0404 20:55:32.706849 47978602034560 learning.py:507] global step 5795: loss = 6.8179 (0.504 sec/step)
I0404 20:55:33.214467 47978602034560 learning.py:507] global step 5796: loss = 6.0168 (0.506 sec/step)
I0404 20:55:33.723603 47978602034560 learning.py:507] global step 5797: loss = 6.8378 (0.506 sec/step)
I0404 20:55:34.223829 47978602034560 learning.py:507] global step 5798: loss = 7.4919 (0.499 sec/step)
I0404 20:55:34.758049 47978602034560 learning.py:507] global step 5799: loss = 6.2889 (0.531 sec/step)
I0404 20:55:35.277641 47978602034560 learning.py:507] global step 5800: loss = 6.4092 (0.518 sec/step)
I0404 20:55:35.795506 47978602034560 learning.py:507] global step 5801: loss = 6.8233 (0.515 sec/step)
I0404 20:55:36.313079 47978602034560 learning.py:507] global step 5802: loss = 5.8878 (0.516 sec/step)
I0404 20:55:36.815209 47978602034560 learning.py:507] global step 5803: loss = 6.0884 (0.499 sec/step)
I0404 20:55:37.330482 47978602034560 learning.py:507] global step 5804: loss = 6.2264 (0.512 sec/step)
I0404 20:55:37.848436 47978602034560 learning.py:507] global step 5805: loss = 7.1883 (0.515 sec/step)
I0404 20:55:38.354665 47978602034560 learning.py:507] global step 5806: loss = 4.6874 (0.505 sec/step)
I0404 20:55:38.873187 47978602034560 learning.py:507] global step 5807: loss = 6.9962 (0.517 sec/step)
I0404 20:55:39.383376 47978602034560 learning.py:507] global step 5808: loss = 5.2591 (0.507 sec/step)
I0404 20:55:39.895142 47978602034560 learning.py:507] global step 5809: loss = 5.2625 (0.509 sec/step)
I0404 20:55:40.407541 47978602034560 learning.py:507] global step 5810: loss = 5.7190 (0.511 sec/step)
I0404 20:55:40.920644 47978602034560 learning.py:507] global step 5811: loss = 4.9311 (0.512 sec/step)
I0404 20:55:41.429174 47978602034560 learning.py:507] global step 5812: loss = 6.2680 (0.507 sec/step)
I0404 20:55:41.943324 47978602034560 learning.py:507] global step 5813: loss = 4.8794 (0.513 sec/step)
I0404 20:55:42.451817 47978602034560 learning.py:507] global step 5814: loss = 6.0682 (0.507 sec/step)
I0404 20:55:42.965029 47978602034560 learning.py:507] global step 5815: loss = 6.9961 (0.512 sec/step)
I0404 20:55:43.479163 47978602034560 learning.py:507] global step 5816: loss = 5.2219 (0.511 sec/step)
I0404 20:55:44.015540 47978602034560 learning.py:507] global step 5817: loss = 6.1587 (0.535 sec/step)
I0404 20:55:44.523484 47978602034560 learning.py:507] global step 5818: loss = 6.8869 (0.506 sec/step)
I0404 20:55:45.058639 47978602034560 learning.py:507] global step 5819: loss = 6.8231 (0.534 sec/step)
I0404 20:55:45.564937 47978602034560 learning.py:507] global step 5820: loss = 6.0070 (0.503 sec/step)
I0404 20:55:46.072196 47978602034560 learning.py:507] global step 5821: loss = 5.8053 (0.504 sec/step)
I0404 20:55:46.583344 47978602034560 learning.py:507] global step 5822: loss = 5.5666 (0.509 sec/step)
I0404 20:55:47.100675 47978602034560 learning.py:507] global step 5823: loss = 6.8389 (0.516 sec/step)
I0404 20:55:47.611639 47978602034560 learning.py:507] global step 5824: loss = 5.8389 (0.509 sec/step)
I0404 20:55:48.117360 47978602034560 learning.py:507] global step 5825: loss = 6.1404 (0.504 sec/step)
I0404 20:55:48.626637 47978602034560 learning.py:507] global step 5826: loss = 4.9808 (0.508 sec/step)
I0404 20:55:49.126907 47978602034560 learning.py:507] global step 5827: loss = 4.7567 (0.499 sec/step)
I0404 20:55:49.662584 47978602034560 learning.py:507] global step 5828: loss = 5.6576 (0.534 sec/step)
I0404 20:55:50.165681 47978602034560 learning.py:507] global step 5829: loss = 6.2683 (0.500 sec/step)
I0404 20:55:50.670435 47978602034560 learning.py:507] global step 5830: loss = 5.3496 (0.503 sec/step)
I0404 20:55:51.177351 47978602034560 learning.py:507] global step 5831: loss = 5.3744 (0.505 sec/step)
I0404 20:55:51.678303 47978602034560 learning.py:507] global step 5832: loss = 6.1806 (0.499 sec/step)
I0404 20:55:52.210760 47978602034560 learning.py:507] global step 5833: loss = 6.1481 (0.530 sec/step)
I0404 20:55:52.743615 47978602034560 learning.py:507] global step 5834: loss = 6.5945 (0.531 sec/step)
I0404 20:55:53.250891 47978602034560 learning.py:507] global step 5835: loss = 6.0466 (0.506 sec/step)
I0404 20:55:53.757397 47978602034560 learning.py:507] global step 5836: loss = 5.6782 (0.504 sec/step)
I0404 20:55:54.274198 47978602034560 learning.py:507] global step 5837: loss = 6.2675 (0.514 sec/step)
I0404 20:55:54.802325 47978602034560 learning.py:507] global step 5838: loss = 5.6454 (0.527 sec/step)
I0404 20:55:55.345049 47978602034560 learning.py:507] global step 5839: loss = 5.2291 (0.541 sec/step)
I0404 20:55:55.861755 47978602034560 learning.py:507] global step 5840: loss = 5.6154 (0.515 sec/step)
I0404 20:55:56.379240 47978602034560 learning.py:507] global step 5841: loss = 5.4235 (0.516 sec/step)
I0404 20:55:56.897314 47978602034560 learning.py:507] global step 5842: loss = 6.5519 (0.516 sec/step)
I0404 20:55:57.401827 47978602034560 learning.py:507] global step 5843: loss = 5.1407 (0.503 sec/step)
I0404 20:55:57.912385 47978602034560 learning.py:507] global step 5844: loss = 4.8663 (0.509 sec/step)
I0404 20:55:58.443936 47978602034560 learning.py:507] global step 5845: loss = 6.0042 (0.530 sec/step)
I0404 20:55:58.956731 47978602034560 learning.py:507] global step 5846: loss = 6.5618 (0.511 sec/step)
I0404 20:55:59.463578 47978602034560 learning.py:507] global step 5847: loss = 6.7225 (0.505 sec/step)
I0404 20:55:59.995869 47978602034560 learning.py:507] global step 5848: loss = 5.6959 (0.531 sec/step)
I0404 20:56:00.530365 47978602034560 learning.py:507] global step 5849: loss = 5.4124 (0.532 sec/step)
I0404 20:56:01.042994 47978602034560 learning.py:507] global step 5850: loss = 7.3937 (0.510 sec/step)
I0404 20:56:01.581187 47978602034560 learning.py:507] global step 5851: loss = 5.5967 (0.537 sec/step)
I0404 20:56:02.083761 47978602034560 learning.py:507] global step 5852: loss = 5.9663 (0.501 sec/step)
I0404 20:56:02.597312 47978602034560 learning.py:507] global step 5853: loss = 6.5116 (0.511 sec/step)
I0404 20:56:03.111413 47978602034560 learning.py:507] global step 5854: loss = 5.7735 (0.513 sec/step)
I0404 20:56:03.621134 47978602034560 learning.py:507] global step 5855: loss = 6.7575 (0.508 sec/step)
I0404 20:56:04.151311 47978602034560 learning.py:507] global step 5856: loss = 5.4404 (0.529 sec/step)
I0404 20:56:04.658582 47978602034560 learning.py:507] global step 5857: loss = 6.8520 (0.504 sec/step)
I0404 20:56:05.174279 47978602034560 learning.py:507] global step 5858: loss = 5.5990 (0.514 sec/step)
I0404 20:56:05.684638 47978602034560 learning.py:507] global step 5859: loss = 5.2725 (0.509 sec/step)
I0404 20:56:06.193776 47978602034560 learning.py:507] global step 5860: loss = 6.2341 (0.506 sec/step)
I0404 20:56:06.708781 47978602034560 learning.py:507] global step 5861: loss = 5.1953 (0.512 sec/step)
I0404 20:56:07.216335 47978602034560 learning.py:507] global step 5862: loss = 5.8512 (0.506 sec/step)
I0404 20:56:07.730861 47978602034560 learning.py:507] global step 5863: loss = 4.7562 (0.513 sec/step)
I0404 20:56:08.266783 47978602034560 learning.py:507] global step 5864: loss = 6.0642 (0.534 sec/step)
I0404 20:56:08.773587 47978602034560 learning.py:507] global step 5865: loss = 5.8984 (0.505 sec/step)
I0404 20:56:09.284556 47978602034560 learning.py:507] global step 5866: loss = 6.7262 (0.509 sec/step)
I0404 20:56:09.810784 47978602034560 learning.py:507] global step 5867: loss = 5.0828 (0.525 sec/step)
I0404 20:56:10.321600 47978602034560 learning.py:507] global step 5868: loss = 6.3504 (0.509 sec/step)
I0404 20:56:10.830051 47978602034560 learning.py:507] global step 5869: loss = 7.0923 (0.507 sec/step)
I0404 20:56:11.336549 47978602034560 learning.py:507] global step 5870: loss = 4.8353 (0.504 sec/step)
I0404 20:56:11.869717 47978602034560 learning.py:507] global step 5871: loss = 5.7279 (0.530 sec/step)
I0404 20:56:12.388336 47978602034560 learning.py:507] global step 5872: loss = 5.2130 (0.517 sec/step)
I0404 20:56:12.898674 47978602034560 learning.py:507] global step 5873: loss = 6.9670 (0.509 sec/step)
I0404 20:56:13.409457 47978602034560 learning.py:507] global step 5874: loss = 6.9938 (0.509 sec/step)
I0404 20:56:13.933985 47978602034560 learning.py:507] global step 5875: loss = 6.1305 (0.522 sec/step)
I0404 20:56:14.468621 47978602034560 learning.py:507] global step 5876: loss = 5.8695 (0.533 sec/step)
I0404 20:56:14.979326 47978602034560 learning.py:507] global step 5877: loss = 5.6046 (0.508 sec/step)
I0404 20:56:15.485838 47978602034560 learning.py:507] global step 5878: loss = 5.5196 (0.505 sec/step)
I0404 20:56:15.993090 47978602034560 learning.py:507] global step 5879: loss = 6.3611 (0.506 sec/step)
I0404 20:56:16.509938 47978602034560 learning.py:507] global step 5880: loss = 5.3704 (0.515 sec/step)
I0404 20:56:17.026742 47978602034560 learning.py:507] global step 5881: loss = 6.3914 (0.515 sec/step)
I0404 20:56:17.542085 47978602034560 learning.py:507] global step 5882: loss = 5.7503 (0.514 sec/step)
I0404 20:56:18.044495 47978602034560 learning.py:507] global step 5883: loss = 5.9579 (0.501 sec/step)
I0404 20:56:18.549125 47978602034560 learning.py:507] global step 5884: loss = 6.4428 (0.503 sec/step)
I0404 20:56:19.062886 47978602034560 learning.py:507] global step 5885: loss = 5.1318 (0.512 sec/step)
I0404 20:56:19.583631 47978602034560 learning.py:507] global step 5886: loss = 5.5117 (0.519 sec/step)
I0404 20:56:20.088667 47978602034560 learning.py:507] global step 5887: loss = 6.2508 (0.502 sec/step)
I0404 20:56:20.618356 47978602034560 learning.py:507] global step 5888: loss = 5.8697 (0.528 sec/step)
I0404 20:56:21.146485 47978602034560 learning.py:507] global step 5889: loss = 6.2305 (0.527 sec/step)
I0404 20:56:21.677232 47978602034560 learning.py:507] global step 5890: loss = 7.1330 (0.529 sec/step)
I0404 20:56:22.188035 47978602034560 learning.py:507] global step 5891: loss = 6.7058 (0.509 sec/step)
I0404 20:56:22.720493 47978602034560 learning.py:507] global step 5892: loss = 6.1728 (0.531 sec/step)
I0404 20:56:23.235488 47978602034560 learning.py:507] global step 5893: loss = 5.8655 (0.513 sec/step)
I0404 20:56:23.774736 47978602034560 learning.py:507] global step 5894: loss = 6.4340 (0.536 sec/step)
I0404 20:56:24.293653 47978602034560 learning.py:507] global step 5895: loss = 5.4534 (0.517 sec/step)
I0404 20:56:24.831117 47978602034560 learning.py:507] global step 5896: loss = 5.7164 (0.535 sec/step)
I0404 20:56:25.332757 47978602034560 learning.py:507] global step 5897: loss = 5.8837 (0.500 sec/step)
I0404 20:56:25.840059 47978602034560 learning.py:507] global step 5898: loss = 6.1338 (0.504 sec/step)
I0404 20:56:26.373891 47978602034560 learning.py:507] global step 5899: loss = 7.0185 (0.531 sec/step)
I0404 20:56:26.878103 47978602034560 learning.py:507] global step 5900: loss = 5.8880 (0.503 sec/step)
I0404 20:56:27.413792 47978602034560 learning.py:507] global step 5901: loss = 6.1417 (0.533 sec/step)
I0404 20:56:27.939357 47978602034560 learning.py:507] global step 5902: loss = 5.6259 (0.524 sec/step)
I0404 20:56:28.462466 47978602034560 learning.py:507] global step 5903: loss = 6.2517 (0.521 sec/step)
I0404 20:56:28.994204 47978602034560 learning.py:507] global step 5904: loss = 5.9149 (0.529 sec/step)
I0404 20:56:29.503993 47978602034560 learning.py:507] global step 5905: loss = 5.0389 (0.508 sec/step)
I0404 20:56:30.033103 47978602034560 learning.py:507] global step 5906: loss = 5.4399 (0.528 sec/step)
I0404 20:56:30.546982 47978602034560 learning.py:507] global step 5907: loss = 5.7069 (0.512 sec/step)
I0404 20:56:31.059554 47978602034560 learning.py:507] global step 5908: loss = 5.0758 (0.511 sec/step)
I0404 20:56:31.589614 47978602034560 learning.py:507] global step 5909: loss = 6.9306 (0.527 sec/step)
I0404 20:56:32.104684 47978602034560 learning.py:507] global step 5910: loss = 6.8613 (0.512 sec/step)
I0404 20:56:32.615734 47978602034560 learning.py:507] global step 5911: loss = 6.4193 (0.509 sec/step)
I0404 20:56:33.138515 47978602034560 learning.py:507] global step 5912: loss = 5.7976 (0.520 sec/step)
I0404 20:56:33.668921 47978602034560 learning.py:507] global step 5913: loss = 7.0641 (0.529 sec/step)
I0404 20:56:34.178538 47978602034560 learning.py:507] global step 5914: loss = 5.9383 (0.507 sec/step)
I0404 20:56:34.687621 47978602034560 learning.py:507] global step 5915: loss = 5.0907 (0.506 sec/step)
I0404 20:56:35.223022 47978602034560 learning.py:507] global step 5916: loss = 7.0949 (0.534 sec/step)
I0404 20:56:35.732996 47978602034560 learning.py:507] global step 5917: loss = 6.3989 (0.508 sec/step)
I0404 20:56:36.264003 47978602034560 learning.py:507] global step 5918: loss = 6.2300 (0.529 sec/step)
I0404 20:56:36.775320 47978602034560 learning.py:507] global step 5919: loss = 6.3887 (0.510 sec/step)
I0404 20:56:37.278528 47978602034560 learning.py:507] global step 5920: loss = 5.6257 (0.502 sec/step)
I0404 20:56:37.789129 47978602034560 learning.py:507] global step 5921: loss = 6.1638 (0.509 sec/step)
I0404 20:56:38.292327 47978602034560 learning.py:507] global step 5922: loss = 6.0718 (0.502 sec/step)
I0404 20:56:38.819932 47978602034560 learning.py:507] global step 5923: loss = 6.0314 (0.526 sec/step)
I0404 20:56:39.331117 47978602034560 learning.py:507] global step 5924: loss = 6.8369 (0.508 sec/step)
I0404 20:56:39.840944 47978602034560 learning.py:507] global step 5925: loss = 6.7690 (0.508 sec/step)
I0404 20:56:40.377090 47978602034560 learning.py:507] global step 5926: loss = 6.9414 (0.533 sec/step)
I0404 20:56:40.897710 47978602034560 learning.py:507] global step 5927: loss = 5.5720 (0.519 sec/step)
I0404 20:56:41.433803 47978602034560 learning.py:507] global step 5928: loss = 5.4802 (0.535 sec/step)
I0404 20:56:41.939597 47978602034560 learning.py:507] global step 5929: loss = 5.5170 (0.504 sec/step)
I0404 20:56:42.454509 47978602034560 learning.py:507] global step 5930: loss = 6.0761 (0.512 sec/step)
I0404 20:56:42.964382 47978602034560 learning.py:507] global step 5931: loss = 6.5991 (0.508 sec/step)
I0404 20:56:43.491293 47978602034560 learning.py:507] global step 5932: loss = 7.1221 (0.524 sec/step)
I0404 20:56:44.026955 47978602034560 learning.py:507] global step 5933: loss = 5.8396 (0.532 sec/step)
I0404 20:56:44.546568 47978602034560 learning.py:507] global step 5934: loss = 6.3479 (0.516 sec/step)
I0404 20:56:45.054580 47978602034560 learning.py:507] global step 5935: loss = 5.9249 (0.505 sec/step)
I0404 20:56:45.584738 47978602034560 learning.py:507] global step 5936: loss = 6.1720 (0.527 sec/step)
I0404 20:56:46.104169 47978602034560 learning.py:507] global step 5937: loss = 4.8784 (0.518 sec/step)
I0404 20:56:46.620967 47978602034560 learning.py:507] global step 5938: loss = 6.0699 (0.514 sec/step)
I0404 20:56:47.134331 47978602034560 learning.py:507] global step 5939: loss = 6.2705 (0.511 sec/step)
I0404 20:56:47.646324 47978602034560 learning.py:507] global step 5940: loss = 6.7371 (0.510 sec/step)
I0404 20:56:48.149707 47978602034560 learning.py:507] global step 5941: loss = 6.1215 (0.501 sec/step)
I0404 20:56:48.681955 47978602034560 learning.py:507] global step 5942: loss = 5.2812 (0.531 sec/step)
I0404 20:56:49.182589 47978602034560 learning.py:507] global step 5943: loss = 6.6813 (0.498 sec/step)
I0404 20:56:49.712293 47978602034560 learning.py:507] global step 5944: loss = 6.3181 (0.528 sec/step)
I0404 20:56:50.219884 47978602034560 learning.py:507] global step 5945: loss = 7.2676 (0.506 sec/step)
I0404 20:56:50.732821 47978602034560 learning.py:507] global step 5946: loss = 6.4567 (0.511 sec/step)
I0404 20:56:51.280956 47978602034560 learning.py:507] global step 5947: loss = 6.3722 (0.547 sec/step)
I0404 20:56:51.798073 47978602034560 learning.py:507] global step 5948: loss = 6.2581 (0.515 sec/step)
I0404 20:56:52.302238 47978602034560 learning.py:507] global step 5949: loss = 7.4865 (0.502 sec/step)
I0404 20:56:52.815608 47978602034560 learning.py:507] global step 5950: loss = 5.6547 (0.512 sec/step)
I0404 20:56:53.326705 47978602034560 learning.py:507] global step 5951: loss = 6.0922 (0.510 sec/step)
I0404 20:56:53.834814 47978602034560 learning.py:507] global step 5952: loss = 5.2881 (0.507 sec/step)
I0404 20:56:54.344215 47978602034560 learning.py:507] global step 5953: loss = 5.0796 (0.508 sec/step)
I0404 20:56:54.861663 47978602034560 learning.py:507] global step 5954: loss = 5.9025 (0.516 sec/step)
I0404 20:56:55.371103 47978602034560 learning.py:507] global step 5955: loss = 5.7803 (0.508 sec/step)
I0404 20:56:55.873957 47978602034560 learning.py:507] global step 5956: loss = 5.5185 (0.501 sec/step)
I0404 20:56:56.407742 47978602034560 learning.py:507] global step 5957: loss = 4.9150 (0.531 sec/step)
I0404 20:56:56.919507 47978602034560 learning.py:507] global step 5958: loss = 7.1325 (0.510 sec/step)
I0404 20:56:57.441700 47978602034560 learning.py:507] global step 5959: loss = 4.9660 (0.521 sec/step)
I0404 20:56:57.963956 47978602034560 learning.py:507] global step 5960: loss = 6.6292 (0.519 sec/step)
I0404 20:56:58.474727 47978602034560 learning.py:507] global step 5961: loss = 4.8049 (0.509 sec/step)
I0404 20:56:59.011439 47978602034560 learning.py:507] global step 5962: loss = 6.2024 (0.535 sec/step)
I0404 20:56:59.517894 47978602034560 learning.py:507] global step 5963: loss = 5.6301 (0.505 sec/step)
I0404 20:57:00.027694 47978602034560 learning.py:507] global step 5964: loss = 6.1107 (0.508 sec/step)
I0404 20:57:00.534857 47978602034560 learning.py:507] global step 5965: loss = 5.7963 (0.506 sec/step)
I0404 20:57:01.052301 47978602034560 learning.py:507] global step 5966: loss = 5.8090 (0.515 sec/step)
I0404 20:57:01.562333 47978602034560 learning.py:507] global step 5967: loss = 5.9227 (0.508 sec/step)
I0404 20:57:02.070736 47978602034560 learning.py:507] global step 5968: loss = 6.5792 (0.507 sec/step)
I0404 20:57:02.580075 47978602034560 learning.py:507] global step 5969: loss = 6.5510 (0.506 sec/step)
I0404 20:57:03.084714 47978602034560 learning.py:507] global step 5970: loss = 6.5292 (0.502 sec/step)
I0404 20:57:03.624051 47978602034560 learning.py:507] global step 5971: loss = 6.6015 (0.538 sec/step)
I0404 20:57:04.134676 47978602034560 learning.py:507] global step 5972: loss = 6.3082 (0.509 sec/step)
I0404 20:57:04.670546 47978602034560 learning.py:507] global step 5973: loss = 5.5835 (0.534 sec/step)
I0404 20:57:05.177855 47978602034560 learning.py:507] global step 5974: loss = 5.7725 (0.506 sec/step)
I0404 20:57:05.685042 47978602034560 learning.py:507] global step 5975: loss = 7.7662 (0.506 sec/step)
I0404 20:57:06.197456 47978602034560 learning.py:507] global step 5976: loss = 5.8950 (0.511 sec/step)
I0404 20:57:06.732905 47978602034560 learning.py:507] global step 5977: loss = 7.6785 (0.534 sec/step)
I0404 20:57:07.266336 47978602034560 learning.py:507] global step 5978: loss = 5.7666 (0.532 sec/step)
I0404 20:57:07.765023 47978602034560 learning.py:507] global step 5979: loss = 4.6215 (0.497 sec/step)
I0404 20:57:08.300522 47978602034560 learning.py:507] global step 5980: loss = 6.1833 (0.534 sec/step)
I0404 20:57:08.811002 47978602034560 learning.py:507] global step 5981: loss = 6.6693 (0.509 sec/step)
I0404 20:57:09.321171 47978602034560 learning.py:507] global step 5982: loss = 7.1912 (0.509 sec/step)
I0404 20:57:09.829195 47978602034560 learning.py:507] global step 5983: loss = 5.8237 (0.505 sec/step)
I0404 20:57:10.339404 47978602034560 learning.py:507] global step 5984: loss = 5.5747 (0.509 sec/step)
I0404 20:57:10.859725 47978602034560 learning.py:507] global step 5985: loss = 6.0252 (0.519 sec/step)
I0404 20:57:11.362695 47978602034560 learning.py:507] global step 5986: loss = 5.8243 (0.500 sec/step)
I0404 20:57:11.871072 47978602034560 learning.py:507] global step 5987: loss = 7.0694 (0.507 sec/step)
I0404 20:57:12.405443 47978602034560 learning.py:507] global step 5988: loss = 6.2682 (0.533 sec/step)
I0404 20:57:12.917832 47978602034560 learning.py:507] global step 5989: loss = 5.2224 (0.511 sec/step)
I0404 20:57:13.432341 47978602034560 learning.py:507] global step 5990: loss = 5.6372 (0.512 sec/step)
I0404 20:57:13.942626 47978602034560 learning.py:507] global step 5991: loss = 6.8246 (0.507 sec/step)
I0404 20:57:14.453119 47978602034560 learning.py:507] global step 5992: loss = 6.9955 (0.508 sec/step)
I0404 20:57:14.982525 47978602034560 learning.py:507] global step 5993: loss = 5.8292 (0.528 sec/step)
I0404 20:57:15.494723 47978602034560 learning.py:507] global step 5994: loss = 6.2584 (0.509 sec/step)
I0404 20:57:16.023177 47978602034560 learning.py:507] global step 5995: loss = 5.9930 (0.527 sec/step)
I0404 20:57:16.530500 47978602034560 learning.py:507] global step 5996: loss = 6.0767 (0.506 sec/step)
I0404 20:57:17.225043 47978602034560 learning.py:507] global step 5997: loss = 5.4767 (0.693 sec/step)
I0404 20:57:17.233084 47983661975296 supervisor.py:1050] Recording summary at step 5997.
I0404 20:57:17.745254 47978602034560 learning.py:507] global step 5998: loss = 5.8488 (0.517 sec/step)
I0404 20:57:18.249819 47978602034560 learning.py:507] global step 5999: loss = 6.3250 (0.503 sec/step)
I0404 20:57:18.771585 47978602034560 learning.py:507] global step 6000: loss = 5.3749 (0.520 sec/step)
I0404 20:57:19.280077 47978602034560 learning.py:507] global step 6001: loss = 5.4379 (0.507 sec/step)
I0404 20:57:19.791054 47978602034560 learning.py:507] global step 6002: loss = 5.6928 (0.509 sec/step)
I0404 20:57:20.311043 47978602034560 learning.py:507] global step 6003: loss = 5.2485 (0.518 sec/step)
I0404 20:57:20.824645 47978602034560 learning.py:507] global step 6004: loss = 6.1560 (0.512 sec/step)
I0404 20:57:21.345654 47978602034560 learning.py:507] global step 6005: loss = 6.0817 (0.519 sec/step)
I0404 20:57:21.856892 47978602034560 learning.py:507] global step 6006: loss = 6.1005 (0.510 sec/step)
I0404 20:57:22.374600 47978602034560 learning.py:507] global step 6007: loss = 6.7037 (0.516 sec/step)
I0404 20:57:22.904422 47978602034560 learning.py:507] global step 6008: loss = 6.1376 (0.528 sec/step)
I0404 20:57:23.423515 47978602034560 learning.py:507] global step 6009: loss = 5.6713 (0.518 sec/step)
I0404 20:57:23.961555 47978602034560 learning.py:507] global step 6010: loss = 5.4239 (0.537 sec/step)
I0404 20:57:24.495359 47978602034560 learning.py:507] global step 6011: loss = 6.1718 (0.532 sec/step)
I0404 20:57:25.003420 47978602034560 learning.py:507] global step 6012: loss = 5.4830 (0.506 sec/step)
I0404 20:57:25.514740 47978602034560 learning.py:507] global step 6013: loss = 5.2354 (0.510 sec/step)
I0404 20:57:26.051211 47978602034560 learning.py:507] global step 6014: loss = 6.2831 (0.534 sec/step)
I0404 20:57:26.566092 47978602034560 learning.py:507] global step 6015: loss = 5.0982 (0.513 sec/step)
I0404 20:57:27.111792 47978602034560 learning.py:507] global step 6016: loss = 5.7284 (0.544 sec/step)
I0404 20:57:27.633385 47978602034560 learning.py:507] global step 6017: loss = 5.5447 (0.520 sec/step)
I0404 20:57:28.144123 47978602034560 learning.py:507] global step 6018: loss = 6.7976 (0.508 sec/step)
I0404 20:57:28.671514 47978602034560 learning.py:507] global step 6019: loss = 5.7057 (0.526 sec/step)
I0404 20:57:29.172808 47978602034560 learning.py:507] global step 6020: loss = 5.3969 (0.500 sec/step)
I0404 20:57:29.705920 47978602034560 learning.py:507] global step 6021: loss = 4.6209 (0.532 sec/step)
I0404 20:57:30.239688 47978602034560 learning.py:507] global step 6022: loss = 7.1193 (0.532 sec/step)
I0404 20:57:30.751825 47978602034560 learning.py:507] global step 6023: loss = 6.3884 (0.511 sec/step)
I0404 20:57:31.268359 47978602034560 learning.py:507] global step 6024: loss = 5.5169 (0.515 sec/step)
I0404 20:57:31.794895 47978602034560 learning.py:507] global step 6025: loss = 6.2426 (0.524 sec/step)
I0404 20:57:32.296602 47978602034560 learning.py:507] global step 6026: loss = 5.0291 (0.500 sec/step)
I0404 20:57:32.828500 47978602034560 learning.py:507] global step 6027: loss = 6.7517 (0.529 sec/step)
I0404 20:57:33.335828 47978602034560 learning.py:507] global step 6028: loss = 7.1093 (0.504 sec/step)
I0404 20:57:33.847463 47978602034560 learning.py:507] global step 6029: loss = 5.8876 (0.509 sec/step)
I0404 20:57:34.352979 47978602034560 learning.py:507] global step 6030: loss = 6.0924 (0.504 sec/step)
I0404 20:57:34.864398 47978602034560 learning.py:507] global step 6031: loss = 5.7883 (0.510 sec/step)
I0404 20:57:35.399650 47978602034560 learning.py:507] global step 6032: loss = 6.6171 (0.532 sec/step)
I0404 20:57:35.911433 47978602034560 learning.py:507] global step 6033: loss = 6.3462 (0.509 sec/step)
I0404 20:57:36.418523 47978602034560 learning.py:507] global step 6034: loss = 5.8767 (0.506 sec/step)
I0404 20:57:36.935006 47978602034560 learning.py:507] global step 6035: loss = 6.0775 (0.514 sec/step)
I0404 20:57:37.470684 47978602034560 learning.py:507] global step 6036: loss = 6.6138 (0.533 sec/step)
I0404 20:57:37.999461 47978602034560 learning.py:507] global step 6037: loss = 5.9191 (0.526 sec/step)
I0404 20:57:38.502978 47978602034560 learning.py:507] global step 6038: loss = 5.5688 (0.501 sec/step)
I0404 20:57:39.026498 47978602034560 learning.py:507] global step 6039: loss = 5.5797 (0.522 sec/step)
I0404 20:57:39.542998 47978602034560 learning.py:507] global step 6040: loss = 6.1061 (0.514 sec/step)
I0404 20:57:40.076264 47978602034560 learning.py:507] global step 6041: loss = 6.2169 (0.532 sec/step)
I0404 20:57:40.615939 47978602034560 learning.py:507] global step 6042: loss = 5.4216 (0.538 sec/step)
I0404 20:57:41.135735 47978602034560 learning.py:507] global step 6043: loss = 5.0380 (0.518 sec/step)
I0404 20:57:41.653442 47978602034560 learning.py:507] global step 6044: loss = 6.1788 (0.516 sec/step)
I0404 20:57:42.160674 47978602034560 learning.py:507] global step 6045: loss = 5.4039 (0.504 sec/step)
I0404 20:57:42.674660 47978602034560 learning.py:507] global step 6046: loss = 5.2408 (0.512 sec/step)
I0404 20:57:43.185089 47978602034560 learning.py:507] global step 6047: loss = 5.7756 (0.509 sec/step)
I0404 20:57:43.690125 47978602034560 learning.py:507] global step 6048: loss = 5.7800 (0.503 sec/step)
I0404 20:57:44.195629 47978602034560 learning.py:507] global step 6049: loss = 6.8733 (0.504 sec/step)
I0404 20:57:44.714764 47978602034560 learning.py:507] global step 6050: loss = 6.2051 (0.518 sec/step)
I0404 20:57:45.239984 47978602034560 learning.py:507] global step 6051: loss = 5.6630 (0.524 sec/step)
I0404 20:57:45.745091 47978602034560 learning.py:507] global step 6052: loss = 6.8527 (0.502 sec/step)
I0404 20:57:46.257211 47978602034560 learning.py:507] global step 6053: loss = 4.9714 (0.509 sec/step)
I0404 20:57:46.793329 47978602034560 learning.py:507] global step 6054: loss = 5.3142 (0.533 sec/step)
I0404 20:57:47.313978 47978602034560 learning.py:507] global step 6055: loss = 5.8309 (0.519 sec/step)
I0404 20:57:47.854664 47978602034560 learning.py:507] global step 6056: loss = 5.9189 (0.538 sec/step)
I0404 20:57:48.356144 47978602034560 learning.py:507] global step 6057: loss = 4.9448 (0.500 sec/step)
I0404 20:57:48.863230 47978602034560 learning.py:507] global step 6058: loss = 5.7836 (0.504 sec/step)
I0404 20:57:49.368345 47978602034560 learning.py:507] global step 6059: loss = 6.3037 (0.502 sec/step)
I0404 20:57:49.878914 47978602034560 learning.py:507] global step 6060: loss = 5.8031 (0.508 sec/step)
I0404 20:57:50.407849 47978602034560 learning.py:507] global step 6061: loss = 6.0171 (0.527 sec/step)
I0404 20:57:50.942217 47978602034560 learning.py:507] global step 6062: loss = 6.6365 (0.533 sec/step)
I0404 20:57:51.481015 47978602034560 learning.py:507] global step 6063: loss = 5.3071 (0.537 sec/step)
I0404 20:57:51.993146 47978602034560 learning.py:507] global step 6064: loss = 5.8222 (0.511 sec/step)
I0404 20:57:52.505647 47978602034560 learning.py:507] global step 6065: loss = 6.2624 (0.510 sec/step)
I0404 20:57:53.007561 47978602034560 learning.py:507] global step 6066: loss = 4.6214 (0.500 sec/step)
I0404 20:57:53.514363 47978602034560 learning.py:507] global step 6067: loss = 5.9829 (0.505 sec/step)
I0404 20:57:54.022040 47978602034560 learning.py:507] global step 6068: loss = 6.1725 (0.506 sec/step)
I0404 20:57:54.532435 47978602034560 learning.py:507] global step 6069: loss = 6.0682 (0.509 sec/step)
I0404 20:57:55.064115 47978602034560 learning.py:507] global step 6070: loss = 6.3175 (0.530 sec/step)
I0404 20:57:55.571592 47978602034560 learning.py:507] global step 6071: loss = 5.9835 (0.505 sec/step)
I0404 20:57:56.101280 47978602034560 learning.py:507] global step 6072: loss = 6.1647 (0.528 sec/step)
I0404 20:57:56.615931 47978602034560 learning.py:507] global step 6073: loss = 5.9814 (0.512 sec/step)
I0404 20:57:57.126395 47978602034560 learning.py:507] global step 6074: loss = 5.5156 (0.509 sec/step)
I0404 20:57:57.628700 47978602034560 learning.py:507] global step 6075: loss = 6.4880 (0.501 sec/step)
I0404 20:57:58.132749 47978602034560 learning.py:507] global step 6076: loss = 5.7005 (0.502 sec/step)
I0404 20:57:58.641923 47978602034560 learning.py:507] global step 6077: loss = 6.3229 (0.508 sec/step)
I0404 20:57:59.170459 47978602034560 learning.py:507] global step 6078: loss = 4.4673 (0.527 sec/step)
I0404 20:57:59.679183 47978602034560 learning.py:507] global step 6079: loss = 6.2641 (0.507 sec/step)
I0404 20:58:00.188123 47978602034560 learning.py:507] global step 6080: loss = 6.6719 (0.507 sec/step)
I0404 20:58:00.701417 47978602034560 learning.py:507] global step 6081: loss = 7.0814 (0.512 sec/step)
I0404 20:58:01.210997 47978602034560 learning.py:507] global step 6082: loss = 5.7900 (0.508 sec/step)
I0404 20:58:01.731618 47978602034560 learning.py:507] global step 6083: loss = 5.3739 (0.519 sec/step)
I0404 20:58:02.257660 47978602034560 learning.py:507] global step 6084: loss = 5.3404 (0.524 sec/step)
I0404 20:58:02.795005 47978602034560 learning.py:507] global step 6085: loss = 6.4266 (0.534 sec/step)
I0404 20:58:03.322214 47978602034560 learning.py:507] global step 6086: loss = 5.7544 (0.524 sec/step)
I0404 20:58:03.831951 47978602034560 learning.py:507] global step 6087: loss = 5.2656 (0.508 sec/step)
I0404 20:58:04.341759 47978602034560 learning.py:507] global step 6088: loss = 5.5092 (0.508 sec/step)
I0404 20:58:04.844264 47978602034560 learning.py:507] global step 6089: loss = 5.4649 (0.500 sec/step)
I0404 20:58:05.363024 47978602034560 learning.py:507] global step 6090: loss = 4.8396 (0.516 sec/step)
I0404 20:58:05.894843 47978602034560 learning.py:507] global step 6091: loss = 6.5388 (0.529 sec/step)
I0404 20:58:06.405387 47978602034560 learning.py:507] global step 6092: loss = 5.5684 (0.509 sec/step)
I0404 20:58:06.912856 47978602034560 learning.py:507] global step 6093: loss = 6.3996 (0.506 sec/step)
I0404 20:58:07.435019 47978602034560 learning.py:507] global step 6094: loss = 5.1788 (0.519 sec/step)
I0404 20:58:07.958315 47978602034560 learning.py:507] global step 6095: loss = 6.4808 (0.522 sec/step)
I0404 20:58:08.465371 47978602034560 learning.py:507] global step 6096: loss = 5.8864 (0.505 sec/step)
I0404 20:58:08.984134 47978602034560 learning.py:507] global step 6097: loss = 6.1278 (0.516 sec/step)
I0404 20:58:09.492728 47978602034560 learning.py:507] global step 6098: loss = 6.2553 (0.507 sec/step)
I0404 20:58:09.998330 47978602034560 learning.py:507] global step 6099: loss = 5.9459 (0.504 sec/step)
I0404 20:58:10.535603 47978602034560 learning.py:507] global step 6100: loss = 5.3376 (0.536 sec/step)
I0404 20:58:11.054532 47978602034560 learning.py:507] global step 6101: loss = 5.5370 (0.517 sec/step)
I0404 20:58:11.562682 47978602034560 learning.py:507] global step 6102: loss = 5.9801 (0.505 sec/step)
I0404 20:58:12.074850 47978602034560 learning.py:507] global step 6103: loss = 6.2389 (0.509 sec/step)
I0404 20:58:12.585717 47978602034560 learning.py:507] global step 6104: loss = 5.1162 (0.508 sec/step)
I0404 20:58:13.114479 47978602034560 learning.py:507] global step 6105: loss = 5.7230 (0.527 sec/step)
I0404 20:58:13.613975 47978602034560 learning.py:507] global step 6106: loss = 5.7948 (0.497 sec/step)
I0404 20:58:14.118252 47978602034560 learning.py:507] global step 6107: loss = 6.2994 (0.502 sec/step)
I0404 20:58:14.635178 47978602034560 learning.py:507] global step 6108: loss = 6.9394 (0.515 sec/step)
I0404 20:58:15.143622 47978602034560 learning.py:507] global step 6109: loss = 6.4503 (0.507 sec/step)
I0404 20:58:15.663041 47978602034560 learning.py:507] global step 6110: loss = 5.4943 (0.517 sec/step)
I0404 20:58:16.171793 47978602034560 learning.py:507] global step 6111: loss = 6.0763 (0.507 sec/step)
I0404 20:58:16.676481 47978602034560 learning.py:507] global step 6112: loss = 5.9345 (0.503 sec/step)
I0404 20:58:17.195514 47978602034560 learning.py:507] global step 6113: loss = 5.4312 (0.516 sec/step)
I0404 20:58:17.707872 47978602034560 learning.py:507] global step 6114: loss = 6.0714 (0.511 sec/step)
I0404 20:58:18.212061 47978602034560 learning.py:507] global step 6115: loss = 6.0107 (0.501 sec/step)
I0404 20:58:18.748509 47978602034560 learning.py:507] global step 6116: loss = 6.8100 (0.535 sec/step)
I0404 20:58:19.250485 47978602034560 learning.py:507] global step 6117: loss = 6.0716 (0.499 sec/step)
I0404 20:58:19.769974 47978602034560 learning.py:507] global step 6118: loss = 6.6511 (0.517 sec/step)
I0404 20:58:20.290455 47978602034560 learning.py:507] global step 6119: loss = 4.8564 (0.519 sec/step)
I0404 20:58:20.832825 47978602034560 learning.py:507] global step 6120: loss = 5.3804 (0.541 sec/step)
I0404 20:58:21.346199 47978602034560 learning.py:507] global step 6121: loss = 6.1192 (0.510 sec/step)
I0404 20:58:21.864762 47978602034560 learning.py:507] global step 6122: loss = 5.9624 (0.517 sec/step)
I0404 20:58:22.367444 47978602034560 learning.py:507] global step 6123: loss = 5.7606 (0.501 sec/step)
I0404 20:58:22.876496 47978602034560 learning.py:507] global step 6124: loss = 5.4422 (0.507 sec/step)
I0404 20:58:23.389928 47978602034560 learning.py:507] global step 6125: loss = 7.4239 (0.512 sec/step)
I0404 20:58:23.900719 47978602034560 learning.py:507] global step 6126: loss = 6.7796 (0.508 sec/step)
I0404 20:58:24.409389 47978602034560 learning.py:507] global step 6127: loss = 6.5556 (0.507 sec/step)
I0404 20:58:24.925175 47978602034560 learning.py:507] global step 6128: loss = 5.9839 (0.514 sec/step)
I0404 20:58:25.428148 47978602034560 learning.py:507] global step 6129: loss = 5.1438 (0.501 sec/step)
I0404 20:58:25.940350 47978602034560 learning.py:507] global step 6130: loss = 6.0555 (0.511 sec/step)
I0404 20:58:26.454243 47978602034560 learning.py:507] global step 6131: loss = 5.9174 (0.512 sec/step)
I0404 20:58:26.962337 47978602034560 learning.py:507] global step 6132: loss = 5.2516 (0.505 sec/step)
I0404 20:58:27.481450 47978602034560 learning.py:507] global step 6133: loss = 5.3023 (0.517 sec/step)
I0404 20:58:27.983683 47978602034560 learning.py:507] global step 6134: loss = 7.0396 (0.501 sec/step)
I0404 20:58:28.516728 47978602034560 learning.py:507] global step 6135: loss = 5.7357 (0.530 sec/step)
I0404 20:58:29.033861 47978602034560 learning.py:507] global step 6136: loss = 6.6112 (0.516 sec/step)
I0404 20:58:29.563786 47978602034560 learning.py:507] global step 6137: loss = 5.8917 (0.528 sec/step)
I0404 20:58:30.078435 47978602034560 learning.py:507] global step 6138: loss = 5.7952 (0.512 sec/step)
I0404 20:58:30.587796 47978602034560 learning.py:507] global step 6139: loss = 5.3444 (0.508 sec/step)
I0404 20:58:31.116683 47978602034560 learning.py:507] global step 6140: loss = 5.4543 (0.526 sec/step)
I0404 20:58:31.625504 47978602034560 learning.py:507] global step 6141: loss = 5.2259 (0.507 sec/step)
I0404 20:58:32.129772 47978602034560 learning.py:507] global step 6142: loss = 6.4540 (0.503 sec/step)
I0404 20:58:32.638217 47978602034560 learning.py:507] global step 6143: loss = 5.2160 (0.507 sec/step)
I0404 20:58:33.154373 47978602034560 learning.py:507] global step 6144: loss = 5.7488 (0.515 sec/step)
I0404 20:58:33.666168 47978602034560 learning.py:507] global step 6145: loss = 7.1760 (0.510 sec/step)
I0404 20:58:34.168157 47978602034560 learning.py:507] global step 6146: loss = 5.4184 (0.500 sec/step)
I0404 20:58:34.697865 47978602034560 learning.py:507] global step 6147: loss = 6.2226 (0.528 sec/step)
I0404 20:58:35.227013 47978602034560 learning.py:507] global step 6148: loss = 5.1253 (0.528 sec/step)
I0404 20:58:35.741625 47978602034560 learning.py:507] global step 6149: loss = 5.2246 (0.512 sec/step)
I0404 20:58:36.256697 47978602034560 learning.py:507] global step 6150: loss = 7.7348 (0.514 sec/step)
I0404 20:58:36.761147 47978602034560 learning.py:507] global step 6151: loss = 6.4973 (0.503 sec/step)
I0404 20:58:37.279326 47978602034560 learning.py:507] global step 6152: loss = 6.9366 (0.517 sec/step)
I0404 20:58:37.785302 47978602034560 learning.py:507] global step 6153: loss = 6.3605 (0.504 sec/step)
I0404 20:58:38.299660 47978602034560 learning.py:507] global step 6154: loss = 6.3310 (0.511 sec/step)
I0404 20:58:38.827287 47978602034560 learning.py:507] global step 6155: loss = 6.3492 (0.525 sec/step)
I0404 20:58:39.338726 47978602034560 learning.py:507] global step 6156: loss = 5.8781 (0.510 sec/step)
I0404 20:58:39.861214 47978602034560 learning.py:507] global step 6157: loss = 5.9970 (0.521 sec/step)
I0404 20:58:40.373996 47978602034560 learning.py:507] global step 6158: loss = 5.5219 (0.511 sec/step)
I0404 20:58:40.881318 47978602034560 learning.py:507] global step 6159: loss = 5.1936 (0.506 sec/step)
I0404 20:58:41.413387 47978602034560 learning.py:507] global step 6160: loss = 5.2245 (0.529 sec/step)
I0404 20:58:41.921221 47978602034560 learning.py:507] global step 6161: loss = 6.3430 (0.506 sec/step)
I0404 20:58:42.438207 47978602034560 learning.py:507] global step 6162: loss = 6.0501 (0.515 sec/step)
I0404 20:58:42.952518 47978602034560 learning.py:507] global step 6163: loss = 6.5451 (0.513 sec/step)
I0404 20:58:43.487481 47978602034560 learning.py:507] global step 6164: loss = 5.4735 (0.532 sec/step)
I0404 20:58:44.001527 47978602034560 learning.py:507] global step 6165: loss = 5.1592 (0.512 sec/step)
I0404 20:58:44.506224 47978602034560 learning.py:507] global step 6166: loss = 5.6490 (0.502 sec/step)
I0404 20:58:45.032445 47978602034560 learning.py:507] global step 6167: loss = 5.4005 (0.525 sec/step)
I0404 20:58:45.543897 47978602034560 learning.py:507] global step 6168: loss = 6.1497 (0.510 sec/step)
I0404 20:58:46.060678 47978602034560 learning.py:507] global step 6169: loss = 4.3816 (0.515 sec/step)
I0404 20:58:46.574771 47978602034560 learning.py:507] global step 6170: loss = 5.7766 (0.513 sec/step)
I0404 20:58:47.083444 47978602034560 learning.py:507] global step 6171: loss = 5.0620 (0.506 sec/step)
I0404 20:58:47.585350 47978602034560 learning.py:507] global step 6172: loss = 6.6930 (0.499 sec/step)
I0404 20:58:48.103832 47978602034560 learning.py:507] global step 6173: loss = 5.6389 (0.517 sec/step)
I0404 20:58:48.614411 47978602034560 learning.py:507] global step 6174: loss = 5.5131 (0.509 sec/step)
I0404 20:58:49.125949 47978602034560 learning.py:507] global step 6175: loss = 5.4600 (0.509 sec/step)
I0404 20:58:49.644493 47978602034560 learning.py:507] global step 6176: loss = 5.5987 (0.517 sec/step)
I0404 20:58:50.158453 47978602034560 learning.py:507] global step 6177: loss = 6.9344 (0.512 sec/step)
I0404 20:58:50.690272 47978602034560 learning.py:507] global step 6178: loss = 4.8336 (0.530 sec/step)
I0404 20:58:51.224425 47978602034560 learning.py:507] global step 6179: loss = 6.8497 (0.533 sec/step)
I0404 20:58:51.751450 47978602034560 learning.py:507] global step 6180: loss = 6.7321 (0.525 sec/step)
I0404 20:58:52.263434 47978602034560 learning.py:507] global step 6181: loss = 5.6231 (0.510 sec/step)
I0404 20:58:52.791463 47978602034560 learning.py:507] global step 6182: loss = 4.6535 (0.526 sec/step)
I0404 20:58:53.310489 47978602034560 learning.py:507] global step 6183: loss = 5.7069 (0.516 sec/step)
I0404 20:58:53.824935 47978602034560 learning.py:507] global step 6184: loss = 5.5746 (0.513 sec/step)
I0404 20:58:54.351742 47978602034560 learning.py:507] global step 6185: loss = 5.9064 (0.525 sec/step)
I0404 20:58:54.870225 47978602034560 learning.py:507] global step 6186: loss = 6.1482 (0.517 sec/step)
I0404 20:58:55.381390 47978602034560 learning.py:507] global step 6187: loss = 5.3862 (0.508 sec/step)
I0404 20:58:55.899127 47978602034560 learning.py:507] global step 6188: loss = 6.0976 (0.516 sec/step)
I0404 20:58:56.433106 47978602034560 learning.py:507] global step 6189: loss = 6.4129 (0.532 sec/step)
I0404 20:58:56.937856 47978602034560 learning.py:507] global step 6190: loss = 5.3336 (0.502 sec/step)
I0404 20:58:57.451090 47978602034560 learning.py:507] global step 6191: loss = 5.6571 (0.512 sec/step)
I0404 20:58:57.963369 47978602034560 learning.py:507] global step 6192: loss = 6.2857 (0.509 sec/step)
I0404 20:58:58.474750 47978602034560 learning.py:507] global step 6193: loss = 5.9872 (0.510 sec/step)
I0404 20:58:58.981369 47978602034560 learning.py:507] global step 6194: loss = 6.9029 (0.505 sec/step)
I0404 20:58:59.513371 47978602034560 learning.py:507] global step 6195: loss = 6.2889 (0.530 sec/step)
I0404 20:59:00.035412 47978602034560 learning.py:507] global step 6196: loss = 6.8125 (0.519 sec/step)
I0404 20:59:00.538523 47978602034560 learning.py:507] global step 6197: loss = 5.8829 (0.500 sec/step)
I0404 20:59:01.044865 47978602034560 learning.py:507] global step 6198: loss = 7.2603 (0.505 sec/step)
I0404 20:59:01.558738 47978602034560 learning.py:507] global step 6199: loss = 5.7766 (0.511 sec/step)
I0404 20:59:02.097769 47978602034560 learning.py:507] global step 6200: loss = 6.2132 (0.537 sec/step)
I0404 20:59:02.603144 47978602034560 learning.py:507] global step 6201: loss = 6.4600 (0.504 sec/step)
I0404 20:59:03.111935 47978602034560 learning.py:507] global step 6202: loss = 5.7631 (0.507 sec/step)
I0404 20:59:03.625755 47978602034560 learning.py:507] global step 6203: loss = 4.7202 (0.512 sec/step)
I0404 20:59:04.131671 47978602034560 learning.py:507] global step 6204: loss = 5.4994 (0.504 sec/step)
I0404 20:59:04.638171 47978602034560 learning.py:507] global step 6205: loss = 5.6457 (0.505 sec/step)
I0404 20:59:05.159782 47978602034560 learning.py:507] global step 6206: loss = 5.5317 (0.520 sec/step)
I0404 20:59:05.676010 47978602034560 learning.py:507] global step 6207: loss = 5.5972 (0.515 sec/step)
I0404 20:59:06.206677 47978602034560 learning.py:507] global step 6208: loss = 6.4632 (0.529 sec/step)
I0404 20:59:06.723644 47978602034560 learning.py:507] global step 6209: loss = 4.8640 (0.515 sec/step)
I0404 20:59:07.236750 47978602034560 learning.py:507] global step 6210: loss = 6.4201 (0.510 sec/step)
I0404 20:59:07.757551 47978602034560 learning.py:507] global step 6211: loss = 5.5200 (0.519 sec/step)
I0404 20:59:08.270084 47978602034560 learning.py:507] global step 6212: loss = 7.1847 (0.510 sec/step)
I0404 20:59:08.789373 47978602034560 learning.py:507] global step 6213: loss = 6.0171 (0.518 sec/step)
I0404 20:59:09.325621 47978602034560 learning.py:507] global step 6214: loss = 6.5462 (0.535 sec/step)
I0404 20:59:09.831826 47978602034560 learning.py:507] global step 6215: loss = 5.5481 (0.505 sec/step)
I0404 20:59:10.335003 47978602034560 learning.py:507] global step 6216: loss = 5.3686 (0.502 sec/step)
I0404 20:59:10.843939 47978602034560 learning.py:507] global step 6217: loss = 5.4235 (0.507 sec/step)
I0404 20:59:11.369294 47978602034560 learning.py:507] global step 6218: loss = 6.3778 (0.522 sec/step)
I0404 20:59:11.918899 47978602034560 learning.py:507] global step 6219: loss = 6.2479 (0.548 sec/step)
I0404 20:59:12.435112 47978602034560 learning.py:507] global step 6220: loss = 5.7047 (0.513 sec/step)
I0404 20:59:12.945959 47978602034560 learning.py:507] global step 6221: loss = 5.7475 (0.508 sec/step)
I0404 20:59:13.471770 47978602034560 learning.py:507] global step 6222: loss = 7.0941 (0.524 sec/step)
I0404 20:59:13.977808 47978602034560 learning.py:507] global step 6223: loss = 6.1420 (0.504 sec/step)
I0404 20:59:14.492108 47978602034560 learning.py:507] global step 6224: loss = 6.0144 (0.513 sec/step)
I0404 20:59:15.003344 47978602034560 learning.py:507] global step 6225: loss = 6.0899 (0.510 sec/step)
I0404 20:59:15.519079 47978602034560 learning.py:507] global step 6226: loss = 6.2080 (0.514 sec/step)
I0404 20:59:16.030319 47978602034560 learning.py:507] global step 6227: loss = 5.0447 (0.510 sec/step)
I0404 20:59:16.541386 47978602034560 learning.py:507] global step 6228: loss = 4.7731 (0.510 sec/step)
I0404 20:59:17.231681 47978602034560 learning.py:507] global step 6229: loss = 6.2095 (0.689 sec/step)
I0404 20:59:17.241070 47983661975296 supervisor.py:1050] Recording summary at step 6229.
I0404 20:59:17.752096 47978602034560 learning.py:507] global step 6230: loss = 7.1522 (0.517 sec/step)
I0404 20:59:18.255926 47978602034560 learning.py:507] global step 6231: loss = 5.1341 (0.502 sec/step)
I0404 20:59:18.791757 47978602034560 learning.py:507] global step 6232: loss = 5.9004 (0.534 sec/step)
I0404 20:59:19.324561 47978602034560 learning.py:507] global step 6233: loss = 5.5710 (0.530 sec/step)
I0404 20:59:19.843590 47978602034560 learning.py:507] global step 6234: loss = 6.7506 (0.517 sec/step)
I0404 20:59:20.351148 47978602034560 learning.py:507] global step 6235: loss = 6.3251 (0.505 sec/step)
I0404 20:59:20.854842 47978602034560 learning.py:507] global step 6236: loss = 5.2405 (0.501 sec/step)
I0404 20:59:21.392677 47978602034560 learning.py:507] global step 6237: loss = 6.1711 (0.536 sec/step)
I0404 20:59:21.904383 47978602034560 learning.py:507] global step 6238: loss = 5.7184 (0.510 sec/step)
I0404 20:59:22.436129 47978602034560 learning.py:507] global step 6239: loss = 6.6185 (0.530 sec/step)
I0404 20:59:22.948630 47978602034560 learning.py:507] global step 6240: loss = 5.3718 (0.511 sec/step)
I0404 20:59:23.478109 47978602034560 learning.py:507] global step 6241: loss = 6.1912 (0.527 sec/step)
I0404 20:59:23.978147 47978602034560 learning.py:507] global step 6242: loss = 5.8927 (0.498 sec/step)
I0404 20:59:24.484711 47978602034560 learning.py:507] global step 6243: loss = 6.8255 (0.505 sec/step)
I0404 20:59:24.995340 47978602034560 learning.py:507] global step 6244: loss = 5.4357 (0.509 sec/step)
I0404 20:59:25.500109 47978602034560 learning.py:507] global step 6245: loss = 5.6573 (0.503 sec/step)
I0404 20:59:26.018395 47978602034560 learning.py:507] global step 6246: loss = 6.3847 (0.517 sec/step)
I0404 20:59:26.555863 47978602034560 learning.py:507] global step 6247: loss = 5.8617 (0.536 sec/step)
I0404 20:59:27.069526 47978602034560 learning.py:507] global step 6248: loss = 4.8004 (0.511 sec/step)
I0404 20:59:27.582319 47978602034560 learning.py:507] global step 6249: loss = 6.0995 (0.510 sec/step)
I0404 20:59:28.092747 47978602034560 learning.py:507] global step 6250: loss = 5.6390 (0.509 sec/step)
I0404 20:59:28.605809 47978602034560 learning.py:507] global step 6251: loss = 5.8045 (0.512 sec/step)
I0404 20:59:29.110310 47978602034560 learning.py:507] global step 6252: loss = 6.0168 (0.502 sec/step)
I0404 20:59:29.617209 47978602034560 learning.py:507] global step 6253: loss = 5.6369 (0.505 sec/step)
I0404 20:59:30.130029 47978602034560 learning.py:507] global step 6254: loss = 5.5434 (0.511 sec/step)
I0404 20:59:30.664283 47978602034560 learning.py:507] global step 6255: loss = 5.8537 (0.531 sec/step)
I0404 20:59:31.175498 47978602034560 learning.py:507] global step 6256: loss = 5.3163 (0.509 sec/step)
I0404 20:59:31.703509 47978602034560 learning.py:507] global step 6257: loss = 6.8746 (0.525 sec/step)
I0404 20:59:32.220454 47978602034560 learning.py:507] global step 6258: loss = 6.1815 (0.515 sec/step)
I0404 20:59:32.732506 47978602034560 learning.py:507] global step 6259: loss = 6.1188 (0.510 sec/step)
I0404 20:59:33.242991 47978602034560 learning.py:507] global step 6260: loss = 5.4163 (0.509 sec/step)
I0404 20:59:33.760158 47978602034560 learning.py:507] global step 6261: loss = 6.2708 (0.516 sec/step)
I0404 20:59:34.269054 47978602034560 learning.py:507] global step 6262: loss = 5.9180 (0.507 sec/step)
I0404 20:59:34.807783 47978602034560 learning.py:507] global step 6263: loss = 4.7650 (0.537 sec/step)
I0404 20:59:35.321692 47978602034560 learning.py:507] global step 6264: loss = 5.5187 (0.512 sec/step)
I0404 20:59:35.831602 47978602034560 learning.py:507] global step 6265: loss = 6.1108 (0.507 sec/step)
I0404 20:59:36.350144 47978602034560 learning.py:507] global step 6266: loss = 6.6662 (0.517 sec/step)
I0404 20:59:36.881752 47978602034560 learning.py:507] global step 6267: loss = 5.0970 (0.529 sec/step)
I0404 20:59:37.393845 47978602034560 learning.py:507] global step 6268: loss = 6.6250 (0.509 sec/step)
I0404 20:59:37.903701 47978602034560 learning.py:507] global step 6269: loss = 5.6298 (0.508 sec/step)
I0404 20:59:38.417974 47978602034560 learning.py:507] global step 6270: loss = 7.8791 (0.513 sec/step)
I0404 20:59:38.930415 47978602034560 learning.py:507] global step 6271: loss = 5.5613 (0.510 sec/step)
I0404 20:59:39.443331 47978602034560 learning.py:507] global step 6272: loss = 6.7744 (0.511 sec/step)
I0404 20:59:39.949936 47978602034560 learning.py:507] global step 6273: loss = 5.8298 (0.505 sec/step)
I0404 20:59:40.460633 47978602034560 learning.py:507] global step 6274: loss = 6.5459 (0.509 sec/step)
I0404 20:59:40.968101 47978602034560 learning.py:507] global step 6275: loss = 5.2883 (0.506 sec/step)
I0404 20:59:41.481409 47978602034560 learning.py:507] global step 6276: loss = 5.7822 (0.512 sec/step)
I0404 20:59:41.994775 47978602034560 learning.py:507] global step 6277: loss = 5.3843 (0.512 sec/step)
I0404 20:59:42.510240 47978602034560 learning.py:507] global step 6278: loss = 5.7784 (0.514 sec/step)
I0404 20:59:43.021677 47978602034560 learning.py:507] global step 6279: loss = 6.0481 (0.510 sec/step)
I0404 20:59:43.552251 47978602034560 learning.py:507] global step 6280: loss = 5.8214 (0.528 sec/step)
I0404 20:59:44.062982 47978602034560 learning.py:507] global step 6281: loss = 5.5627 (0.509 sec/step)
I0404 20:59:44.572552 47978602034560 learning.py:507] global step 6282: loss = 4.6614 (0.508 sec/step)
I0404 20:59:45.083808 47978602034560 learning.py:507] global step 6283: loss = 6.2932 (0.508 sec/step)
I0404 20:59:45.589373 47978602034560 learning.py:507] global step 6284: loss = 6.5920 (0.503 sec/step)
I0404 20:59:46.122686 47978602034560 learning.py:507] global step 6285: loss = 5.1963 (0.532 sec/step)
I0404 20:59:46.667015 47978602034560 learning.py:507] global step 6286: loss = 6.0597 (0.541 sec/step)
I0404 20:59:47.199464 47978602034560 learning.py:507] global step 6287: loss = 6.2900 (0.531 sec/step)
I0404 20:59:47.733663 47978602034560 learning.py:507] global step 6288: loss = 5.1271 (0.533 sec/step)
I0404 20:59:48.250937 47978602034560 learning.py:507] global step 6289: loss = 6.0726 (0.516 sec/step)
I0404 20:59:48.764053 47978602034560 learning.py:507] global step 6290: loss = 5.6370 (0.510 sec/step)
I0404 20:59:49.270427 47978602034560 learning.py:507] global step 6291: loss = 6.5508 (0.505 sec/step)
I0404 20:59:49.786070 47978602034560 learning.py:507] global step 6292: loss = 5.7916 (0.514 sec/step)
I0404 20:59:50.297293 47978602034560 learning.py:507] global step 6293: loss = 5.4918 (0.508 sec/step)
I0404 20:59:50.812322 47978602034560 learning.py:507] global step 6294: loss = 6.7893 (0.512 sec/step)
I0404 20:59:51.322016 47978602034560 learning.py:507] global step 6295: loss = 6.0408 (0.508 sec/step)
I0404 20:59:51.825582 47978602034560 learning.py:507] global step 6296: loss = 6.2160 (0.502 sec/step)
I0404 20:59:52.346347 47978602034560 learning.py:507] global step 6297: loss = 6.2589 (0.519 sec/step)
I0404 20:59:52.884082 47978602034560 learning.py:507] global step 6298: loss = 6.0572 (0.536 sec/step)
I0404 20:59:53.403802 47978602034560 learning.py:507] global step 6299: loss = 5.5949 (0.517 sec/step)
I0404 20:59:53.911088 47978602034560 learning.py:507] global step 6300: loss = 5.6923 (0.504 sec/step)
I0404 20:59:54.419498 47978602034560 learning.py:507] global step 6301: loss = 6.0114 (0.506 sec/step)
I0404 20:59:54.939814 47978602034560 learning.py:507] global step 6302: loss = 5.6300 (0.519 sec/step)
I0404 20:59:55.451275 47978602034560 learning.py:507] global step 6303: loss = 5.3625 (0.509 sec/step)
I0404 20:59:55.951017 47978602034560 learning.py:507] global step 6304: loss = 5.6972 (0.498 sec/step)
I0404 20:59:56.463772 47978602034560 learning.py:507] global step 6305: loss = 6.8758 (0.511 sec/step)
I0404 20:59:56.973602 47978602034560 learning.py:507] global step 6306: loss = 4.8880 (0.507 sec/step)
I0404 20:59:57.485925 47978602034560 learning.py:507] global step 6307: loss = 5.8360 (0.511 sec/step)
I0404 20:59:57.991990 47978602034560 learning.py:507] global step 6308: loss = 5.6718 (0.505 sec/step)
I0404 20:59:58.520077 47978602034560 learning.py:507] global step 6309: loss = 6.9281 (0.527 sec/step)
I0404 20:59:59.029400 47978602034560 learning.py:507] global step 6310: loss = 4.9341 (0.508 sec/step)
I0404 20:59:59.552739 47978602034560 learning.py:507] global step 6311: loss = 6.6608 (0.522 sec/step)
I0404 21:00:00.077600 47978602034560 learning.py:507] global step 6312: loss = 5.8852 (0.523 sec/step)
I0404 21:00:00.581259 47978602034560 learning.py:507] global step 6313: loss = 5.6319 (0.502 sec/step)
I0404 21:00:01.111784 47978602034560 learning.py:507] global step 6314: loss = 5.2070 (0.529 sec/step)
I0404 21:00:01.622837 47978602034560 learning.py:507] global step 6315: loss = 5.6502 (0.508 sec/step)
I0404 21:00:02.129516 47978602034560 learning.py:507] global step 6316: loss = 6.6661 (0.504 sec/step)
I0404 21:00:02.636925 47978602034560 learning.py:507] global step 6317: loss = 4.8968 (0.505 sec/step)
I0404 21:00:03.142790 47978602034560 learning.py:507] global step 6318: loss = 6.2090 (0.504 sec/step)
I0404 21:00:03.671827 47978602034560 learning.py:507] global step 6319: loss = 5.8911 (0.527 sec/step)
I0404 21:00:04.178950 47978602034560 learning.py:507] global step 6320: loss = 5.7578 (0.504 sec/step)
I0404 21:00:04.688016 47978602034560 learning.py:507] global step 6321: loss = 6.4403 (0.506 sec/step)
I0404 21:00:05.210613 47978602034560 learning.py:507] global step 6322: loss = 6.2652 (0.520 sec/step)
I0404 21:00:05.714841 47978602034560 learning.py:507] global step 6323: loss = 6.1108 (0.503 sec/step)
I0404 21:00:06.220775 47978602034560 learning.py:507] global step 6324: loss = 6.1412 (0.503 sec/step)
I0404 21:00:06.724964 47978602034560 learning.py:507] global step 6325: loss = 5.0205 (0.503 sec/step)
I0404 21:00:07.260117 47978602034560 learning.py:507] global step 6326: loss = 5.5620 (0.532 sec/step)
I0404 21:00:07.769611 47978602034560 learning.py:507] global step 6327: loss = 5.3415 (0.508 sec/step)
I0404 21:00:08.280617 47978602034560 learning.py:507] global step 6328: loss = 5.3776 (0.509 sec/step)
I0404 21:00:08.802024 47978602034560 learning.py:507] global step 6329: loss = 6.3055 (0.520 sec/step)
I0404 21:00:09.342682 47978602034560 learning.py:507] global step 6330: loss = 6.4162 (0.539 sec/step)
I0404 21:00:09.848259 47978602034560 learning.py:507] global step 6331: loss = 5.6964 (0.504 sec/step)
I0404 21:00:10.357078 47978602034560 learning.py:507] global step 6332: loss = 7.1938 (0.506 sec/step)
I0404 21:00:10.863328 47978602034560 learning.py:507] global step 6333: loss = 5.4563 (0.503 sec/step)
I0404 21:00:11.375799 47978602034560 learning.py:507] global step 6334: loss = 6.0830 (0.510 sec/step)
I0404 21:00:11.885962 47978602034560 learning.py:507] global step 6335: loss = 5.4336 (0.507 sec/step)
I0404 21:00:12.396944 47978602034560 learning.py:507] global step 6336: loss = 5.5877 (0.508 sec/step)
I0404 21:00:12.904251 47978602034560 learning.py:507] global step 6337: loss = 5.6023 (0.504 sec/step)
I0404 21:00:13.421909 47978602034560 learning.py:507] global step 6338: loss = 5.6144 (0.516 sec/step)
I0404 21:00:13.958154 47978602034560 learning.py:507] global step 6339: loss = 5.2482 (0.535 sec/step)
I0404 21:00:14.465334 47978602034560 learning.py:507] global step 6340: loss = 5.4146 (0.506 sec/step)
I0404 21:00:14.972306 47978602034560 learning.py:507] global step 6341: loss = 5.9959 (0.505 sec/step)
I0404 21:00:15.503618 47978602034560 learning.py:507] global step 6342: loss = 4.9330 (0.530 sec/step)
I0404 21:00:16.016074 47978602034560 learning.py:507] global step 6343: loss = 6.0637 (0.510 sec/step)
I0404 21:00:16.519312 47978602034560 learning.py:507] global step 6344: loss = 5.6432 (0.502 sec/step)
I0404 21:00:17.022101 47978602034560 learning.py:507] global step 6345: loss = 4.9452 (0.501 sec/step)
I0404 21:00:17.568761 47978602034560 learning.py:507] global step 6346: loss = 5.2254 (0.544 sec/step)
I0404 21:00:18.070668 47978602034560 learning.py:507] global step 6347: loss = 5.7693 (0.499 sec/step)
I0404 21:00:18.593092 47978602034560 learning.py:507] global step 6348: loss = 5.3468 (0.520 sec/step)
I0404 21:00:19.125190 47978602034560 learning.py:507] global step 6349: loss = 5.7448 (0.531 sec/step)
I0404 21:00:19.628888 47978602034560 learning.py:507] global step 6350: loss = 5.5637 (0.502 sec/step)
I0404 21:00:20.151283 47978602034560 learning.py:507] global step 6351: loss = 5.9057 (0.521 sec/step)
I0404 21:00:20.672291 47978602034560 learning.py:507] global step 6352: loss = 6.5036 (0.519 sec/step)
I0404 21:00:21.173233 47978602034560 learning.py:507] global step 6353: loss = 7.0988 (0.499 sec/step)
I0404 21:00:21.703533 47978602034560 learning.py:507] global step 6354: loss = 6.5026 (0.529 sec/step)
I0404 21:00:22.228610 47978602034560 learning.py:507] global step 6355: loss = 5.1002 (0.523 sec/step)
I0404 21:00:22.739711 47978602034560 learning.py:507] global step 6356: loss = 5.2202 (0.509 sec/step)
I0404 21:00:23.253903 47978602034560 learning.py:507] global step 6357: loss = 6.2751 (0.513 sec/step)
I0404 21:00:23.770132 47978602034560 learning.py:507] global step 6358: loss = 5.1812 (0.515 sec/step)
I0404 21:00:24.274628 47978602034560 learning.py:507] global step 6359: loss = 7.0424 (0.502 sec/step)
I0404 21:00:24.793503 47978602034560 learning.py:507] global step 6360: loss = 6.1793 (0.517 sec/step)
I0404 21:00:25.319562 47978602034560 learning.py:507] global step 6361: loss = 5.6308 (0.524 sec/step)
I0404 21:00:25.831415 47978602034560 learning.py:507] global step 6362: loss = 5.6922 (0.510 sec/step)
I0404 21:00:26.338135 47978602034560 learning.py:507] global step 6363: loss = 6.3014 (0.505 sec/step)
I0404 21:00:26.875893 47978602034560 learning.py:507] global step 6364: loss = 5.4459 (0.536 sec/step)
I0404 21:00:27.386250 47978602034560 learning.py:507] global step 6365: loss = 5.4703 (0.509 sec/step)
I0404 21:00:27.909902 47978602034560 learning.py:507] global step 6366: loss = 7.0432 (0.522 sec/step)
I0404 21:00:28.433522 47978602034560 learning.py:507] global step 6367: loss = 5.6310 (0.522 sec/step)
I0404 21:00:28.939090 47978602034560 learning.py:507] global step 6368: loss = 5.4560 (0.504 sec/step)
I0404 21:00:29.457315 47978602034560 learning.py:507] global step 6369: loss = 5.6646 (0.515 sec/step)
I0404 21:00:29.985343 47978602034560 learning.py:507] global step 6370: loss = 6.1388 (0.525 sec/step)
I0404 21:00:30.490742 47978602034560 learning.py:507] global step 6371: loss = 5.6971 (0.502 sec/step)
I0404 21:00:30.994168 47978602034560 learning.py:507] global step 6372: loss = 6.6394 (0.502 sec/step)
I0404 21:00:31.525960 47978602034560 learning.py:507] global step 6373: loss = 6.2365 (0.530 sec/step)
I0404 21:00:32.026419 47978602034560 learning.py:507] global step 6374: loss = 6.1136 (0.499 sec/step)
I0404 21:00:32.535782 47978602034560 learning.py:507] global step 6375: loss = 6.5305 (0.506 sec/step)
I0404 21:00:33.045936 47978602034560 learning.py:507] global step 6376: loss = 6.6693 (0.507 sec/step)
I0404 21:00:33.565649 47978602034560 learning.py:507] global step 6377: loss = 7.2354 (0.518 sec/step)
I0404 21:00:34.069789 47978602034560 learning.py:507] global step 6378: loss = 5.1930 (0.501 sec/step)
I0404 21:00:34.573764 47978602034560 learning.py:507] global step 6379: loss = 6.6752 (0.501 sec/step)
I0404 21:00:35.090667 47978602034560 learning.py:507] global step 6380: loss = 5.1416 (0.514 sec/step)
I0404 21:00:35.607292 47978602034560 learning.py:507] global step 6381: loss = 5.6790 (0.515 sec/step)
I0404 21:00:36.111581 47978602034560 learning.py:507] global step 6382: loss = 6.9253 (0.503 sec/step)
I0404 21:00:36.634782 47978602034560 learning.py:507] global step 6383: loss = 5.9442 (0.522 sec/step)
I0404 21:00:37.154532 47978602034560 learning.py:507] global step 6384: loss = 6.7423 (0.517 sec/step)
I0404 21:00:37.670800 47978602034560 learning.py:507] global step 6385: loss = 6.0919 (0.515 sec/step)
I0404 21:00:38.175203 47978602034560 learning.py:507] global step 6386: loss = 5.9678 (0.503 sec/step)
I0404 21:00:38.685561 47978602034560 learning.py:507] global step 6387: loss = 5.4952 (0.509 sec/step)
I0404 21:00:39.194609 47978602034560 learning.py:507] global step 6388: loss = 5.7443 (0.507 sec/step)
I0404 21:00:39.704277 47978602034560 learning.py:507] global step 6389: loss = 6.5735 (0.508 sec/step)
I0404 21:00:40.214511 47978602034560 learning.py:507] global step 6390: loss = 6.7030 (0.507 sec/step)
I0404 21:00:40.719798 47978602034560 learning.py:507] global step 6391: loss = 7.1594 (0.504 sec/step)
I0404 21:00:41.233562 47978602034560 learning.py:507] global step 6392: loss = 6.0537 (0.512 sec/step)
I0404 21:00:41.761353 47978602034560 learning.py:507] global step 6393: loss = 6.5488 (0.525 sec/step)
I0404 21:00:42.275665 47978602034560 learning.py:507] global step 6394: loss = 4.9974 (0.511 sec/step)
I0404 21:00:42.789720 47978602034560 learning.py:507] global step 6395: loss = 6.1718 (0.513 sec/step)
I0404 21:00:43.294325 47978602034560 learning.py:507] global step 6396: loss = 6.1463 (0.503 sec/step)
I0404 21:00:43.825594 47978602034560 learning.py:507] global step 6397: loss = 5.6011 (0.529 sec/step)
I0404 21:00:44.343918 47978602034560 learning.py:507] global step 6398: loss = 5.9882 (0.517 sec/step)
I0404 21:00:44.867566 47978602034560 learning.py:507] global step 6399: loss = 6.3733 (0.522 sec/step)
I0404 21:00:45.389617 47978602034560 learning.py:507] global step 6400: loss = 5.7159 (0.519 sec/step)
I0404 21:00:45.904719 47978602034560 learning.py:507] global step 6401: loss = 4.7833 (0.513 sec/step)
I0404 21:00:46.442826 47978602034560 learning.py:507] global step 6402: loss = 6.6354 (0.537 sec/step)
I0404 21:00:46.969877 47978602034560 learning.py:507] global step 6403: loss = 5.3078 (0.524 sec/step)
I0404 21:00:47.484771 47978602034560 learning.py:507] global step 6404: loss = 6.3075 (0.512 sec/step)
I0404 21:00:47.994486 47978602034560 learning.py:507] global step 6405: loss = 6.0387 (0.507 sec/step)
I0404 21:00:48.507563 47978602034560 learning.py:507] global step 6406: loss = 5.7040 (0.512 sec/step)
I0404 21:00:49.021365 47978602034560 learning.py:507] global step 6407: loss = 5.7106 (0.511 sec/step)
I0404 21:00:49.523938 47978602034560 learning.py:507] global step 6408: loss = 6.3145 (0.501 sec/step)
I0404 21:00:50.058795 47978602034560 learning.py:507] global step 6409: loss = 5.2531 (0.533 sec/step)
I0404 21:00:50.562079 47978602034560 learning.py:507] global step 6410: loss = 5.9281 (0.500 sec/step)
I0404 21:00:51.092528 47978602034560 learning.py:507] global step 6411: loss = 6.8814 (0.528 sec/step)
I0404 21:00:51.598068 47978602034560 learning.py:507] global step 6412: loss = 6.4769 (0.504 sec/step)
I0404 21:00:52.113333 47978602034560 learning.py:507] global step 6413: loss = 6.0460 (0.514 sec/step)
I0404 21:00:52.628581 47978602034560 learning.py:507] global step 6414: loss = 6.8203 (0.514 sec/step)
I0404 21:00:53.146601 47978602034560 learning.py:507] global step 6415: loss = 5.2502 (0.516 sec/step)
I0404 21:00:53.650794 47978602034560 learning.py:507] global step 6416: loss = 6.1617 (0.501 sec/step)
I0404 21:00:54.164368 47978602034560 learning.py:507] global step 6417: loss = 5.8066 (0.512 sec/step)
I0404 21:00:54.676551 47978602034560 learning.py:507] global step 6418: loss = 5.7025 (0.511 sec/step)
I0404 21:00:55.187871 47978602034560 learning.py:507] global step 6419: loss = 4.9952 (0.510 sec/step)
I0404 21:00:55.706881 47978602034560 learning.py:507] global step 6420: loss = 4.3432 (0.518 sec/step)
I0404 21:00:56.216386 47978602034560 learning.py:507] global step 6421: loss = 6.0393 (0.508 sec/step)
I0404 21:00:56.728682 47978602034560 learning.py:507] global step 6422: loss = 7.1195 (0.511 sec/step)
I0404 21:00:57.258836 47978602034560 learning.py:507] global step 6423: loss = 5.6605 (0.527 sec/step)
I0404 21:00:57.771252 47978602034560 learning.py:507] global step 6424: loss = 5.9700 (0.509 sec/step)
I0404 21:00:58.286234 47978602034560 learning.py:507] global step 6425: loss = 6.4494 (0.513 sec/step)
I0404 21:00:58.795606 47978602034560 learning.py:507] global step 6426: loss = 5.1503 (0.508 sec/step)
I0404 21:00:59.305300 47978602034560 learning.py:507] global step 6427: loss = 6.4506 (0.508 sec/step)
I0404 21:00:59.835111 47978602034560 learning.py:507] global step 6428: loss = 5.9316 (0.528 sec/step)
I0404 21:01:00.342905 47978602034560 learning.py:507] global step 6429: loss = 6.1952 (0.505 sec/step)
I0404 21:01:00.862704 47978602034560 learning.py:507] global step 6430: loss = 6.2287 (0.518 sec/step)
I0404 21:01:01.394035 47978602034560 learning.py:507] global step 6431: loss = 5.6998 (0.530 sec/step)
I0404 21:01:01.922308 47978602034560 learning.py:507] global step 6432: loss = 5.4829 (0.527 sec/step)
I0404 21:01:02.435408 47978602034560 learning.py:507] global step 6433: loss = 7.0266 (0.512 sec/step)
I0404 21:01:02.951365 47978602034560 learning.py:507] global step 6434: loss = 6.7839 (0.513 sec/step)
I0404 21:01:03.464171 47978602034560 learning.py:507] global step 6435: loss = 6.3932 (0.511 sec/step)
I0404 21:01:03.989537 47978602034560 learning.py:507] global step 6436: loss = 5.6507 (0.524 sec/step)
I0404 21:01:04.516561 47978602034560 learning.py:507] global step 6437: loss = 5.8297 (0.526 sec/step)
I0404 21:01:05.019601 47978602034560 learning.py:507] global step 6438: loss = 6.0240 (0.501 sec/step)
I0404 21:01:05.535658 47978602034560 learning.py:507] global step 6439: loss = 6.3659 (0.514 sec/step)
I0404 21:01:06.047559 47978602034560 learning.py:507] global step 6440: loss = 7.3458 (0.510 sec/step)
I0404 21:01:06.564983 47978602034560 learning.py:507] global step 6441: loss = 5.5467 (0.516 sec/step)
I0404 21:01:07.080809 47978602034560 learning.py:507] global step 6442: loss = 8.1092 (0.514 sec/step)
I0404 21:01:07.613650 47978602034560 learning.py:507] global step 6443: loss = 5.7360 (0.531 sec/step)
I0404 21:01:08.114199 47978602034560 learning.py:507] global step 6444: loss = 6.8361 (0.499 sec/step)
I0404 21:01:08.650303 47978602034560 learning.py:507] global step 6445: loss = 7.3073 (0.533 sec/step)
I0404 21:01:09.184541 47978602034560 learning.py:507] global step 6446: loss = 6.8102 (0.533 sec/step)
I0404 21:01:09.691849 47978602034560 learning.py:507] global step 6447: loss = 7.0238 (0.506 sec/step)
I0404 21:01:10.205876 47978602034560 learning.py:507] global step 6448: loss = 5.3063 (0.511 sec/step)
I0404 21:01:10.717432 47978602034560 learning.py:507] global step 6449: loss = 5.5816 (0.510 sec/step)
I0404 21:01:11.224134 47978602034560 learning.py:507] global step 6450: loss = 5.9329 (0.505 sec/step)
I0404 21:01:11.738258 47978602034560 learning.py:507] global step 6451: loss = 6.6815 (0.512 sec/step)
I0404 21:01:12.259695 47978602034560 learning.py:507] global step 6452: loss = 5.9818 (0.520 sec/step)
I0404 21:01:12.777112 47978602034560 learning.py:507] global step 6453: loss = 6.4487 (0.516 sec/step)
I0404 21:01:13.308387 47978602034560 learning.py:507] global step 6454: loss = 5.5591 (0.528 sec/step)
I0404 21:01:13.841072 47978602034560 learning.py:507] global step 6455: loss = 6.0136 (0.530 sec/step)
I0404 21:01:14.377375 47978602034560 learning.py:507] global step 6456: loss = 5.8889 (0.535 sec/step)
I0404 21:01:14.893363 47978602034560 learning.py:507] global step 6457: loss = 5.8468 (0.514 sec/step)
I0404 21:01:15.423513 47978602034560 learning.py:507] global step 6458: loss = 7.0490 (0.529 sec/step)
I0404 21:01:15.949301 47978602034560 learning.py:507] global step 6459: loss = 6.8580 (0.523 sec/step)
I0404 21:01:16.460373 47978602034560 learning.py:507] global step 6460: loss = 5.7350 (0.509 sec/step)
I0404 21:01:17.105314 47978602034560 learning.py:507] global step 6461: loss = 6.2078 (0.639 sec/step)
I0404 21:01:17.301926 47983661975296 supervisor.py:1050] Recording summary at step 6461.
I0404 21:01:17.663004 47978602034560 learning.py:507] global step 6462: loss = 5.9293 (0.552 sec/step)
I0404 21:01:18.175558 47978602034560 learning.py:507] global step 6463: loss = 5.4058 (0.511 sec/step)
I0404 21:01:18.683035 47978602034560 learning.py:507] global step 6464: loss = 5.5496 (0.506 sec/step)
I0404 21:01:19.184386 47978602034560 learning.py:507] global step 6465: loss = 5.8202 (0.500 sec/step)
I0404 21:01:19.721540 47978602034560 learning.py:507] global step 6466: loss = 6.9268 (0.536 sec/step)
I0404 21:01:20.229229 47978602034560 learning.py:507] global step 6467: loss = 5.6954 (0.505 sec/step)
I0404 21:01:20.742109 47978602034560 learning.py:507] global step 6468: loss = 5.9785 (0.511 sec/step)
I0404 21:01:21.290026 47978602034560 learning.py:507] global step 6469: loss = 5.4835 (0.546 sec/step)
I0404 21:01:21.806693 47978602034560 learning.py:507] global step 6470: loss = 5.9356 (0.515 sec/step)
I0404 21:01:22.323439 47978602034560 learning.py:507] global step 6471: loss = 6.1450 (0.515 sec/step)
I0404 21:01:22.864318 47978602034560 learning.py:507] global step 6472: loss = 5.1622 (0.539 sec/step)
I0404 21:01:23.377311 47978602034560 learning.py:507] global step 6473: loss = 6.4506 (0.511 sec/step)
I0404 21:01:23.894289 47978602034560 learning.py:507] global step 6474: loss = 5.7629 (0.515 sec/step)
I0404 21:01:24.407194 47978602034560 learning.py:507] global step 6475: loss = 4.8617 (0.511 sec/step)
I0404 21:01:24.918864 47978602034560 learning.py:507] global step 6476: loss = 5.9044 (0.510 sec/step)
I0404 21:01:25.427779 47978602034560 learning.py:507] global step 6477: loss = 6.3014 (0.507 sec/step)
I0404 21:01:25.935420 47978602034560 learning.py:507] global step 6478: loss = 5.6568 (0.505 sec/step)
I0404 21:01:26.445989 47978602034560 learning.py:507] global step 6479: loss = 5.0597 (0.508 sec/step)
I0404 21:01:26.955478 47978602034560 learning.py:507] global step 6480: loss = 5.8570 (0.508 sec/step)
I0404 21:01:27.471397 47978602034560 learning.py:507] global step 6481: loss = 5.9387 (0.513 sec/step)
I0404 21:01:27.977387 47978602034560 learning.py:507] global step 6482: loss = 5.0884 (0.503 sec/step)
I0404 21:01:28.479313 47978602034560 learning.py:507] global step 6483: loss = 5.9193 (0.499 sec/step)
I0404 21:01:28.993216 47978602034560 learning.py:507] global step 6484: loss = 6.4970 (0.512 sec/step)
I0404 21:01:29.515431 47978602034560 learning.py:507] global step 6485: loss = 5.1700 (0.519 sec/step)
I0404 21:01:30.027306 47978602034560 learning.py:507] global step 6486: loss = 6.4170 (0.509 sec/step)
I0404 21:01:30.532123 47978602034560 learning.py:507] global step 6487: loss = 6.2726 (0.502 sec/step)
I0404 21:01:31.033998 47978602034560 learning.py:507] global step 6488: loss = 6.0385 (0.500 sec/step)
I0404 21:01:31.544067 47978602034560 learning.py:507] global step 6489: loss = 5.7258 (0.509 sec/step)
I0404 21:01:32.049305 47978602034560 learning.py:507] global step 6490: loss = 5.8711 (0.504 sec/step)
I0404 21:01:32.592222 47978602034560 learning.py:507] global step 6491: loss = 5.7869 (0.541 sec/step)
I0404 21:01:33.103147 47978602034560 learning.py:507] global step 6492: loss = 5.9785 (0.508 sec/step)
I0404 21:01:33.622524 47978602034560 learning.py:507] global step 6493: loss = 6.3715 (0.518 sec/step)
I0404 21:01:34.143724 47978602034560 learning.py:507] global step 6494: loss = 5.2261 (0.520 sec/step)
I0404 21:01:34.660039 47978602034560 learning.py:507] global step 6495: loss = 5.7442 (0.515 sec/step)
I0404 21:01:35.169203 47978602034560 learning.py:507] global step 6496: loss = 5.5748 (0.508 sec/step)
I0404 21:01:35.672991 47978602034560 learning.py:507] global step 6497: loss = 5.2885 (0.502 sec/step)
I0404 21:01:36.180840 47978602034560 learning.py:507] global step 6498: loss = 7.1073 (0.506 sec/step)
I0404 21:01:36.717000 47978602034560 learning.py:507] global step 6499: loss = 5.4986 (0.535 sec/step)
I0404 21:01:37.225813 47978602034560 learning.py:507] global step 6500: loss = 5.6968 (0.506 sec/step)
I0404 21:01:37.739990 47978602034560 learning.py:507] global step 6501: loss = 4.9642 (0.511 sec/step)
I0404 21:01:38.251822 47978602034560 learning.py:507] global step 6502: loss = 6.0379 (0.510 sec/step)
I0404 21:01:38.781089 47978602034560 learning.py:507] global step 6503: loss = 6.7971 (0.526 sec/step)
I0404 21:01:39.292872 47978602034560 learning.py:507] global step 6504: loss = 5.5227 (0.509 sec/step)
I0404 21:01:39.798910 47978602034560 learning.py:507] global step 6505: loss = 6.4621 (0.503 sec/step)
I0404 21:01:40.317569 47978602034560 learning.py:507] global step 6506: loss = 5.7966 (0.517 sec/step)
I0404 21:01:40.820723 47978602034560 learning.py:507] global step 6507: loss = 5.6471 (0.502 sec/step)
I0404 21:01:41.351780 47978602034560 learning.py:507] global step 6508: loss = 6.6560 (0.529 sec/step)
I0404 21:01:41.889095 47978602034560 learning.py:507] global step 6509: loss = 6.5790 (0.536 sec/step)
I0404 21:01:42.396457 47978602034560 learning.py:507] global step 6510: loss = 7.4220 (0.506 sec/step)
I0404 21:01:42.916095 47978602034560 learning.py:507] global step 6511: loss = 6.3178 (0.517 sec/step)
I0404 21:01:43.436847 47978602034560 learning.py:507] global step 6512: loss = 6.3241 (0.519 sec/step)
I0404 21:01:43.947994 47978602034560 learning.py:507] global step 6513: loss = 5.5664 (0.510 sec/step)
I0404 21:01:44.451845 47978602034560 learning.py:507] global step 6514: loss = 5.1581 (0.501 sec/step)
I0404 21:01:44.962182 47978602034560 learning.py:507] global step 6515: loss = 5.4661 (0.507 sec/step)
I0404 21:01:45.478582 47978602034560 learning.py:507] global step 6516: loss = 5.2687 (0.515 sec/step)
I0404 21:01:45.993401 47978602034560 learning.py:507] global step 6517: loss = 5.6040 (0.513 sec/step)
I0404 21:01:46.503995 47978602034560 learning.py:507] global step 6518: loss = 5.9968 (0.509 sec/step)
I0404 21:01:47.015060 47978602034560 learning.py:507] global step 6519: loss = 6.1462 (0.508 sec/step)
I0404 21:01:47.527546 47978602034560 learning.py:507] global step 6520: loss = 7.1973 (0.510 sec/step)
I0404 21:01:48.044444 47978602034560 learning.py:507] global step 6521: loss = 5.8696 (0.515 sec/step)
I0404 21:01:48.581815 47978602034560 learning.py:507] global step 6522: loss = 7.0670 (0.535 sec/step)
I0404 21:01:49.083950 47978602034560 learning.py:507] global step 6523: loss = 5.8143 (0.499 sec/step)
I0404 21:01:49.605588 47978602034560 learning.py:507] global step 6524: loss = 6.3863 (0.520 sec/step)
I0404 21:01:50.135126 47978602034560 learning.py:507] global step 6525: loss = 5.6509 (0.528 sec/step)
I0404 21:01:50.640296 47978602034560 learning.py:507] global step 6526: loss = 6.8299 (0.504 sec/step)
I0404 21:01:51.162416 47978602034560 learning.py:507] global step 6527: loss = 5.6517 (0.519 sec/step)
I0404 21:01:51.674949 47978602034560 learning.py:507] global step 6528: loss = 6.3712 (0.511 sec/step)
I0404 21:01:52.191392 47978602034560 learning.py:507] global step 6529: loss = 5.6727 (0.515 sec/step)
I0404 21:01:52.707347 47978602034560 learning.py:507] global step 6530: loss = 5.4643 (0.513 sec/step)
I0404 21:01:53.236270 47978602034560 learning.py:507] global step 6531: loss = 5.4825 (0.527 sec/step)
I0404 21:01:53.748408 47978602034560 learning.py:507] global step 6532: loss = 5.0135 (0.511 sec/step)
I0404 21:01:54.254188 47978602034560 learning.py:507] global step 6533: loss = 6.4632 (0.503 sec/step)
I0404 21:01:54.776219 47978602034560 learning.py:507] global step 6534: loss = 5.7301 (0.519 sec/step)
I0404 21:01:55.290246 47978602034560 learning.py:507] global step 6535: loss = 4.7060 (0.511 sec/step)
I0404 21:01:55.792197 47978602034560 learning.py:507] global step 6536: loss = 6.4851 (0.500 sec/step)
I0404 21:01:56.324115 47978602034560 learning.py:507] global step 6537: loss = 6.6809 (0.530 sec/step)
I0404 21:01:56.839501 47978602034560 learning.py:507] global step 6538: loss = 6.2153 (0.512 sec/step)
I0404 21:01:57.356619 47978602034560 learning.py:507] global step 6539: loss = 5.1911 (0.516 sec/step)
I0404 21:01:57.875003 47978602034560 learning.py:507] global step 6540: loss = 5.9106 (0.517 sec/step)
I0404 21:01:58.381323 47978602034560 learning.py:507] global step 6541: loss = 5.2137 (0.503 sec/step)
I0404 21:01:58.910265 47978602034560 learning.py:507] global step 6542: loss = 6.4084 (0.527 sec/step)
I0404 21:01:59.413801 47978602034560 learning.py:507] global step 6543: loss = 5.9701 (0.502 sec/step)
I0404 21:01:59.938817 47978602034560 learning.py:507] global step 6544: loss = 6.7255 (0.523 sec/step)
I0404 21:02:00.459840 47978602034560 learning.py:507] global step 6545: loss = 4.9399 (0.520 sec/step)
I0404 21:02:00.972913 47978602034560 learning.py:507] global step 6546: loss = 6.6889 (0.512 sec/step)
I0404 21:02:01.478776 47978602034560 learning.py:507] global step 6547: loss = 5.5992 (0.504 sec/step)
I0404 21:02:01.984384 47978602034560 learning.py:507] global step 6548: loss = 5.8000 (0.504 sec/step)
I0404 21:02:02.520773 47978602034560 learning.py:507] global step 6549: loss = 5.9459 (0.533 sec/step)
I0404 21:02:03.031590 47978602034560 learning.py:507] global step 6550: loss = 5.4286 (0.508 sec/step)
I0404 21:02:03.546927 47978602034560 learning.py:507] global step 6551: loss = 5.8581 (0.513 sec/step)
I0404 21:02:04.053451 47978602034560 learning.py:507] global step 6552: loss = 6.4473 (0.503 sec/step)
I0404 21:02:04.569201 47978602034560 learning.py:507] global step 6553: loss = 5.8575 (0.514 sec/step)
I0404 21:02:05.104543 47978602034560 learning.py:507] global step 6554: loss = 5.5061 (0.534 sec/step)
I0404 21:02:05.609368 47978602034560 learning.py:507] global step 6555: loss = 5.2805 (0.503 sec/step)
I0404 21:02:06.136904 47978602034560 learning.py:507] global step 6556: loss = 6.0041 (0.525 sec/step)
I0404 21:02:06.679615 47978602034560 learning.py:507] global step 6557: loss = 6.1708 (0.541 sec/step)
I0404 21:02:07.195268 47978602034560 learning.py:507] global step 6558: loss = 5.4240 (0.514 sec/step)
I0404 21:02:07.714973 47978602034560 learning.py:507] global step 6559: loss = 5.6647 (0.517 sec/step)
I0404 21:02:08.246297 47978602034560 learning.py:507] global step 6560: loss = 5.7635 (0.528 sec/step)
I0404 21:02:08.758152 47978602034560 learning.py:507] global step 6561: loss = 5.1152 (0.509 sec/step)
I0404 21:02:09.277719 47978602034560 learning.py:507] global step 6562: loss = 5.2762 (0.518 sec/step)
I0404 21:02:09.784118 47978602034560 learning.py:507] global step 6563: loss = 5.4970 (0.504 sec/step)
I0404 21:02:10.323520 47978602034560 learning.py:507] global step 6564: loss = 6.0838 (0.538 sec/step)
I0404 21:02:10.838951 47978602034560 learning.py:507] global step 6565: loss = 5.4760 (0.514 sec/step)
I0404 21:02:11.353171 47978602034560 learning.py:507] global step 6566: loss = 5.7605 (0.513 sec/step)
I0404 21:02:11.878762 47978602034560 learning.py:507] global step 6567: loss = 6.7637 (0.523 sec/step)
I0404 21:02:12.400370 47978602034560 learning.py:507] global step 6568: loss = 5.0433 (0.520 sec/step)
I0404 21:02:12.908607 47978602034560 learning.py:507] global step 6569: loss = 5.8191 (0.507 sec/step)
I0404 21:02:13.417514 47978602034560 learning.py:507] global step 6570: loss = 5.5467 (0.507 sec/step)
I0404 21:02:13.929841 47978602034560 learning.py:507] global step 6571: loss = 5.9558 (0.511 sec/step)
I0404 21:02:14.445626 47978602034560 learning.py:507] global step 6572: loss = 6.0026 (0.514 sec/step)
I0404 21:02:14.980130 47978602034560 learning.py:507] global step 6573: loss = 5.5362 (0.533 sec/step)
I0404 21:02:15.497697 47978602034560 learning.py:507] global step 6574: loss = 4.9581 (0.515 sec/step)
I0404 21:02:16.014926 47978602034560 learning.py:507] global step 6575: loss = 5.7496 (0.514 sec/step)
I0404 21:02:16.528613 47978602034560 learning.py:507] global step 6576: loss = 6.2479 (0.512 sec/step)
I0404 21:02:17.036766 47978602034560 learning.py:507] global step 6577: loss = 5.5554 (0.505 sec/step)
I0404 21:02:17.560260 47978602034560 learning.py:507] global step 6578: loss = 6.4626 (0.522 sec/step)
I0404 21:02:18.063335 47978602034560 learning.py:507] global step 6579: loss = 5.7934 (0.500 sec/step)
I0404 21:02:18.582884 47978602034560 learning.py:507] global step 6580: loss = 6.0561 (0.518 sec/step)
I0404 21:02:19.099898 47978602034560 learning.py:507] global step 6581: loss = 5.6198 (0.515 sec/step)
I0404 21:02:19.617510 47978602034560 learning.py:507] global step 6582: loss = 6.2729 (0.516 sec/step)
I0404 21:02:20.124177 47978602034560 learning.py:507] global step 6583: loss = 6.1446 (0.504 sec/step)
I0404 21:02:20.640282 47978602034560 learning.py:507] global step 6584: loss = 6.2810 (0.513 sec/step)
I0404 21:02:21.158060 47978602034560 learning.py:507] global step 6585: loss = 5.3877 (0.515 sec/step)
I0404 21:02:21.684929 47978602034560 learning.py:507] global step 6586: loss = 5.8454 (0.524 sec/step)
I0404 21:02:22.205306 47978602034560 learning.py:507] global step 6587: loss = 5.5371 (0.517 sec/step)
I0404 21:02:22.710637 47978602034560 learning.py:507] global step 6588: loss = 6.2243 (0.504 sec/step)
I0404 21:02:23.221357 47978602034560 learning.py:507] global step 6589: loss = 6.3762 (0.509 sec/step)
I0404 21:02:23.733648 47978602034560 learning.py:507] global step 6590: loss = 5.6635 (0.509 sec/step)
I0404 21:02:24.240010 47978602034560 learning.py:507] global step 6591: loss = 6.4016 (0.505 sec/step)
I0404 21:02:24.755743 47978602034560 learning.py:507] global step 6592: loss = 6.7025 (0.514 sec/step)
I0404 21:02:25.262719 47978602034560 learning.py:507] global step 6593: loss = 5.8424 (0.505 sec/step)
I0404 21:02:25.771112 47978602034560 learning.py:507] global step 6594: loss = 6.2282 (0.506 sec/step)
I0404 21:02:26.286274 47978602034560 learning.py:507] global step 6595: loss = 5.6609 (0.514 sec/step)
I0404 21:02:26.789296 47978602034560 learning.py:507] global step 6596: loss = 7.5896 (0.501 sec/step)
I0404 21:02:27.308257 47978602034560 learning.py:507] global step 6597: loss = 6.0866 (0.517 sec/step)
I0404 21:02:27.827444 47978602034560 learning.py:507] global step 6598: loss = 7.1152 (0.516 sec/step)
I0404 21:02:28.340294 47978602034560 learning.py:507] global step 6599: loss = 6.2987 (0.511 sec/step)
I0404 21:02:28.881280 47978602034560 learning.py:507] global step 6600: loss = 5.8228 (0.539 sec/step)
I0404 21:02:29.404677 47978602034560 learning.py:507] global step 6601: loss = 5.4869 (0.520 sec/step)
I0404 21:02:29.918455 47978602034560 learning.py:507] global step 6602: loss = 5.4918 (0.512 sec/step)
I0404 21:02:30.427459 47978602034560 learning.py:507] global step 6603: loss = 6.1716 (0.507 sec/step)
I0404 21:02:30.930610 47978602034560 learning.py:507] global step 6604: loss = 5.6810 (0.500 sec/step)
I0404 21:02:31.442321 47978602034560 learning.py:507] global step 6605: loss = 6.0335 (0.510 sec/step)
I0404 21:02:31.957053 47978602034560 learning.py:507] global step 6606: loss = 5.8296 (0.512 sec/step)
I0404 21:02:32.475934 47978602034560 learning.py:507] global step 6607: loss = 6.0196 (0.516 sec/step)
I0404 21:02:32.977657 47978602034560 learning.py:507] global step 6608: loss = 5.3754 (0.500 sec/step)
I0404 21:02:33.486102 47978602034560 learning.py:507] global step 6609: loss = 6.5269 (0.506 sec/step)
I0404 21:02:34.017287 47978602034560 learning.py:507] global step 6610: loss = 5.3975 (0.530 sec/step)
I0404 21:02:34.546540 47978602034560 learning.py:507] global step 6611: loss = 6.9707 (0.528 sec/step)
I0404 21:02:35.056453 47978602034560 learning.py:507] global step 6612: loss = 5.2467 (0.508 sec/step)
I0404 21:02:35.565713 47978602034560 learning.py:507] global step 6613: loss = 5.5308 (0.508 sec/step)
I0404 21:02:36.107559 47978602034560 learning.py:507] global step 6614: loss = 6.8033 (0.540 sec/step)
I0404 21:02:36.611135 47978602034560 learning.py:507] global step 6615: loss = 5.2731 (0.502 sec/step)
I0404 21:02:37.116813 47978602034560 learning.py:507] global step 6616: loss = 6.0778 (0.504 sec/step)
I0404 21:02:37.627527 47978602034560 learning.py:507] global step 6617: loss = 5.5526 (0.509 sec/step)
I0404 21:02:38.131741 47978602034560 learning.py:507] global step 6618: loss = 6.3584 (0.503 sec/step)
I0404 21:02:38.660584 47978602034560 learning.py:507] global step 6619: loss = 6.0257 (0.527 sec/step)
I0404 21:02:39.194577 47978602034560 learning.py:507] global step 6620: loss = 6.2047 (0.532 sec/step)
I0404 21:02:39.718005 47978602034560 learning.py:507] global step 6621: loss = 5.0309 (0.522 sec/step)
I0404 21:02:40.230700 47978602034560 learning.py:507] global step 6622: loss = 6.4368 (0.511 sec/step)
I0404 21:02:40.742863 47978602034560 learning.py:507] global step 6623: loss = 6.4804 (0.511 sec/step)
I0404 21:02:41.249238 47978602034560 learning.py:507] global step 6624: loss = 6.1486 (0.505 sec/step)
I0404 21:02:41.752968 47978602034560 learning.py:507] global step 6625: loss = 6.4667 (0.502 sec/step)
I0404 21:02:42.271377 47978602034560 learning.py:507] global step 6626: loss = 6.0932 (0.516 sec/step)
I0404 21:02:42.782090 47978602034560 learning.py:507] global step 6627: loss = 6.0834 (0.509 sec/step)
I0404 21:02:43.290084 47978602034560 learning.py:507] global step 6628: loss = 5.2059 (0.506 sec/step)
I0404 21:02:43.798825 47978602034560 learning.py:507] global step 6629: loss = 5.6053 (0.507 sec/step)
I0404 21:02:44.324512 47978602034560 learning.py:507] global step 6630: loss = 5.1746 (0.524 sec/step)
I0404 21:02:44.831750 47978602034560 learning.py:507] global step 6631: loss = 7.0681 (0.504 sec/step)
I0404 21:02:45.345921 47978602034560 learning.py:507] global step 6632: loss = 5.8727 (0.513 sec/step)
I0404 21:02:45.880188 47978602034560 learning.py:507] global step 6633: loss = 6.6483 (0.531 sec/step)
I0404 21:02:46.392129 47978602034560 learning.py:507] global step 6634: loss = 6.4204 (0.510 sec/step)
I0404 21:02:46.896224 47978602034560 learning.py:507] global step 6635: loss = 4.6022 (0.501 sec/step)
I0404 21:02:47.439298 47978602034560 learning.py:507] global step 6636: loss = 6.0083 (0.541 sec/step)
I0404 21:02:47.974493 47978602034560 learning.py:507] global step 6637: loss = 5.2476 (0.532 sec/step)
I0404 21:02:48.475777 47978602034560 learning.py:507] global step 6638: loss = 6.2571 (0.500 sec/step)
I0404 21:02:48.983739 47978602034560 learning.py:507] global step 6639: loss = 6.2740 (0.506 sec/step)
I0404 21:02:49.497009 47978602034560 learning.py:507] global step 6640: loss = 7.3874 (0.512 sec/step)
I0404 21:02:50.003244 47978602034560 learning.py:507] global step 6641: loss = 6.6089 (0.505 sec/step)
I0404 21:02:50.506587 47978602034560 learning.py:507] global step 6642: loss = 5.7396 (0.500 sec/step)
I0404 21:02:51.024382 47978602034560 learning.py:507] global step 6643: loss = 5.0799 (0.515 sec/step)
I0404 21:02:51.532587 47978602034560 learning.py:507] global step 6644: loss = 6.3821 (0.507 sec/step)
I0404 21:02:52.041510 47978602034560 learning.py:507] global step 6645: loss = 7.3742 (0.507 sec/step)
I0404 21:02:52.561636 47978602034560 learning.py:507] global step 6646: loss = 6.6162 (0.517 sec/step)
I0404 21:02:53.096839 47978602034560 learning.py:507] global step 6647: loss = 5.1397 (0.534 sec/step)
I0404 21:02:53.606272 47978602034560 learning.py:507] global step 6648: loss = 5.5204 (0.508 sec/step)
I0404 21:02:54.138003 47978602034560 learning.py:507] global step 6649: loss = 6.8911 (0.530 sec/step)
I0404 21:02:54.657831 47978602034560 learning.py:507] global step 6650: loss = 5.8510 (0.518 sec/step)
I0404 21:02:55.169001 47978602034560 learning.py:507] global step 6651: loss = 6.7704 (0.510 sec/step)
I0404 21:02:55.677279 47978602034560 learning.py:507] global step 6652: loss = 6.5770 (0.507 sec/step)
I0404 21:02:56.221433 47978602034560 learning.py:507] global step 6653: loss = 6.4293 (0.543 sec/step)
I0404 21:02:56.721565 47978602034560 learning.py:507] global step 6654: loss = 5.9764 (0.499 sec/step)
I0404 21:02:57.219994 47978602034560 learning.py:507] global step 6655: loss = 6.2215 (0.497 sec/step)
I0404 21:02:57.730193 47978602034560 learning.py:507] global step 6656: loss = 6.8162 (0.507 sec/step)
I0404 21:02:58.245287 47978602034560 learning.py:507] global step 6657: loss = 6.6237 (0.514 sec/step)
I0404 21:02:58.752629 47978602034560 learning.py:507] global step 6658: loss = 5.0190 (0.504 sec/step)
I0404 21:02:59.270639 47978602034560 learning.py:507] global step 6659: loss = 4.4269 (0.516 sec/step)
I0404 21:02:59.802482 47978602034560 learning.py:507] global step 6660: loss = 6.2110 (0.530 sec/step)
I0404 21:03:00.312132 47978602034560 learning.py:507] global step 6661: loss = 6.1160 (0.508 sec/step)
I0404 21:03:00.821519 47978602034560 learning.py:507] global step 6662: loss = 6.1000 (0.507 sec/step)
I0404 21:03:01.336595 47978602034560 learning.py:507] global step 6663: loss = 5.6539 (0.513 sec/step)
I0404 21:03:01.843520 47978602034560 learning.py:507] global step 6664: loss = 5.7892 (0.504 sec/step)
I0404 21:03:02.365197 47978602034560 learning.py:507] global step 6665: loss = 6.6272 (0.520 sec/step)
I0404 21:03:02.872809 47978602034560 learning.py:507] global step 6666: loss = 6.3404 (0.506 sec/step)
I0404 21:03:03.378369 47978602034560 learning.py:507] global step 6667: loss = 5.0751 (0.504 sec/step)
I0404 21:03:03.892404 47978602034560 learning.py:507] global step 6668: loss = 5.9951 (0.511 sec/step)
I0404 21:03:04.404187 47978602034560 learning.py:507] global step 6669: loss = 5.2718 (0.510 sec/step)
I0404 21:03:04.910141 47978602034560 learning.py:507] global step 6670: loss = 5.2564 (0.504 sec/step)
I0404 21:03:05.414267 47978602034560 learning.py:507] global step 6671: loss = 5.7439 (0.501 sec/step)
I0404 21:03:05.925752 47978602034560 learning.py:507] global step 6672: loss = 6.8630 (0.510 sec/step)
I0404 21:03:06.440909 47978602034560 learning.py:507] global step 6673: loss = 6.7178 (0.512 sec/step)
I0404 21:03:06.951718 47978602034560 learning.py:507] global step 6674: loss = 5.8968 (0.509 sec/step)
I0404 21:03:07.466048 47978602034560 learning.py:507] global step 6675: loss = 6.3262 (0.513 sec/step)
I0404 21:03:07.974611 47978602034560 learning.py:507] global step 6676: loss = 5.5180 (0.507 sec/step)
I0404 21:03:08.503157 47978602034560 learning.py:507] global step 6677: loss = 7.6183 (0.527 sec/step)
I0404 21:03:09.016885 47978602034560 learning.py:507] global step 6678: loss = 5.9001 (0.512 sec/step)
I0404 21:03:09.522633 47978602034560 learning.py:507] global step 6679: loss = 4.8406 (0.504 sec/step)
I0404 21:03:10.036652 47978602034560 learning.py:507] global step 6680: loss = 4.9159 (0.512 sec/step)
I0404 21:03:10.575084 47978602034560 learning.py:507] global step 6681: loss = 5.9141 (0.536 sec/step)
I0404 21:03:11.079275 47978602034560 learning.py:507] global step 6682: loss = 5.6719 (0.503 sec/step)
I0404 21:03:11.587291 47978602034560 learning.py:507] global step 6683: loss = 5.3444 (0.506 sec/step)
I0404 21:03:12.093634 47978602034560 learning.py:507] global step 6684: loss = 4.6849 (0.505 sec/step)
I0404 21:03:12.601329 47978602034560 learning.py:507] global step 6685: loss = 5.2887 (0.505 sec/step)
I0404 21:03:13.130308 47978602034560 learning.py:507] global step 6686: loss = 6.2112 (0.527 sec/step)
I0404 21:03:13.665451 47978602034560 learning.py:507] global step 6687: loss = 6.0213 (0.534 sec/step)
I0404 21:03:14.183006 47978602034560 learning.py:507] global step 6688: loss = 6.6393 (0.515 sec/step)
I0404 21:03:14.703336 47978602034560 learning.py:507] global step 6689: loss = 5.6253 (0.519 sec/step)
I0404 21:03:15.212560 47978602034560 learning.py:507] global step 6690: loss = 5.9212 (0.508 sec/step)
I0404 21:03:15.715492 47978602034560 learning.py:507] global step 6691: loss = 6.1741 (0.501 sec/step)
I0404 21:03:16.227519 47978602034560 learning.py:507] global step 6692: loss = 6.3398 (0.510 sec/step)
I0404 21:03:16.744096 47978602034560 learning.py:507] global step 6693: loss = 5.5092 (0.514 sec/step)
I0404 21:03:17.107938 47983661975296 supervisor.py:1050] Recording summary at step 6693.
I0404 21:03:17.451541 47978602034560 learning.py:507] global step 6694: loss = 7.0095 (0.689 sec/step)
I0404 21:03:17.960565 47978602034560 learning.py:507] global step 6695: loss = 6.1359 (0.506 sec/step)
I0404 21:03:18.468041 47978602034560 learning.py:507] global step 6696: loss = 6.0766 (0.506 sec/step)
I0404 21:03:19.002338 47978602034560 learning.py:507] global step 6697: loss = 5.9915 (0.533 sec/step)
I0404 21:03:19.505170 47978602034560 learning.py:507] global step 6698: loss = 6.2758 (0.500 sec/step)
I0404 21:03:20.009706 47978602034560 learning.py:507] global step 6699: loss = 5.1554 (0.502 sec/step)
I0404 21:03:20.515715 47978602034560 learning.py:507] global step 6700: loss = 5.1224 (0.504 sec/step)
I0404 21:03:21.024588 47978602034560 learning.py:507] global step 6701: loss = 5.8409 (0.507 sec/step)
I0404 21:03:21.529301 47978602034560 learning.py:507] global step 6702: loss = 5.6889 (0.503 sec/step)
I0404 21:03:22.068641 47978602034560 learning.py:507] global step 6703: loss = 6.0840 (0.537 sec/step)
I0404 21:03:22.608731 47978602034560 learning.py:507] global step 6704: loss = 6.6058 (0.538 sec/step)
I0404 21:03:23.127448 47978602034560 learning.py:507] global step 6705: loss = 6.1890 (0.517 sec/step)
I0404 21:03:23.647423 47978602034560 learning.py:507] global step 6706: loss = 6.5978 (0.517 sec/step)
I0404 21:03:24.163070 47978602034560 learning.py:507] global step 6707: loss = 5.8503 (0.513 sec/step)
I0404 21:03:24.672994 47978602034560 learning.py:507] global step 6708: loss = 6.2680 (0.508 sec/step)
I0404 21:03:25.189245 47978602034560 learning.py:507] global step 6709: loss = 5.8392 (0.515 sec/step)
I0404 21:03:25.704139 47978602034560 learning.py:507] global step 6710: loss = 6.7795 (0.513 sec/step)
I0404 21:03:26.226638 47978602034560 learning.py:507] global step 6711: loss = 6.9893 (0.521 sec/step)
I0404 21:03:26.756900 47978602034560 learning.py:507] global step 6712: loss = 5.4418 (0.529 sec/step)
I0404 21:03:27.260229 47978602034560 learning.py:507] global step 6713: loss = 4.9573 (0.502 sec/step)
I0404 21:03:27.777618 47978602034560 learning.py:507] global step 6714: loss = 6.7611 (0.516 sec/step)
I0404 21:03:28.302274 47978602034560 learning.py:507] global step 6715: loss = 5.7254 (0.523 sec/step)
I0404 21:03:28.817624 47978602034560 learning.py:507] global step 6716: loss = 5.5938 (0.512 sec/step)
I0404 21:03:29.322485 47978602034560 learning.py:507] global step 6717: loss = 5.8909 (0.503 sec/step)
I0404 21:03:29.839477 47978602034560 learning.py:507] global step 6718: loss = 5.7869 (0.515 sec/step)
I0404 21:03:30.350986 47978602034560 learning.py:507] global step 6719: loss = 5.8401 (0.510 sec/step)
I0404 21:03:30.866702 47978602034560 learning.py:507] global step 6720: loss = 5.1986 (0.514 sec/step)
I0404 21:03:31.386635 47978602034560 learning.py:507] global step 6721: loss = 5.0799 (0.518 sec/step)
I0404 21:03:31.919700 47978602034560 learning.py:507] global step 6722: loss = 6.8362 (0.531 sec/step)
I0404 21:03:32.443574 47978602034560 learning.py:507] global step 6723: loss = 6.8985 (0.522 sec/step)
I0404 21:03:32.962579 47978602034560 learning.py:507] global step 6724: loss = 5.7471 (0.517 sec/step)
I0404 21:03:33.465542 47978602034560 learning.py:507] global step 6725: loss = 5.8957 (0.500 sec/step)
I0404 21:03:33.975399 47978602034560 learning.py:507] global step 6726: loss = 5.8867 (0.508 sec/step)
I0404 21:03:34.481931 47978602034560 learning.py:507] global step 6727: loss = 6.5289 (0.505 sec/step)
I0404 21:03:34.994713 47978602034560 learning.py:507] global step 6728: loss = 5.9937 (0.511 sec/step)
I0404 21:03:35.497902 47978602034560 learning.py:507] global step 6729: loss = 5.7034 (0.502 sec/step)
I0404 21:03:36.011637 47978602034560 learning.py:507] global step 6730: loss = 6.9146 (0.512 sec/step)
I0404 21:03:36.534778 47978602034560 learning.py:507] global step 6731: loss = 6.3519 (0.522 sec/step)
I0404 21:03:37.045914 47978602034560 learning.py:507] global step 6732: loss = 5.4179 (0.510 sec/step)
I0404 21:03:37.568047 47978602034560 learning.py:507] global step 6733: loss = 6.5963 (0.521 sec/step)
I0404 21:03:38.077440 47978602034560 learning.py:507] global step 6734: loss = 5.5789 (0.506 sec/step)
I0404 21:03:38.583637 47978602034560 learning.py:507] global step 6735: loss = 5.8954 (0.503 sec/step)
I0404 21:03:39.092996 47978602034560 learning.py:507] global step 6736: loss = 5.4136 (0.508 sec/step)
I0404 21:03:39.607649 47978602034560 learning.py:507] global step 6737: loss = 6.2895 (0.513 sec/step)
I0404 21:03:40.112059 47978602034560 learning.py:507] global step 6738: loss = 5.9451 (0.501 sec/step)
I0404 21:03:40.622110 47978602034560 learning.py:507] global step 6739: loss = 5.4437 (0.508 sec/step)
I0404 21:03:41.150224 47978602034560 learning.py:507] global step 6740: loss = 5.9767 (0.525 sec/step)
I0404 21:03:41.658745 47978602034560 learning.py:507] global step 6741: loss = 6.1252 (0.506 sec/step)
I0404 21:03:42.166529 47978602034560 learning.py:507] global step 6742: loss = 5.6512 (0.506 sec/step)
I0404 21:03:42.676612 47978602034560 learning.py:507] global step 6743: loss = 6.2027 (0.508 sec/step)
I0404 21:03:43.191243 47978602034560 learning.py:507] global step 6744: loss = 7.0777 (0.512 sec/step)
I0404 21:03:43.702178 47978602034560 learning.py:507] global step 6745: loss = 5.4715 (0.508 sec/step)
I0404 21:03:44.215968 47978602034560 learning.py:507] global step 6746: loss = 5.9838 (0.512 sec/step)
I0404 21:03:44.715099 47978602034560 learning.py:507] global step 6747: loss = 6.3403 (0.498 sec/step)
I0404 21:03:45.231785 47978602034560 learning.py:507] global step 6748: loss = 6.1772 (0.515 sec/step)
I0404 21:03:45.734233 47978602034560 learning.py:507] global step 6749: loss = 6.1152 (0.501 sec/step)
I0404 21:03:46.239120 47978602034560 learning.py:507] global step 6750: loss = 5.7533 (0.503 sec/step)
I0404 21:03:46.751549 47978602034560 learning.py:507] global step 6751: loss = 7.0266 (0.511 sec/step)
I0404 21:03:47.262047 47978602034560 learning.py:507] global step 6752: loss = 5.6867 (0.509 sec/step)
I0404 21:03:47.773847 47978602034560 learning.py:507] global step 6753: loss = 5.5139 (0.510 sec/step)
I0404 21:03:48.287331 47978602034560 learning.py:507] global step 6754: loss = 5.9551 (0.512 sec/step)
I0404 21:03:48.794015 47978602034560 learning.py:507] global step 6755: loss = 5.4152 (0.505 sec/step)
I0404 21:03:49.307999 47978602034560 learning.py:507] global step 6756: loss = 5.7797 (0.512 sec/step)
I0404 21:03:49.810646 47978602034560 learning.py:507] global step 6757: loss = 4.8683 (0.501 sec/step)
I0404 21:03:50.346728 47978602034560 learning.py:507] global step 6758: loss = 6.3931 (0.534 sec/step)
I0404 21:03:50.870146 47978602034560 learning.py:507] global step 6759: loss = 6.0963 (0.522 sec/step)
I0404 21:03:51.407092 47978602034560 learning.py:507] global step 6760: loss = 5.9309 (0.535 sec/step)
I0404 21:03:51.913872 47978602034560 learning.py:507] global step 6761: loss = 6.6581 (0.505 sec/step)
I0404 21:03:52.421635 47978602034560 learning.py:507] global step 6762: loss = 7.3222 (0.505 sec/step)
I0404 21:03:52.940899 47978602034560 learning.py:507] global step 6763: loss = 5.2178 (0.518 sec/step)
I0404 21:03:53.461662 47978602034560 learning.py:507] global step 6764: loss = 5.6273 (0.519 sec/step)
I0404 21:03:53.971925 47978602034560 learning.py:507] global step 6765: loss = 6.5113 (0.509 sec/step)
I0404 21:03:54.485703 47978602034560 learning.py:507] global step 6766: loss = 4.9033 (0.512 sec/step)
I0404 21:03:54.992801 47978602034560 learning.py:507] global step 6767: loss = 5.8574 (0.506 sec/step)
I0404 21:03:55.503998 47978602034560 learning.py:507] global step 6768: loss = 5.6246 (0.510 sec/step)
I0404 21:03:56.003125 47978602034560 learning.py:507] global step 6769: loss = 5.7214 (0.498 sec/step)
I0404 21:03:56.515652 47978602034560 learning.py:507] global step 6770: loss = 5.7948 (0.511 sec/step)
I0404 21:03:57.017508 47978602034560 learning.py:507] global step 6771: loss = 5.3220 (0.500 sec/step)
I0404 21:03:57.521845 47978602034560 learning.py:507] global step 6772: loss = 6.3200 (0.503 sec/step)
I0404 21:03:58.050736 47978602034560 learning.py:507] global step 6773: loss = 5.7712 (0.526 sec/step)
I0404 21:03:58.563686 47978602034560 learning.py:507] global step 6774: loss = 5.8120 (0.510 sec/step)
I0404 21:03:59.065622 47978602034560 learning.py:507] global step 6775: loss = 6.1387 (0.500 sec/step)
I0404 21:03:59.588245 47978602034560 learning.py:507] global step 6776: loss = 5.5402 (0.521 sec/step)
I0404 21:04:00.099891 47978602034560 learning.py:507] global step 6777: loss = 5.3580 (0.510 sec/step)
I0404 21:04:00.603716 47978602034560 learning.py:507] global step 6778: loss = 6.9459 (0.502 sec/step)
I0404 21:04:01.133726 47978602034560 learning.py:507] global step 6779: loss = 5.6117 (0.528 sec/step)
I0404 21:04:01.641019 47978602034560 learning.py:507] global step 6780: loss = 5.6623 (0.506 sec/step)
I0404 21:04:02.177897 47978602034560 learning.py:507] global step 6781: loss = 5.2314 (0.535 sec/step)
I0404 21:04:02.685982 47978602034560 learning.py:507] global step 6782: loss = 5.4602 (0.506 sec/step)
I0404 21:04:03.198713 47978602034560 learning.py:507] global step 6783: loss = 5.4177 (0.511 sec/step)
I0404 21:04:03.718972 47978602034560 learning.py:507] global step 6784: loss = 5.5664 (0.519 sec/step)
I0404 21:04:04.238313 47978602034560 learning.py:507] global step 6785: loss = 6.1101 (0.516 sec/step)
I0404 21:04:04.741539 47978602034560 learning.py:507] global step 6786: loss = 5.6805 (0.502 sec/step)
I0404 21:04:05.252123 47978602034560 learning.py:507] global step 6787: loss = 6.2357 (0.508 sec/step)
I0404 21:04:05.758066 47978602034560 learning.py:507] global step 6788: loss = 6.5912 (0.504 sec/step)
I0404 21:04:06.282956 47978602034560 learning.py:507] global step 6789: loss = 5.4034 (0.523 sec/step)
I0404 21:04:06.797880 47978602034560 learning.py:507] global step 6790: loss = 5.0450 (0.513 sec/step)
I0404 21:04:07.304177 47978602034560 learning.py:507] global step 6791: loss = 5.8721 (0.505 sec/step)
I0404 21:04:07.827691 47978602034560 learning.py:507] global step 6792: loss = 6.0174 (0.522 sec/step)
I0404 21:04:08.335252 47978602034560 learning.py:507] global step 6793: loss = 5.9752 (0.506 sec/step)
I0404 21:04:08.844355 47978602034560 learning.py:507] global step 6794: loss = 5.2685 (0.506 sec/step)
I0404 21:04:09.367341 47978602034560 learning.py:507] global step 6795: loss = 6.1064 (0.521 sec/step)
I0404 21:04:09.881442 47978602034560 learning.py:507] global step 6796: loss = 6.7642 (0.511 sec/step)
I0404 21:04:10.387046 47978602034560 learning.py:507] global step 6797: loss = 6.5589 (0.504 sec/step)
I0404 21:04:10.898726 47978602034560 learning.py:507] global step 6798: loss = 6.4912 (0.510 sec/step)
I0404 21:04:11.414324 47978602034560 learning.py:507] global step 6799: loss = 5.6756 (0.514 sec/step)
I0404 21:04:11.925945 47978602034560 learning.py:507] global step 6800: loss = 5.3527 (0.509 sec/step)
I0404 21:04:12.428413 47978602034560 learning.py:507] global step 6801: loss = 4.9774 (0.501 sec/step)
I0404 21:04:12.942978 47978602034560 learning.py:507] global step 6802: loss = 5.2699 (0.512 sec/step)
I0404 21:04:13.446602 47978602034560 learning.py:507] global step 6803: loss = 6.4078 (0.502 sec/step)
I0404 21:04:13.971399 47978602034560 learning.py:507] global step 6804: loss = 6.1395 (0.523 sec/step)
I0404 21:04:14.483455 47978602034560 learning.py:507] global step 6805: loss = 5.4020 (0.511 sec/step)
I0404 21:04:14.999634 47978602034560 learning.py:507] global step 6806: loss = 5.9509 (0.515 sec/step)
I0404 21:04:15.520916 47978602034560 learning.py:507] global step 6807: loss = 5.8310 (0.520 sec/step)
I0404 21:04:16.028259 47978602034560 learning.py:507] global step 6808: loss = 6.5010 (0.506 sec/step)
I0404 21:04:16.564425 47978602034560 learning.py:507] global step 6809: loss = 6.1037 (0.535 sec/step)
I0404 21:04:17.069425 47978602034560 learning.py:507] global step 6810: loss = 5.6308 (0.503 sec/step)
I0404 21:04:17.577693 47978602034560 learning.py:507] global step 6811: loss = 6.4581 (0.507 sec/step)
I0404 21:04:18.095425 47978602034560 learning.py:507] global step 6812: loss = 6.5091 (0.516 sec/step)
I0404 21:04:18.597096 47978602034560 learning.py:507] global step 6813: loss = 5.5835 (0.500 sec/step)
I0404 21:04:19.107455 47978602034560 learning.py:507] global step 6814: loss = 6.8345 (0.509 sec/step)
I0404 21:04:19.611945 47978602034560 learning.py:507] global step 6815: loss = 6.0997 (0.503 sec/step)
I0404 21:04:20.117394 47978602034560 learning.py:507] global step 6816: loss = 5.6929 (0.503 sec/step)
I0404 21:04:20.644755 47978602034560 learning.py:507] global step 6817: loss = 6.3665 (0.524 sec/step)
I0404 21:04:21.162169 47978602034560 learning.py:507] global step 6818: loss = 6.3052 (0.515 sec/step)
I0404 21:04:21.676080 47978602034560 learning.py:507] global step 6819: loss = 6.8216 (0.512 sec/step)
I0404 21:04:22.191817 47978602034560 learning.py:507] global step 6820: loss = 5.6223 (0.514 sec/step)
I0404 21:04:22.701739 47978602034560 learning.py:507] global step 6821: loss = 6.6044 (0.508 sec/step)
I0404 21:04:23.223586 47978602034560 learning.py:507] global step 6822: loss = 6.9001 (0.520 sec/step)
I0404 21:04:23.729516 47978602034560 learning.py:507] global step 6823: loss = 6.9436 (0.504 sec/step)
I0404 21:04:24.236035 47978602034560 learning.py:507] global step 6824: loss = 5.5016 (0.505 sec/step)
I0404 21:04:24.761118 47978602034560 learning.py:507] global step 6825: loss = 6.1685 (0.522 sec/step)
I0404 21:04:25.263648 47978602034560 learning.py:507] global step 6826: loss = 6.5813 (0.501 sec/step)
I0404 21:04:25.781996 47978602034560 learning.py:507] global step 6827: loss = 6.2477 (0.517 sec/step)
I0404 21:04:26.282425 47978602034560 learning.py:507] global step 6828: loss = 5.8829 (0.497 sec/step)
I0404 21:04:26.808737 47978602034560 learning.py:507] global step 6829: loss = 4.8512 (0.525 sec/step)
I0404 21:04:27.321823 47978602034560 learning.py:507] global step 6830: loss = 5.8178 (0.510 sec/step)
I0404 21:04:27.831004 47978602034560 learning.py:507] global step 6831: loss = 5.2246 (0.508 sec/step)
I0404 21:04:28.351541 47978602034560 learning.py:507] global step 6832: loss = 4.8788 (0.519 sec/step)
I0404 21:04:28.865509 47978602034560 learning.py:507] global step 6833: loss = 6.4657 (0.511 sec/step)
I0404 21:04:29.403293 47978602034560 learning.py:507] global step 6834: loss = 5.8511 (0.536 sec/step)
I0404 21:04:29.914464 47978602034560 learning.py:507] global step 6835: loss = 5.5561 (0.510 sec/step)
I0404 21:04:30.436743 47978602034560 learning.py:507] global step 6836: loss = 5.4326 (0.521 sec/step)
I0404 21:04:30.947243 47978602034560 learning.py:507] global step 6837: loss = 5.3708 (0.509 sec/step)
I0404 21:04:31.462496 47978602034560 learning.py:507] global step 6838: loss = 5.0900 (0.514 sec/step)
I0404 21:04:31.972757 47978602034560 learning.py:507] global step 6839: loss = 6.0345 (0.509 sec/step)
I0404 21:04:32.477797 47978602034560 learning.py:507] global step 6840: loss = 5.4841 (0.503 sec/step)
I0404 21:04:32.986741 47978602034560 learning.py:507] global step 6841: loss = 6.7708 (0.507 sec/step)
I0404 21:04:33.503089 47978602034560 learning.py:507] global step 6842: loss = 5.3899 (0.515 sec/step)
I0404 21:04:34.015153 47978602034560 learning.py:507] global step 6843: loss = 6.6822 (0.509 sec/step)
I0404 21:04:34.542942 47978602034560 learning.py:507] global step 6844: loss = 5.4984 (0.525 sec/step)
I0404 21:04:35.058652 47978602034560 learning.py:507] global step 6845: loss = 6.3421 (0.514 sec/step)
I0404 21:04:35.566770 47978602034560 learning.py:507] global step 6846: loss = 5.9800 (0.505 sec/step)
I0404 21:04:36.070215 47978602034560 learning.py:507] global step 6847: loss = 5.0158 (0.501 sec/step)
I0404 21:04:36.572619 47978602034560 learning.py:507] global step 6848: loss = 5.5631 (0.500 sec/step)
I0404 21:04:37.085934 47978602034560 learning.py:507] global step 6849: loss = 5.7275 (0.512 sec/step)
I0404 21:04:37.598702 47978602034560 learning.py:507] global step 6850: loss = 7.6684 (0.510 sec/step)
I0404 21:04:38.106215 47978602034560 learning.py:507] global step 6851: loss = 6.2327 (0.505 sec/step)
I0404 21:04:38.621585 47978602034560 learning.py:507] global step 6852: loss = 5.4016 (0.514 sec/step)
I0404 21:04:39.136686 47978602034560 learning.py:507] global step 6853: loss = 5.1102 (0.512 sec/step)
I0404 21:04:39.671340 47978602034560 learning.py:507] global step 6854: loss = 6.2016 (0.533 sec/step)
I0404 21:04:40.175202 47978602034560 learning.py:507] global step 6855: loss = 6.2810 (0.501 sec/step)
I0404 21:04:40.705635 47978602034560 learning.py:507] global step 6856: loss = 5.2420 (0.529 sec/step)
I0404 21:04:41.210529 47978602034560 learning.py:507] global step 6857: loss = 5.2770 (0.503 sec/step)
I0404 21:04:41.714599 47978602034560 learning.py:507] global step 6858: loss = 5.6996 (0.503 sec/step)
I0404 21:04:42.218094 47978602034560 learning.py:507] global step 6859: loss = 4.9845 (0.501 sec/step)
I0404 21:04:42.730820 47978602034560 learning.py:507] global step 6860: loss = 6.4447 (0.511 sec/step)
I0404 21:04:43.234810 47978602034560 learning.py:507] global step 6861: loss = 6.5305 (0.502 sec/step)
I0404 21:04:43.771856 47978602034560 learning.py:507] global step 6862: loss = 6.4709 (0.535 sec/step)
I0404 21:04:44.300211 47978602034560 learning.py:507] global step 6863: loss = 6.5987 (0.527 sec/step)
I0404 21:04:44.810148 47978602034560 learning.py:507] global step 6864: loss = 6.6789 (0.508 sec/step)
I0404 21:04:45.320989 47978602034560 learning.py:507] global step 6865: loss = 6.2777 (0.509 sec/step)
I0404 21:04:45.822212 47978602034560 learning.py:507] global step 6866: loss = 5.7458 (0.500 sec/step)
I0404 21:04:46.368021 47978602034560 learning.py:507] global step 6867: loss = 6.0716 (0.544 sec/step)
I0404 21:04:46.869254 47978602034560 learning.py:507] global step 6868: loss = 6.2665 (0.500 sec/step)
I0404 21:04:47.378591 47978602034560 learning.py:507] global step 6869: loss = 5.8629 (0.506 sec/step)
I0404 21:04:47.896818 47978602034560 learning.py:507] global step 6870: loss = 6.2515 (0.515 sec/step)
I0404 21:04:48.410522 47978602034560 learning.py:507] global step 6871: loss = 7.2478 (0.511 sec/step)
I0404 21:04:48.924633 47978602034560 learning.py:507] global step 6872: loss = 5.6396 (0.513 sec/step)
I0404 21:04:49.437105 47978602034560 learning.py:507] global step 6873: loss = 5.3231 (0.510 sec/step)
I0404 21:04:49.945551 47978602034560 learning.py:507] global step 6874: loss = 5.7473 (0.507 sec/step)
I0404 21:04:50.450038 47978602034560 learning.py:507] global step 6875: loss = 5.2733 (0.502 sec/step)
I0404 21:04:50.960006 47978602034560 learning.py:507] global step 6876: loss = 5.7249 (0.507 sec/step)
I0404 21:04:51.467305 47978602034560 learning.py:507] global step 6877: loss = 5.4138 (0.506 sec/step)
I0404 21:04:51.974541 47978602034560 learning.py:507] global step 6878: loss = 5.7868 (0.506 sec/step)
I0404 21:04:52.503830 47978602034560 learning.py:507] global step 6879: loss = 5.7754 (0.528 sec/step)
I0404 21:04:53.008843 47978602034560 learning.py:507] global step 6880: loss = 6.1464 (0.503 sec/step)
I0404 21:04:53.529060 47978602034560 learning.py:507] global step 6881: loss = 6.0640 (0.519 sec/step)
I0404 21:04:54.041236 47978602034560 learning.py:507] global step 6882: loss = 5.3662 (0.509 sec/step)
I0404 21:04:54.552332 47978602034560 learning.py:507] global step 6883: loss = 5.2134 (0.510 sec/step)
I0404 21:04:55.061738 47978602034560 learning.py:507] global step 6884: loss = 5.6901 (0.508 sec/step)
I0404 21:04:55.562234 47978602034560 learning.py:507] global step 6885: loss = 7.1499 (0.498 sec/step)
I0404 21:04:56.089855 47978602034560 learning.py:507] global step 6886: loss = 5.6468 (0.526 sec/step)
I0404 21:04:56.609848 47978602034560 learning.py:507] global step 6887: loss = 7.5802 (0.517 sec/step)
I0404 21:04:57.112540 47978602034560 learning.py:507] global step 6888: loss = 6.0145 (0.501 sec/step)
I0404 21:04:57.655235 47978602034560 learning.py:507] global step 6889: loss = 5.5367 (0.541 sec/step)
I0404 21:04:58.189942 47978602034560 learning.py:507] global step 6890: loss = 5.4885 (0.532 sec/step)
I0404 21:04:58.705553 47978602034560 learning.py:507] global step 6891: loss = 5.1976 (0.514 sec/step)
I0404 21:04:59.223492 47978602034560 learning.py:507] global step 6892: loss = 5.6135 (0.515 sec/step)
I0404 21:04:59.728767 47978602034560 learning.py:507] global step 6893: loss = 6.1106 (0.504 sec/step)
I0404 21:05:00.244062 47978602034560 learning.py:507] global step 6894: loss = 5.8827 (0.514 sec/step)
I0404 21:05:00.775608 47978602034560 learning.py:507] global step 6895: loss = 6.2358 (0.530 sec/step)
I0404 21:05:01.282190 47978602034560 learning.py:507] global step 6896: loss = 5.9197 (0.504 sec/step)
I0404 21:05:01.803391 47978602034560 learning.py:507] global step 6897: loss = 5.5433 (0.518 sec/step)
I0404 21:05:02.311600 47978602034560 learning.py:507] global step 6898: loss = 5.9269 (0.507 sec/step)
I0404 21:05:02.821707 47978602034560 learning.py:507] global step 6899: loss = 6.2361 (0.507 sec/step)
I0404 21:05:03.322862 47978602034560 learning.py:507] global step 6900: loss = 6.6247 (0.500 sec/step)
I0404 21:05:03.831902 47978602034560 learning.py:507] global step 6901: loss = 5.4896 (0.507 sec/step)
I0404 21:05:04.337957 47978602034560 learning.py:507] global step 6902: loss = 5.0469 (0.504 sec/step)
I0404 21:05:04.838883 47978602034560 learning.py:507] global step 6903: loss = 6.7073 (0.499 sec/step)
I0404 21:05:05.345067 47978602034560 learning.py:507] global step 6904: loss = 5.5276 (0.505 sec/step)
I0404 21:05:05.856988 47978602034560 learning.py:507] global step 6905: loss = 5.6235 (0.510 sec/step)
I0404 21:05:06.362435 47978602034560 learning.py:507] global step 6906: loss = 5.8627 (0.504 sec/step)
I0404 21:05:06.875135 47978602034560 learning.py:507] global step 6907: loss = 5.8979 (0.511 sec/step)
I0404 21:05:07.381890 47978602034560 learning.py:507] global step 6908: loss = 5.2206 (0.504 sec/step)
I0404 21:05:07.888818 47978602034560 learning.py:507] global step 6909: loss = 5.9327 (0.504 sec/step)
I0404 21:05:08.399381 47978602034560 learning.py:507] global step 6910: loss = 5.2330 (0.509 sec/step)
I0404 21:05:08.929769 47978602034560 learning.py:507] global step 6911: loss = 6.9126 (0.528 sec/step)
I0404 21:05:09.440467 47978602034560 learning.py:507] global step 6912: loss = 5.3276 (0.508 sec/step)
I0404 21:05:09.961635 47978602034560 learning.py:507] global step 6913: loss = 5.6004 (0.520 sec/step)
I0404 21:05:10.469423 47978602034560 learning.py:507] global step 6914: loss = 6.5091 (0.505 sec/step)
I0404 21:05:10.976594 47978602034560 learning.py:507] global step 6915: loss = 5.7167 (0.506 sec/step)
I0404 21:05:11.486669 47978602034560 learning.py:507] global step 6916: loss = 5.5091 (0.507 sec/step)
I0404 21:05:11.999259 47978602034560 learning.py:507] global step 6917: loss = 4.8793 (0.511 sec/step)
I0404 21:05:12.506644 47978602034560 learning.py:507] global step 6918: loss = 7.3706 (0.506 sec/step)
I0404 21:05:13.010137 47978602034560 learning.py:507] global step 6919: loss = 7.4765 (0.501 sec/step)
I0404 21:05:13.544179 47978602034560 learning.py:507] global step 6920: loss = 5.9320 (0.531 sec/step)
I0404 21:05:14.062903 47978602034560 learning.py:507] global step 6921: loss = 5.7850 (0.516 sec/step)
I0404 21:05:14.573968 47978602034560 learning.py:507] global step 6922: loss = 5.1403 (0.508 sec/step)
I0404 21:05:15.105839 47978602034560 learning.py:507] global step 6923: loss = 5.3457 (0.529 sec/step)
I0404 21:05:15.622759 47978602034560 learning.py:507] global step 6924: loss = 5.7099 (0.514 sec/step)
I0404 21:05:16.144438 47978602034560 learning.py:507] global step 6925: loss = 5.5581 (0.520 sec/step)
I0404 21:05:16.636511 47983666177792 supervisor.py:1117] Saving checkpoint to path ../../trainingOutput/model.ckpt
I0404 21:05:16.696459 47978602034560 learning.py:507] global step 6926: loss = 5.3229 (0.539 sec/step)
I0404 21:05:17.073605 47983661975296 supervisor.py:1050] Recording summary at step 6926.
I0404 21:05:17.432565 47978602034560 learning.py:507] global step 6927: loss = 5.6648 (0.713 sec/step)
I0404 21:05:18.216734 47978602034560 learning.py:507] global step 6928: loss = 5.2413 (0.505 sec/step)
I0404 21:05:18.745337 47978602034560 learning.py:507] global step 6929: loss = 5.7022 (0.526 sec/step)
I0404 21:05:19.265631 47978602034560 learning.py:507] global step 6930: loss = 6.2715 (0.519 sec/step)
I0404 21:05:19.798096 47978602034560 learning.py:507] global step 6931: loss = 6.7757 (0.530 sec/step)
I0404 21:05:20.307401 47978602034560 learning.py:507] global step 6932: loss = 6.2498 (0.508 sec/step)
I0404 21:05:20.813780 47978602034560 learning.py:507] global step 6933: loss = 5.2809 (0.505 sec/step)
I0404 21:05:21.323873 47978602034560 learning.py:507] global step 6934: loss = 5.6004 (0.508 sec/step)
I0404 21:05:21.841712 47978602034560 learning.py:507] global step 6935: loss = 5.6461 (0.515 sec/step)
I0404 21:05:22.352195 47978602034560 learning.py:507] global step 6936: loss = 6.3664 (0.509 sec/step)
I0404 21:05:22.889153 47978602034560 learning.py:507] global step 6937: loss = 6.1309 (0.535 sec/step)
I0404 21:05:23.417416 47978602034560 learning.py:507] global step 6938: loss = 6.7051 (0.525 sec/step)
I0404 21:05:23.935225 47978602034560 learning.py:507] global step 6939: loss = 5.3405 (0.515 sec/step)
I0404 21:05:24.456872 47978602034560 learning.py:507] global step 6940: loss = 6.3809 (0.519 sec/step)
I0404 21:05:24.965705 47978602034560 learning.py:507] global step 6941: loss = 5.9225 (0.506 sec/step)
I0404 21:05:25.473194 47978602034560 learning.py:507] global step 6942: loss = 5.7651 (0.506 sec/step)
I0404 21:05:26.006971 47978602034560 learning.py:507] global step 6943: loss = 6.2528 (0.531 sec/step)
I0404 21:05:26.523885 47978602034560 learning.py:507] global step 6944: loss = 5.5074 (0.514 sec/step)
I0404 21:05:27.025609 47978602034560 learning.py:507] global step 6945: loss = 5.8634 (0.500 sec/step)
I0404 21:05:27.525079 47978602034560 learning.py:507] global step 6946: loss = 5.9651 (0.498 sec/step)
I0404 21:05:28.046631 47978602034560 learning.py:507] global step 6947: loss = 5.5210 (0.520 sec/step)
I0404 21:05:28.556815 47978602034560 learning.py:507] global step 6948: loss = 6.2134 (0.509 sec/step)
I0404 21:05:29.080845 47978602034560 learning.py:507] global step 6949: loss = 6.9195 (0.522 sec/step)
I0404 21:05:29.585952 47978602034560 learning.py:507] global step 6950: loss = 6.9434 (0.503 sec/step)
I0404 21:05:30.108327 47978602034560 learning.py:507] global step 6951: loss = 4.2570 (0.521 sec/step)
I0404 21:05:30.635226 47978602034560 learning.py:507] global step 6952: loss = 5.8003 (0.525 sec/step)
I0404 21:05:31.155525 47978602034560 learning.py:507] global step 6953: loss = 6.6802 (0.519 sec/step)
I0404 21:05:31.673060 47978602034560 learning.py:507] global step 6954: loss = 5.6949 (0.515 sec/step)
I0404 21:05:32.176703 47978602034560 learning.py:507] global step 6955: loss = 6.6312 (0.502 sec/step)
I0404 21:05:32.705381 47978602034560 learning.py:507] global step 6956: loss = 6.0290 (0.527 sec/step)
I0404 21:05:33.220381 47978602034560 learning.py:507] global step 6957: loss = 6.1598 (0.513 sec/step)
I0404 21:05:33.734100 47978602034560 learning.py:507] global step 6958: loss = 5.8293 (0.512 sec/step)
I0404 21:05:34.251301 47978602034560 learning.py:507] global step 6959: loss = 5.3298 (0.516 sec/step)
I0404 21:05:34.759591 47978602034560 learning.py:507] global step 6960: loss = 5.1770 (0.505 sec/step)
I0404 21:05:35.286637 47978602034560 learning.py:507] global step 6961: loss = 5.6946 (0.524 sec/step)
I0404 21:05:35.806498 47978602034560 learning.py:507] global step 6962: loss = 5.8266 (0.518 sec/step)
I0404 21:05:36.324376 47978602034560 learning.py:507] global step 6963: loss = 5.3259 (0.515 sec/step)
I0404 21:05:36.855054 47978602034560 learning.py:507] global step 6964: loss = 6.0664 (0.529 sec/step)
I0404 21:05:37.373527 47978602034560 learning.py:507] global step 6965: loss = 6.1660 (0.517 sec/step)
I0404 21:05:37.878612 47978602034560 learning.py:507] global step 6966: loss = 5.9669 (0.503 sec/step)
I0404 21:05:38.396060 47978602034560 learning.py:507] global step 6967: loss = 6.5992 (0.516 sec/step)
I0404 21:05:38.904303 47978602034560 learning.py:507] global step 6968: loss = 6.2196 (0.507 sec/step)
I0404 21:05:39.414824 47978602034560 learning.py:507] global step 6969: loss = 6.4248 (0.509 sec/step)
I0404 21:05:39.954520 47978602034560 learning.py:507] global step 6970: loss = 6.0003 (0.538 sec/step)
I0404 21:05:40.460043 47978602034560 learning.py:507] global step 6971: loss = 6.6218 (0.504 sec/step)
I0404 21:05:40.961407 47978602034560 learning.py:507] global step 6972: loss = 5.8051 (0.500 sec/step)
I0404 21:05:41.468276 47978602034560 learning.py:507] global step 6973: loss = 5.6391 (0.504 sec/step)
I0404 21:05:41.983986 47978602034560 learning.py:507] global step 6974: loss = 6.0915 (0.513 sec/step)
I0404 21:05:42.495271 47978602034560 learning.py:507] global step 6975: loss = 5.3644 (0.510 sec/step)
I0404 21:05:43.008894 47978602034560 learning.py:507] global step 6976: loss = 6.1608 (0.511 sec/step)
I0404 21:05:43.546148 47978602034560 learning.py:507] global step 6977: loss = 6.1281 (0.536 sec/step)
I0404 21:05:44.047616 47978602034560 learning.py:507] global step 6978: loss = 5.8054 (0.499 sec/step)
I0404 21:05:44.560212 47978602034560 learning.py:507] global step 6979: loss = 6.9982 (0.511 sec/step)
I0404 21:05:45.071694 47978602034560 learning.py:507] global step 6980: loss = 5.9796 (0.510 sec/step)
I0404 21:05:45.587821 47978602034560 learning.py:507] global step 6981: loss = 5.9831 (0.515 sec/step)
I0404 21:05:46.104700 47978602034560 learning.py:507] global step 6982: loss = 6.0728 (0.515 sec/step)
I0404 21:05:46.613162 47978602034560 learning.py:507] global step 6983: loss = 6.3488 (0.506 sec/step)
I0404 21:05:47.141434 47978602034560 learning.py:507] global step 6984: loss = 6.7294 (0.525 sec/step)
I0404 21:05:47.655110 47978602034560 learning.py:507] global step 6985: loss = 6.0969 (0.512 sec/step)
I0404 21:05:48.187361 47978602034560 learning.py:507] global step 6986: loss = 6.9024 (0.531 sec/step)
I0404 21:05:48.703195 47978602034560 learning.py:507] global step 6987: loss = 5.7173 (0.514 sec/step)
I0404 21:05:49.225958 47978602034560 learning.py:507] global step 6988: loss = 6.8919 (0.521 sec/step)
I0404 21:05:49.733297 47978602034560 learning.py:507] global step 6989: loss = 6.0648 (0.506 sec/step)
I0404 21:05:50.271721 47978602034560 learning.py:507] global step 6990: loss = 6.5228 (0.537 sec/step)
I0404 21:05:50.781342 47978602034560 learning.py:507] global step 6991: loss = 4.2120 (0.508 sec/step)
I0404 21:05:51.293313 47978602034560 learning.py:507] global step 6992: loss = 4.9718 (0.510 sec/step)
I0404 21:05:51.805167 47978602034560 learning.py:507] global step 6993: loss = 6.8483 (0.510 sec/step)
I0404 21:05:52.320712 47978602034560 learning.py:507] global step 6994: loss = 5.6766 (0.514 sec/step)
I0404 21:05:52.837054 47978602034560 learning.py:507] global step 6995: loss = 5.2216 (0.513 sec/step)
I0404 21:05:53.350787 47978602034560 learning.py:507] global step 6996: loss = 5.9658 (0.512 sec/step)
I0404 21:05:53.860177 47978602034560 learning.py:507] global step 6997: loss = 6.2706 (0.508 sec/step)
I0404 21:05:54.374307 47978602034560 learning.py:507] global step 6998: loss = 5.5890 (0.513 sec/step)
I0404 21:05:54.904615 47978602034560 learning.py:507] global step 6999: loss = 6.1823 (0.529 sec/step)
I0404 21:05:55.414430 47978602034560 learning.py:507] global step 7000: loss = 5.5998 (0.508 sec/step)
I0404 21:05:55.950491 47978602034560 learning.py:507] global step 7001: loss = 5.3400 (0.534 sec/step)
I0404 21:05:56.458725 47978602034560 learning.py:507] global step 7002: loss = 5.2221 (0.507 sec/step)
I0404 21:05:56.969318 47978602034560 learning.py:507] global step 7003: loss = 5.2561 (0.508 sec/step)
I0404 21:05:57.482296 47978602034560 learning.py:507] global step 7004: loss = 5.9566 (0.511 sec/step)
I0404 21:05:57.991570 47978602034560 learning.py:507] global step 7005: loss = 5.4090 (0.506 sec/step)
I0404 21:05:58.494919 47978602034560 learning.py:507] global step 7006: loss = 6.1470 (0.502 sec/step)
I0404 21:05:58.994604 47978602034560 learning.py:507] global step 7007: loss = 6.8601 (0.498 sec/step)
I0404 21:05:59.524805 47978602034560 learning.py:507] global step 7008: loss = 5.8134 (0.529 sec/step)
I0404 21:06:00.036935 47978602034560 learning.py:507] global step 7009: loss = 5.7864 (0.511 sec/step)
I0404 21:06:00.542928 47978602034560 learning.py:507] global step 7010: loss = 6.0308 (0.504 sec/step)
I0404 21:06:01.071929 47978602034560 learning.py:507] global step 7011: loss = 6.2733 (0.527 sec/step)
I0404 21:06:01.577768 47978602034560 learning.py:507] global step 7012: loss = 6.1749 (0.503 sec/step)
I0404 21:06:02.083299 47978602034560 learning.py:507] global step 7013: loss = 5.0835 (0.504 sec/step)
I0404 21:06:02.590085 47978602034560 learning.py:507] global step 7014: loss = 7.1330 (0.504 sec/step)
I0404 21:06:03.107810 47978602034560 learning.py:507] global step 7015: loss = 5.8624 (0.515 sec/step)
I0404 21:06:03.618087 47978602034560 learning.py:507] global step 7016: loss = 5.8286 (0.509 sec/step)
I0404 21:06:04.137038 47978602034560 learning.py:507] global step 7017: loss = 5.2334 (0.516 sec/step)
I0404 21:06:04.666129 47978602034560 learning.py:507] global step 7018: loss = 6.4988 (0.528 sec/step)
I0404 21:06:05.169680 47978602034560 learning.py:507] global step 7019: loss = 6.0481 (0.502 sec/step)
I0404 21:06:05.677015 47978602034560 learning.py:507] global step 7020: loss = 5.5132 (0.506 sec/step)
I0404 21:06:06.190626 47978602034560 learning.py:507] global step 7021: loss = 5.6666 (0.512 sec/step)
I0404 21:06:06.702749 47978602034560 learning.py:507] global step 7022: loss = 5.7486 (0.509 sec/step)
I0404 21:06:07.213212 47978602034560 learning.py:507] global step 7023: loss = 4.7982 (0.509 sec/step)
I0404 21:06:07.719093 47978602034560 learning.py:507] global step 7024: loss = 6.3185 (0.504 sec/step)
I0404 21:06:08.231214 47978602034560 learning.py:507] global step 7025: loss = 5.3169 (0.511 sec/step)
I0404 21:06:08.750821 47978602034560 learning.py:507] global step 7026: loss = 5.8407 (0.517 sec/step)
I0404 21:06:09.269787 47978602034560 learning.py:507] global step 7027: loss = 4.5154 (0.517 sec/step)
I0404 21:06:09.802857 47978602034560 learning.py:507] global step 7028: loss = 6.7856 (0.531 sec/step)
I0404 21:06:10.315304 47978602034560 learning.py:507] global step 7029: loss = 6.0856 (0.511 sec/step)
I0404 21:06:10.830261 47978602034560 learning.py:507] global step 7030: loss = 7.0635 (0.513 sec/step)
I0404 21:06:11.337385 47978602034560 learning.py:507] global step 7031: loss = 6.5305 (0.506 sec/step)
I0404 21:06:11.842964 47978602034560 learning.py:507] global step 7032: loss = 6.2998 (0.504 sec/step)
I0404 21:06:12.357110 47978602034560 learning.py:507] global step 7033: loss = 5.8473 (0.513 sec/step)
I0404 21:06:12.871191 47978602034560 learning.py:507] global step 7034: loss = 4.9470 (0.512 sec/step)
I0404 21:06:13.394654 47978602034560 learning.py:507] global step 7035: loss = 5.3467 (0.521 sec/step)
I0404 21:06:13.905062 47978602034560 learning.py:507] global step 7036: loss = 6.2861 (0.509 sec/step)
I0404 21:06:14.417302 47978602034560 learning.py:507] global step 7037: loss = 5.5602 (0.510 sec/step)
I0404 21:06:14.932101 47978602034560 learning.py:507] global step 7038: loss = 6.0989 (0.513 sec/step)
I0404 21:06:15.453207 47978602034560 learning.py:507] global step 7039: loss = 6.1923 (0.520 sec/step)
I0404 21:06:15.961539 47978602034560 learning.py:507] global step 7040: loss = 6.5059 (0.505 sec/step)
I0404 21:06:16.468307 47978602034560 learning.py:507] global step 7041: loss = 6.1528 (0.505 sec/step)
I0404 21:06:16.985766 47978602034560 learning.py:507] global step 7042: loss = 5.9824 (0.515 sec/step)
I0404 21:06:17.504787 47978602034560 learning.py:507] global step 7043: loss = 5.5515 (0.516 sec/step)
I0404 21:06:18.033961 47978602034560 learning.py:507] global step 7044: loss = 5.6444 (0.528 sec/step)
I0404 21:06:18.548080 47978602034560 learning.py:507] global step 7045: loss = 5.3197 (0.511 sec/step)
I0404 21:06:19.064229 47978602034560 learning.py:507] global step 7046: loss = 6.0266 (0.513 sec/step)
I0404 21:06:19.583635 47978602034560 learning.py:507] global step 7047: loss = 5.2357 (0.518 sec/step)
I0404 21:06:20.085439 47978602034560 learning.py:507] global step 7048: loss = 5.2863 (0.500 sec/step)
I0404 21:06:20.589915 47978602034560 learning.py:507] global step 7049: loss = 5.9618 (0.503 sec/step)
I0404 21:06:21.127595 47978602034560 learning.py:507] global step 7050: loss = 6.8682 (0.536 sec/step)
I0404 21:06:21.638559 47978602034560 learning.py:507] global step 7051: loss = 5.1221 (0.508 sec/step)
I0404 21:06:22.154494 47978602034560 learning.py:507] global step 7052: loss = 5.3080 (0.513 sec/step)
I0404 21:06:22.674126 47978602034560 learning.py:507] global step 7053: loss = 6.2633 (0.518 sec/step)
I0404 21:06:23.185930 47978602034560 learning.py:507] global step 7054: loss = 6.7846 (0.509 sec/step)
I0404 21:06:23.696285 47978602034560 learning.py:507] global step 7055: loss = 5.5289 (0.508 sec/step)
I0404 21:06:24.206694 47978602034560 learning.py:507] global step 7056: loss = 4.9648 (0.509 sec/step)
I0404 21:06:24.712060 47978602034560 learning.py:507] global step 7057: loss = 6.2925 (0.504 sec/step)
I0404 21:06:25.225056 47978602034560 learning.py:507] global step 7058: loss = 5.9817 (0.512 sec/step)
I0404 21:06:25.731696 47978602034560 learning.py:507] global step 7059: loss = 5.7990 (0.505 sec/step)
I0404 21:06:26.264829 47978602034560 learning.py:507] global step 7060: loss = 5.1733 (0.531 sec/step)
I0404 21:06:26.783900 47978602034560 learning.py:507] global step 7061: loss = 8.5542 (0.517 sec/step)
I0404 21:06:27.287240 47978602034560 learning.py:507] global step 7062: loss = 5.9489 (0.502 sec/step)
I0404 21:06:27.794795 47978602034560 learning.py:507] global step 7063: loss = 5.7246 (0.505 sec/step)
I0404 21:06:28.319606 47978602034560 learning.py:507] global step 7064: loss = 5.7653 (0.522 sec/step)
I0404 21:06:28.833953 47978602034560 learning.py:507] global step 7065: loss = 5.2248 (0.511 sec/step)
I0404 21:06:29.345200 47978602034560 learning.py:507] global step 7066: loss = 5.0057 (0.510 sec/step)
I0404 21:06:29.857427 47978602034560 learning.py:507] global step 7067: loss = 7.0118 (0.511 sec/step)
I0404 21:06:30.386549 47978602034560 learning.py:507] global step 7068: loss = 4.7169 (0.528 sec/step)
I0404 21:06:30.906879 47978602034560 learning.py:507] global step 7069: loss = 5.4763 (0.519 sec/step)
I0404 21:06:31.425280 47978602034560 learning.py:507] global step 7070: loss = 4.8939 (0.517 sec/step)
I0404 21:06:31.964812 47978602034560 learning.py:507] global step 7071: loss = 5.5646 (0.538 sec/step)
I0404 21:06:32.495515 47978602034560 learning.py:507] global step 7072: loss = 6.5089 (0.529 sec/step)
I0404 21:06:33.013464 47978602034560 learning.py:507] global step 7073: loss = 7.3942 (0.515 sec/step)
I0404 21:06:33.522037 47978602034560 learning.py:507] global step 7074: loss = 6.9580 (0.507 sec/step)
I0404 21:06:34.025572 47978602034560 learning.py:507] global step 7075: loss = 7.5682 (0.501 sec/step)
I0404 21:06:34.535786 47978602034560 learning.py:507] global step 7076: loss = 6.1394 (0.509 sec/step)
I0404 21:06:35.044674 47978602034560 learning.py:507] global step 7077: loss = 5.5395 (0.507 sec/step)
I0404 21:06:35.558238 47978602034560 learning.py:507] global step 7078: loss = 5.9399 (0.511 sec/step)
I0404 21:06:36.067516 47978602034560 learning.py:507] global step 7079: loss = 5.6570 (0.506 sec/step)
I0404 21:06:36.571521 47978602034560 learning.py:507] global step 7080: loss = 5.3616 (0.501 sec/step)
I0404 21:06:37.105768 47978602034560 learning.py:507] global step 7081: loss = 5.5052 (0.533 sec/step)
I0404 21:06:37.615926 47978602034560 learning.py:507] global step 7082: loss = 6.9453 (0.509 sec/step)
I0404 21:06:38.127408 47978602034560 learning.py:507] global step 7083: loss = 5.9642 (0.509 sec/step)
I0404 21:06:38.657871 47978602034560 learning.py:507] global step 7084: loss = 6.8102 (0.529 sec/step)
I0404 21:06:39.178354 47978602034560 learning.py:507] global step 7085: loss = 5.1901 (0.519 sec/step)
I0404 21:06:39.686363 47978602034560 learning.py:507] global step 7086: loss = 5.1109 (0.506 sec/step)
I0404 21:06:40.200420 47978602034560 learning.py:507] global step 7087: loss = 6.2455 (0.513 sec/step)
I0404 21:06:40.732185 47978602034560 learning.py:507] global step 7088: loss = 7.4819 (0.529 sec/step)
I0404 21:06:41.247319 47978602034560 learning.py:507] global step 7089: loss = 6.4631 (0.514 sec/step)
I0404 21:06:41.766952 47978602034560 learning.py:507] global step 7090: loss = 5.8741 (0.518 sec/step)
I0404 21:06:42.273263 47978602034560 learning.py:507] global step 7091: loss = 5.4262 (0.505 sec/step)
I0404 21:06:42.783594 47978602034560 learning.py:507] global step 7092: loss = 6.0177 (0.509 sec/step)
I0404 21:06:43.299847 47978602034560 learning.py:507] global step 7093: loss = 5.8981 (0.515 sec/step)
I0404 21:06:43.810237 47978602034560 learning.py:507] global step 7094: loss = 5.5703 (0.509 sec/step)
I0404 21:06:44.315901 47978602034560 learning.py:507] global step 7095: loss = 5.7598 (0.504 sec/step)
I0404 21:06:44.835803 47978602034560 learning.py:507] global step 7096: loss = 6.0057 (0.518 sec/step)
I0404 21:06:45.354313 47978602034560 learning.py:507] global step 7097: loss = 5.9015 (0.517 sec/step)
I0404 21:06:45.862020 47978602034560 learning.py:507] global step 7098: loss = 5.2096 (0.505 sec/step)
I0404 21:06:46.387608 47978602034560 learning.py:507] global step 7099: loss = 5.2837 (0.524 sec/step)
I0404 21:06:46.898439 47978602034560 learning.py:507] global step 7100: loss = 7.1643 (0.509 sec/step)
I0404 21:06:47.404496 47978602034560 learning.py:507] global step 7101: loss = 7.0388 (0.504 sec/step)
I0404 21:06:47.906754 47978602034560 learning.py:507] global step 7102: loss = 4.9760 (0.499 sec/step)
I0404 21:06:48.423755 47978602034560 learning.py:507] global step 7103: loss = 5.5806 (0.515 sec/step)
I0404 21:06:48.933785 47978602034560 learning.py:507] global step 7104: loss = 5.7030 (0.508 sec/step)
I0404 21:06:49.439755 47978602034560 learning.py:507] global step 7105: loss = 6.0032 (0.503 sec/step)
I0404 21:06:49.946938 47978602034560 learning.py:507] global step 7106: loss = 6.3514 (0.504 sec/step)
I0404 21:06:50.459019 47978602034560 learning.py:507] global step 7107: loss = 6.2951 (0.509 sec/step)
I0404 21:06:50.975050 47978602034560 learning.py:507] global step 7108: loss = 5.8753 (0.515 sec/step)
I0404 21:06:51.504459 47978602034560 learning.py:507] global step 7109: loss = 5.9541 (0.528 sec/step)
I0404 21:06:52.018958 47978602034560 learning.py:507] global step 7110: loss = 6.1356 (0.513 sec/step)
I0404 21:06:52.528357 47978602034560 learning.py:507] global step 7111: loss = 6.1242 (0.507 sec/step)
I0404 21:06:53.049195 47978602034560 learning.py:507] global step 7112: loss = 5.4154 (0.518 sec/step)
I0404 21:06:53.575899 47978602034560 learning.py:507] global step 7113: loss = 5.4709 (0.524 sec/step)
I0404 21:06:54.115624 47978602034560 learning.py:507] global step 7114: loss = 6.7072 (0.538 sec/step)
I0404 21:06:54.622290 47978602034560 learning.py:507] global step 7115: loss = 6.2463 (0.505 sec/step)
I0404 21:06:55.129157 47978602034560 learning.py:507] global step 7116: loss = 7.6671 (0.504 sec/step)
I0404 21:06:55.652424 47978602034560 learning.py:507] global step 7117: loss = 5.2167 (0.522 sec/step)
I0404 21:06:56.164173 47978602034560 learning.py:507] global step 7118: loss = 4.5907 (0.509 sec/step)
I0404 21:06:56.699425 47978602034560 learning.py:507] global step 7119: loss = 4.8551 (0.534 sec/step)
I0404 21:06:57.213848 47978602034560 learning.py:507] global step 7120: loss = 6.5008 (0.513 sec/step)
I0404 21:06:57.717149 47978602034560 learning.py:507] global step 7121: loss = 6.3811 (0.500 sec/step)
I0404 21:06:58.224055 47978602034560 learning.py:507] global step 7122: loss = 6.3196 (0.505 sec/step)
I0404 21:06:58.740513 47978602034560 learning.py:507] global step 7123: loss = 6.0962 (0.515 sec/step)
I0404 21:06:59.272711 47978602034560 learning.py:507] global step 7124: loss = 5.5814 (0.531 sec/step)
I0404 21:06:59.787881 47978602034560 learning.py:507] global step 7125: loss = 5.6311 (0.514 sec/step)
I0404 21:07:00.307456 47978602034560 learning.py:507] global step 7126: loss = 6.2667 (0.518 sec/step)
I0404 21:07:00.841817 47978602034560 learning.py:507] global step 7127: loss = 5.8955 (0.533 sec/step)
I0404 21:07:01.348983 47978602034560 learning.py:507] global step 7128: loss = 6.1723 (0.506 sec/step)
I0404 21:07:01.873111 47978602034560 learning.py:507] global step 7129: loss = 5.1087 (0.523 sec/step)
I0404 21:07:02.384115 47978602034560 learning.py:507] global step 7130: loss = 6.2756 (0.509 sec/step)
I0404 21:07:02.921108 47978602034560 learning.py:507] global step 7131: loss = 5.1509 (0.535 sec/step)
I0404 21:07:03.433626 47978602034560 learning.py:507] global step 7132: loss = 6.0642 (0.511 sec/step)
I0404 21:07:03.937978 47978602034560 learning.py:507] global step 7133: loss = 5.6397 (0.502 sec/step)
I0404 21:07:04.443124 47978602034560 learning.py:507] global step 7134: loss = 5.8204 (0.504 sec/step)
I0404 21:07:04.968069 47978602034560 learning.py:507] global step 7135: loss = 5.1196 (0.523 sec/step)
I0404 21:07:05.505839 47978602034560 learning.py:507] global step 7136: loss = 5.6152 (0.536 sec/step)
I0404 21:07:06.043413 47978602034560 learning.py:507] global step 7137: loss = 6.5398 (0.536 sec/step)
I0404 21:07:06.556531 47978602034560 learning.py:507] global step 7138: loss = 5.9538 (0.512 sec/step)
I0404 21:07:07.071143 47978602034560 learning.py:507] global step 7139: loss = 6.2456 (0.512 sec/step)
I0404 21:07:07.599107 47978602034560 learning.py:507] global step 7140: loss = 6.1972 (0.526 sec/step)
I0404 21:07:08.108051 47978602034560 learning.py:507] global step 7141: loss = 5.6839 (0.507 sec/step)
I0404 21:07:08.622894 47978602034560 learning.py:507] global step 7142: loss = 6.2328 (0.513 sec/step)
I0404 21:07:09.150582 47978602034560 learning.py:507] global step 7143: loss = 5.3981 (0.526 sec/step)
I0404 21:07:09.658587 47978602034560 learning.py:507] global step 7144: loss = 5.9958 (0.506 sec/step)
I0404 21:07:10.173203 47978602034560 learning.py:507] global step 7145: loss = 5.1378 (0.513 sec/step)
I0404 21:07:10.691380 47978602034560 learning.py:507] global step 7146: loss = 6.8594 (0.515 sec/step)
I0404 21:07:11.218057 47978602034560 learning.py:507] global step 7147: loss = 5.8601 (0.524 sec/step)
I0404 21:07:11.754040 47978602034560 learning.py:507] global step 7148: loss = 5.7200 (0.534 sec/step)
I0404 21:07:12.273300 47978602034560 learning.py:507] global step 7149: loss = 5.8140 (0.518 sec/step)
I0404 21:07:12.775382 47978602034560 learning.py:507] global step 7150: loss = 6.1408 (0.500 sec/step)
I0404 21:07:13.298007 47978602034560 learning.py:507] global step 7151: loss = 5.9104 (0.521 sec/step)
I0404 21:07:13.812414 47978602034560 learning.py:507] global step 7152: loss = 5.2146 (0.513 sec/step)
I0404 21:07:14.346881 47978602034560 learning.py:507] global step 7153: loss = 5.8263 (0.533 sec/step)
I0404 21:07:14.848220 47978602034560 learning.py:507] global step 7154: loss = 5.8125 (0.499 sec/step)
I0404 21:07:15.361153 47978602034560 learning.py:507] global step 7155: loss = 6.0571 (0.511 sec/step)
I0404 21:07:15.880015 47978602034560 learning.py:507] global step 7156: loss = 5.8392 (0.517 sec/step)
I0404 21:07:16.408020 47978602034560 learning.py:507] global step 7157: loss = 6.0970 (0.526 sec/step)
I0404 21:07:16.932245 47978602034560 learning.py:507] global step 7158: loss = 5.9897 (0.518 sec/step)
I0404 21:07:17.295328 47983661975296 supervisor.py:1050] Recording summary at step 7158.
I0404 21:07:17.609211 47978602034560 learning.py:507] global step 7159: loss = 5.5293 (0.674 sec/step)
I0404 21:07:18.118351 47978602034560 learning.py:507] global step 7160: loss = 5.0866 (0.506 sec/step)
I0404 21:07:18.627566 47978602034560 learning.py:507] global step 7161: loss = 4.7626 (0.506 sec/step)
I0404 21:07:19.135138 47978602034560 learning.py:507] global step 7162: loss = 6.8775 (0.506 sec/step)
I0404 21:07:19.644834 47978602034560 learning.py:507] global step 7163: loss = 5.2590 (0.507 sec/step)
I0404 21:07:20.174126 47978602034560 learning.py:507] global step 7164: loss = 6.1425 (0.528 sec/step)
I0404 21:07:20.680986 47978602034560 learning.py:507] global step 7165: loss = 5.9573 (0.504 sec/step)
I0404 21:07:21.197089 47978602034560 learning.py:507] global step 7166: loss = 6.2238 (0.515 sec/step)
I0404 21:07:21.705595 47978602034560 learning.py:507] global step 7167: loss = 6.0188 (0.507 sec/step)
I0404 21:07:22.224808 47978602034560 learning.py:507] global step 7168: loss = 6.9056 (0.518 sec/step)
I0404 21:07:22.734184 47978602034560 learning.py:507] global step 7169: loss = 5.0818 (0.508 sec/step)
I0404 21:07:23.238534 47978602034560 learning.py:507] global step 7170: loss = 5.8504 (0.501 sec/step)
I0404 21:07:23.743257 47978602034560 learning.py:507] global step 7171: loss = 5.9931 (0.502 sec/step)
I0404 21:07:24.270593 47978602034560 learning.py:507] global step 7172: loss = 5.5580 (0.526 sec/step)
I0404 21:07:24.814197 47978602034560 learning.py:507] global step 7173: loss = 4.8426 (0.541 sec/step)
I0404 21:07:25.323065 47978602034560 learning.py:507] global step 7174: loss = 6.9427 (0.506 sec/step)
I0404 21:07:25.836638 47978602034560 learning.py:507] global step 7175: loss = 6.4601 (0.511 sec/step)
I0404 21:07:26.352839 47978602034560 learning.py:507] global step 7176: loss = 6.0528 (0.513 sec/step)
I0404 21:07:26.857716 47978602034560 learning.py:507] global step 7177: loss = 6.7461 (0.502 sec/step)
I0404 21:07:27.366438 47978602034560 learning.py:507] global step 7178: loss = 5.1561 (0.506 sec/step)
I0404 21:07:27.907725 47978602034560 learning.py:507] global step 7179: loss = 5.9131 (0.538 sec/step)
I0404 21:07:28.424117 47978602034560 learning.py:507] global step 7180: loss = 5.6748 (0.515 sec/step)
I0404 21:07:28.950049 47978602034560 learning.py:507] global step 7181: loss = 6.1647 (0.523 sec/step)
I0404 21:07:29.459179 47978602034560 learning.py:507] global step 7182: loss = 6.4974 (0.508 sec/step)
I0404 21:07:29.990432 47978602034560 learning.py:507] global step 7183: loss = 6.1201 (0.530 sec/step)
I0404 21:07:30.508077 47978602034560 learning.py:507] global step 7184: loss = 6.0714 (0.516 sec/step)
I0404 21:07:31.011545 47978602034560 learning.py:507] global step 7185: loss = 6.1945 (0.501 sec/step)
I0404 21:07:31.516909 47978602034560 learning.py:507] global step 7186: loss = 5.4682 (0.504 sec/step)
I0404 21:07:32.037545 47978602034560 learning.py:507] global step 7187: loss = 5.6018 (0.519 sec/step)
I0404 21:07:32.543488 47978602034560 learning.py:507] global step 7188: loss = 5.8426 (0.504 sec/step)
I0404 21:07:33.064393 47978602034560 learning.py:507] global step 7189: loss = 5.4072 (0.519 sec/step)
I0404 21:07:33.578883 47978602034560 learning.py:507] global step 7190: loss = 6.0079 (0.513 sec/step)
I0404 21:07:34.091834 47978602034560 learning.py:507] global step 7191: loss = 4.8879 (0.511 sec/step)
I0404 21:07:34.608293 47978602034560 learning.py:507] global step 7192: loss = 6.3326 (0.515 sec/step)
I0404 21:07:35.110942 47978602034560 learning.py:507] global step 7193: loss = 6.1505 (0.500 sec/step)
I0404 21:07:35.642836 47978602034560 learning.py:507] global step 7194: loss = 5.6457 (0.530 sec/step)
I0404 21:07:36.143744 47978602034560 learning.py:507] global step 7195: loss = 5.8041 (0.499 sec/step)
I0404 21:07:36.642610 47978602034560 learning.py:507] global step 7196: loss = 5.5256 (0.497 sec/step)
I0404 21:07:37.147929 47978602034560 learning.py:507] global step 7197: loss = 6.5958 (0.504 sec/step)
I0404 21:07:37.648344 47978602034560 learning.py:507] global step 7198: loss = 5.2208 (0.499 sec/step)
I0404 21:07:38.183240 47978602034560 learning.py:507] global step 7199: loss = 5.2943 (0.533 sec/step)
I0404 21:07:38.686655 47978602034560 learning.py:507] global step 7200: loss = 5.2744 (0.501 sec/step)
I0404 21:07:39.211158 47978602034560 learning.py:507] global step 7201: loss = 6.0391 (0.523 sec/step)
I0404 21:07:39.714741 47978602034560 learning.py:507] global step 7202: loss = 5.8467 (0.502 sec/step)
I0404 21:07:40.239476 47978602034560 learning.py:507] global step 7203: loss = 5.1014 (0.523 sec/step)
I0404 21:07:40.772201 47978602034560 learning.py:507] global step 7204: loss = 6.0011 (0.530 sec/step)
I0404 21:07:41.294987 47978602034560 learning.py:507] global step 7205: loss = 5.6669 (0.521 sec/step)
I0404 21:07:41.805104 47978602034560 learning.py:507] global step 7206: loss = 5.2380 (0.507 sec/step)
I0404 21:07:42.314527 47978602034560 learning.py:507] global step 7207: loss = 5.2459 (0.508 sec/step)
I0404 21:07:42.843335 47978602034560 learning.py:507] global step 7208: loss = 5.2966 (0.527 sec/step)
I0404 21:07:43.346014 47978602034560 learning.py:507] global step 7209: loss = 5.6342 (0.501 sec/step)
I0404 21:07:43.853787 47978602034560 learning.py:507] global step 7210: loss = 6.6365 (0.506 sec/step)
I0404 21:07:44.386264 47978602034560 learning.py:507] global step 7211: loss = 6.0222 (0.531 sec/step)
I0404 21:07:44.897392 47978602034560 learning.py:507] global step 7212: loss = 6.4006 (0.510 sec/step)
I0404 21:07:45.400616 47978602034560 learning.py:507] global step 7213: loss = 4.9885 (0.502 sec/step)
I0404 21:07:45.905839 47978602034560 learning.py:507] global step 7214: loss = 5.3501 (0.504 sec/step)
I0404 21:07:46.420349 47978602034560 learning.py:507] global step 7215: loss = 5.7385 (0.512 sec/step)
I0404 21:07:46.932328 47978602034560 learning.py:507] global step 7216: loss = 5.5032 (0.510 sec/step)
I0404 21:07:47.430815 47978602034560 learning.py:507] global step 7217: loss = 6.1314 (0.497 sec/step)
I0404 21:07:47.973384 47978602034560 learning.py:507] global step 7218: loss = 7.0527 (0.541 sec/step)
I0404 21:07:48.494195 47978602034560 learning.py:507] global step 7219: loss = 5.7486 (0.517 sec/step)
I0404 21:07:49.010222 47978602034560 learning.py:507] global step 7220: loss = 6.0874 (0.515 sec/step)
I0404 21:07:49.511446 47978602034560 learning.py:507] global step 7221: loss = 6.3609 (0.500 sec/step)
I0404 21:07:50.028881 47978602034560 learning.py:507] global step 7222: loss = 5.8675 (0.515 sec/step)
I0404 21:07:50.534666 47978602034560 learning.py:507] global step 7223: loss = 6.9850 (0.503 sec/step)
I0404 21:07:51.046997 47978602034560 learning.py:507] global step 7224: loss = 5.2166 (0.511 sec/step)
I0404 21:07:51.553869 47978602034560 learning.py:507] global step 7225: loss = 5.7361 (0.505 sec/step)
I0404 21:07:52.092958 47978602034560 learning.py:507] global step 7226: loss = 6.1629 (0.537 sec/step)
I0404 21:07:52.600821 47978602034560 learning.py:507] global step 7227: loss = 5.8823 (0.505 sec/step)
I0404 21:07:53.121015 47978602034560 learning.py:507] global step 7228: loss = 5.9028 (0.519 sec/step)
I0404 21:07:53.658712 47978602034560 learning.py:507] global step 7229: loss = 5.4077 (0.536 sec/step)
I0404 21:07:54.186893 47978602034560 learning.py:507] global step 7230: loss = 6.6911 (0.525 sec/step)
I0404 21:07:54.698348 47978602034560 learning.py:507] global step 7231: loss = 5.6438 (0.510 sec/step)
I0404 21:07:55.211119 47978602034560 learning.py:507] global step 7232: loss = 4.7138 (0.511 sec/step)
I0404 21:07:55.734263 47978602034560 learning.py:507] global step 7233: loss = 5.9664 (0.522 sec/step)
I0404 21:07:56.238476 47978602034560 learning.py:507] global step 7234: loss = 4.8374 (0.503 sec/step)
I0404 21:07:56.738961 47978602034560 learning.py:507] global step 7235: loss = 5.3616 (0.498 sec/step)
I0404 21:07:57.254106 47978602034560 learning.py:507] global step 7236: loss = 6.6823 (0.512 sec/step)
I0404 21:07:57.760957 47978602034560 learning.py:507] global step 7237: loss = 5.2181 (0.505 sec/step)
I0404 21:07:58.270956 47978602034560 learning.py:507] global step 7238: loss = 6.3122 (0.508 sec/step)
I0404 21:07:58.773996 47978602034560 learning.py:507] global step 7239: loss = 6.1081 (0.501 sec/step)
I0404 21:07:59.302708 47978602034560 learning.py:507] global step 7240: loss = 5.4550 (0.527 sec/step)
I0404 21:07:59.836405 47978602034560 learning.py:507] global step 7241: loss = 5.4558 (0.532 sec/step)
I0404 21:08:00.372828 47978602034560 learning.py:507] global step 7242: loss = 5.4299 (0.534 sec/step)
I0404 21:08:00.873462 47978602034560 learning.py:507] global step 7243: loss = 6.7253 (0.499 sec/step)
I0404 21:08:01.410338 47978602034560 learning.py:507] global step 7244: loss = 5.9797 (0.534 sec/step)
I0404 21:08:01.916185 47978602034560 learning.py:507] global step 7245: loss = 5.0533 (0.504 sec/step)
I0404 21:08:02.431662 47978602034560 learning.py:507] global step 7246: loss = 6.0513 (0.514 sec/step)
I0404 21:08:02.939951 47978602034560 learning.py:507] global step 7247: loss = 5.0654 (0.505 sec/step)
I0404 21:08:03.452973 47978602034560 learning.py:507] global step 7248: loss = 5.9813 (0.511 sec/step)
I0404 21:08:03.960124 47978602034560 learning.py:507] global step 7249: loss = 5.8941 (0.504 sec/step)
I0404 21:08:04.463256 47978602034560 learning.py:507] global step 7250: loss = 5.7100 (0.500 sec/step)
I0404 21:08:04.991509 47978602034560 learning.py:507] global step 7251: loss = 4.5129 (0.525 sec/step)
I0404 21:08:05.526387 47978602034560 learning.py:507] global step 7252: loss = 5.2968 (0.532 sec/step)
I0404 21:08:06.038034 47978602034560 learning.py:507] global step 7253: loss = 5.7697 (0.510 sec/step)
I0404 21:08:06.548437 47978602034560 learning.py:507] global step 7254: loss = 6.2009 (0.509 sec/step)
I0404 21:08:07.058557 47978602034560 learning.py:507] global step 7255: loss = 6.4993 (0.509 sec/step)
I0404 21:08:07.566958 47978602034560 learning.py:507] global step 7256: loss = 6.7939 (0.507 sec/step)
I0404 21:08:08.086176 47978602034560 learning.py:507] global step 7257: loss = 6.6079 (0.518 sec/step)
I0404 21:08:08.616824 47978602034560 learning.py:507] global step 7258: loss = 5.6529 (0.528 sec/step)
I0404 21:08:09.120052 47978602034560 learning.py:507] global step 7259: loss = 6.1383 (0.502 sec/step)
I0404 21:08:09.630014 47978602034560 learning.py:507] global step 7260: loss = 5.3043 (0.508 sec/step)
I0404 21:08:10.159555 47978602034560 learning.py:507] global step 7261: loss = 4.9146 (0.528 sec/step)
I0404 21:08:10.669560 47978602034560 learning.py:507] global step 7262: loss = 4.4481 (0.508 sec/step)
I0404 21:08:11.176662 47978602034560 learning.py:507] global step 7263: loss = 5.9396 (0.504 sec/step)
I0404 21:08:11.678167 47978602034560 learning.py:507] global step 7264: loss = 5.2144 (0.499 sec/step)
I0404 21:08:12.184749 47978602034560 learning.py:507] global step 7265: loss = 6.2317 (0.505 sec/step)
I0404 21:08:12.697196 47978602034560 learning.py:507] global step 7266: loss = 5.1485 (0.511 sec/step)
I0404 21:08:13.216933 47978602034560 learning.py:507] global step 7267: loss = 6.4729 (0.518 sec/step)
I0404 21:08:13.725336 47978602034560 learning.py:507] global step 7268: loss = 6.1316 (0.505 sec/step)
I0404 21:08:14.237809 47978602034560 learning.py:507] global step 7269: loss = 6.8865 (0.511 sec/step)
I0404 21:08:14.784674 47978602034560 learning.py:507] global step 7270: loss = 6.5764 (0.544 sec/step)
I0404 21:08:15.314160 47978602034560 learning.py:507] global step 7271: loss = 5.6783 (0.528 sec/step)
I0404 21:08:15.828222 47978602034560 learning.py:507] global step 7272: loss = 5.9734 (0.512 sec/step)
I0404 21:08:16.341124 47978602034560 learning.py:507] global step 7273: loss = 5.7782 (0.510 sec/step)
I0404 21:08:16.871636 47978602034560 learning.py:507] global step 7274: loss = 5.8240 (0.528 sec/step)
I0404 21:08:17.398077 47978602034560 learning.py:507] global step 7275: loss = 6.8928 (0.524 sec/step)
I0404 21:08:17.899963 47978602034560 learning.py:507] global step 7276: loss = 6.6525 (0.500 sec/step)
I0404 21:08:18.419311 47978602034560 learning.py:507] global step 7277: loss = 6.0593 (0.518 sec/step)
I0404 21:08:18.941600 47978602034560 learning.py:507] global step 7278: loss = 6.3244 (0.521 sec/step)
I0404 21:08:19.457577 47978602034560 learning.py:507] global step 7279: loss = 6.5175 (0.513 sec/step)
I0404 21:08:19.965421 47978602034560 learning.py:507] global step 7280: loss = 6.4848 (0.506 sec/step)
I0404 21:08:20.507757 47978602034560 learning.py:507] global step 7281: loss = 7.1940 (0.541 sec/step)
I0404 21:08:21.038656 47978602034560 learning.py:507] global step 7282: loss = 5.1815 (0.528 sec/step)
I0404 21:08:21.567259 47978602034560 learning.py:507] global step 7283: loss = 4.7746 (0.526 sec/step)
I0404 21:08:22.074917 47978602034560 learning.py:507] global step 7284: loss = 5.3054 (0.506 sec/step)
I0404 21:08:22.584811 47978602034560 learning.py:507] global step 7285: loss = 5.3046 (0.508 sec/step)
I0404 21:08:23.092834 47978602034560 learning.py:507] global step 7286: loss = 4.9692 (0.506 sec/step)
I0404 21:08:23.599141 47978602034560 learning.py:507] global step 7287: loss = 5.9179 (0.505 sec/step)
I0404 21:08:24.105776 47978602034560 learning.py:507] global step 7288: loss = 5.8421 (0.504 sec/step)
I0404 21:08:24.616178 47978602034560 learning.py:507] global step 7289: loss = 6.7681 (0.509 sec/step)
I0404 21:08:25.136636 47978602034560 learning.py:507] global step 7290: loss = 5.3282 (0.518 sec/step)
I0404 21:08:25.640703 47978602034560 learning.py:507] global step 7291: loss = 5.9085 (0.501 sec/step)
I0404 21:08:26.146878 47978602034560 learning.py:507] global step 7292: loss = 5.6069 (0.505 sec/step)
I0404 21:08:26.649692 47978602034560 learning.py:507] global step 7293: loss = 5.9906 (0.500 sec/step)
I0404 21:08:27.162125 47978602034560 learning.py:507] global step 7294: loss = 5.6262 (0.510 sec/step)
I0404 21:08:27.674094 47978602034560 learning.py:507] global step 7295: loss = 6.2147 (0.510 sec/step)
I0404 21:08:28.181020 47978602034560 learning.py:507] global step 7296: loss = 6.4560 (0.505 sec/step)
I0404 21:08:28.701133 47978602034560 learning.py:507] global step 7297: loss = 7.2882 (0.519 sec/step)
I0404 21:08:29.217618 47978602034560 learning.py:507] global step 7298: loss = 6.9112 (0.515 sec/step)
I0404 21:08:29.755683 47978602034560 learning.py:507] global step 7299: loss = 4.5610 (0.536 sec/step)
I0404 21:08:30.260636 47978602034560 learning.py:507] global step 7300: loss = 5.6237 (0.503 sec/step)
I0404 21:08:30.775439 47978602034560 learning.py:507] global step 7301: loss = 5.6882 (0.513 sec/step)
I0404 21:08:31.288781 47978602034560 learning.py:507] global step 7302: loss = 4.5402 (0.512 sec/step)
I0404 21:08:31.803638 47978602034560 learning.py:507] global step 7303: loss = 6.8793 (0.512 sec/step)
I0404 21:08:32.313722 47978602034560 learning.py:507] global step 7304: loss = 5.3534 (0.509 sec/step)
I0404 21:08:32.844519 47978602034560 learning.py:507] global step 7305: loss = 6.8290 (0.529 sec/step)
I0404 21:08:33.347872 47978602034560 learning.py:507] global step 7306: loss = 6.1991 (0.502 sec/step)
I0404 21:08:33.868875 47978602034560 learning.py:507] global step 7307: loss = 5.8890 (0.519 sec/step)
I0404 21:08:34.375936 47978602034560 learning.py:507] global step 7308: loss = 5.3092 (0.504 sec/step)
I0404 21:08:34.894770 47978602034560 learning.py:507] global step 7309: loss = 6.9439 (0.517 sec/step)
I0404 21:08:35.414762 47978602034560 learning.py:507] global step 7310: loss = 5.8616 (0.517 sec/step)
I0404 21:08:35.946274 47978602034560 learning.py:507] global step 7311: loss = 5.3103 (0.530 sec/step)
I0404 21:08:36.460903 47978602034560 learning.py:507] global step 7312: loss = 6.8350 (0.513 sec/step)
I0404 21:08:36.971395 47978602034560 learning.py:507] global step 7313: loss = 6.1478 (0.509 sec/step)
I0404 21:08:37.489704 47978602034560 learning.py:507] global step 7314: loss = 5.4787 (0.517 sec/step)
I0404 21:08:37.999489 47978602034560 learning.py:507] global step 7315: loss = 6.4683 (0.508 sec/step)
I0404 21:08:38.507812 47978602034560 learning.py:507] global step 7316: loss = 5.9394 (0.505 sec/step)
I0404 21:08:39.017744 47978602034560 learning.py:507] global step 7317: loss = 6.2716 (0.508 sec/step)
I0404 21:08:39.528625 47978602034560 learning.py:507] global step 7318: loss = 4.9572 (0.509 sec/step)
I0404 21:08:40.037611 47978602034560 learning.py:507] global step 7319: loss = 6.0077 (0.506 sec/step)
I0404 21:08:40.547528 47978602034560 learning.py:507] global step 7320: loss = 5.5865 (0.508 sec/step)
I0404 21:08:41.053272 47978602034560 learning.py:507] global step 7321: loss = 5.8076 (0.503 sec/step)
I0404 21:08:41.576256 47978602034560 learning.py:507] global step 7322: loss = 7.1950 (0.521 sec/step)
I0404 21:08:42.096099 47978602034560 learning.py:507] global step 7323: loss = 6.2298 (0.518 sec/step)
I0404 21:08:42.609936 47978602034560 learning.py:507] global step 7324: loss = 5.8601 (0.512 sec/step)
I0404 21:08:43.112302 47978602034560 learning.py:507] global step 7325: loss = 6.1486 (0.500 sec/step)
I0404 21:08:43.618944 47978602034560 learning.py:507] global step 7326: loss = 6.1582 (0.504 sec/step)
I0404 21:08:44.124204 47978602034560 learning.py:507] global step 7327: loss = 5.0805 (0.502 sec/step)
I0404 21:08:44.637440 47978602034560 learning.py:507] global step 7328: loss = 5.9629 (0.512 sec/step)
I0404 21:08:45.141039 47978602034560 learning.py:507] global step 7329: loss = 6.1634 (0.502 sec/step)
I0404 21:08:45.648756 47978602034560 learning.py:507] global step 7330: loss = 5.3351 (0.505 sec/step)
I0404 21:08:46.178043 47978602034560 learning.py:507] global step 7331: loss = 6.0897 (0.528 sec/step)
I0404 21:08:46.709655 47978602034560 learning.py:507] global step 7332: loss = 4.5973 (0.530 sec/step)
I0404 21:08:47.216298 47978602034560 learning.py:507] global step 7333: loss = 6.5533 (0.504 sec/step)
I0404 21:08:47.728204 47978602034560 learning.py:507] global step 7334: loss = 5.6865 (0.510 sec/step)
I0404 21:08:48.264152 47978602034560 learning.py:507] global step 7335: loss = 5.3959 (0.534 sec/step)
I0404 21:08:48.792069 47978602034560 learning.py:507] global step 7336: loss = 5.4192 (0.525 sec/step)
I0404 21:08:49.309053 47978602034560 learning.py:507] global step 7337: loss = 5.0220 (0.515 sec/step)
I0404 21:08:49.838238 47978602034560 learning.py:507] global step 7338: loss = 4.8970 (0.528 sec/step)
I0404 21:08:50.350931 47978602034560 learning.py:507] global step 7339: loss = 6.4903 (0.510 sec/step)
I0404 21:08:50.866020 47978602034560 learning.py:507] global step 7340: loss = 6.1630 (0.514 sec/step)
I0404 21:08:51.368064 47978602034560 learning.py:507] global step 7341: loss = 4.0101 (0.501 sec/step)
I0404 21:08:51.898580 47978602034560 learning.py:507] global step 7342: loss = 5.8178 (0.528 sec/step)
I0404 21:08:52.404756 47978602034560 learning.py:507] global step 7343: loss = 6.6374 (0.505 sec/step)
I0404 21:08:52.920229 47978602034560 learning.py:507] global step 7344: loss = 6.1370 (0.514 sec/step)
I0404 21:08:53.448269 47978602034560 learning.py:507] global step 7345: loss = 7.0680 (0.526 sec/step)
I0404 21:08:53.957754 47978602034560 learning.py:507] global step 7346: loss = 5.0097 (0.508 sec/step)
I0404 21:08:54.477308 47978602034560 learning.py:507] global step 7347: loss = 6.1641 (0.518 sec/step)
I0404 21:08:54.980839 47978602034560 learning.py:507] global step 7348: loss = 5.5931 (0.501 sec/step)
I0404 21:08:55.488096 47978602034560 learning.py:507] global step 7349: loss = 5.9935 (0.506 sec/step)
I0404 21:08:55.996077 47978602034560 learning.py:507] global step 7350: loss = 6.1031 (0.506 sec/step)
I0404 21:08:56.527869 47978602034560 learning.py:507] global step 7351: loss = 6.7779 (0.529 sec/step)
I0404 21:08:57.041510 47978602034560 learning.py:507] global step 7352: loss = 5.9808 (0.512 sec/step)
I0404 21:08:57.548064 47978602034560 learning.py:507] global step 7353: loss = 5.8114 (0.505 sec/step)
I0404 21:08:58.066112 47978602034560 learning.py:507] global step 7354: loss = 7.2250 (0.516 sec/step)
I0404 21:08:58.569310 47978602034560 learning.py:507] global step 7355: loss = 4.9315 (0.500 sec/step)
I0404 21:08:59.071589 47978602034560 learning.py:507] global step 7356: loss = 5.1338 (0.501 sec/step)
I0404 21:08:59.583518 47978602034560 learning.py:507] global step 7357: loss = 5.6712 (0.510 sec/step)
I0404 21:09:00.097457 47978602034560 learning.py:507] global step 7358: loss = 5.4365 (0.511 sec/step)
I0404 21:09:00.602476 47978602034560 learning.py:507] global step 7359: loss = 6.5207 (0.502 sec/step)
I0404 21:09:01.103391 47978602034560 learning.py:507] global step 7360: loss = 5.4308 (0.499 sec/step)
I0404 21:09:01.642303 47978602034560 learning.py:507] global step 7361: loss = 5.7438 (0.537 sec/step)
I0404 21:09:02.151988 47978602034560 learning.py:507] global step 7362: loss = 5.5301 (0.508 sec/step)
I0404 21:09:02.682653 47978602034560 learning.py:507] global step 7363: loss = 6.0912 (0.528 sec/step)
I0404 21:09:03.207138 47978602034560 learning.py:507] global step 7364: loss = 8.0491 (0.522 sec/step)
I0404 21:09:03.717051 47978602034560 learning.py:507] global step 7365: loss = 7.1516 (0.507 sec/step)
I0404 21:09:04.218239 47978602034560 learning.py:507] global step 7366: loss = 5.6381 (0.500 sec/step)
I0404 21:09:04.739048 47978602034560 learning.py:507] global step 7367: loss = 5.7271 (0.519 sec/step)
I0404 21:09:05.244078 47978602034560 learning.py:507] global step 7368: loss = 5.7080 (0.503 sec/step)
I0404 21:09:05.749752 47978602034560 learning.py:507] global step 7369: loss = 6.0627 (0.504 sec/step)
I0404 21:09:06.273368 47978602034560 learning.py:507] global step 7370: loss = 5.5125 (0.522 sec/step)
I0404 21:09:06.784520 47978602034560 learning.py:507] global step 7371: loss = 4.6806 (0.508 sec/step)
I0404 21:09:07.297872 47978602034560 learning.py:507] global step 7372: loss = 5.1867 (0.512 sec/step)
I0404 21:09:07.806539 47978602034560 learning.py:507] global step 7373: loss = 5.5865 (0.507 sec/step)
I0404 21:09:08.327973 47978602034560 learning.py:507] global step 7374: loss = 5.1850 (0.519 sec/step)
I0404 21:09:08.832128 47978602034560 learning.py:507] global step 7375: loss = 5.7307 (0.502 sec/step)
I0404 21:09:09.343868 47978602034560 learning.py:507] global step 7376: loss = 5.9428 (0.509 sec/step)
I0404 21:09:09.855148 47978602034560 learning.py:507] global step 7377: loss = 6.6575 (0.510 sec/step)
I0404 21:09:10.360273 47978602034560 learning.py:507] global step 7378: loss = 6.3307 (0.504 sec/step)
I0404 21:09:10.880930 47978602034560 learning.py:507] global step 7379: loss = 6.0688 (0.519 sec/step)
I0404 21:09:11.386879 47978602034560 learning.py:507] global step 7380: loss = 6.5798 (0.504 sec/step)
I0404 21:09:11.893924 47978602034560 learning.py:507] global step 7381: loss = 5.8941 (0.504 sec/step)
I0404 21:09:12.432346 47978602034560 learning.py:507] global step 7382: loss = 6.4419 (0.536 sec/step)
I0404 21:09:12.931921 47978602034560 learning.py:507] global step 7383: loss = 5.2491 (0.498 sec/step)
I0404 21:09:13.441275 47978602034560 learning.py:507] global step 7384: loss = 7.6493 (0.506 sec/step)
I0404 21:09:13.946422 47978602034560 learning.py:507] global step 7385: loss = 6.0143 (0.504 sec/step)
I0404 21:09:14.455543 47978602034560 learning.py:507] global step 7386: loss = 5.5884 (0.507 sec/step)
I0404 21:09:14.979647 47978602034560 learning.py:507] global step 7387: loss = 6.1791 (0.523 sec/step)
I0404 21:09:15.495610 47978602034560 learning.py:507] global step 7388: loss = 5.2094 (0.513 sec/step)
I0404 21:09:16.003409 47978602034560 learning.py:507] global step 7389: loss = 6.8934 (0.506 sec/step)
I0404 21:09:16.522850 47978602034560 learning.py:507] global step 7390: loss = 6.2309 (0.518 sec/step)
I0404 21:09:17.199949 47978602034560 learning.py:507] global step 7391: loss = 6.6271 (0.671 sec/step)
I0404 21:09:17.340058 47983661975296 supervisor.py:1050] Recording summary at step 7391.
I0404 21:09:17.749295 47978602034560 learning.py:507] global step 7392: loss = 5.8987 (0.544 sec/step)
I0404 21:09:18.251417 47978602034560 learning.py:507] global step 7393: loss = 5.1518 (0.501 sec/step)
I0404 21:09:18.783020 47978602034560 learning.py:507] global step 7394: loss = 6.5788 (0.530 sec/step)
I0404 21:09:19.321595 47978602034560 learning.py:507] global step 7395: loss = 5.9477 (0.536 sec/step)
I0404 21:09:19.830993 47978602034560 learning.py:507] global step 7396: loss = 6.9055 (0.508 sec/step)
I0404 21:09:20.343011 47978602034560 learning.py:507] global step 7397: loss = 5.2032 (0.510 sec/step)
I0404 21:09:20.879738 47978602034560 learning.py:507] global step 7398: loss = 5.9214 (0.535 sec/step)
I0404 21:09:21.392692 47978602034560 learning.py:507] global step 7399: loss = 5.8700 (0.510 sec/step)
I0404 21:09:21.903782 47978602034560 learning.py:507] global step 7400: loss = 5.1986 (0.509 sec/step)
I0404 21:09:22.418982 47978602034560 learning.py:507] global step 7401: loss = 5.8956 (0.514 sec/step)
I0404 21:09:22.937894 47978602034560 learning.py:507] global step 7402: loss = 6.2666 (0.517 sec/step)
I0404 21:09:23.452067 47978602034560 learning.py:507] global step 7403: loss = 5.6496 (0.511 sec/step)
I0404 21:09:23.980967 47978602034560 learning.py:507] global step 7404: loss = 6.1464 (0.527 sec/step)
I0404 21:09:24.486539 47978602034560 learning.py:507] global step 7405: loss = 6.0858 (0.504 sec/step)
I0404 21:09:25.026092 47978602034560 learning.py:507] global step 7406: loss = 5.7480 (0.538 sec/step)
I0404 21:09:25.542393 47978602034560 learning.py:507] global step 7407: loss = 5.6837 (0.513 sec/step)
I0404 21:09:26.073748 47978602034560 learning.py:507] global step 7408: loss = 5.7138 (0.530 sec/step)
I0404 21:09:26.577312 47978602034560 learning.py:507] global step 7409: loss = 6.1655 (0.502 sec/step)
I0404 21:09:27.087941 47978602034560 learning.py:507] global step 7410: loss = 5.3585 (0.509 sec/step)
I0404 21:09:27.600505 47978602034560 learning.py:507] global step 7411: loss = 5.8803 (0.510 sec/step)
I0404 21:09:28.106712 47978602034560 learning.py:507] global step 7412: loss = 6.2477 (0.505 sec/step)
I0404 21:09:28.606441 47978602034560 learning.py:507] global step 7413: loss = 6.1090 (0.498 sec/step)
I0404 21:09:29.118934 47978602034560 learning.py:507] global step 7414: loss = 5.2467 (0.511 sec/step)
I0404 21:09:29.635968 47978602034560 learning.py:507] global step 7415: loss = 5.4629 (0.515 sec/step)
I0404 21:09:30.148288 47978602034560 learning.py:507] global step 7416: loss = 5.0338 (0.511 sec/step)
I0404 21:09:30.680926 47978602034560 learning.py:507] global step 7417: loss = 5.9673 (0.531 sec/step)
I0404 21:09:31.192709 47978602034560 learning.py:507] global step 7418: loss = 6.3367 (0.509 sec/step)
I0404 21:09:31.698932 47978602034560 learning.py:507] global step 7419: loss = 6.6973 (0.505 sec/step)
I0404 21:09:32.207230 47978602034560 learning.py:507] global step 7420: loss = 6.0087 (0.507 sec/step)
I0404 21:09:32.721753 47978602034560 learning.py:507] global step 7421: loss = 5.7093 (0.513 sec/step)
I0404 21:09:33.251321 47978602034560 learning.py:507] global step 7422: loss = 5.9610 (0.528 sec/step)
I0404 21:09:33.752609 47978602034560 learning.py:507] global step 7423: loss = 6.2998 (0.500 sec/step)
I0404 21:09:34.264081 47978602034560 learning.py:507] global step 7424: loss = 6.1819 (0.509 sec/step)
I0404 21:09:34.783423 47978602034560 learning.py:507] global step 7425: loss = 6.0848 (0.517 sec/step)
I0404 21:09:35.300590 47978602034560 learning.py:507] global step 7426: loss = 5.3748 (0.514 sec/step)
I0404 21:09:35.801585 47978602034560 learning.py:507] global step 7427: loss = 6.3218 (0.499 sec/step)
I0404 21:09:36.331650 47978602034560 learning.py:507] global step 7428: loss = 5.4145 (0.528 sec/step)
I0404 21:09:36.858117 47978602034560 learning.py:507] global step 7429: loss = 5.0511 (0.524 sec/step)
I0404 21:09:37.362089 47978602034560 learning.py:507] global step 7430: loss = 6.7664 (0.501 sec/step)
I0404 21:09:37.879444 47978602034560 learning.py:507] global step 7431: loss = 6.2956 (0.515 sec/step)
I0404 21:09:38.408253 47978602034560 learning.py:507] global step 7432: loss = 5.4872 (0.527 sec/step)
I0404 21:09:38.932435 47978602034560 learning.py:507] global step 7433: loss = 6.0310 (0.523 sec/step)
I0404 21:09:39.453445 47978602034560 learning.py:507] global step 7434: loss = 6.0091 (0.518 sec/step)
I0404 21:09:39.970433 47978602034560 learning.py:507] global step 7435: loss = 6.7599 (0.515 sec/step)
I0404 21:09:40.501148 47978602034560 learning.py:507] global step 7436: loss = 6.1347 (0.529 sec/step)
I0404 21:09:41.016345 47978602034560 learning.py:507] global step 7437: loss = 4.9328 (0.512 sec/step)
I0404 21:09:41.524765 47978602034560 learning.py:507] global step 7438: loss = 5.7783 (0.507 sec/step)
I0404 21:09:42.033489 47978602034560 learning.py:507] global step 7439: loss = 5.5015 (0.507 sec/step)
I0404 21:09:42.552684 47978602034560 learning.py:507] global step 7440: loss = 6.3303 (0.516 sec/step)
I0404 21:09:43.055860 47978602034560 learning.py:507] global step 7441: loss = 5.8943 (0.502 sec/step)
I0404 21:09:43.567876 47978602034560 learning.py:507] global step 7442: loss = 6.0776 (0.510 sec/step)
I0404 21:09:44.094510 47978602034560 learning.py:507] global step 7443: loss = 5.7484 (0.525 sec/step)
I0404 21:09:44.602635 47978602034560 learning.py:507] global step 7444: loss = 6.7517 (0.507 sec/step)
I0404 21:09:45.104856 47978602034560 learning.py:507] global step 7445: loss = 5.7450 (0.499 sec/step)
I0404 21:09:45.622238 47978602034560 learning.py:507] global step 7446: loss = 6.5496 (0.515 sec/step)
I0404 21:09:46.147906 47978602034560 learning.py:507] global step 7447: loss = 6.8472 (0.524 sec/step)
I0404 21:09:46.659523 47978602034560 learning.py:507] global step 7448: loss = 5.6790 (0.510 sec/step)
I0404 21:09:47.169842 47978602034560 learning.py:507] global step 7449: loss = 6.7510 (0.509 sec/step)
I0404 21:09:47.673559 47978602034560 learning.py:507] global step 7450: loss = 4.9271 (0.502 sec/step)
I0404 21:09:48.180849 47978602034560 learning.py:507] global step 7451: loss = 5.5355 (0.506 sec/step)
I0404 21:09:48.698480 47978602034560 learning.py:507] global step 7452: loss = 5.6708 (0.516 sec/step)
I0404 21:09:49.215384 47978602034560 learning.py:507] global step 7453: loss = 4.8001 (0.515 sec/step)
I0404 21:09:49.719002 47978602034560 learning.py:507] global step 7454: loss = 5.8192 (0.502 sec/step)
I0404 21:09:50.249253 47978602034560 learning.py:507] global step 7455: loss = 5.2728 (0.529 sec/step)
I0404 21:09:50.753897 47978602034560 learning.py:507] global step 7456: loss = 6.7853 (0.503 sec/step)
I0404 21:09:51.289763 47978602034560 learning.py:507] global step 7457: loss = 5.8245 (0.533 sec/step)
I0404 21:09:51.799309 47978602034560 learning.py:507] global step 7458: loss = 5.8960 (0.508 sec/step)
I0404 21:09:52.304924 47978602034560 learning.py:507] global step 7459: loss = 6.3492 (0.503 sec/step)
I0404 21:09:52.814744 47978602034560 learning.py:507] global step 7460: loss = 5.6821 (0.508 sec/step)
I0404 21:09:53.351500 47978602034560 learning.py:507] global step 7461: loss = 5.9966 (0.535 sec/step)
I0404 21:09:53.878036 47978602034560 learning.py:507] global step 7462: loss = 5.4749 (0.524 sec/step)
I0404 21:09:54.415324 47978602034560 learning.py:507] global step 7463: loss = 4.9723 (0.536 sec/step)
I0404 21:09:54.928084 47978602034560 learning.py:507] global step 7464: loss = 6.4627 (0.511 sec/step)
I0404 21:09:55.434427 47978602034560 learning.py:507] global step 7465: loss = 5.8400 (0.505 sec/step)
I0404 21:09:55.939043 47978602034560 learning.py:507] global step 7466: loss = 6.0272 (0.503 sec/step)
I0404 21:09:56.452221 47978602034560 learning.py:507] global step 7467: loss = 5.7794 (0.512 sec/step)
I0404 21:09:56.983640 47978602034560 learning.py:507] global step 7468: loss = 6.2776 (0.530 sec/step)
I0404 21:09:57.494042 47978602034560 learning.py:507] global step 7469: loss = 6.7883 (0.509 sec/step)
I0404 21:09:58.000113 47978602034560 learning.py:507] global step 7470: loss = 5.3437 (0.504 sec/step)
I0404 21:09:58.511400 47978602034560 learning.py:507] global step 7471: loss = 6.3314 (0.508 sec/step)
I0404 21:09:59.015162 47978602034560 learning.py:507] global step 7472: loss = 6.4200 (0.502 sec/step)
I0404 21:09:59.527038 47978602034560 learning.py:507] global step 7473: loss = 5.5023 (0.510 sec/step)
I0404 21:10:00.041345 47978602034560 learning.py:507] global step 7474: loss = 5.6374 (0.513 sec/step)
I0404 21:10:00.558529 47978602034560 learning.py:507] global step 7475: loss = 6.2037 (0.516 sec/step)
I0404 21:10:01.066116 47978602034560 learning.py:507] global step 7476: loss = 5.3893 (0.506 sec/step)
I0404 21:10:01.574597 47978602034560 learning.py:507] global step 7477: loss = 5.5837 (0.507 sec/step)
I0404 21:10:02.079245 47978602034560 learning.py:507] global step 7478: loss = 6.0573 (0.503 sec/step)
I0404 21:10:02.582904 47978602034560 learning.py:507] global step 7479: loss = 5.5848 (0.502 sec/step)
I0404 21:10:03.114149 47978602034560 learning.py:507] global step 7480: loss = 4.9100 (0.530 sec/step)
I0404 21:10:03.617622 47978602034560 learning.py:507] global step 7481: loss = 6.3022 (0.501 sec/step)
I0404 21:10:04.126615 47978602034560 learning.py:507] global step 7482: loss = 6.3278 (0.506 sec/step)
I0404 21:10:04.648749 47978602034560 learning.py:507] global step 7483: loss = 5.5819 (0.520 sec/step)
I0404 21:10:05.151857 47978602034560 learning.py:507] global step 7484: loss = 5.2039 (0.500 sec/step)
I0404 21:10:05.658842 47978602034560 learning.py:507] global step 7485: loss = 5.8107 (0.505 sec/step)
I0404 21:10:06.176049 47978602034560 learning.py:507] global step 7486: loss = 5.4460 (0.514 sec/step)
I0404 21:10:06.689422 47978602034560 learning.py:507] global step 7487: loss = 6.1436 (0.511 sec/step)
I0404 21:10:07.214249 47978602034560 learning.py:507] global step 7488: loss = 6.7837 (0.522 sec/step)
I0404 21:10:07.733855 47978602034560 learning.py:507] global step 7489: loss = 6.4553 (0.517 sec/step)
I0404 21:10:08.239668 47978602034560 learning.py:507] global step 7490: loss = 6.5757 (0.504 sec/step)
I0404 21:10:08.774350 47978602034560 learning.py:507] global step 7491: loss = 6.3288 (0.533 sec/step)
I0404 21:10:09.290925 47978602034560 learning.py:507] global step 7492: loss = 5.5730 (0.514 sec/step)
I0404 21:10:09.794796 47978602034560 learning.py:507] global step 7493: loss = 5.2753 (0.502 sec/step)
I0404 21:10:10.338296 47978602034560 learning.py:507] global step 7494: loss = 6.5151 (0.542 sec/step)
I0404 21:10:10.851094 47978602034560 learning.py:507] global step 7495: loss = 5.8715 (0.511 sec/step)
I0404 21:10:11.365864 47978602034560 learning.py:507] global step 7496: loss = 6.2411 (0.513 sec/step)
I0404 21:10:11.897856 47978602034560 learning.py:507] global step 7497: loss = 6.3790 (0.530 sec/step)
I0404 21:10:12.411554 47978602034560 learning.py:507] global step 7498: loss = 5.7272 (0.512 sec/step)
I0404 21:10:12.924686 47978602034560 learning.py:507] global step 7499: loss = 6.2382 (0.512 sec/step)
I0404 21:10:13.440206 47978602034560 learning.py:507] global step 7500: loss = 6.1728 (0.513 sec/step)
I0404 21:10:13.977497 47978602034560 learning.py:507] global step 7501: loss = 5.7037 (0.536 sec/step)
I0404 21:10:14.491513 47978602034560 learning.py:507] global step 7502: loss = 5.0034 (0.511 sec/step)
I0404 21:10:15.009734 47978602034560 learning.py:507] global step 7503: loss = 6.3480 (0.515 sec/step)
I0404 21:10:15.522139 47978602034560 learning.py:507] global step 7504: loss = 5.7824 (0.510 sec/step)
I0404 21:10:16.053346 47978602034560 learning.py:507] global step 7505: loss = 5.9591 (0.528 sec/step)
I0404 21:10:16.559957 47978602034560 learning.py:507] global step 7506: loss = 6.7557 (0.505 sec/step)
I0404 21:10:17.070308 47978602034560 learning.py:507] global step 7507: loss = 6.0541 (0.508 sec/step)
I0404 21:10:17.584173 47978602034560 learning.py:507] global step 7508: loss = 7.8827 (0.512 sec/step)
I0404 21:10:18.099265 47978602034560 learning.py:507] global step 7509: loss = 6.2010 (0.514 sec/step)
I0404 21:10:18.615732 47978602034560 learning.py:507] global step 7510: loss = 5.8471 (0.515 sec/step)
I0404 21:10:19.140548 47978602034560 learning.py:507] global step 7511: loss = 5.8142 (0.523 sec/step)
I0404 21:10:19.647904 47978602034560 learning.py:507] global step 7512: loss = 5.3024 (0.504 sec/step)
I0404 21:10:20.154176 47978602034560 learning.py:507] global step 7513: loss = 6.5172 (0.505 sec/step)
I0404 21:10:20.682086 47978602034560 learning.py:507] global step 7514: loss = 5.8611 (0.525 sec/step)
I0404 21:10:21.214105 47978602034560 learning.py:507] global step 7515: loss = 5.4394 (0.529 sec/step)
I0404 21:10:21.743210 47978602034560 learning.py:507] global step 7516: loss = 5.5827 (0.527 sec/step)
I0404 21:10:22.256632 47978602034560 learning.py:507] global step 7517: loss = 6.7622 (0.511 sec/step)
I0404 21:10:22.787387 47978602034560 learning.py:507] global step 7518: loss = 5.9218 (0.528 sec/step)
I0404 21:10:23.292531 47978602034560 learning.py:507] global step 7519: loss = 6.0549 (0.504 sec/step)
I0404 21:10:23.806868 47978602034560 learning.py:507] global step 7520: loss = 5.3893 (0.513 sec/step)
I0404 21:10:24.315613 47978602034560 learning.py:507] global step 7521: loss = 6.2194 (0.507 sec/step)
I0404 21:10:24.841400 47978602034560 learning.py:507] global step 7522: loss = 5.5381 (0.524 sec/step)
I0404 21:10:25.356617 47978602034560 learning.py:507] global step 7523: loss = 4.9714 (0.514 sec/step)
I0404 21:10:25.868308 47978602034560 learning.py:507] global step 7524: loss = 5.4354 (0.510 sec/step)
I0404 21:10:26.379564 47978602034560 learning.py:507] global step 7525: loss = 6.7486 (0.510 sec/step)
I0404 21:10:26.882803 47978602034560 learning.py:507] global step 7526: loss = 6.3097 (0.502 sec/step)
I0404 21:10:27.405355 47978602034560 learning.py:507] global step 7527: loss = 7.0691 (0.521 sec/step)
I0404 21:10:27.914285 47978602034560 learning.py:507] global step 7528: loss = 5.5366 (0.507 sec/step)
I0404 21:10:28.416731 47978602034560 learning.py:507] global step 7529: loss = 6.3217 (0.500 sec/step)
I0404 21:10:28.927150 47978602034560 learning.py:507] global step 7530: loss = 5.9187 (0.509 sec/step)
I0404 21:10:29.441530 47978602034560 learning.py:507] global step 7531: loss = 6.1877 (0.513 sec/step)
I0404 21:10:29.948911 47978602034560 learning.py:507] global step 7532: loss = 5.2994 (0.506 sec/step)
I0404 21:10:30.459111 47978602034560 learning.py:507] global step 7533: loss = 5.5574 (0.509 sec/step)
I0404 21:10:30.979533 47978602034560 learning.py:507] global step 7534: loss = 6.1270 (0.518 sec/step)
I0404 21:10:31.502010 47978602034560 learning.py:507] global step 7535: loss = 5.9891 (0.520 sec/step)
I0404 21:10:32.006742 47978602034560 learning.py:507] global step 7536: loss = 6.0916 (0.503 sec/step)
I0404 21:10:32.539715 47978602034560 learning.py:507] global step 7537: loss = 5.5056 (0.531 sec/step)
I0404 21:10:33.062071 47978602034560 learning.py:507] global step 7538: loss = 5.2455 (0.519 sec/step)
I0404 21:10:33.571835 47978602034560 learning.py:507] global step 7539: loss = 5.9209 (0.508 sec/step)
I0404 21:10:34.083183 47978602034560 learning.py:507] global step 7540: loss = 5.7407 (0.510 sec/step)
I0404 21:10:34.602258 47978602034560 learning.py:507] global step 7541: loss = 5.6030 (0.516 sec/step)
I0404 21:10:35.116850 47978602034560 learning.py:507] global step 7542: loss = 5.5085 (0.513 sec/step)
I0404 21:10:35.649660 47978602034560 learning.py:507] global step 7543: loss = 6.2267 (0.531 sec/step)
I0404 21:10:36.158194 47978602034560 learning.py:507] global step 7544: loss = 4.8263 (0.507 sec/step)
I0404 21:10:36.660029 47978602034560 learning.py:507] global step 7545: loss = 5.5103 (0.500 sec/step)
I0404 21:10:37.169889 47978602034560 learning.py:507] global step 7546: loss = 6.4689 (0.508 sec/step)
I0404 21:10:37.675194 47978602034560 learning.py:507] global step 7547: loss = 6.1356 (0.504 sec/step)
I0404 21:10:38.181071 47978602034560 learning.py:507] global step 7548: loss = 7.6736 (0.504 sec/step)
I0404 21:10:38.701850 47978602034560 learning.py:507] global step 7549: loss = 5.6285 (0.518 sec/step)
I0404 21:10:39.222797 47978602034560 learning.py:507] global step 7550: loss = 5.4300 (0.518 sec/step)
I0404 21:10:39.731219 47978602034560 learning.py:507] global step 7551: loss = 5.7106 (0.507 sec/step)
I0404 21:10:40.230415 47978602034560 learning.py:507] global step 7552: loss = 6.2024 (0.496 sec/step)
I0404 21:10:40.742755 47978602034560 learning.py:507] global step 7553: loss = 5.8898 (0.511 sec/step)
I0404 21:10:41.270533 47978602034560 learning.py:507] global step 7554: loss = 5.1099 (0.526 sec/step)
I0404 21:10:41.788144 47978602034560 learning.py:507] global step 7555: loss = 6.4627 (0.516 sec/step)
I0404 21:10:42.299322 47978602034560 learning.py:507] global step 7556: loss = 4.7494 (0.508 sec/step)
I0404 21:10:42.807045 47978602034560 learning.py:507] global step 7557: loss = 5.0817 (0.505 sec/step)
I0404 21:10:43.310099 47978602034560 learning.py:507] global step 7558: loss = 6.0458 (0.500 sec/step)
I0404 21:10:43.849483 47978602034560 learning.py:507] global step 7559: loss = 7.2517 (0.536 sec/step)
I0404 21:10:44.361628 47978602034560 learning.py:507] global step 7560: loss = 6.4803 (0.511 sec/step)
I0404 21:10:44.888803 47978602034560 learning.py:507] global step 7561: loss = 5.7668 (0.526 sec/step)
I0404 21:10:45.394353 47978602034560 learning.py:507] global step 7562: loss = 5.4756 (0.504 sec/step)
I0404 21:10:45.907485 47978602034560 learning.py:507] global step 7563: loss = 6.4433 (0.512 sec/step)
I0404 21:10:46.443663 47978602034560 learning.py:507] global step 7564: loss = 7.0138 (0.535 sec/step)
I0404 21:10:46.977066 47978602034560 learning.py:507] global step 7565: loss = 5.5118 (0.531 sec/step)
I0404 21:10:47.499578 47978602034560 learning.py:507] global step 7566: loss = 4.7109 (0.520 sec/step)
I0404 21:10:48.026530 47978602034560 learning.py:507] global step 7567: loss = 6.1828 (0.524 sec/step)
I0404 21:10:48.532995 47978602034560 learning.py:507] global step 7568: loss = 5.4872 (0.505 sec/step)
I0404 21:10:49.041402 47978602034560 learning.py:507] global step 7569: loss = 5.1478 (0.507 sec/step)
I0404 21:10:49.552654 47978602034560 learning.py:507] global step 7570: loss = 4.9699 (0.510 sec/step)
I0404 21:10:50.055023 47978602034560 learning.py:507] global step 7571: loss = 6.6166 (0.500 sec/step)
I0404 21:10:50.565148 47978602034560 learning.py:507] global step 7572: loss = 6.1500 (0.509 sec/step)
I0404 21:10:51.077043 47978602034560 learning.py:507] global step 7573: loss = 5.5284 (0.509 sec/step)
I0404 21:10:51.600274 47978602034560 learning.py:507] global step 7574: loss = 6.2328 (0.522 sec/step)
I0404 21:10:52.140898 47978602034560 learning.py:507] global step 7575: loss = 6.0720 (0.539 sec/step)
I0404 21:10:52.645286 47978602034560 learning.py:507] global step 7576: loss = 6.4133 (0.502 sec/step)
I0404 21:10:53.149030 47978602034560 learning.py:507] global step 7577: loss = 6.1559 (0.502 sec/step)
I0404 21:10:53.671477 47978602034560 learning.py:507] global step 7578: loss = 5.2754 (0.521 sec/step)
I0404 21:10:54.202450 47978602034560 learning.py:507] global step 7579: loss = 5.4735 (0.529 sec/step)
I0404 21:10:54.719411 47978602034560 learning.py:507] global step 7580: loss = 5.5298 (0.515 sec/step)
I0404 21:10:55.249930 47978602034560 learning.py:507] global step 7581: loss = 5.5269 (0.529 sec/step)
I0404 21:10:55.759679 47978602034560 learning.py:507] global step 7582: loss = 6.1170 (0.507 sec/step)
I0404 21:10:56.297710 47978602034560 learning.py:507] global step 7583: loss = 6.2769 (0.536 sec/step)
I0404 21:10:56.808132 47978602034560 learning.py:507] global step 7584: loss = 5.3736 (0.509 sec/step)
I0404 21:10:57.311640 47978602034560 learning.py:507] global step 7585: loss = 5.5633 (0.502 sec/step)
I0404 21:10:57.850481 47978602034560 learning.py:507] global step 7586: loss = 5.6786 (0.537 sec/step)
I0404 21:10:58.359222 47978602034560 learning.py:507] global step 7587: loss = 4.8341 (0.507 sec/step)
I0404 21:10:58.869393 47978602034560 learning.py:507] global step 7588: loss = 5.8137 (0.507 sec/step)
I0404 21:10:59.393763 47978602034560 learning.py:507] global step 7589: loss = 6.6843 (0.523 sec/step)
I0404 21:10:59.903738 47978602034560 learning.py:507] global step 7590: loss = 5.0577 (0.508 sec/step)
I0404 21:11:00.415356 47978602034560 learning.py:507] global step 7591: loss = 5.4119 (0.509 sec/step)
I0404 21:11:00.935221 47978602034560 learning.py:507] global step 7592: loss = 5.9120 (0.518 sec/step)
I0404 21:11:01.473650 47978602034560 learning.py:507] global step 7593: loss = 5.5272 (0.537 sec/step)
I0404 21:11:01.991157 47978602034560 learning.py:507] global step 7594: loss = 4.8132 (0.516 sec/step)
I0404 21:11:02.499125 47978602034560 learning.py:507] global step 7595: loss = 6.8548 (0.506 sec/step)
I0404 21:11:03.025637 47978602034560 learning.py:507] global step 7596: loss = 6.0414 (0.525 sec/step)
I0404 21:11:03.560061 47978602034560 learning.py:507] global step 7597: loss = 4.8742 (0.533 sec/step)
I0404 21:11:04.075313 47978602034560 learning.py:507] global step 7598: loss = 5.8840 (0.514 sec/step)
I0404 21:11:04.594595 47978602034560 learning.py:507] global step 7599: loss = 5.6477 (0.518 sec/step)
I0404 21:11:05.108381 47978602034560 learning.py:507] global step 7600: loss = 7.2632 (0.512 sec/step)
I0404 21:11:05.643257 47978602034560 learning.py:507] global step 7601: loss = 5.9362 (0.533 sec/step)
I0404 21:11:06.157588 47978602034560 learning.py:507] global step 7602: loss = 4.8833 (0.513 sec/step)
I0404 21:11:06.669493 47978602034560 learning.py:507] global step 7603: loss = 5.0737 (0.510 sec/step)
I0404 21:11:07.171008 47978602034560 learning.py:507] global step 7604: loss = 5.8333 (0.500 sec/step)
I0404 21:11:07.679850 47978602034560 learning.py:507] global step 7605: loss = 6.2894 (0.507 sec/step)
I0404 21:11:08.189718 47978602034560 learning.py:507] global step 7606: loss = 5.2522 (0.508 sec/step)
I0404 21:11:08.701872 47978602034560 learning.py:507] global step 7607: loss = 5.8081 (0.511 sec/step)
I0404 21:11:09.212954 47978602034560 learning.py:507] global step 7608: loss = 5.0447 (0.509 sec/step)
I0404 21:11:09.725373 47978602034560 learning.py:507] global step 7609: loss = 5.4774 (0.510 sec/step)
I0404 21:11:10.234880 47978602034560 learning.py:507] global step 7610: loss = 5.8627 (0.507 sec/step)
I0404 21:11:10.748367 47978602034560 learning.py:507] global step 7611: loss = 6.3651 (0.511 sec/step)
I0404 21:11:11.277341 47978602034560 learning.py:507] global step 7612: loss = 6.5527 (0.526 sec/step)
I0404 21:11:11.779867 47978602034560 learning.py:507] global step 7613: loss = 5.7074 (0.500 sec/step)
I0404 21:11:12.296205 47978602034560 learning.py:507] global step 7614: loss = 4.9127 (0.513 sec/step)
I0404 21:11:12.802796 47978602034560 learning.py:507] global step 7615: loss = 7.3319 (0.505 sec/step)
I0404 21:11:13.314693 47978602034560 learning.py:507] global step 7616: loss = 6.2301 (0.509 sec/step)
I0404 21:11:13.830917 47978602034560 learning.py:507] global step 7617: loss = 5.8330 (0.515 sec/step)
I0404 21:11:14.335258 47978602034560 learning.py:507] global step 7618: loss = 5.4048 (0.503 sec/step)
I0404 21:11:14.847188 47978602034560 learning.py:507] global step 7619: loss = 5.4063 (0.510 sec/step)
I0404 21:11:15.376020 47978602034560 learning.py:507] global step 7620: loss = 4.7677 (0.527 sec/step)
I0404 21:11:15.883566 47978602034560 learning.py:507] global step 7621: loss = 5.9964 (0.506 sec/step)
I0404 21:11:16.389986 47978602034560 learning.py:507] global step 7622: loss = 5.9621 (0.504 sec/step)
I0404 21:11:16.906975 47978602034560 learning.py:507] global step 7623: loss = 6.2176 (0.511 sec/step)
I0404 21:11:17.285986 47983661975296 supervisor.py:1050] Recording summary at step 7623.
I0404 21:11:17.607047 47978602034560 learning.py:507] global step 7624: loss = 6.5053 (0.685 sec/step)
I0404 21:11:18.122315 47978602034560 learning.py:507] global step 7625: loss = 5.5338 (0.512 sec/step)
I0404 21:11:18.630793 47978602034560 learning.py:507] global step 7626: loss = 5.0889 (0.507 sec/step)
I0404 21:11:19.137639 47978602034560 learning.py:507] global step 7627: loss = 6.8303 (0.505 sec/step)
I0404 21:11:19.648181 47978602034560 learning.py:507] global step 7628: loss = 5.7605 (0.509 sec/step)
I0404 21:11:20.153368 47978602034560 learning.py:507] global step 7629: loss = 6.7556 (0.504 sec/step)
I0404 21:11:20.668029 47978602034560 learning.py:507] global step 7630: loss = 5.6558 (0.513 sec/step)
I0404 21:11:21.176087 47978602034560 learning.py:507] global step 7631: loss = 6.4262 (0.507 sec/step)
I0404 21:11:21.691200 47978602034560 learning.py:507] global step 7632: loss = 6.0630 (0.512 sec/step)
I0404 21:11:22.198156 47978602034560 learning.py:507] global step 7633: loss = 5.3818 (0.504 sec/step)
I0404 21:11:22.710433 47978602034560 learning.py:507] global step 7634: loss = 5.4284 (0.509 sec/step)
I0404 21:11:23.218315 47978602034560 learning.py:507] global step 7635: loss = 6.9514 (0.506 sec/step)
I0404 21:11:23.747595 47978602034560 learning.py:507] global step 7636: loss = 6.5867 (0.528 sec/step)
I0404 21:11:24.245707 47978602034560 learning.py:507] global step 7637: loss = 5.5726 (0.497 sec/step)
I0404 21:11:24.759531 47978602034560 learning.py:507] global step 7638: loss = 6.3861 (0.512 sec/step)
I0404 21:11:25.270500 47978602034560 learning.py:507] global step 7639: loss = 5.1288 (0.508 sec/step)
I0404 21:11:25.805585 47978602034560 learning.py:507] global step 7640: loss = 5.2993 (0.532 sec/step)
I0404 21:11:26.305634 47978602034560 learning.py:507] global step 7641: loss = 4.6833 (0.497 sec/step)
I0404 21:11:26.810930 47978602034560 learning.py:507] global step 7642: loss = 5.5422 (0.504 sec/step)
I0404 21:11:27.320812 47978602034560 learning.py:507] global step 7643: loss = 5.1437 (0.508 sec/step)
I0404 21:11:27.832316 47978602034560 learning.py:507] global step 7644: loss = 4.7557 (0.510 sec/step)
I0404 21:11:28.364932 47978602034560 learning.py:507] global step 7645: loss = 6.8051 (0.531 sec/step)
I0404 21:11:28.878486 47978602034560 learning.py:507] global step 7646: loss = 6.2125 (0.512 sec/step)
I0404 21:11:29.411241 47978602034560 learning.py:507] global step 7647: loss = 6.5959 (0.531 sec/step)
I0404 21:11:29.914246 47978602034560 learning.py:507] global step 7648: loss = 5.7043 (0.502 sec/step)
I0404 21:11:30.441457 47978602034560 learning.py:507] global step 7649: loss = 5.8360 (0.526 sec/step)
I0404 21:11:30.950263 47978602034560 learning.py:507] global step 7650: loss = 5.9246 (0.507 sec/step)
I0404 21:11:31.468204 47978602034560 learning.py:507] global step 7651: loss = 5.5053 (0.516 sec/step)
I0404 21:11:31.975281 47978602034560 learning.py:507] global step 7652: loss = 5.9717 (0.504 sec/step)
I0404 21:11:32.487689 47978602034560 learning.py:507] global step 7653: loss = 5.2462 (0.510 sec/step)
I0404 21:11:32.994647 47978602034560 learning.py:507] global step 7654: loss = 5.2946 (0.504 sec/step)
I0404 21:11:33.504010 47978602034560 learning.py:507] global step 7655: loss = 6.5273 (0.508 sec/step)
I0404 21:11:34.020321 47978602034560 learning.py:507] global step 7656: loss = 5.6255 (0.515 sec/step)
I0404 21:11:34.531241 47978602034560 learning.py:507] global step 7657: loss = 6.2579 (0.508 sec/step)
I0404 21:11:35.067803 47978602034560 learning.py:507] global step 7658: loss = 6.4433 (0.534 sec/step)
I0404 21:11:35.594275 47978602034560 learning.py:507] global step 7659: loss = 5.5433 (0.525 sec/step)
I0404 21:11:36.093979 47978602034560 learning.py:507] global step 7660: loss = 6.4309 (0.498 sec/step)
I0404 21:11:36.602120 47978602034560 learning.py:507] global step 7661: loss = 5.4711 (0.507 sec/step)
I0404 21:11:37.110886 47978602034560 learning.py:507] global step 7662: loss = 5.1846 (0.507 sec/step)
I0404 21:11:37.644081 47978602034560 learning.py:507] global step 7663: loss = 5.6048 (0.532 sec/step)
I0404 21:11:38.157935 47978602034560 learning.py:507] global step 7664: loss = 5.3071 (0.511 sec/step)
I0404 21:11:38.660941 47978602034560 learning.py:507] global step 7665: loss = 5.5217 (0.501 sec/step)
I0404 21:11:39.196890 47978602034560 learning.py:507] global step 7666: loss = 5.9040 (0.534 sec/step)
I0404 21:11:39.713214 47978602034560 learning.py:507] global step 7667: loss = 5.3175 (0.515 sec/step)
I0404 21:11:40.217049 47978602034560 learning.py:507] global step 7668: loss = 5.2939 (0.501 sec/step)
I0404 21:11:40.742422 47978602034560 learning.py:507] global step 7669: loss = 6.3946 (0.524 sec/step)
I0404 21:11:41.250720 47978602034560 learning.py:507] global step 7670: loss = 5.6159 (0.505 sec/step)
I0404 21:11:41.782397 47978602034560 learning.py:507] global step 7671: loss = 6.4680 (0.529 sec/step)
I0404 21:11:42.298868 47978602034560 learning.py:507] global step 7672: loss = 5.5221 (0.514 sec/step)
I0404 21:11:42.818602 47978602034560 learning.py:507] global step 7673: loss = 5.6367 (0.518 sec/step)
I0404 21:11:43.350041 47978602034560 learning.py:507] global step 7674: loss = 5.5777 (0.529 sec/step)
I0404 21:11:43.858309 47978602034560 learning.py:507] global step 7675: loss = 5.6957 (0.507 sec/step)
I0404 21:11:44.386370 47978602034560 learning.py:507] global step 7676: loss = 6.3069 (0.526 sec/step)
I0404 21:11:44.900321 47978602034560 learning.py:507] global step 7677: loss = 5.4848 (0.511 sec/step)
I0404 21:11:45.405043 47978602034560 learning.py:507] global step 7678: loss = 5.0986 (0.503 sec/step)
I0404 21:11:45.936655 47978602034560 learning.py:507] global step 7679: loss = 6.3941 (0.530 sec/step)
I0404 21:11:46.455109 47978602034560 learning.py:507] global step 7680: loss = 5.2133 (0.517 sec/step)
I0404 21:11:46.966241 47978602034560 learning.py:507] global step 7681: loss = 6.0199 (0.510 sec/step)
I0404 21:11:47.476815 47978602034560 learning.py:507] global step 7682: loss = 5.5117 (0.508 sec/step)
I0404 21:11:47.996808 47978602034560 learning.py:507] global step 7683: loss = 5.6476 (0.517 sec/step)
I0404 21:11:48.511696 47978602034560 learning.py:507] global step 7684: loss = 6.6280 (0.513 sec/step)
I0404 21:11:49.019715 47978602034560 learning.py:507] global step 7685: loss = 5.1834 (0.506 sec/step)
I0404 21:11:49.535832 47978602034560 learning.py:507] global step 7686: loss = 6.5676 (0.515 sec/step)
I0404 21:11:50.072105 47978602034560 learning.py:507] global step 7687: loss = 5.8014 (0.535 sec/step)
I0404 21:11:50.593155 47978602034560 learning.py:507] global step 7688: loss = 6.1215 (0.518 sec/step)
I0404 21:11:51.097220 47978602034560 learning.py:507] global step 7689: loss = 5.6100 (0.503 sec/step)
I0404 21:11:51.608284 47978602034560 learning.py:507] global step 7690: loss = 6.2578 (0.509 sec/step)
I0404 21:11:52.119743 47978602034560 learning.py:507] global step 7691: loss = 6.7003 (0.509 sec/step)
I0404 21:11:52.647847 47978602034560 learning.py:507] global step 7692: loss = 5.6858 (0.527 sec/step)
I0404 21:11:53.164589 47978602034560 learning.py:507] global step 7693: loss = 5.1637 (0.515 sec/step)
I0404 21:11:53.680040 47978602034560 learning.py:507] global step 7694: loss = 7.1132 (0.514 sec/step)
I0404 21:11:54.213593 47978602034560 learning.py:507] global step 7695: loss = 5.7947 (0.531 sec/step)
I0404 21:11:54.729387 47978602034560 learning.py:507] global step 7696: loss = 5.4809 (0.513 sec/step)
I0404 21:11:55.257702 47978602034560 learning.py:507] global step 7697: loss = 5.4212 (0.525 sec/step)
I0404 21:11:55.763904 47978602034560 learning.py:507] global step 7698: loss = 6.1788 (0.505 sec/step)
I0404 21:11:56.264329 47978602034560 learning.py:507] global step 7699: loss = 5.3572 (0.498 sec/step)
I0404 21:11:56.780959 47978602034560 learning.py:507] global step 7700: loss = 6.6838 (0.515 sec/step)
I0404 21:11:57.297103 47978602034560 learning.py:507] global step 7701: loss = 5.9053 (0.515 sec/step)
I0404 21:11:57.801705 47978602034560 learning.py:507] global step 7702: loss = 7.7052 (0.503 sec/step)
I0404 21:11:58.314901 47978602034560 learning.py:507] global step 7703: loss = 5.8411 (0.512 sec/step)
I0404 21:11:58.823733 47978602034560 learning.py:507] global step 7704: loss = 5.8205 (0.506 sec/step)
I0404 21:11:59.358183 47978602034560 learning.py:507] global step 7705: loss = 6.2854 (0.532 sec/step)
I0404 21:11:59.872871 47978602034560 learning.py:507] global step 7706: loss = 7.0596 (0.512 sec/step)
I0404 21:12:00.375396 47978602034560 learning.py:507] global step 7707: loss = 5.0207 (0.501 sec/step)
I0404 21:12:00.896522 47978602034560 learning.py:507] global step 7708: loss = 6.2896 (0.520 sec/step)
I0404 21:12:01.402344 47978602034560 learning.py:507] global step 7709: loss = 7.6960 (0.504 sec/step)
I0404 21:12:01.917552 47978602034560 learning.py:507] global step 7710: loss = 5.4935 (0.514 sec/step)
I0404 21:12:02.425197 47978602034560 learning.py:507] global step 7711: loss = 6.3203 (0.505 sec/step)
I0404 21:12:02.954135 47978602034560 learning.py:507] global step 7712: loss = 6.3006 (0.526 sec/step)
I0404 21:12:03.483316 47978602034560 learning.py:507] global step 7713: loss = 5.0260 (0.528 sec/step)
I0404 21:12:04.005343 47978602034560 learning.py:507] global step 7714: loss = 5.8570 (0.520 sec/step)
I0404 21:12:04.509924 47978602034560 learning.py:507] global step 7715: loss = 4.8514 (0.503 sec/step)
I0404 21:12:05.019150 47978602034560 learning.py:507] global step 7716: loss = 5.9279 (0.508 sec/step)
I0404 21:12:05.563230 47978602034560 learning.py:507] global step 7717: loss = 5.2186 (0.541 sec/step)
I0404 21:12:06.092178 47978602034560 learning.py:507] global step 7718: loss = 5.2079 (0.527 sec/step)
I0404 21:12:06.601135 47978602034560 learning.py:507] global step 7719: loss = 5.8138 (0.507 sec/step)
I0404 21:12:07.120220 47978602034560 learning.py:507] global step 7720: loss = 6.4463 (0.518 sec/step)
I0404 21:12:07.636925 47978602034560 learning.py:507] global step 7721: loss = 7.0192 (0.515 sec/step)
I0404 21:12:08.152880 47978602034560 learning.py:507] global step 7722: loss = 4.8650 (0.514 sec/step)
I0404 21:12:08.670811 47978602034560 learning.py:507] global step 7723: loss = 5.5364 (0.516 sec/step)
I0404 21:12:09.177936 47978602034560 learning.py:507] global step 7724: loss = 5.9617 (0.506 sec/step)
I0404 21:12:09.696490 47978602034560 learning.py:507] global step 7725: loss = 5.9114 (0.517 sec/step)
I0404 21:12:10.212426 47978602034560 learning.py:507] global step 7726: loss = 5.6853 (0.514 sec/step)
I0404 21:12:10.720719 47978602034560 learning.py:507] global step 7727: loss = 6.1889 (0.505 sec/step)
I0404 21:12:11.240513 47978602034560 learning.py:507] global step 7728: loss = 6.3883 (0.518 sec/step)
I0404 21:12:11.752892 47978602034560 learning.py:507] global step 7729: loss = 6.7437 (0.511 sec/step)
I0404 21:12:12.260362 47978602034560 learning.py:507] global step 7730: loss = 5.5165 (0.506 sec/step)
I0404 21:12:12.783534 47978602034560 learning.py:507] global step 7731: loss = 5.0342 (0.522 sec/step)
I0404 21:12:13.300823 47978602034560 learning.py:507] global step 7732: loss = 6.0739 (0.514 sec/step)
I0404 21:12:13.815887 47978602034560 learning.py:507] global step 7733: loss = 5.9774 (0.513 sec/step)
I0404 21:12:14.317411 47978602034560 learning.py:507] global step 7734: loss = 5.5472 (0.500 sec/step)
I0404 21:12:14.855821 47978602034560 learning.py:507] global step 7735: loss = 5.7396 (0.537 sec/step)
I0404 21:12:15.369185 47978602034560 learning.py:507] global step 7736: loss = 5.6253 (0.512 sec/step)
I0404 21:12:15.883556 47978602034560 learning.py:507] global step 7737: loss = 6.5248 (0.513 sec/step)
I0404 21:12:16.413119 47978602034560 learning.py:507] global step 7738: loss = 5.5596 (0.527 sec/step)
I0404 21:12:16.949614 47978602034560 learning.py:507] global step 7739: loss = 6.2974 (0.535 sec/step)
I0404 21:12:17.452592 47978602034560 learning.py:507] global step 7740: loss = 5.3916 (0.501 sec/step)
I0404 21:12:17.991124 47978602034560 learning.py:507] global step 7741: loss = 5.8368 (0.537 sec/step)
I0404 21:12:18.496772 47978602034560 learning.py:507] global step 7742: loss = 6.3386 (0.503 sec/step)
I0404 21:12:19.003973 47978602034560 learning.py:507] global step 7743: loss = 6.0540 (0.504 sec/step)
I0404 21:12:19.504102 47978602034560 learning.py:507] global step 7744: loss = 6.4490 (0.499 sec/step)
I0404 21:12:20.017709 47978602034560 learning.py:507] global step 7745: loss = 6.1808 (0.512 sec/step)
I0404 21:12:20.523154 47978602034560 learning.py:507] global step 7746: loss = 6.3126 (0.504 sec/step)
I0404 21:12:21.065165 47978602034560 learning.py:507] global step 7747: loss = 6.3461 (0.540 sec/step)
I0404 21:12:21.582672 47978602034560 learning.py:507] global step 7748: loss = 6.0763 (0.516 sec/step)
I0404 21:12:22.094856 47978602034560 learning.py:507] global step 7749: loss = 6.1576 (0.511 sec/step)
I0404 21:12:22.609076 47978602034560 learning.py:507] global step 7750: loss = 6.1498 (0.511 sec/step)
I0404 21:12:23.112662 47978602034560 learning.py:507] global step 7751: loss = 5.3837 (0.502 sec/step)
I0404 21:12:23.618746 47978602034560 learning.py:507] global step 7752: loss = 5.5504 (0.505 sec/step)
I0404 21:12:24.145263 47978602034560 learning.py:507] global step 7753: loss = 6.8114 (0.524 sec/step)
I0404 21:12:24.645424 47978602034560 learning.py:507] global step 7754: loss = 6.1133 (0.499 sec/step)
I0404 21:12:25.155212 47978602034560 learning.py:507] global step 7755: loss = 5.9535 (0.508 sec/step)
I0404 21:12:25.668685 47978602034560 learning.py:507] global step 7756: loss = 5.4928 (0.510 sec/step)
I0404 21:12:26.203034 47978602034560 learning.py:507] global step 7757: loss = 6.6742 (0.533 sec/step)
I0404 21:12:26.715403 47978602034560 learning.py:507] global step 7758: loss = 5.7597 (0.509 sec/step)
I0404 21:12:27.250452 47978602034560 learning.py:507] global step 7759: loss = 6.4571 (0.533 sec/step)
I0404 21:12:27.751148 47978602034560 learning.py:507] global step 7760: loss = 5.7875 (0.498 sec/step)
I0404 21:12:28.259623 47978602034560 learning.py:507] global step 7761: loss = 6.6699 (0.507 sec/step)
I0404 21:12:28.793754 47978602034560 learning.py:507] global step 7762: loss = 4.8106 (0.531 sec/step)
I0404 21:12:29.317927 47978602034560 learning.py:507] global step 7763: loss = 5.7584 (0.523 sec/step)
I0404 21:12:29.836722 47978602034560 learning.py:507] global step 7764: loss = 5.7217 (0.517 sec/step)
I0404 21:12:30.354595 47978602034560 learning.py:507] global step 7765: loss = 5.8007 (0.515 sec/step)
I0404 21:12:30.869108 47978602034560 learning.py:507] global step 7766: loss = 6.4187 (0.513 sec/step)
I0404 21:12:31.378144 47978602034560 learning.py:507] global step 7767: loss = 6.0193 (0.508 sec/step)
I0404 21:12:31.910041 47978602034560 learning.py:507] global step 7768: loss = 6.1148 (0.529 sec/step)
I0404 21:12:32.420012 47978602034560 learning.py:507] global step 7769: loss = 6.5165 (0.508 sec/step)
I0404 21:12:32.924452 47978602034560 learning.py:507] global step 7770: loss = 5.3717 (0.503 sec/step)
I0404 21:12:33.425615 47978602034560 learning.py:507] global step 7771: loss = 5.2910 (0.500 sec/step)
I0404 21:12:33.929030 47978602034560 learning.py:507] global step 7772: loss = 5.9262 (0.502 sec/step)
I0404 21:12:34.447893 47978602034560 learning.py:507] global step 7773: loss = 6.9260 (0.517 sec/step)
I0404 21:12:34.958986 47978602034560 learning.py:507] global step 7774: loss = 4.7109 (0.508 sec/step)
I0404 21:12:35.466235 47978602034560 learning.py:507] global step 7775: loss = 4.7107 (0.506 sec/step)
I0404 21:12:35.968164 47978602034560 learning.py:507] global step 7776: loss = 5.6744 (0.499 sec/step)
I0404 21:12:36.477032 47978602034560 learning.py:507] global step 7777: loss = 5.0477 (0.506 sec/step)
I0404 21:12:36.988203 47978602034560 learning.py:507] global step 7778: loss = 5.8799 (0.510 sec/step)
I0404 21:12:37.506982 47978602034560 learning.py:507] global step 7779: loss = 5.5424 (0.517 sec/step)
I0404 21:12:38.010698 47978602034560 learning.py:507] global step 7780: loss = 5.9854 (0.502 sec/step)
I0404 21:12:38.519919 47978602034560 learning.py:507] global step 7781: loss = 6.4247 (0.508 sec/step)
I0404 21:12:39.030334 47978602034560 learning.py:507] global step 7782: loss = 6.1052 (0.509 sec/step)
I0404 21:12:39.545503 47978602034560 learning.py:507] global step 7783: loss = 4.9299 (0.514 sec/step)
I0404 21:12:40.048550 47978602034560 learning.py:507] global step 7784: loss = 6.7116 (0.501 sec/step)
I0404 21:12:40.569318 47978602034560 learning.py:507] global step 7785: loss = 7.0452 (0.519 sec/step)
I0404 21:12:41.074729 47978602034560 learning.py:507] global step 7786: loss = 6.9087 (0.504 sec/step)
I0404 21:12:41.578490 47978602034560 learning.py:507] global step 7787: loss = 5.9791 (0.502 sec/step)
I0404 21:12:42.081412 47978602034560 learning.py:507] global step 7788: loss = 6.0286 (0.501 sec/step)
I0404 21:12:42.613987 47978602034560 learning.py:507] global step 7789: loss = 6.9587 (0.531 sec/step)
I0404 21:12:43.118818 47978602034560 learning.py:507] global step 7790: loss = 6.3939 (0.503 sec/step)
I0404 21:12:43.622845 47978602034560 learning.py:507] global step 7791: loss = 5.1637 (0.502 sec/step)
I0404 21:12:44.134118 47978602034560 learning.py:507] global step 7792: loss = 5.4634 (0.510 sec/step)
I0404 21:12:44.640622 47978602034560 learning.py:507] global step 7793: loss = 6.9454 (0.505 sec/step)
I0404 21:12:45.159868 47978602034560 learning.py:507] global step 7794: loss = 5.3351 (0.518 sec/step)
I0404 21:12:45.681900 47978602034560 learning.py:507] global step 7795: loss = 5.9353 (0.520 sec/step)
I0404 21:12:46.185229 47978602034560 learning.py:507] global step 7796: loss = 6.1784 (0.500 sec/step)
I0404 21:12:46.691144 47978602034560 learning.py:507] global step 7797: loss = 5.4860 (0.504 sec/step)
I0404 21:12:47.206491 47978602034560 learning.py:507] global step 7798: loss = 6.6638 (0.514 sec/step)
I0404 21:12:47.714559 47978602034560 learning.py:507] global step 7799: loss = 6.0396 (0.507 sec/step)
I0404 21:12:48.225028 47978602034560 learning.py:507] global step 7800: loss = 5.9232 (0.509 sec/step)
I0404 21:12:48.736161 47978602034560 learning.py:507] global step 7801: loss = 6.0881 (0.510 sec/step)
I0404 21:12:49.253538 47978602034560 learning.py:507] global step 7802: loss = 6.7992 (0.516 sec/step)
I0404 21:12:49.765416 47978602034560 learning.py:507] global step 7803: loss = 5.7169 (0.510 sec/step)
I0404 21:12:50.277728 47978602034560 learning.py:507] global step 7804: loss = 6.2223 (0.511 sec/step)
I0404 21:12:50.805412 47978602034560 learning.py:507] global step 7805: loss = 5.7842 (0.526 sec/step)
I0404 21:12:51.339465 47978602034560 learning.py:507] global step 7806: loss = 6.6214 (0.532 sec/step)
I0404 21:12:51.860909 47978602034560 learning.py:507] global step 7807: loss = 5.4257 (0.519 sec/step)
I0404 21:12:52.363232 47978602034560 learning.py:507] global step 7808: loss = 5.4214 (0.501 sec/step)
I0404 21:12:52.875836 47978602034560 learning.py:507] global step 7809: loss = 5.4551 (0.510 sec/step)
I0404 21:12:53.387650 47978602034560 learning.py:507] global step 7810: loss = 6.2336 (0.510 sec/step)
I0404 21:12:53.891538 47978602034560 learning.py:507] global step 7811: loss = 6.0081 (0.502 sec/step)
I0404 21:12:54.409218 47978602034560 learning.py:507] global step 7812: loss = 6.4870 (0.516 sec/step)
I0404 21:12:54.952747 47978602034560 learning.py:507] global step 7813: loss = 6.8331 (0.542 sec/step)
I0404 21:12:55.457160 47978602034560 learning.py:507] global step 7814: loss = 5.6428 (0.502 sec/step)
I0404 21:12:55.966930 47978602034560 learning.py:507] global step 7815: loss = 5.0273 (0.508 sec/step)
I0404 21:12:56.504164 47978602034560 learning.py:507] global step 7816: loss = 6.2239 (0.534 sec/step)
I0404 21:12:57.014955 47978602034560 learning.py:507] global step 7817: loss = 5.0535 (0.508 sec/step)
I0404 21:12:57.525055 47978602034560 learning.py:507] global step 7818: loss = 5.9664 (0.508 sec/step)
I0404 21:12:58.026339 47978602034560 learning.py:507] global step 7819: loss = 6.4241 (0.500 sec/step)
I0404 21:12:58.535251 47978602034560 learning.py:507] global step 7820: loss = 5.5904 (0.507 sec/step)
I0404 21:12:59.045544 47978602034560 learning.py:507] global step 7821: loss = 5.8982 (0.509 sec/step)
I0404 21:12:59.565820 47978602034560 learning.py:507] global step 7822: loss = 5.2706 (0.519 sec/step)
I0404 21:13:00.102181 47978602034560 learning.py:507] global step 7823: loss = 5.9122 (0.535 sec/step)
I0404 21:13:00.631707 47978602034560 learning.py:507] global step 7824: loss = 6.6862 (0.528 sec/step)
I0404 21:13:01.139432 47978602034560 learning.py:507] global step 7825: loss = 6.4907 (0.506 sec/step)
I0404 21:13:01.650504 47978602034560 learning.py:507] global step 7826: loss = 5.1695 (0.509 sec/step)
I0404 21:13:02.164911 47978602034560 learning.py:507] global step 7827: loss = 5.3466 (0.513 sec/step)
I0404 21:13:02.702063 47978602034560 learning.py:507] global step 7828: loss = 5.7289 (0.536 sec/step)
I0404 21:13:03.214359 47978602034560 learning.py:507] global step 7829: loss = 5.6138 (0.511 sec/step)
I0404 21:13:03.738342 47978602034560 learning.py:507] global step 7830: loss = 5.4775 (0.522 sec/step)
I0404 21:13:04.254127 47978602034560 learning.py:507] global step 7831: loss = 5.7226 (0.514 sec/step)
I0404 21:13:04.783997 47978602034560 learning.py:507] global step 7832: loss = 5.1259 (0.528 sec/step)
I0404 21:13:05.302987 47978602034560 learning.py:507] global step 7833: loss = 4.2647 (0.516 sec/step)
I0404 21:13:05.810900 47978602034560 learning.py:507] global step 7834: loss = 6.8816 (0.506 sec/step)
I0404 21:13:06.334257 47978602034560 learning.py:507] global step 7835: loss = 5.2579 (0.520 sec/step)
I0404 21:13:06.847526 47978602034560 learning.py:507] global step 7836: loss = 5.2825 (0.512 sec/step)
I0404 21:13:07.356901 47978602034560 learning.py:507] global step 7837: loss = 5.3629 (0.508 sec/step)
I0404 21:13:07.869687 47978602034560 learning.py:507] global step 7838: loss = 6.1651 (0.511 sec/step)
I0404 21:13:08.379083 47978602034560 learning.py:507] global step 7839: loss = 5.7340 (0.508 sec/step)
I0404 21:13:08.904751 47978602034560 learning.py:507] global step 7840: loss = 6.3504 (0.524 sec/step)
I0404 21:13:09.434193 47978602034560 learning.py:507] global step 7841: loss = 6.1205 (0.528 sec/step)
I0404 21:13:09.946813 47978602034560 learning.py:507] global step 7842: loss = 6.3200 (0.510 sec/step)
I0404 21:13:10.460627 47978602034560 learning.py:507] global step 7843: loss = 5.1211 (0.512 sec/step)
I0404 21:13:10.981525 47978602034560 learning.py:507] global step 7844: loss = 6.1849 (0.519 sec/step)
I0404 21:13:11.510742 47978602034560 learning.py:507] global step 7845: loss = 5.8961 (0.528 sec/step)
I0404 21:13:12.019925 47978602034560 learning.py:507] global step 7846: loss = 7.1957 (0.508 sec/step)
I0404 21:13:12.522864 47978602034560 learning.py:507] global step 7847: loss = 6.0502 (0.501 sec/step)
I0404 21:13:13.051403 47978602034560 learning.py:507] global step 7848: loss = 5.9188 (0.526 sec/step)
I0404 21:13:13.557367 47978602034560 learning.py:507] global step 7849: loss = 5.4470 (0.504 sec/step)
I0404 21:13:14.057211 47978602034560 learning.py:507] global step 7850: loss = 5.7936 (0.497 sec/step)
I0404 21:13:14.573166 47978602034560 learning.py:507] global step 7851: loss = 5.8443 (0.514 sec/step)
I0404 21:13:15.092112 47978602034560 learning.py:507] global step 7852: loss = 4.8852 (0.517 sec/step)
I0404 21:13:15.627251 47978602034560 learning.py:507] global step 7853: loss = 5.2373 (0.534 sec/step)
I0404 21:13:16.140259 47978602034560 learning.py:507] global step 7854: loss = 6.8276 (0.511 sec/step)
I0404 21:13:16.669386 47978602034560 learning.py:507] global step 7855: loss = 6.2058 (0.523 sec/step)
I0404 21:13:17.035565 47983661975296 supervisor.py:1050] Recording summary at step 7855.
I0404 21:13:17.382248 47978602034560 learning.py:507] global step 7856: loss = 5.7874 (0.693 sec/step)
I0404 21:13:17.897992 47978602034560 learning.py:507] global step 7857: loss = 6.1875 (0.514 sec/step)
I0404 21:13:18.410024 47978602034560 learning.py:507] global step 7858: loss = 6.1016 (0.510 sec/step)
I0404 21:13:18.933404 47978602034560 learning.py:507] global step 7859: loss = 6.4669 (0.521 sec/step)
I0404 21:13:19.448039 47978602034560 learning.py:507] global step 7860: loss = 6.1422 (0.512 sec/step)
I0404 21:13:19.958047 47978602034560 learning.py:507] global step 7861: loss = 7.1587 (0.508 sec/step)
I0404 21:13:20.473573 47978602034560 learning.py:507] global step 7862: loss = 5.8716 (0.514 sec/step)
I0404 21:13:20.985224 47978602034560 learning.py:507] global step 7863: loss = 6.9253 (0.510 sec/step)
I0404 21:13:21.517412 47978602034560 learning.py:507] global step 7864: loss = 6.1847 (0.529 sec/step)
I0404 21:13:22.027369 47978602034560 learning.py:507] global step 7865: loss = 5.8989 (0.507 sec/step)
I0404 21:13:22.531673 47978602034560 learning.py:507] global step 7866: loss = 7.2311 (0.501 sec/step)
I0404 21:13:23.049660 47978602034560 learning.py:507] global step 7867: loss = 5.5887 (0.516 sec/step)
I0404 21:13:23.568595 47978602034560 learning.py:507] global step 7868: loss = 6.1996 (0.517 sec/step)
I0404 21:13:24.075119 47978602034560 learning.py:507] global step 7869: loss = 5.2779 (0.505 sec/step)
I0404 21:13:24.579237 47978602034560 learning.py:507] global step 7870: loss = 5.7350 (0.501 sec/step)
I0404 21:13:25.103030 47978602034560 learning.py:507] global step 7871: loss = 6.4631 (0.522 sec/step)
I0404 21:13:25.628466 47978602034560 learning.py:507] global step 7872: loss = 4.8637 (0.524 sec/step)
I0404 21:13:26.148726 47978602034560 learning.py:507] global step 7873: loss = 5.6554 (0.519 sec/step)
I0404 21:13:26.684060 47978602034560 learning.py:507] global step 7874: loss = 5.7843 (0.534 sec/step)
I0404 21:13:27.190244 47978602034560 learning.py:507] global step 7875: loss = 6.2578 (0.505 sec/step)
I0404 21:13:27.700590 47978602034560 learning.py:507] global step 7876: loss = 6.6640 (0.509 sec/step)
I0404 21:13:28.211815 47978602034560 learning.py:507] global step 7877: loss = 5.8879 (0.508 sec/step)
I0404 21:13:28.724523 47978602034560 learning.py:507] global step 7878: loss = 5.5591 (0.511 sec/step)
I0404 21:13:29.235834 47978602034560 learning.py:507] global step 7879: loss = 5.7493 (0.510 sec/step)
I0404 21:13:29.750450 47978602034560 learning.py:507] global step 7880: loss = 5.0152 (0.513 sec/step)
I0404 21:13:30.273967 47978602034560 learning.py:507] global step 7881: loss = 5.9320 (0.522 sec/step)
I0404 21:13:30.794063 47978602034560 learning.py:507] global step 7882: loss = 5.5560 (0.517 sec/step)
I0404 21:13:31.297970 47978602034560 learning.py:507] global step 7883: loss = 6.8755 (0.502 sec/step)
I0404 21:13:31.817837 47978602034560 learning.py:507] global step 7884: loss = 5.2453 (0.518 sec/step)
I0404 21:13:32.329390 47978602034560 learning.py:507] global step 7885: loss = 7.1863 (0.510 sec/step)
I0404 21:13:32.841464 47978602034560 learning.py:507] global step 7886: loss = 6.1283 (0.511 sec/step)
I0404 21:13:33.355045 47978602034560 learning.py:507] global step 7887: loss = 6.2681 (0.511 sec/step)
I0404 21:13:33.875982 47978602034560 learning.py:507] global step 7888: loss = 6.0194 (0.519 sec/step)
I0404 21:13:34.392195 47978602034560 learning.py:507] global step 7889: loss = 5.8725 (0.515 sec/step)
I0404 21:13:34.902933 47978602034560 learning.py:507] global step 7890: loss = 6.4888 (0.509 sec/step)
I0404 21:13:35.406100 47978602034560 learning.py:507] global step 7891: loss = 5.7761 (0.502 sec/step)
I0404 21:13:35.914203 47978602034560 learning.py:507] global step 7892: loss = 7.7712 (0.506 sec/step)
I0404 21:13:36.433862 47978602034560 learning.py:507] global step 7893: loss = 4.9974 (0.518 sec/step)
I0404 21:13:36.942879 47978602034560 learning.py:507] global step 7894: loss = 5.9584 (0.507 sec/step)
I0404 21:13:37.460786 47978602034560 learning.py:507] global step 7895: loss = 4.6316 (0.516 sec/step)
I0404 21:13:37.963138 47978602034560 learning.py:507] global step 7896: loss = 5.7036 (0.501 sec/step)
I0404 21:13:38.479149 47978602034560 learning.py:507] global step 7897: loss = 5.9632 (0.514 sec/step)
I0404 21:13:39.008824 47978602034560 learning.py:507] global step 7898: loss = 4.0834 (0.528 sec/step)
I0404 21:13:39.520082 47978602034560 learning.py:507] global step 7899: loss = 5.3198 (0.510 sec/step)
I0404 21:13:40.031850 47978602034560 learning.py:507] global step 7900: loss = 4.8343 (0.510 sec/step)
I0404 21:13:40.536096 47978602034560 learning.py:507] global step 7901: loss = 6.1838 (0.503 sec/step)
I0404 21:13:41.072780 47978602034560 learning.py:507] global step 7902: loss = 6.0580 (0.535 sec/step)
I0404 21:13:41.586460 47978602034560 learning.py:507] global step 7903: loss = 5.3137 (0.511 sec/step)
I0404 21:13:42.106247 47978602034560 learning.py:507] global step 7904: loss = 5.5842 (0.518 sec/step)
I0404 21:13:42.621771 47978602034560 learning.py:507] global step 7905: loss = 6.2796 (0.514 sec/step)
I0404 21:13:43.150663 47978602034560 learning.py:507] global step 7906: loss = 4.8579 (0.526 sec/step)
I0404 21:13:43.654665 47978602034560 learning.py:507] global step 7907: loss = 5.2876 (0.502 sec/step)
I0404 21:13:44.156858 47978602034560 learning.py:507] global step 7908: loss = 6.4737 (0.501 sec/step)
I0404 21:13:44.665876 47978602034560 learning.py:507] global step 7909: loss = 6.1281 (0.507 sec/step)
I0404 21:13:45.179559 47978602034560 learning.py:507] global step 7910: loss = 6.1536 (0.512 sec/step)
I0404 21:13:45.699959 47978602034560 learning.py:507] global step 7911: loss = 6.6043 (0.519 sec/step)
I0404 21:13:46.204461 47978602034560 learning.py:507] global step 7912: loss = 6.4818 (0.502 sec/step)
I0404 21:13:46.713243 47978602034560 learning.py:507] global step 7913: loss = 5.6913 (0.506 sec/step)
I0404 21:13:47.221049 47978602034560 learning.py:507] global step 7914: loss = 5.8390 (0.506 sec/step)
I0404 21:13:47.749399 47978602034560 learning.py:507] global step 7915: loss = 5.2382 (0.527 sec/step)
I0404 21:13:48.288029 47978602034560 learning.py:507] global step 7916: loss = 5.5730 (0.537 sec/step)
I0404 21:13:48.795268 47978602034560 learning.py:507] global step 7917: loss = 6.3000 (0.504 sec/step)
I0404 21:13:49.336782 47978602034560 learning.py:507] global step 7918: loss = 6.6895 (0.540 sec/step)
I0404 21:13:49.842072 47978602034560 learning.py:507] global step 7919: loss = 6.1092 (0.504 sec/step)
I0404 21:13:50.342801 47978602034560 learning.py:507] global step 7920: loss = 4.8840 (0.499 sec/step)
I0404 21:13:50.857998 47978602034560 learning.py:507] global step 7921: loss = 5.4149 (0.512 sec/step)
I0404 21:13:51.393625 47978602034560 learning.py:507] global step 7922: loss = 6.0297 (0.534 sec/step)
I0404 21:13:51.906085 47978602034560 learning.py:507] global step 7923: loss = 5.4550 (0.510 sec/step)
I0404 21:13:52.425997 47978602034560 learning.py:507] global step 7924: loss = 6.0663 (0.517 sec/step)
I0404 21:13:52.945759 47978602034560 learning.py:507] global step 7925: loss = 5.7951 (0.518 sec/step)
I0404 21:13:53.448841 47978602034560 learning.py:507] global step 7926: loss = 5.8031 (0.500 sec/step)
I0404 21:13:53.965534 47978602034560 learning.py:507] global step 7927: loss = 6.4466 (0.514 sec/step)
I0404 21:13:54.466986 47978602034560 learning.py:507] global step 7928: loss = 6.6358 (0.499 sec/step)
I0404 21:13:54.979393 47978602034560 learning.py:507] global step 7929: loss = 6.4867 (0.510 sec/step)
I0404 21:13:55.482271 47978602034560 learning.py:507] global step 7930: loss = 6.0352 (0.501 sec/step)
I0404 21:13:55.999403 47978602034560 learning.py:507] global step 7931: loss = 6.8549 (0.516 sec/step)
I0404 21:13:56.498744 47978602034560 learning.py:507] global step 7932: loss = 5.8949 (0.498 sec/step)
I0404 21:13:57.008108 47978602034560 learning.py:507] global step 7933: loss = 6.4854 (0.508 sec/step)
I0404 21:13:57.516413 47978602034560 learning.py:507] global step 7934: loss = 5.8776 (0.505 sec/step)
I0404 21:13:58.026174 47978602034560 learning.py:507] global step 7935: loss = 5.0362 (0.507 sec/step)
I0404 21:13:58.529259 47978602034560 learning.py:507] global step 7936: loss = 5.5586 (0.502 sec/step)
I0404 21:13:59.034383 47978602034560 learning.py:507] global step 7937: loss = 5.7457 (0.504 sec/step)
I0404 21:13:59.573909 47978602034560 learning.py:507] global step 7938: loss = 5.1993 (0.538 sec/step)
I0404 21:14:00.077681 47978602034560 learning.py:507] global step 7939: loss = 4.8383 (0.502 sec/step)
I0404 21:14:00.591182 47978602034560 learning.py:507] global step 7940: loss = 5.3645 (0.512 sec/step)
I0404 21:14:01.107174 47978602034560 learning.py:507] global step 7941: loss = 6.0273 (0.514 sec/step)
I0404 21:14:01.618621 47978602034560 learning.py:507] global step 7942: loss = 5.1111 (0.510 sec/step)
I0404 21:14:02.135556 47978602034560 learning.py:507] global step 7943: loss = 5.0198 (0.515 sec/step)
I0404 21:14:02.648778 47978602034560 learning.py:507] global step 7944: loss = 5.1097 (0.512 sec/step)
I0404 21:14:03.157239 47978602034560 learning.py:507] global step 7945: loss = 6.3932 (0.507 sec/step)
I0404 21:14:03.684687 47978602034560 learning.py:507] global step 7946: loss = 5.6877 (0.525 sec/step)
I0404 21:14:04.215581 47978602034560 learning.py:507] global step 7947: loss = 5.6452 (0.529 sec/step)
I0404 21:14:04.748433 47978602034560 learning.py:507] global step 7948: loss = 6.1554 (0.531 sec/step)
I0404 21:14:05.263760 47978602034560 learning.py:507] global step 7949: loss = 5.7763 (0.514 sec/step)
I0404 21:14:05.787691 47978602034560 learning.py:507] global step 7950: loss = 5.4186 (0.522 sec/step)
I0404 21:14:06.294699 47978602034560 learning.py:507] global step 7951: loss = 5.3758 (0.504 sec/step)
I0404 21:14:06.824226 47978602034560 learning.py:507] global step 7952: loss = 5.9719 (0.528 sec/step)
I0404 21:14:07.346828 47978602034560 learning.py:507] global step 7953: loss = 5.3564 (0.521 sec/step)
I0404 21:14:07.872693 47978602034560 learning.py:507] global step 7954: loss = 5.3433 (0.523 sec/step)
I0404 21:14:08.381873 47978602034560 learning.py:507] global step 7955: loss = 4.9816 (0.508 sec/step)
I0404 21:14:08.914591 47978602034560 learning.py:507] global step 7956: loss = 5.9438 (0.531 sec/step)
I0404 21:14:09.424479 47978602034560 learning.py:507] global step 7957: loss = 5.2832 (0.508 sec/step)
I0404 21:14:09.929590 47978602034560 learning.py:507] global step 7958: loss = 5.2205 (0.504 sec/step)
I0404 21:14:10.453102 47978602034560 learning.py:507] global step 7959: loss = 5.5969 (0.522 sec/step)
I0404 21:14:10.970294 47978602034560 learning.py:507] global step 7960: loss = 5.2412 (0.514 sec/step)
I0404 21:14:11.483297 47978602034560 learning.py:507] global step 7961: loss = 6.4872 (0.510 sec/step)
I0404 21:14:11.993695 47978602034560 learning.py:507] global step 7962: loss = 5.7098 (0.507 sec/step)
I0404 21:14:12.511370 47978602034560 learning.py:507] global step 7963: loss = 5.1723 (0.516 sec/step)
I0404 21:14:13.031137 47978602034560 learning.py:507] global step 7964: loss = 5.4722 (0.518 sec/step)
I0404 21:14:13.557343 47978602034560 learning.py:507] global step 7965: loss = 6.6382 (0.525 sec/step)
I0404 21:14:14.060981 47978602034560 learning.py:507] global step 7966: loss = 6.1284 (0.502 sec/step)
I0404 21:14:14.576994 47978602034560 learning.py:507] global step 7967: loss = 6.6988 (0.514 sec/step)
I0404 21:14:15.114194 47978602034560 learning.py:507] global step 7968: loss = 5.2023 (0.536 sec/step)
I0404 21:14:15.633621 47978602034560 learning.py:507] global step 7969: loss = 5.8606 (0.518 sec/step)
I0404 21:14:16.138185 47978602034560 learning.py:507] global step 7970: loss = 6.1109 (0.503 sec/step)
I0404 21:14:16.645882 47978602034560 learning.py:507] global step 7971: loss = 5.5687 (0.506 sec/step)
I0404 21:14:17.164265 47978602034560 learning.py:507] global step 7972: loss = 5.7882 (0.517 sec/step)
I0404 21:14:17.677929 47978602034560 learning.py:507] global step 7973: loss = 6.1924 (0.512 sec/step)
I0404 21:14:18.182660 47978602034560 learning.py:507] global step 7974: loss = 4.5874 (0.503 sec/step)
I0404 21:14:18.689047 47978602034560 learning.py:507] global step 7975: loss = 6.1315 (0.505 sec/step)
I0404 21:14:19.212158 47978602034560 learning.py:507] global step 7976: loss = 5.7086 (0.521 sec/step)
I0404 21:14:19.739917 47978602034560 learning.py:507] global step 7977: loss = 5.9609 (0.526 sec/step)
I0404 21:14:20.269055 47978602034560 learning.py:507] global step 7978: loss = 6.4190 (0.528 sec/step)
I0404 21:14:20.785701 47978602034560 learning.py:507] global step 7979: loss = 7.6930 (0.515 sec/step)
I0404 21:14:21.307557 47978602034560 learning.py:507] global step 7980: loss = 5.5696 (0.520 sec/step)
I0404 21:14:21.843346 47978602034560 learning.py:507] global step 7981: loss = 5.9787 (0.533 sec/step)
I0404 21:14:22.358633 47978602034560 learning.py:507] global step 7982: loss = 5.0995 (0.514 sec/step)
I0404 21:14:22.858260 47978602034560 learning.py:507] global step 7983: loss = 6.8733 (0.497 sec/step)
I0404 21:14:23.389135 47978602034560 learning.py:507] global step 7984: loss = 6.4574 (0.529 sec/step)
I0404 21:14:23.897297 47978602034560 learning.py:507] global step 7985: loss = 6.0505 (0.507 sec/step)
I0404 21:14:24.403439 47978602034560 learning.py:507] global step 7986: loss = 5.3484 (0.504 sec/step)
I0404 21:14:24.931248 47978602034560 learning.py:507] global step 7987: loss = 6.3739 (0.526 sec/step)
I0404 21:14:25.462399 47978602034560 learning.py:507] global step 7988: loss = 5.1264 (0.530 sec/step)
I0404 21:14:25.969060 47978602034560 learning.py:507] global step 7989: loss = 6.0095 (0.505 sec/step)
I0404 21:14:26.484554 47978602034560 learning.py:507] global step 7990: loss = 6.6602 (0.514 sec/step)
I0404 21:14:27.013514 47978602034560 learning.py:507] global step 7991: loss = 6.5025 (0.526 sec/step)
I0404 21:14:27.515203 47978602034560 learning.py:507] global step 7992: loss = 5.3383 (0.500 sec/step)
I0404 21:14:28.050122 47978602034560 learning.py:507] global step 7993: loss = 5.9806 (0.533 sec/step)
I0404 21:14:28.558248 47978602034560 learning.py:507] global step 7994: loss = 5.1285 (0.506 sec/step)
I0404 21:14:29.079652 47978602034560 learning.py:507] global step 7995: loss = 5.6770 (0.520 sec/step)
I0404 21:14:29.593760 47978602034560 learning.py:507] global step 7996: loss = 6.6712 (0.513 sec/step)
I0404 21:14:30.102613 47978602034560 learning.py:507] global step 7997: loss = 6.6544 (0.506 sec/step)
I0404 21:14:30.612260 47978602034560 learning.py:507] global step 7998: loss = 5.4037 (0.508 sec/step)
I0404 21:14:31.147455 47978602034560 learning.py:507] global step 7999: loss = 4.7762 (0.532 sec/step)
I0404 21:14:31.657841 47978602034560 learning.py:507] global step 8000: loss = 6.4179 (0.507 sec/step)
I0404 21:14:32.158746 47978602034560 learning.py:507] global step 8001: loss = 6.3344 (0.499 sec/step)
I0404 21:14:32.678845 47978602034560 learning.py:507] global step 8002: loss = 5.3432 (0.519 sec/step)
I0404 21:14:33.192615 47978602034560 learning.py:507] global step 8003: loss = 6.7048 (0.512 sec/step)
I0404 21:14:33.694038 47978602034560 learning.py:507] global step 8004: loss = 5.3389 (0.500 sec/step)
I0404 21:14:34.213610 47978602034560 learning.py:507] global step 8005: loss = 7.6189 (0.518 sec/step)
I0404 21:14:34.726100 47978602034560 learning.py:507] global step 8006: loss = 6.5503 (0.511 sec/step)
I0404 21:14:35.231492 47978602034560 learning.py:507] global step 8007: loss = 5.3495 (0.504 sec/step)
I0404 21:14:35.768693 47978602034560 learning.py:507] global step 8008: loss = 5.2023 (0.536 sec/step)
I0404 21:14:36.279867 47978602034560 learning.py:507] global step 8009: loss = 6.4941 (0.510 sec/step)
I0404 21:14:36.785096 47978602034560 learning.py:507] global step 8010: loss = 6.2087 (0.502 sec/step)
I0404 21:14:37.291599 47978602034560 learning.py:507] global step 8011: loss = 5.5468 (0.505 sec/step)
I0404 21:14:37.830615 47978602034560 learning.py:507] global step 8012: loss = 6.9440 (0.537 sec/step)
I0404 21:14:38.345494 47978602034560 learning.py:507] global step 8013: loss = 6.3224 (0.513 sec/step)
I0404 21:14:38.850632 47978602034560 learning.py:507] global step 8014: loss = 5.9045 (0.502 sec/step)
I0404 21:14:39.368836 47978602034560 learning.py:507] global step 8015: loss = 5.6110 (0.517 sec/step)
I0404 21:14:39.885147 47978602034560 learning.py:507] global step 8016: loss = 6.0826 (0.515 sec/step)
I0404 21:14:40.405399 47978602034560 learning.py:507] global step 8017: loss = 6.4397 (0.519 sec/step)
I0404 21:14:40.919116 47978602034560 learning.py:507] global step 8018: loss = 6.5379 (0.512 sec/step)
I0404 21:14:41.454933 47978602034560 learning.py:507] global step 8019: loss = 5.0459 (0.534 sec/step)
I0404 21:14:41.959288 47978602034560 learning.py:507] global step 8020: loss = 5.9888 (0.501 sec/step)
I0404 21:14:42.475109 47978602034560 learning.py:507] global step 8021: loss = 5.3262 (0.514 sec/step)
I0404 21:14:43.015686 47978602034560 learning.py:507] global step 8022: loss = 5.6934 (0.539 sec/step)
I0404 21:14:43.547660 47978602034560 learning.py:507] global step 8023: loss = 5.9378 (0.530 sec/step)
I0404 21:14:44.055148 47978602034560 learning.py:507] global step 8024: loss = 6.0136 (0.506 sec/step)
I0404 21:14:44.568146 47978602034560 learning.py:507] global step 8025: loss = 5.4420 (0.511 sec/step)
I0404 21:14:45.069557 47978602034560 learning.py:507] global step 8026: loss = 5.8077 (0.499 sec/step)
I0404 21:14:45.575486 47978602034560 learning.py:507] global step 8027: loss = 6.4877 (0.504 sec/step)
I0404 21:14:46.087825 47978602034560 learning.py:507] global step 8028: loss = 6.1281 (0.511 sec/step)
I0404 21:14:46.596549 47978602034560 learning.py:507] global step 8029: loss = 5.2554 (0.507 sec/step)
I0404 21:14:47.099655 47978602034560 learning.py:507] global step 8030: loss = 6.2071 (0.500 sec/step)
I0404 21:14:47.609603 47978602034560 learning.py:507] global step 8031: loss = 6.0722 (0.508 sec/step)
I0404 21:14:48.120898 47978602034560 learning.py:507] global step 8032: loss = 6.4447 (0.510 sec/step)
I0404 21:14:48.632663 47978602034560 learning.py:507] global step 8033: loss = 5.7220 (0.510 sec/step)
I0404 21:14:49.170375 47978602034560 learning.py:507] global step 8034: loss = 6.9366 (0.536 sec/step)
I0404 21:14:49.677427 47978602034560 learning.py:507] global step 8035: loss = 5.0668 (0.504 sec/step)
I0404 21:14:50.208337 47978602034560 learning.py:507] global step 8036: loss = 6.4869 (0.529 sec/step)
I0404 21:14:50.719936 47978602034560 learning.py:507] global step 8037: loss = 6.7504 (0.509 sec/step)
I0404 21:14:51.228643 47978602034560 learning.py:507] global step 8038: loss = 6.4468 (0.507 sec/step)
I0404 21:14:51.748863 47978602034560 learning.py:507] global step 8039: loss = 5.8087 (0.517 sec/step)
I0404 21:14:52.263518 47978602034560 learning.py:507] global step 8040: loss = 5.7191 (0.512 sec/step)
I0404 21:14:52.776164 47978602034560 learning.py:507] global step 8041: loss = 5.8628 (0.511 sec/step)
I0404 21:14:53.306056 47978602034560 learning.py:507] global step 8042: loss = 5.8321 (0.527 sec/step)
I0404 21:14:53.817706 47978602034560 learning.py:507] global step 8043: loss = 5.6199 (0.510 sec/step)
I0404 21:14:54.325950 47978602034560 learning.py:507] global step 8044: loss = 4.9449 (0.507 sec/step)
I0404 21:14:54.833889 47978602034560 learning.py:507] global step 8045: loss = 6.0938 (0.506 sec/step)
I0404 21:14:55.340334 47978602034560 learning.py:507] global step 8046: loss = 5.2818 (0.505 sec/step)
I0404 21:14:55.857157 47978602034560 learning.py:507] global step 8047: loss = 5.1181 (0.515 sec/step)
I0404 21:14:56.385551 47978602034560 learning.py:507] global step 8048: loss = 5.7523 (0.527 sec/step)
I0404 21:14:56.904973 47978602034560 learning.py:507] global step 8049: loss = 5.5360 (0.518 sec/step)
I0404 21:14:57.419965 47978602034560 learning.py:507] global step 8050: loss = 5.8426 (0.512 sec/step)
I0404 21:14:57.926813 47978602034560 learning.py:507] global step 8051: loss = 6.1554 (0.505 sec/step)
I0404 21:14:58.436654 47978602034560 learning.py:507] global step 8052: loss = 5.9011 (0.508 sec/step)
I0404 21:14:58.942674 47978602034560 learning.py:507] global step 8053: loss = 5.9646 (0.504 sec/step)
I0404 21:14:59.442615 47978602034560 learning.py:507] global step 8054: loss = 5.5700 (0.498 sec/step)
I0404 21:14:59.959165 47978602034560 learning.py:507] global step 8055: loss = 4.6598 (0.515 sec/step)
I0404 21:15:00.466558 47978602034560 learning.py:507] global step 8056: loss = 5.3012 (0.506 sec/step)
I0404 21:15:00.971022 47978602034560 learning.py:507] global step 8057: loss = 6.2001 (0.503 sec/step)
I0404 21:15:01.484076 47978602034560 learning.py:507] global step 8058: loss = 5.2291 (0.512 sec/step)
I0404 21:15:02.016670 47978602034560 learning.py:507] global step 8059: loss = 5.1766 (0.531 sec/step)
I0404 21:15:02.533085 47978602034560 learning.py:507] global step 8060: loss = 4.7746 (0.515 sec/step)
I0404 21:15:03.054584 47978602034560 learning.py:507] global step 8061: loss = 6.4181 (0.520 sec/step)
I0404 21:15:03.588053 47978602034560 learning.py:507] global step 8062: loss = 5.4319 (0.531 sec/step)
I0404 21:15:04.102313 47978602034560 learning.py:507] global step 8063: loss = 5.7635 (0.513 sec/step)
I0404 21:15:04.608415 47978602034560 learning.py:507] global step 8064: loss = 5.8174 (0.505 sec/step)
I0404 21:15:05.112575 47978602034560 learning.py:507] global step 8065: loss = 5.8262 (0.503 sec/step)
I0404 21:15:05.649090 47978602034560 learning.py:507] global step 8066: loss = 5.7078 (0.535 sec/step)
I0404 21:15:06.150173 47978602034560 learning.py:507] global step 8067: loss = 5.9022 (0.499 sec/step)
I0404 21:15:06.687014 47978602034560 learning.py:507] global step 8068: loss = 5.6648 (0.535 sec/step)
I0404 21:15:07.205611 47978602034560 learning.py:507] global step 8069: loss = 4.7890 (0.517 sec/step)
I0404 21:15:07.723969 47978602034560 learning.py:507] global step 8070: loss = 5.6042 (0.517 sec/step)
I0404 21:15:08.237437 47978602034560 learning.py:507] global step 8071: loss = 4.9640 (0.511 sec/step)
I0404 21:15:08.758742 47978602034560 learning.py:507] global step 8072: loss = 5.4651 (0.518 sec/step)
I0404 21:15:09.265955 47978602034560 learning.py:507] global step 8073: loss = 6.2290 (0.504 sec/step)
I0404 21:15:09.773168 47978602034560 learning.py:507] global step 8074: loss = 5.5391 (0.506 sec/step)
I0404 21:15:10.295097 47978602034560 learning.py:507] global step 8075: loss = 6.6296 (0.520 sec/step)
I0404 21:15:10.835528 47978602034560 learning.py:507] global step 8076: loss = 6.2223 (0.539 sec/step)
I0404 21:15:11.337491 47978602034560 learning.py:507] global step 8077: loss = 7.9309 (0.500 sec/step)
I0404 21:15:11.849712 47978602034560 learning.py:507] global step 8078: loss = 6.2849 (0.511 sec/step)
I0404 21:15:12.362314 47978602034560 learning.py:507] global step 8079: loss = 6.2690 (0.511 sec/step)
I0404 21:15:12.868663 47978602034560 learning.py:507] global step 8080: loss = 6.0622 (0.505 sec/step)
I0404 21:15:13.374495 47978602034560 learning.py:507] global step 8081: loss = 5.7929 (0.503 sec/step)
I0404 21:15:13.879912 47978602034560 learning.py:507] global step 8082: loss = 5.7483 (0.504 sec/step)
I0404 21:15:14.394652 47978602034560 learning.py:507] global step 8083: loss = 5.6545 (0.512 sec/step)
I0404 21:15:14.940464 47978602034560 learning.py:507] global step 8084: loss = 6.2525 (0.544 sec/step)
I0404 21:15:15.450629 47978602034560 learning.py:507] global step 8085: loss = 5.7500 (0.509 sec/step)
I0404 21:15:15.983894 47978602034560 learning.py:507] global step 8086: loss = 5.7295 (0.532 sec/step)
I0404 21:15:16.498219 47978602034560 learning.py:507] global step 8087: loss = 5.7825 (0.513 sec/step)
I0404 21:15:16.636534 47983666177792 supervisor.py:1117] Saving checkpoint to path ../../trainingOutput/model.ckpt
I0404 21:15:17.178396 47978602034560 learning.py:507] global step 8088: loss = 6.8746 (0.666 sec/step)
I0404 21:15:17.214887 47983661975296 supervisor.py:1050] Recording summary at step 8088.
I0404 21:15:17.930351 47978602034560 learning.py:507] global step 8089: loss = 5.5246 (0.704 sec/step)
I0404 21:15:18.469139 47978602034560 learning.py:507] global step 8090: loss = 6.0020 (0.534 sec/step)
I0404 21:15:19.008356 47978602034560 learning.py:507] global step 8091: loss = 6.6019 (0.538 sec/step)
I0404 21:15:19.518223 47978602034560 learning.py:507] global step 8092: loss = 5.9489 (0.508 sec/step)
I0404 21:15:20.033113 47978602034560 learning.py:507] global step 8093: loss = 6.4207 (0.513 sec/step)
I0404 21:15:20.539107 47978602034560 learning.py:507] global step 8094: loss = 5.6906 (0.503 sec/step)
I0404 21:15:21.062230 47978602034560 learning.py:507] global step 8095: loss = 7.4769 (0.522 sec/step)
I0404 21:15:21.585542 47978602034560 learning.py:507] global step 8096: loss = 5.8752 (0.520 sec/step)
I0404 21:15:22.117477 47978602034560 learning.py:507] global step 8097: loss = 5.6693 (0.529 sec/step)
I0404 21:15:22.656640 47978602034560 learning.py:507] global step 8098: loss = 5.0443 (0.538 sec/step)
I0404 21:15:23.162504 47978602034560 learning.py:507] global step 8099: loss = 6.8566 (0.503 sec/step)
I0404 21:15:23.667544 47978602034560 learning.py:507] global step 8100: loss = 5.5548 (0.503 sec/step)
I0404 21:15:24.179428 47978602034560 learning.py:507] global step 8101: loss = 7.0667 (0.510 sec/step)
I0404 21:15:24.693851 47978602034560 learning.py:507] global step 8102: loss = 5.2263 (0.512 sec/step)
I0404 21:15:25.209652 47978602034560 learning.py:507] global step 8103: loss = 5.4603 (0.513 sec/step)
I0404 21:15:25.728942 47978602034560 learning.py:507] global step 8104: loss = 5.6793 (0.516 sec/step)
I0404 21:15:26.251381 47978602034560 learning.py:507] global step 8105: loss = 6.5170 (0.521 sec/step)
I0404 21:15:26.760769 47978602034560 learning.py:507] global step 8106: loss = 6.6362 (0.506 sec/step)
I0404 21:15:27.294692 47978602034560 learning.py:507] global step 8107: loss = 5.4570 (0.531 sec/step)
I0404 21:15:27.795240 47978602034560 learning.py:507] global step 8108: loss = 6.0432 (0.499 sec/step)
I0404 21:15:28.305731 47978602034560 learning.py:507] global step 8109: loss = 5.6078 (0.509 sec/step)
I0404 21:15:28.810023 47978602034560 learning.py:507] global step 8110: loss = 5.1684 (0.501 sec/step)
I0404 21:15:29.322211 47978602034560 learning.py:507] global step 8111: loss = 5.8579 (0.511 sec/step)
I0404 21:15:29.845358 47978602034560 learning.py:507] global step 8112: loss = 6.0059 (0.522 sec/step)
I0404 21:15:30.382643 47978602034560 learning.py:507] global step 8113: loss = 5.2716 (0.536 sec/step)
I0404 21:15:30.887943 47978602034560 learning.py:507] global step 8114: loss = 6.2658 (0.504 sec/step)
I0404 21:15:31.408150 47978602034560 learning.py:507] global step 8115: loss = 7.1256 (0.517 sec/step)
I0404 21:15:31.916989 47978602034560 learning.py:507] global step 8116: loss = 6.4657 (0.506 sec/step)
I0404 21:15:32.447110 47978602034560 learning.py:507] global step 8117: loss = 6.2169 (0.527 sec/step)
I0404 21:15:32.975778 47978602034560 learning.py:507] global step 8118: loss = 5.8209 (0.527 sec/step)
I0404 21:15:33.479197 47978602034560 learning.py:507] global step 8119: loss = 5.7027 (0.501 sec/step)
I0404 21:15:34.000443 47978602034560 learning.py:507] global step 8120: loss = 5.6844 (0.520 sec/step)
I0404 21:15:34.512984 47978602034560 learning.py:507] global step 8121: loss = 6.6322 (0.511 sec/step)
I0404 21:15:35.022826 47978602034560 learning.py:507] global step 8122: loss = 5.2307 (0.508 sec/step)
I0404 21:15:35.558677 47978602034560 learning.py:507] global step 8123: loss = 5.8169 (0.533 sec/step)
I0404 21:15:36.095561 47978602034560 learning.py:507] global step 8124: loss = 5.0585 (0.535 sec/step)
I0404 21:15:36.606717 47978602034560 learning.py:507] global step 8125: loss = 6.4633 (0.509 sec/step)
I0404 21:15:37.120125 47978602034560 learning.py:507] global step 8126: loss = 6.1759 (0.512 sec/step)
I0404 21:15:37.627245 47978602034560 learning.py:507] global step 8127: loss = 5.5171 (0.506 sec/step)
I0404 21:15:38.132308 47978602034560 learning.py:507] global step 8128: loss = 6.4246 (0.504 sec/step)
I0404 21:15:38.644451 47978602034560 learning.py:507] global step 8129: loss = 6.7880 (0.509 sec/step)
I0404 21:15:39.154786 47978602034560 learning.py:507] global step 8130: loss = 6.5068 (0.509 sec/step)
I0404 21:15:39.690388 47978602034560 learning.py:507] global step 8131: loss = 5.8033 (0.534 sec/step)
I0404 21:15:40.208197 47978602034560 learning.py:507] global step 8132: loss = 5.6426 (0.515 sec/step)
I0404 21:15:40.740975 47978602034560 learning.py:507] global step 8133: loss = 5.4707 (0.530 sec/step)
I0404 21:15:41.285589 47978602034560 learning.py:507] global step 8134: loss = 6.5070 (0.543 sec/step)
I0404 21:15:41.820530 47978602034560 learning.py:507] global step 8135: loss = 5.0657 (0.533 sec/step)
I0404 21:15:42.330494 47978602034560 learning.py:507] global step 8136: loss = 6.4727 (0.508 sec/step)
I0404 21:15:42.844577 47978602034560 learning.py:507] global step 8137: loss = 5.7857 (0.513 sec/step)
I0404 21:15:43.384274 47978602034560 learning.py:507] global step 8138: loss = 5.3637 (0.538 sec/step)
I0404 21:15:43.894852 47978602034560 learning.py:507] global step 8139: loss = 6.0840 (0.509 sec/step)
I0404 21:15:44.409946 47978602034560 learning.py:507] global step 8140: loss = 4.5218 (0.513 sec/step)
I0404 21:15:44.935150 47978602034560 learning.py:507] global step 8141: loss = 5.5811 (0.524 sec/step)
I0404 21:15:45.454822 47978602034560 learning.py:507] global step 8142: loss = 4.9606 (0.518 sec/step)
I0404 21:15:45.966609 47978602034560 learning.py:507] global step 8143: loss = 5.2922 (0.510 sec/step)
I0404 21:15:46.466353 47978602034560 learning.py:507] global step 8144: loss = 6.0813 (0.497 sec/step)
I0404 21:15:46.975688 47978602034560 learning.py:507] global step 8145: loss = 6.4408 (0.506 sec/step)
I0404 21:15:47.494142 47978602034560 learning.py:507] global step 8146: loss = 5.6424 (0.516 sec/step)
I0404 21:15:48.025449 47978602034560 learning.py:507] global step 8147: loss = 5.3767 (0.530 sec/step)
I0404 21:15:48.532948 47978602034560 learning.py:507] global step 8148: loss = 6.4184 (0.506 sec/step)
I0404 21:15:49.038522 47978602034560 learning.py:507] global step 8149: loss = 5.4558 (0.504 sec/step)
I0404 21:15:49.554117 47978602034560 learning.py:507] global step 8150: loss = 5.4409 (0.513 sec/step)
I0404 21:15:50.095432 47978602034560 learning.py:507] global step 8151: loss = 6.1815 (0.540 sec/step)
I0404 21:15:50.619490 47978602034560 learning.py:507] global step 8152: loss = 6.6781 (0.522 sec/step)
I0404 21:15:51.121578 47978602034560 learning.py:507] global step 8153: loss = 5.2749 (0.499 sec/step)
I0404 21:15:51.627588 47978602034560 learning.py:507] global step 8154: loss = 5.8284 (0.504 sec/step)
I0404 21:15:52.143512 47978602034560 learning.py:507] global step 8155: loss = 5.2245 (0.514 sec/step)
I0404 21:15:52.672061 47978602034560 learning.py:507] global step 8156: loss = 5.5898 (0.527 sec/step)
I0404 21:15:53.186482 47978602034560 learning.py:507] global step 8157: loss = 6.2338 (0.513 sec/step)
I0404 21:15:53.693292 47978602034560 learning.py:507] global step 8158: loss = 7.0236 (0.505 sec/step)
I0404 21:15:54.223580 47978602034560 learning.py:507] global step 8159: loss = 5.6311 (0.527 sec/step)
I0404 21:15:54.734220 47978602034560 learning.py:507] global step 8160: loss = 5.9288 (0.508 sec/step)
I0404 21:15:55.250280 47978602034560 learning.py:507] global step 8161: loss = 6.3617 (0.513 sec/step)
I0404 21:15:55.755270 47978602034560 learning.py:507] global step 8162: loss = 6.4537 (0.503 sec/step)
I0404 21:15:56.288433 47978602034560 learning.py:507] global step 8163: loss = 5.3230 (0.532 sec/step)
I0404 21:15:56.795059 47978602034560 learning.py:507] global step 8164: loss = 5.9621 (0.505 sec/step)
I0404 21:15:57.305034 47978602034560 learning.py:507] global step 8165: loss = 5.9299 (0.508 sec/step)
I0404 21:15:57.845029 47978602034560 learning.py:507] global step 8166: loss = 6.1798 (0.538 sec/step)
I0404 21:15:58.347904 47978602034560 learning.py:507] global step 8167: loss = 5.6643 (0.501 sec/step)
I0404 21:15:58.850641 47978602034560 learning.py:507] global step 8168: loss = 5.7054 (0.500 sec/step)
I0404 21:15:59.387691 47978602034560 learning.py:507] global step 8169: loss = 5.1015 (0.536 sec/step)
I0404 21:15:59.910868 47978602034560 learning.py:507] global step 8170: loss = 6.0825 (0.522 sec/step)
I0404 21:16:00.436222 47978602034560 learning.py:507] global step 8171: loss = 6.7588 (0.524 sec/step)
I0404 21:16:00.943185 47978602034560 learning.py:507] global step 8172: loss = 5.8157 (0.504 sec/step)
I0404 21:16:01.454686 47978602034560 learning.py:507] global step 8173: loss = 5.8509 (0.510 sec/step)
I0404 21:16:01.985402 47978602034560 learning.py:507] global step 8174: loss = 5.2360 (0.529 sec/step)
I0404 21:16:02.525794 47978602034560 learning.py:507] global step 8175: loss = 5.5461 (0.539 sec/step)
I0404 21:16:03.047036 47978602034560 learning.py:507] global step 8176: loss = 6.4978 (0.520 sec/step)
I0404 21:16:03.568631 47978602034560 learning.py:507] global step 8177: loss = 5.5332 (0.520 sec/step)
I0404 21:16:04.072861 47978602034560 learning.py:507] global step 8178: loss = 5.5575 (0.503 sec/step)
I0404 21:16:04.599325 47978602034560 learning.py:507] global step 8179: loss = 5.4412 (0.525 sec/step)
I0404 21:16:05.110657 47978602034560 learning.py:507] global step 8180: loss = 5.5792 (0.509 sec/step)
I0404 21:16:05.637720 47978602034560 learning.py:507] global step 8181: loss = 6.1378 (0.524 sec/step)
I0404 21:16:06.157052 47978602034560 learning.py:507] global step 8182: loss = 6.5256 (0.518 sec/step)
I0404 21:16:06.664722 47978602034560 learning.py:507] global step 8183: loss = 6.0719 (0.506 sec/step)
I0404 21:16:07.182096 47978602034560 learning.py:507] global step 8184: loss = 7.1754 (0.516 sec/step)
I0404 21:16:07.692464 47978602034560 learning.py:507] global step 8185: loss = 5.6047 (0.507 sec/step)
I0404 21:16:08.204501 47978602034560 learning.py:507] global step 8186: loss = 6.5249 (0.510 sec/step)
I0404 21:16:08.726912 47978602034560 learning.py:507] global step 8187: loss = 4.9066 (0.521 sec/step)
I0404 21:16:09.233857 47978602034560 learning.py:507] global step 8188: loss = 5.3358 (0.505 sec/step)
I0404 21:16:09.743207 47978602034560 learning.py:507] global step 8189: loss = 4.8159 (0.508 sec/step)
I0404 21:16:10.251333 47978602034560 learning.py:507] global step 8190: loss = 5.8062 (0.507 sec/step)
I0404 21:16:10.785516 47978602034560 learning.py:507] global step 8191: loss = 4.5500 (0.533 sec/step)
I0404 21:16:11.316581 47978602034560 learning.py:507] global step 8192: loss = 6.0108 (0.529 sec/step)
I0404 21:16:11.831311 47978602034560 learning.py:507] global step 8193: loss = 5.4224 (0.513 sec/step)
I0404 21:16:12.351783 47978602034560 learning.py:507] global step 8194: loss = 6.6061 (0.519 sec/step)
I0404 21:16:12.862429 47978602034560 learning.py:507] global step 8195: loss = 5.2790 (0.508 sec/step)
I0404 21:16:13.362681 47978602034560 learning.py:507] global step 8196: loss = 5.9091 (0.497 sec/step)
I0404 21:16:13.883384 47978602034560 learning.py:507] global step 8197: loss = 5.6375 (0.519 sec/step)
I0404 21:16:14.386850 47978602034560 learning.py:507] global step 8198: loss = 5.4786 (0.501 sec/step)
I0404 21:16:14.907915 47978602034560 learning.py:507] global step 8199: loss = 4.6988 (0.518 sec/step)
I0404 21:16:15.415767 47978602034560 learning.py:507] global step 8200: loss = 5.0784 (0.506 sec/step)
I0404 21:16:15.928506 47978602034560 learning.py:507] global step 8201: loss = 5.5406 (0.511 sec/step)
I0404 21:16:16.443271 47978602034560 learning.py:507] global step 8202: loss = 6.2463 (0.513 sec/step)
I0404 21:16:16.963916 47978602034560 learning.py:507] global step 8203: loss = 5.5618 (0.518 sec/step)
I0404 21:16:17.467926 47978602034560 learning.py:507] global step 8204: loss = 5.7799 (0.502 sec/step)
I0404 21:16:17.971981 47978602034560 learning.py:507] global step 8205: loss = 5.3633 (0.502 sec/step)
I0404 21:16:18.491702 47978602034560 learning.py:507] global step 8206: loss = 6.2748 (0.517 sec/step)
I0404 21:16:19.002405 47978602034560 learning.py:507] global step 8207: loss = 5.7359 (0.509 sec/step)
I0404 21:16:19.505923 47978602034560 learning.py:507] global step 8208: loss = 5.4011 (0.501 sec/step)
I0404 21:16:20.034603 47978602034560 learning.py:507] global step 8209: loss = 5.6596 (0.527 sec/step)
I0404 21:16:20.538254 47978602034560 learning.py:507] global step 8210: loss = 5.2981 (0.502 sec/step)
I0404 21:16:21.062888 47978602034560 learning.py:507] global step 8211: loss = 5.9401 (0.523 sec/step)
I0404 21:16:21.592053 47978602034560 learning.py:507] global step 8212: loss = 5.8167 (0.526 sec/step)
I0404 21:16:22.101929 47978602034560 learning.py:507] global step 8213: loss = 5.1865 (0.507 sec/step)
I0404 21:16:22.604512 47978602034560 learning.py:507] global step 8214: loss = 5.9925 (0.500 sec/step)
I0404 21:16:23.114555 47978602034560 learning.py:507] global step 8215: loss = 5.9062 (0.508 sec/step)
I0404 21:16:23.627956 47978602034560 learning.py:507] global step 8216: loss = 6.1521 (0.512 sec/step)
I0404 21:16:24.138503 47978602034560 learning.py:507] global step 8217: loss = 5.2702 (0.509 sec/step)
I0404 21:16:24.646918 47978602034560 learning.py:507] global step 8218: loss = 4.9663 (0.506 sec/step)
I0404 21:16:25.163503 47978602034560 learning.py:507] global step 8219: loss = 5.6789 (0.514 sec/step)
I0404 21:16:25.692274 47978602034560 learning.py:507] global step 8220: loss = 5.9816 (0.526 sec/step)
I0404 21:16:26.231002 47978602034560 learning.py:507] global step 8221: loss = 6.4342 (0.537 sec/step)
I0404 21:16:26.756477 47978602034560 learning.py:507] global step 8222: loss = 5.7003 (0.524 sec/step)
I0404 21:16:27.273009 47978602034560 learning.py:507] global step 8223: loss = 6.6999 (0.515 sec/step)
I0404 21:16:27.800462 47978602034560 learning.py:507] global step 8224: loss = 6.2739 (0.526 sec/step)
I0404 21:16:28.311820 47978602034560 learning.py:507] global step 8225: loss = 5.1707 (0.508 sec/step)
I0404 21:16:28.814600 47978602034560 learning.py:507] global step 8226: loss = 6.1226 (0.501 sec/step)
I0404 21:16:29.323094 47978602034560 learning.py:507] global step 8227: loss = 4.8071 (0.506 sec/step)
I0404 21:16:29.859738 47978602034560 learning.py:507] global step 8228: loss = 5.2622 (0.535 sec/step)
I0404 21:16:30.394540 47978602034560 learning.py:507] global step 8229: loss = 4.9186 (0.532 sec/step)
I0404 21:16:30.924247 47978602034560 learning.py:507] global step 8230: loss = 5.3369 (0.527 sec/step)
I0404 21:16:31.430775 47978602034560 learning.py:507] global step 8231: loss = 5.2394 (0.504 sec/step)
I0404 21:16:31.937861 47978602034560 learning.py:507] global step 8232: loss = 6.0537 (0.506 sec/step)
I0404 21:16:32.456175 47978602034560 learning.py:507] global step 8233: loss = 5.5431 (0.515 sec/step)
I0404 21:16:32.960866 47978602034560 learning.py:507] global step 8234: loss = 5.6571 (0.503 sec/step)
I0404 21:16:33.492365 47978602034560 learning.py:507] global step 8235: loss = 6.5330 (0.529 sec/step)
I0404 21:16:34.031399 47978602034560 learning.py:507] global step 8236: loss = 6.1677 (0.537 sec/step)
I0404 21:16:34.539131 47978602034560 learning.py:507] global step 8237: loss = 5.3447 (0.506 sec/step)
I0404 21:16:35.049503 47978602034560 learning.py:507] global step 8238: loss = 5.6748 (0.509 sec/step)
I0404 21:16:35.569601 47978602034560 learning.py:507] global step 8239: loss = 5.7774 (0.518 sec/step)
I0404 21:16:36.083319 47978602034560 learning.py:507] global step 8240: loss = 7.0997 (0.512 sec/step)
I0404 21:16:36.593396 47978602034560 learning.py:507] global step 8241: loss = 6.2724 (0.509 sec/step)
I0404 21:16:37.104535 47978602034560 learning.py:507] global step 8242: loss = 6.2548 (0.510 sec/step)
I0404 21:16:37.612838 47978602034560 learning.py:507] global step 8243: loss = 5.1734 (0.507 sec/step)
I0404 21:16:38.137402 47978602034560 learning.py:507] global step 8244: loss = 5.4634 (0.523 sec/step)
I0404 21:16:38.651590 47978602034560 learning.py:507] global step 8245: loss = 5.3412 (0.513 sec/step)
I0404 21:16:39.156037 47978602034560 learning.py:507] global step 8246: loss = 6.5084 (0.503 sec/step)
I0404 21:16:39.665881 47978602034560 learning.py:507] global step 8247: loss = 6.0000 (0.508 sec/step)
I0404 21:16:40.172831 47978602034560 learning.py:507] global step 8248: loss = 6.4720 (0.505 sec/step)
I0404 21:16:40.693129 47978602034560 learning.py:507] global step 8249: loss = 5.7408 (0.519 sec/step)
I0404 21:16:41.208090 47978602034560 learning.py:507] global step 8250: loss = 5.4686 (0.513 sec/step)
I0404 21:16:41.737336 47978602034560 learning.py:507] global step 8251: loss = 6.3511 (0.526 sec/step)
I0404 21:16:42.242280 47978602034560 learning.py:507] global step 8252: loss = 5.8193 (0.503 sec/step)
I0404 21:16:42.771186 47978602034560 learning.py:507] global step 8253: loss = 5.7848 (0.526 sec/step)
I0404 21:16:43.302955 47978602034560 learning.py:507] global step 8254: loss = 7.0499 (0.529 sec/step)
I0404 21:16:43.812114 47978602034560 learning.py:507] global step 8255: loss = 6.2142 (0.508 sec/step)
I0404 21:16:44.322563 47978602034560 learning.py:507] global step 8256: loss = 5.5532 (0.508 sec/step)
I0404 21:16:44.830984 47978602034560 learning.py:507] global step 8257: loss = 7.2661 (0.506 sec/step)
I0404 21:16:45.339373 47978602034560 learning.py:507] global step 8258: loss = 6.5800 (0.507 sec/step)
I0404 21:16:45.855384 47978602034560 learning.py:507] global step 8259: loss = 5.7428 (0.515 sec/step)
I0404 21:16:46.360591 47978602034560 learning.py:507] global step 8260: loss = 5.9810 (0.504 sec/step)
I0404 21:16:46.865440 47978602034560 learning.py:507] global step 8261: loss = 5.9354 (0.502 sec/step)
I0404 21:16:47.396525 47978602034560 learning.py:507] global step 8262: loss = 7.0793 (0.529 sec/step)
I0404 21:16:47.922641 47978602034560 learning.py:507] global step 8263: loss = 6.5060 (0.523 sec/step)
I0404 21:16:48.461024 47978602034560 learning.py:507] global step 8264: loss = 6.0660 (0.537 sec/step)
I0404 21:16:48.974038 47978602034560 learning.py:507] global step 8265: loss = 5.3066 (0.510 sec/step)
I0404 21:16:49.475468 47978602034560 learning.py:507] global step 8266: loss = 5.5605 (0.499 sec/step)
I0404 21:16:49.995644 47978602034560 learning.py:507] global step 8267: loss = 4.8700 (0.517 sec/step)
I0404 21:16:50.507418 47978602034560 learning.py:507] global step 8268: loss = 6.6027 (0.510 sec/step)
I0404 21:16:51.014440 47978602034560 learning.py:507] global step 8269: loss = 6.5925 (0.504 sec/step)
I0404 21:16:51.528529 47978602034560 learning.py:507] global step 8270: loss = 5.6328 (0.513 sec/step)
I0404 21:16:52.034514 47978602034560 learning.py:507] global step 8271: loss = 6.2351 (0.505 sec/step)
I0404 21:16:52.549307 47978602034560 learning.py:507] global step 8272: loss = 7.0605 (0.513 sec/step)
I0404 21:16:53.068180 47978602034560 learning.py:507] global step 8273: loss = 5.8217 (0.517 sec/step)
I0404 21:16:53.581556 47978602034560 learning.py:507] global step 8274: loss = 5.3263 (0.512 sec/step)
I0404 21:16:54.091545 47978602034560 learning.py:507] global step 8275: loss = 5.5671 (0.507 sec/step)
I0404 21:16:54.602802 47978602034560 learning.py:507] global step 8276: loss = 5.4915 (0.510 sec/step)
I0404 21:16:55.107851 47978602034560 learning.py:507] global step 8277: loss = 5.1401 (0.502 sec/step)
I0404 21:16:55.645407 47978602034560 learning.py:507] global step 8278: loss = 6.0814 (0.536 sec/step)
I0404 21:16:56.157712 47978602034560 learning.py:507] global step 8279: loss = 5.6139 (0.511 sec/step)
I0404 21:16:56.662492 47978602034560 learning.py:507] global step 8280: loss = 6.8857 (0.502 sec/step)
I0404 21:16:57.189517 47978602034560 learning.py:507] global step 8281: loss = 5.4006 (0.525 sec/step)
I0404 21:16:57.716128 47978602034560 learning.py:507] global step 8282: loss = 5.6815 (0.525 sec/step)
I0404 21:16:58.235580 47978602034560 learning.py:507] global step 8283: loss = 6.1764 (0.517 sec/step)
I0404 21:16:58.746397 47978602034560 learning.py:507] global step 8284: loss = 5.5629 (0.508 sec/step)
I0404 21:16:59.263543 47978602034560 learning.py:507] global step 8285: loss = 4.9938 (0.514 sec/step)
I0404 21:16:59.771675 47978602034560 learning.py:507] global step 8286: loss = 5.2972 (0.505 sec/step)
I0404 21:17:00.291545 47978602034560 learning.py:507] global step 8287: loss = 5.7224 (0.517 sec/step)
I0404 21:17:00.820698 47978602034560 learning.py:507] global step 8288: loss = 4.9875 (0.528 sec/step)
I0404 21:17:01.320503 47978602034560 learning.py:507] global step 8289: loss = 6.1941 (0.498 sec/step)
I0404 21:17:01.860305 47978602034560 learning.py:507] global step 8290: loss = 6.0847 (0.538 sec/step)
I0404 21:17:02.400598 47978602034560 learning.py:507] global step 8291: loss = 6.4653 (0.539 sec/step)
I0404 21:17:02.932175 47978602034560 learning.py:507] global step 8292: loss = 6.2231 (0.530 sec/step)
I0404 21:17:03.440693 47978602034560 learning.py:507] global step 8293: loss = 5.4951 (0.507 sec/step)
I0404 21:17:03.961516 47978602034560 learning.py:507] global step 8294: loss = 5.3187 (0.518 sec/step)
I0404 21:17:04.468377 47978602034560 learning.py:507] global step 8295: loss = 5.2422 (0.505 sec/step)
I0404 21:17:04.979923 47978602034560 learning.py:507] global step 8296: loss = 5.9919 (0.510 sec/step)
I0404 21:17:05.512269 47978602034560 learning.py:507] global step 8297: loss = 6.0181 (0.531 sec/step)
I0404 21:17:06.037585 47978602034560 learning.py:507] global step 8298: loss = 5.8660 (0.522 sec/step)
I0404 21:17:06.560501 47978602034560 learning.py:507] global step 8299: loss = 6.5755 (0.521 sec/step)
I0404 21:17:07.080528 47978602034560 learning.py:507] global step 8300: loss = 6.6811 (0.517 sec/step)
I0404 21:17:07.585336 47978602034560 learning.py:507] global step 8301: loss = 5.2466 (0.502 sec/step)
I0404 21:17:08.085704 47978602034560 learning.py:507] global step 8302: loss = 5.5740 (0.499 sec/step)
I0404 21:17:08.599400 47978602034560 learning.py:507] global step 8303: loss = 7.1068 (0.512 sec/step)
I0404 21:17:09.108959 47978602034560 learning.py:507] global step 8304: loss = 6.7877 (0.508 sec/step)
I0404 21:17:09.640724 47978602034560 learning.py:507] global step 8305: loss = 5.8466 (0.530 sec/step)
I0404 21:17:10.145216 47978602034560 learning.py:507] global step 8306: loss = 5.1970 (0.503 sec/step)
I0404 21:17:10.656432 47978602034560 learning.py:507] global step 8307: loss = 5.7080 (0.510 sec/step)
I0404 21:17:11.169025 47978602034560 learning.py:507] global step 8308: loss = 6.2576 (0.511 sec/step)
I0404 21:17:11.681047 47978602034560 learning.py:507] global step 8309: loss = 5.9043 (0.510 sec/step)
I0404 21:17:12.219578 47978602034560 learning.py:507] global step 8310: loss = 5.7390 (0.537 sec/step)
I0404 21:17:12.735934 47978602034560 learning.py:507] global step 8311: loss = 5.6630 (0.515 sec/step)
I0404 21:17:13.270150 47978602034560 learning.py:507] global step 8312: loss = 5.7211 (0.531 sec/step)
I0404 21:17:13.770022 47978602034560 learning.py:507] global step 8313: loss = 5.8365 (0.498 sec/step)
I0404 21:17:14.281794 47978602034560 learning.py:507] global step 8314: loss = 6.2152 (0.509 sec/step)
I0404 21:17:14.784225 47978602034560 learning.py:507] global step 8315: loss = 6.1088 (0.501 sec/step)
I0404 21:17:15.327657 47978602034560 learning.py:507] global step 8316: loss = 4.8372 (0.542 sec/step)
I0404 21:17:15.844442 47978602034560 learning.py:507] global step 8317: loss = 6.6312 (0.515 sec/step)
I0404 21:17:16.356989 47978602034560 learning.py:507] global step 8318: loss = 5.8070 (0.511 sec/step)
I0404 21:17:16.872544 47978602034560 learning.py:507] global step 8319: loss = 5.7735 (0.502 sec/step)
I0404 21:17:17.236520 47983661975296 supervisor.py:1050] Recording summary at step 8319.
I0404 21:17:17.554214 47978602034560 learning.py:507] global step 8320: loss = 6.4666 (0.678 sec/step)
I0404 21:17:18.062175 47978602034560 learning.py:507] global step 8321: loss = 5.0694 (0.506 sec/step)
I0404 21:17:18.577013 47978602034560 learning.py:507] global step 8322: loss = 5.6835 (0.513 sec/step)
I0404 21:17:19.088404 47978602034560 learning.py:507] global step 8323: loss = 6.1669 (0.510 sec/step)
I0404 21:17:19.603074 47978602034560 learning.py:507] global step 8324: loss = 6.1082 (0.513 sec/step)
I0404 21:17:20.106558 47978602034560 learning.py:507] global step 8325: loss = 6.2270 (0.501 sec/step)
I0404 21:17:20.613273 47978602034560 learning.py:507] global step 8326: loss = 5.9033 (0.505 sec/step)
I0404 21:17:21.122696 47978602034560 learning.py:507] global step 8327: loss = 5.9038 (0.508 sec/step)
I0404 21:17:21.641611 47978602034560 learning.py:507] global step 8328: loss = 6.0550 (0.517 sec/step)
I0404 21:17:22.162894 47978602034560 learning.py:507] global step 8329: loss = 5.3442 (0.520 sec/step)
I0404 21:17:22.671118 47978602034560 learning.py:507] global step 8330: loss = 6.0716 (0.505 sec/step)
I0404 21:17:23.182657 47978602034560 learning.py:507] global step 8331: loss = 6.6812 (0.510 sec/step)
I0404 21:17:23.694620 47978602034560 learning.py:507] global step 8332: loss = 6.3744 (0.510 sec/step)
I0404 21:17:24.202615 47978602034560 learning.py:507] global step 8333: loss = 6.9133 (0.505 sec/step)
I0404 21:17:24.712765 47978602034560 learning.py:507] global step 8334: loss = 5.4972 (0.509 sec/step)
I0404 21:17:25.250396 47978602034560 learning.py:507] global step 8335: loss = 6.2092 (0.536 sec/step)
I0404 21:17:25.753329 47978602034560 learning.py:507] global step 8336: loss = 5.6918 (0.500 sec/step)
I0404 21:17:26.254255 47978602034560 learning.py:507] global step 8337: loss = 7.0067 (0.499 sec/step)
I0404 21:17:26.781609 47978602034560 learning.py:507] global step 8338: loss = 5.8088 (0.526 sec/step)
I0404 21:17:27.312582 47978602034560 learning.py:507] global step 8339: loss = 5.9240 (0.529 sec/step)
I0404 21:17:27.816060 47978602034560 learning.py:507] global step 8340: loss = 5.8855 (0.502 sec/step)
I0404 21:17:28.340602 47978602034560 learning.py:507] global step 8341: loss = 6.8448 (0.523 sec/step)
I0404 21:17:28.851750 47978602034560 learning.py:507] global step 8342: loss = 5.8554 (0.510 sec/step)
I0404 21:17:29.357413 47978602034560 learning.py:507] global step 8343: loss = 5.6999 (0.504 sec/step)
I0404 21:17:29.868355 47978602034560 learning.py:507] global step 8344: loss = 5.7775 (0.509 sec/step)
I0404 21:17:30.382137 47978602034560 learning.py:507] global step 8345: loss = 4.8433 (0.512 sec/step)
I0404 21:17:30.889496 47978602034560 learning.py:507] global step 8346: loss = 5.7682 (0.506 sec/step)
I0404 21:17:31.388991 47978602034560 learning.py:507] global step 8347: loss = 6.5084 (0.498 sec/step)
I0404 21:17:31.921017 47978602034560 learning.py:507] global step 8348: loss = 5.6713 (0.530 sec/step)
I0404 21:17:32.431873 47978602034560 learning.py:507] global step 8349: loss = 5.6254 (0.509 sec/step)
I0404 21:17:32.968982 47978602034560 learning.py:507] global step 8350: loss = 5.7913 (0.534 sec/step)
I0404 21:17:33.502928 47978602034560 learning.py:507] global step 8351: loss = 6.4140 (0.531 sec/step)
I0404 21:17:34.019423 47978602034560 learning.py:507] global step 8352: loss = 5.9865 (0.515 sec/step)
I0404 21:17:34.545366 47978602034560 learning.py:507] global step 8353: loss = 6.0205 (0.524 sec/step)
I0404 21:17:35.061426 47978602034560 learning.py:507] global step 8354: loss = 5.2355 (0.513 sec/step)
I0404 21:17:35.581143 47978602034560 learning.py:507] global step 8355: loss = 6.2070 (0.518 sec/step)
I0404 21:17:36.093127 47978602034560 learning.py:507] global step 8356: loss = 6.0833 (0.510 sec/step)
I0404 21:17:36.620457 47978602034560 learning.py:507] global step 8357: loss = 5.4948 (0.524 sec/step)
I0404 21:17:37.149577 47978602034560 learning.py:507] global step 8358: loss = 6.9930 (0.526 sec/step)
I0404 21:17:37.676226 47978602034560 learning.py:507] global step 8359: loss = 5.1316 (0.525 sec/step)
I0404 21:17:38.193803 47978602034560 learning.py:507] global step 8360: loss = 6.0222 (0.516 sec/step)
I0404 21:17:38.693633 47978602034560 learning.py:507] global step 8361: loss = 6.3634 (0.498 sec/step)
I0404 21:17:39.193828 47978602034560 learning.py:507] global step 8362: loss = 5.1550 (0.499 sec/step)
I0404 21:17:39.737393 47978602034560 learning.py:507] global step 8363: loss = 5.5566 (0.541 sec/step)
I0404 21:17:40.247025 47978602034560 learning.py:507] global step 8364: loss = 5.4347 (0.508 sec/step)
I0404 21:17:40.754747 47978602034560 learning.py:507] global step 8365: loss = 5.7161 (0.506 sec/step)
I0404 21:17:41.265403 47978602034560 learning.py:507] global step 8366: loss = 6.3173 (0.509 sec/step)
I0404 21:17:41.779276 47978602034560 learning.py:507] global step 8367: loss = 5.5539 (0.512 sec/step)
I0404 21:17:42.308154 47978602034560 learning.py:507] global step 8368: loss = 5.6062 (0.527 sec/step)
I0404 21:17:42.820456 47978602034560 learning.py:507] global step 8369: loss = 5.6735 (0.511 sec/step)
I0404 21:17:43.329019 47978602034560 learning.py:507] global step 8370: loss = 5.5966 (0.506 sec/step)
I0404 21:17:43.864957 47978602034560 learning.py:507] global step 8371: loss = 5.7941 (0.533 sec/step)
I0404 21:17:44.399965 47978602034560 learning.py:507] global step 8372: loss = 6.1021 (0.533 sec/step)
I0404 21:17:44.908440 47978602034560 learning.py:507] global step 8373: loss = 5.4941 (0.507 sec/step)
I0404 21:17:45.429449 47978602034560 learning.py:507] global step 8374: loss = 5.0308 (0.519 sec/step)
I0404 21:17:45.946493 47978602034560 learning.py:507] global step 8375: loss = 6.7516 (0.516 sec/step)
I0404 21:17:46.484850 47978602034560 learning.py:507] global step 8376: loss = 5.8324 (0.536 sec/step)
I0404 21:17:46.994279 47978602034560 learning.py:507] global step 8377: loss = 6.5374 (0.508 sec/step)
I0404 21:17:47.511018 47978602034560 learning.py:507] global step 8378: loss = 5.7010 (0.515 sec/step)
I0404 21:17:48.018035 47978602034560 learning.py:507] global step 8379: loss = 5.9662 (0.505 sec/step)
I0404 21:17:48.527248 47978602034560 learning.py:507] global step 8380: loss = 5.5798 (0.508 sec/step)
I0404 21:17:49.035214 47978602034560 learning.py:507] global step 8381: loss = 6.4026 (0.506 sec/step)
I0404 21:17:49.540543 47978602034560 learning.py:507] global step 8382: loss = 6.5088 (0.504 sec/step)
I0404 21:17:50.056630 47978602034560 learning.py:507] global step 8383: loss = 6.4209 (0.515 sec/step)
I0404 21:17:50.560715 47978602034560 learning.py:507] global step 8384: loss = 6.6716 (0.501 sec/step)
I0404 21:17:51.091006 47978602034560 learning.py:507] global step 8385: loss = 6.2584 (0.529 sec/step)
I0404 21:17:51.599017 47978602034560 learning.py:507] global step 8386: loss = 5.3005 (0.506 sec/step)
I0404 21:17:52.121174 47978602034560 learning.py:507] global step 8387: loss = 6.0802 (0.521 sec/step)
I0404 21:17:52.636903 47978602034560 learning.py:507] global step 8388: loss = 5.3381 (0.513 sec/step)
I0404 21:17:53.167933 47978602034560 learning.py:507] global step 8389: loss = 5.8001 (0.529 sec/step)
I0404 21:17:53.667756 47978602034560 learning.py:507] global step 8390: loss = 5.8406 (0.498 sec/step)
I0404 21:17:54.175603 47978602034560 learning.py:507] global step 8391: loss = 4.6809 (0.506 sec/step)
I0404 21:17:54.682456 47978602034560 learning.py:507] global step 8392: loss = 5.6512 (0.505 sec/step)
I0404 21:17:55.211771 47978602034560 learning.py:507] global step 8393: loss = 6.4697 (0.528 sec/step)
I0404 21:17:55.751387 47978602034560 learning.py:507] global step 8394: loss = 5.6639 (0.538 sec/step)
I0404 21:17:56.255739 47978602034560 learning.py:507] global step 8395: loss = 5.6306 (0.503 sec/step)
I0404 21:17:56.767802 47978602034560 learning.py:507] global step 8396: loss = 6.4796 (0.511 sec/step)
I0404 21:17:57.271536 47978602034560 learning.py:507] global step 8397: loss = 5.0756 (0.501 sec/step)
I0404 21:17:57.792897 47978602034560 learning.py:507] global step 8398: loss = 4.8315 (0.519 sec/step)
I0404 21:17:58.301007 47978602034560 learning.py:507] global step 8399: loss = 7.3057 (0.506 sec/step)
I0404 21:17:58.800382 47978602034560 learning.py:507] global step 8400: loss = 5.8295 (0.498 sec/step)
I0404 21:17:59.320612 47978602034560 learning.py:507] global step 8401: loss = 7.0185 (0.517 sec/step)
I0404 21:17:59.829781 47978602034560 learning.py:507] global step 8402: loss = 5.8174 (0.508 sec/step)
I0404 21:18:00.367425 47978602034560 learning.py:507] global step 8403: loss = 6.2010 (0.536 sec/step)
I0404 21:18:00.887601 47978602034560 learning.py:507] global step 8404: loss = 5.3317 (0.519 sec/step)
I0404 21:18:01.400111 47978602034560 learning.py:507] global step 8405: loss = 5.5053 (0.511 sec/step)
I0404 21:18:01.914551 47978602034560 learning.py:507] global step 8406: loss = 4.7297 (0.513 sec/step)
I0404 21:18:02.420839 47978602034560 learning.py:507] global step 8407: loss = 5.2703 (0.505 sec/step)
I0404 21:18:02.926543 47978602034560 learning.py:507] global step 8408: loss = 5.7774 (0.503 sec/step)
I0404 21:18:03.430926 47978602034560 learning.py:507] global step 8409: loss = 6.0266 (0.503 sec/step)
I0404 21:18:03.946693 47978602034560 learning.py:507] global step 8410: loss = 5.0571 (0.513 sec/step)
I0404 21:18:04.467438 47978602034560 learning.py:507] global step 8411: loss = 5.8053 (0.519 sec/step)
I0404 21:18:04.970792 47978602034560 learning.py:507] global step 8412: loss = 6.2729 (0.502 sec/step)
I0404 21:18:05.475342 47978602034560 learning.py:507] global step 8413: loss = 6.3388 (0.502 sec/step)
I0404 21:18:06.007823 47978602034560 learning.py:507] global step 8414: loss = 5.8658 (0.531 sec/step)
I0404 21:18:06.529654 47978602034560 learning.py:507] global step 8415: loss = 6.8258 (0.520 sec/step)
I0404 21:18:07.030797 47978602034560 learning.py:507] global step 8416: loss = 6.1726 (0.500 sec/step)
I0404 21:18:07.550401 47978602034560 learning.py:507] global step 8417: loss = 5.4928 (0.518 sec/step)
I0404 21:18:08.085382 47978602034560 learning.py:507] global step 8418: loss = 6.2280 (0.532 sec/step)
I0404 21:18:08.606032 47978602034560 learning.py:507] global step 8419: loss = 5.0129 (0.519 sec/step)
I0404 21:18:09.122483 47978602034560 learning.py:507] global step 8420: loss = 5.0918 (0.514 sec/step)
I0404 21:18:09.647294 47978602034560 learning.py:507] global step 8421: loss = 6.3567 (0.522 sec/step)
I0404 21:18:10.164202 47978602034560 learning.py:507] global step 8422: loss = 5.6299 (0.515 sec/step)
I0404 21:18:10.667605 47978602034560 learning.py:507] global step 8423: loss = 6.2154 (0.502 sec/step)
I0404 21:18:11.202229 47978602034560 learning.py:507] global step 8424: loss = 5.8457 (0.533 sec/step)
I0404 21:18:11.704386 47978602034560 learning.py:507] global step 8425: loss = 4.9864 (0.501 sec/step)
I0404 21:18:12.217702 47978602034560 learning.py:507] global step 8426: loss = 5.1195 (0.512 sec/step)
I0404 21:18:12.754734 47978602034560 learning.py:507] global step 8427: loss = 5.5047 (0.535 sec/step)
I0404 21:18:13.265585 47978602034560 learning.py:507] global step 8428: loss = 5.7873 (0.509 sec/step)
I0404 21:18:13.779091 47978602034560 learning.py:507] global step 8429: loss = 5.9606 (0.512 sec/step)
I0404 21:18:14.285973 47978602034560 learning.py:507] global step 8430: loss = 6.2064 (0.505 sec/step)
I0404 21:18:14.821578 47978602034560 learning.py:507] global step 8431: loss = 5.6041 (0.534 sec/step)
I0404 21:18:15.333131 47978602034560 learning.py:507] global step 8432: loss = 6.2084 (0.510 sec/step)
I0404 21:18:15.851170 47978602034560 learning.py:507] global step 8433: loss = 6.8443 (0.516 sec/step)
I0404 21:18:16.362372 47978602034560 learning.py:507] global step 8434: loss = 5.3828 (0.510 sec/step)
I0404 21:18:16.885952 47978602034560 learning.py:507] global step 8435: loss = 6.1769 (0.522 sec/step)
I0404 21:18:17.418149 47978602034560 learning.py:507] global step 8436: loss = 6.9762 (0.531 sec/step)
I0404 21:18:17.923792 47978602034560 learning.py:507] global step 8437: loss = 6.1505 (0.504 sec/step)
I0404 21:18:18.448838 47978602034560 learning.py:507] global step 8438: loss = 5.7322 (0.524 sec/step)
I0404 21:18:18.971252 47978602034560 learning.py:507] global step 8439: loss = 5.5850 (0.521 sec/step)
I0404 21:18:19.491163 47978602034560 learning.py:507] global step 8440: loss = 6.4123 (0.518 sec/step)
I0404 21:18:20.002721 47978602034560 learning.py:507] global step 8441: loss = 6.6296 (0.510 sec/step)
I0404 21:18:20.535743 47978602034560 learning.py:507] global step 8442: loss = 5.6237 (0.531 sec/step)
I0404 21:18:21.046687 47978602034560 learning.py:507] global step 8443: loss = 5.0224 (0.509 sec/step)
I0404 21:18:21.552001 47978602034560 learning.py:507] global step 8444: loss = 5.5065 (0.504 sec/step)
I0404 21:18:22.069218 47978602034560 learning.py:507] global step 8445: loss = 6.1509 (0.516 sec/step)
I0404 21:18:22.584745 47978602034560 learning.py:507] global step 8446: loss = 6.2741 (0.514 sec/step)
I0404 21:18:23.118241 47978602034560 learning.py:507] global step 8447: loss = 5.6745 (0.532 sec/step)
I0404 21:18:23.626777 47978602034560 learning.py:507] global step 8448: loss = 5.2777 (0.507 sec/step)
I0404 21:18:24.159808 47978602034560 learning.py:507] global step 8449: loss = 6.4922 (0.530 sec/step)
I0404 21:18:24.668663 47978602034560 learning.py:507] global step 8450: loss = 5.1735 (0.507 sec/step)
I0404 21:18:25.176775 47978602034560 learning.py:507] global step 8451: loss = 5.8576 (0.507 sec/step)
I0404 21:18:25.693521 47978602034560 learning.py:507] global step 8452: loss = 6.2091 (0.515 sec/step)
I0404 21:18:26.207420 47978602034560 learning.py:507] global step 8453: loss = 6.2219 (0.512 sec/step)
I0404 21:18:26.711857 47978602034560 learning.py:507] global step 8454: loss = 7.0160 (0.503 sec/step)
I0404 21:18:27.227254 47978602034560 learning.py:507] global step 8455: loss = 6.5852 (0.513 sec/step)
I0404 21:18:27.773359 47978602034560 learning.py:507] global step 8456: loss = 5.1114 (0.545 sec/step)
I0404 21:18:28.277186 47978602034560 learning.py:507] global step 8457: loss = 6.3681 (0.502 sec/step)
I0404 21:18:28.781797 47978602034560 learning.py:507] global step 8458: loss = 6.1616 (0.503 sec/step)
I0404 21:18:29.304858 47978602034560 learning.py:507] global step 8459: loss = 6.2842 (0.522 sec/step)
I0404 21:18:29.847601 47978602034560 learning.py:507] global step 8460: loss = 5.9490 (0.541 sec/step)
I0404 21:18:30.372204 47978602034560 learning.py:507] global step 8461: loss = 5.6327 (0.522 sec/step)
I0404 21:18:30.899000 47978602034560 learning.py:507] global step 8462: loss = 5.1419 (0.525 sec/step)
I0404 21:18:31.406088 47978602034560 learning.py:507] global step 8463: loss = 6.3855 (0.506 sec/step)
I0404 21:18:31.920431 47978602034560 learning.py:507] global step 8464: loss = 6.0247 (0.513 sec/step)
I0404 21:18:32.452270 47978602034560 learning.py:507] global step 8465: loss = 5.8585 (0.529 sec/step)
I0404 21:18:32.961847 47978602034560 learning.py:507] global step 8466: loss = 6.9018 (0.508 sec/step)
I0404 21:18:33.466690 47978602034560 learning.py:507] global step 8467: loss = 5.5363 (0.502 sec/step)
I0404 21:18:33.988282 47978602034560 learning.py:507] global step 8468: loss = 5.1734 (0.519 sec/step)
I0404 21:18:34.500577 47978602034560 learning.py:507] global step 8469: loss = 5.9172 (0.511 sec/step)
I0404 21:18:35.008144 47978602034560 learning.py:507] global step 8470: loss = 5.5329 (0.505 sec/step)
I0404 21:18:35.519173 47978602034560 learning.py:507] global step 8471: loss = 5.4021 (0.509 sec/step)
I0404 21:18:36.032129 47978602034560 learning.py:507] global step 8472: loss = 5.3711 (0.511 sec/step)
I0404 21:18:36.543498 47978602034560 learning.py:507] global step 8473: loss = 7.0128 (0.508 sec/step)
I0404 21:18:37.052881 47978602034560 learning.py:507] global step 8474: loss = 6.4096 (0.506 sec/step)
I0404 21:18:37.588281 47978602034560 learning.py:507] global step 8475: loss = 6.7754 (0.534 sec/step)
I0404 21:18:38.101000 47978602034560 learning.py:507] global step 8476: loss = 6.4303 (0.511 sec/step)
I0404 21:18:38.606059 47978602034560 learning.py:507] global step 8477: loss = 6.1377 (0.503 sec/step)
I0404 21:18:39.119239 47978602034560 learning.py:507] global step 8478: loss = 5.3292 (0.512 sec/step)
I0404 21:18:39.649286 47978602034560 learning.py:507] global step 8479: loss = 5.6535 (0.527 sec/step)
I0404 21:18:40.183367 47978602034560 learning.py:507] global step 8480: loss = 4.8334 (0.533 sec/step)
I0404 21:18:40.694687 47978602034560 learning.py:507] global step 8481: loss = 4.4368 (0.508 sec/step)
I0404 21:18:41.206724 47978602034560 learning.py:507] global step 8482: loss = 6.4221 (0.510 sec/step)
I0404 21:18:41.720427 47978602034560 learning.py:507] global step 8483: loss = 5.6624 (0.512 sec/step)
I0404 21:18:42.236164 47978602034560 learning.py:507] global step 8484: loss = 5.9290 (0.514 sec/step)
I0404 21:18:42.756599 47978602034560 learning.py:507] global step 8485: loss = 5.6291 (0.517 sec/step)
I0404 21:18:43.292642 47978602034560 learning.py:507] global step 8486: loss = 6.2052 (0.534 sec/step)
I0404 21:18:43.798464 47978602034560 learning.py:507] global step 8487: loss = 6.5320 (0.504 sec/step)
I0404 21:18:44.321432 47978602034560 learning.py:507] global step 8488: loss = 6.0813 (0.521 sec/step)
I0404 21:18:44.843786 47978602034560 learning.py:507] global step 8489: loss = 5.8864 (0.521 sec/step)
I0404 21:18:45.353683 47978602034560 learning.py:507] global step 8490: loss = 6.2783 (0.508 sec/step)
I0404 21:18:45.882858 47978602034560 learning.py:507] global step 8491: loss = 6.1781 (0.528 sec/step)
I0404 21:18:46.398045 47978602034560 learning.py:507] global step 8492: loss = 5.5898 (0.514 sec/step)
I0404 21:18:46.902737 47978602034560 learning.py:507] global step 8493: loss = 6.2116 (0.503 sec/step)
I0404 21:18:47.401874 47978602034560 learning.py:507] global step 8494: loss = 6.7695 (0.498 sec/step)
I0404 21:18:47.912864 47978602034560 learning.py:507] global step 8495: loss = 5.6705 (0.508 sec/step)
I0404 21:18:48.414673 47978602034560 learning.py:507] global step 8496: loss = 5.0149 (0.499 sec/step)
I0404 21:18:48.940208 47978602034560 learning.py:507] global step 8497: loss = 6.6509 (0.524 sec/step)
I0404 21:18:49.462237 47978602034560 learning.py:507] global step 8498: loss = 5.5376 (0.520 sec/step)
I0404 21:18:49.980222 47978602034560 learning.py:507] global step 8499: loss = 5.4029 (0.515 sec/step)
I0404 21:18:50.491885 47978602034560 learning.py:507] global step 8500: loss = 5.8892 (0.510 sec/step)
I0404 21:18:50.994548 47978602034560 learning.py:507] global step 8501: loss = 4.9858 (0.501 sec/step)
I0404 21:18:51.493840 47978602034560 learning.py:507] global step 8502: loss = 5.4251 (0.498 sec/step)
I0404 21:18:52.005873 47978602034560 learning.py:507] global step 8503: loss = 6.0427 (0.510 sec/step)
I0404 21:18:52.510280 47978602034560 learning.py:507] global step 8504: loss = 5.8458 (0.502 sec/step)
I0404 21:18:53.034278 47978602034560 learning.py:507] global step 8505: loss = 5.4245 (0.522 sec/step)
I0404 21:18:53.542679 47978602034560 learning.py:507] global step 8506: loss = 5.1395 (0.507 sec/step)
I0404 21:18:54.077600 47978602034560 learning.py:507] global step 8507: loss = 5.6354 (0.532 sec/step)
I0404 21:18:54.592340 47978602034560 learning.py:507] global step 8508: loss = 6.0495 (0.513 sec/step)
I0404 21:18:55.111824 47978602034560 learning.py:507] global step 8509: loss = 6.9640 (0.518 sec/step)
I0404 21:18:55.618112 47978602034560 learning.py:507] global step 8510: loss = 6.2475 (0.505 sec/step)
I0404 21:18:56.128631 47978602034560 learning.py:507] global step 8511: loss = 6.2198 (0.509 sec/step)
I0404 21:18:56.644455 47978602034560 learning.py:507] global step 8512: loss = 5.4201 (0.514 sec/step)
I0404 21:18:57.188234 47978602034560 learning.py:507] global step 8513: loss = 4.9331 (0.542 sec/step)
I0404 21:18:57.728122 47978602034560 learning.py:507] global step 8514: loss = 5.6208 (0.538 sec/step)
I0404 21:18:58.262290 47978602034560 learning.py:507] global step 8515: loss = 5.9682 (0.533 sec/step)
I0404 21:18:58.787383 47978602034560 learning.py:507] global step 8516: loss = 5.5850 (0.522 sec/step)
I0404 21:18:59.315626 47978602034560 learning.py:507] global step 8517: loss = 6.3791 (0.527 sec/step)
I0404 21:18:59.829519 47978602034560 learning.py:507] global step 8518: loss = 6.3808 (0.512 sec/step)
I0404 21:19:00.345509 47978602034560 learning.py:507] global step 8519: loss = 5.4642 (0.514 sec/step)
I0404 21:19:00.860519 47978602034560 learning.py:507] global step 8520: loss = 4.8631 (0.513 sec/step)
I0404 21:19:01.378154 47978602034560 learning.py:507] global step 8521: loss = 6.8744 (0.516 sec/step)
I0404 21:19:01.894022 47978602034560 learning.py:507] global step 8522: loss = 5.0010 (0.513 sec/step)
I0404 21:19:02.410243 47978602034560 learning.py:507] global step 8523: loss = 5.5746 (0.513 sec/step)
I0404 21:19:02.934735 47978602034560 learning.py:507] global step 8524: loss = 5.3955 (0.523 sec/step)
I0404 21:19:03.434046 47978602034560 learning.py:507] global step 8525: loss = 6.1404 (0.498 sec/step)
I0404 21:19:03.972152 47978602034560 learning.py:507] global step 8526: loss = 5.3399 (0.536 sec/step)
I0404 21:19:04.489882 47978602034560 learning.py:507] global step 8527: loss = 4.7229 (0.516 sec/step)
I0404 21:19:05.023155 47978602034560 learning.py:507] global step 8528: loss = 5.2727 (0.532 sec/step)
I0404 21:19:05.533049 47978602034560 learning.py:507] global step 8529: loss = 6.2160 (0.508 sec/step)
I0404 21:19:06.051756 47978602034560 learning.py:507] global step 8530: loss = 5.9529 (0.516 sec/step)
I0404 21:19:06.570463 47978602034560 learning.py:507] global step 8531: loss = 6.1210 (0.517 sec/step)
I0404 21:19:07.085222 47978602034560 learning.py:507] global step 8532: loss = 5.6156 (0.513 sec/step)
I0404 21:19:07.622008 47978602034560 learning.py:507] global step 8533: loss = 5.4497 (0.535 sec/step)
I0404 21:19:08.125358 47978602034560 learning.py:507] global step 8534: loss = 5.9019 (0.502 sec/step)
I0404 21:19:08.644021 47978602034560 learning.py:507] global step 8535: loss = 5.9608 (0.517 sec/step)
I0404 21:19:09.146407 47978602034560 learning.py:507] global step 8536: loss = 5.2351 (0.500 sec/step)
I0404 21:19:09.653213 47978602034560 learning.py:507] global step 8537: loss = 4.5756 (0.503 sec/step)
I0404 21:19:10.160950 47978602034560 learning.py:507] global step 8538: loss = 5.9334 (0.506 sec/step)
I0404 21:19:10.671009 47978602034560 learning.py:507] global step 8539: loss = 4.9630 (0.508 sec/step)
I0404 21:19:11.181170 47978602034560 learning.py:507] global step 8540: loss = 5.5935 (0.509 sec/step)
I0404 21:19:11.687291 47978602034560 learning.py:507] global step 8541: loss = 5.6037 (0.505 sec/step)
I0404 21:19:12.211903 47978602034560 learning.py:507] global step 8542: loss = 6.0802 (0.523 sec/step)
I0404 21:19:12.725034 47978602034560 learning.py:507] global step 8543: loss = 4.9354 (0.512 sec/step)
I0404 21:19:13.238760 47978602034560 learning.py:507] global step 8544: loss = 5.6986 (0.511 sec/step)
I0404 21:19:13.749158 47978602034560 learning.py:507] global step 8545: loss = 5.9150 (0.508 sec/step)
I0404 21:19:14.254225 47978602034560 learning.py:507] global step 8546: loss = 6.5948 (0.504 sec/step)
I0404 21:19:14.763497 47978602034560 learning.py:507] global step 8547: loss = 5.2231 (0.508 sec/step)
I0404 21:19:15.303332 47978602034560 learning.py:507] global step 8548: loss = 5.3658 (0.538 sec/step)
I0404 21:19:15.804754 47978602034560 learning.py:507] global step 8549: loss = 5.8443 (0.500 sec/step)
I0404 21:19:16.344208 47978602034560 learning.py:507] global step 8550: loss = 6.0765 (0.538 sec/step)
I0404 21:19:16.870312 47978602034560 learning.py:507] global step 8551: loss = 5.6745 (0.515 sec/step)
I0404 21:19:17.236322 47983661975296 supervisor.py:1050] Recording summary at step 8551.
I0404 21:19:17.559088 47978602034560 learning.py:507] global step 8552: loss = 6.3874 (0.685 sec/step)
I0404 21:19:18.069698 47978602034560 learning.py:507] global step 8553: loss = 5.5336 (0.509 sec/step)
I0404 21:19:18.585636 47978602034560 learning.py:507] global step 8554: loss = 6.5055 (0.514 sec/step)
I0404 21:19:19.115918 47978602034560 learning.py:507] global step 8555: loss = 5.9404 (0.529 sec/step)
I0404 21:19:19.624892 47978602034560 learning.py:507] global step 8556: loss = 6.4220 (0.507 sec/step)
I0404 21:19:20.153377 47978602034560 learning.py:507] global step 8557: loss = 6.4987 (0.527 sec/step)
I0404 21:19:20.661486 47978602034560 learning.py:507] global step 8558: loss = 5.4193 (0.507 sec/step)
I0404 21:19:21.170092 47978602034560 learning.py:507] global step 8559: loss = 4.9569 (0.506 sec/step)
I0404 21:19:21.668844 47978602034560 learning.py:507] global step 8560: loss = 6.2223 (0.496 sec/step)
I0404 21:19:22.210247 47978602034560 learning.py:507] global step 8561: loss = 4.6550 (0.540 sec/step)
I0404 21:19:22.740962 47978602034560 learning.py:507] global step 8562: loss = 5.0087 (0.529 sec/step)
I0404 21:19:23.254187 47978602034560 learning.py:507] global step 8563: loss = 6.6426 (0.510 sec/step)
I0404 21:19:23.759057 47978602034560 learning.py:507] global step 8564: loss = 4.9208 (0.503 sec/step)
I0404 21:19:24.278296 47978602034560 learning.py:507] global step 8565: loss = 5.5168 (0.516 sec/step)
I0404 21:19:24.789426 47978602034560 learning.py:507] global step 8566: loss = 7.0107 (0.508 sec/step)
I0404 21:19:25.303308 47978602034560 learning.py:507] global step 8567: loss = 5.2598 (0.512 sec/step)
I0404 21:19:25.834159 47978602034560 learning.py:507] global step 8568: loss = 5.5189 (0.528 sec/step)
I0404 21:19:26.342672 47978602034560 learning.py:507] global step 8569: loss = 5.8596 (0.506 sec/step)
I0404 21:19:26.873846 47978602034560 learning.py:507] global step 8570: loss = 5.6477 (0.530 sec/step)
I0404 21:19:27.386497 47978602034560 learning.py:507] global step 8571: loss = 5.5808 (0.511 sec/step)
I0404 21:19:27.919006 47978602034560 learning.py:507] global step 8572: loss = 5.1258 (0.531 sec/step)
I0404 21:19:28.440301 47978602034560 learning.py:507] global step 8573: loss = 5.1318 (0.518 sec/step)
I0404 21:19:28.950541 47978602034560 learning.py:507] global step 8574: loss = 5.8225 (0.509 sec/step)
I0404 21:19:29.465152 47978602034560 learning.py:507] global step 8575: loss = 6.0000 (0.513 sec/step)
I0404 21:19:29.984360 47978602034560 learning.py:507] global step 8576: loss = 4.9544 (0.518 sec/step)
I0404 21:19:30.490016 47978602034560 learning.py:507] global step 8577: loss = 4.9892 (0.504 sec/step)
I0404 21:19:31.005630 47978602034560 learning.py:507] global step 8578: loss = 6.6918 (0.513 sec/step)
I0404 21:19:31.540616 47978602034560 learning.py:507] global step 8579: loss = 4.9843 (0.532 sec/step)
I0404 21:19:32.052052 47978602034560 learning.py:507] global step 8580: loss = 5.7312 (0.509 sec/step)
I0404 21:19:32.571135 47978602034560 learning.py:507] global step 8581: loss = 5.7326 (0.518 sec/step)
I0404 21:19:33.104324 47978602034560 learning.py:507] global step 8582: loss = 5.8489 (0.532 sec/step)
I0404 21:19:33.620627 47978602034560 learning.py:507] global step 8583: loss = 5.9799 (0.515 sec/step)
I0404 21:19:34.128771 47978602034560 learning.py:507] global step 8584: loss = 6.0058 (0.507 sec/step)
I0404 21:19:34.642543 47978602034560 learning.py:507] global step 8585: loss = 6.7491 (0.512 sec/step)
I0404 21:19:35.188090 47978602034560 learning.py:507] global step 8586: loss = 5.3600 (0.544 sec/step)
I0404 21:19:35.694650 47978602034560 learning.py:507] global step 8587: loss = 6.6455 (0.504 sec/step)
I0404 21:19:36.206478 47978602034560 learning.py:507] global step 8588: loss = 6.3981 (0.510 sec/step)
I0404 21:19:36.738760 47978602034560 learning.py:507] global step 8589: loss = 6.2940 (0.529 sec/step)
I0404 21:19:37.247032 47978602034560 learning.py:507] global step 8590: loss = 5.1353 (0.507 sec/step)
I0404 21:19:37.750403 47978602034560 learning.py:507] global step 8591: loss = 6.7204 (0.501 sec/step)
I0404 21:19:38.262100 47978602034560 learning.py:507] global step 8592: loss = 5.5343 (0.509 sec/step)
I0404 21:19:38.778604 47978602034560 learning.py:507] global step 8593: loss = 5.7182 (0.515 sec/step)
I0404 21:19:39.284547 47978602034560 learning.py:507] global step 8594: loss = 4.9216 (0.504 sec/step)
I0404 21:19:39.805265 47978602034560 learning.py:507] global step 8595: loss = 5.7261 (0.518 sec/step)
I0404 21:19:40.326145 47978602034560 learning.py:507] global step 8596: loss = 6.1775 (0.519 sec/step)
I0404 21:19:40.846799 47978602034560 learning.py:507] global step 8597: loss = 5.0871 (0.518 sec/step)
I0404 21:19:41.359719 47978602034560 learning.py:507] global step 8598: loss = 6.2588 (0.511 sec/step)
I0404 21:19:41.870751 47978602034560 learning.py:507] global step 8599: loss = 5.5246 (0.509 sec/step)
I0404 21:19:42.405061 47978602034560 learning.py:507] global step 8600: loss = 5.7301 (0.533 sec/step)
I0404 21:19:42.934203 47978602034560 learning.py:507] global step 8601: loss = 4.8803 (0.528 sec/step)
I0404 21:19:43.474981 47978602034560 learning.py:507] global step 8602: loss = 5.9608 (0.539 sec/step)
I0404 21:19:44.005328 47978602034560 learning.py:507] global step 8603: loss = 6.5578 (0.529 sec/step)
I0404 21:19:44.509573 47978602034560 learning.py:507] global step 8604: loss = 6.1607 (0.503 sec/step)
I0404 21:19:45.029258 47978602034560 learning.py:507] global step 8605: loss = 5.1609 (0.518 sec/step)
I0404 21:19:45.551812 47978602034560 learning.py:507] global step 8606: loss = 5.8596 (0.521 sec/step)
I0404 21:19:46.053076 47978602034560 learning.py:507] global step 8607: loss = 5.8463 (0.500 sec/step)
I0404 21:19:46.583061 47978602034560 learning.py:507] global step 8608: loss = 7.1251 (0.527 sec/step)
I0404 21:19:47.104347 47978602034560 learning.py:507] global step 8609: loss = 5.1595 (0.520 sec/step)
I0404 21:19:47.634539 47978602034560 learning.py:507] global step 8610: loss = 5.5941 (0.529 sec/step)
I0404 21:19:48.139741 47978602034560 learning.py:507] global step 8611: loss = 4.8018 (0.504 sec/step)
I0404 21:19:48.671742 47978602034560 learning.py:507] global step 8612: loss = 6.2497 (0.530 sec/step)
I0404 21:19:49.173196 47978602034560 learning.py:507] global step 8613: loss = 5.2189 (0.500 sec/step)
I0404 21:19:49.709994 47978602034560 learning.py:507] global step 8614: loss = 5.5546 (0.535 sec/step)
I0404 21:19:50.233899 47978602034560 learning.py:507] global step 8615: loss = 5.9351 (0.522 sec/step)
I0404 21:19:50.736855 47978602034560 learning.py:507] global step 8616: loss = 5.3736 (0.501 sec/step)
I0404 21:19:51.253865 47978602034560 learning.py:507] global step 8617: loss = 6.3966 (0.515 sec/step)
I0404 21:19:51.801144 47978602034560 learning.py:507] global step 8618: loss = 5.8296 (0.546 sec/step)
I0404 21:19:52.338112 47978602034560 learning.py:507] global step 8619: loss = 6.3635 (0.535 sec/step)
I0404 21:19:52.859653 47978602034560 learning.py:507] global step 8620: loss = 4.5746 (0.520 sec/step)
I0404 21:19:53.364683 47978602034560 learning.py:507] global step 8621: loss = 5.8131 (0.502 sec/step)
I0404 21:19:53.874663 47978602034560 learning.py:507] global step 8622: loss = 6.1863 (0.508 sec/step)
I0404 21:19:54.405511 47978602034560 learning.py:507] global step 8623: loss = 6.4656 (0.528 sec/step)
I0404 21:19:54.915466 47978602034560 learning.py:507] global step 8624: loss = 5.1715 (0.508 sec/step)
I0404 21:19:55.428773 47978602034560 learning.py:507] global step 8625: loss = 5.0357 (0.510 sec/step)
I0404 21:19:55.943780 47978602034560 learning.py:507] global step 8626: loss = 6.2099 (0.512 sec/step)
I0404 21:19:56.454012 47978602034560 learning.py:507] global step 8627: loss = 5.0731 (0.507 sec/step)
I0404 21:19:56.967843 47978602034560 learning.py:507] global step 8628: loss = 5.4184 (0.511 sec/step)
I0404 21:19:57.476417 47978602034560 learning.py:507] global step 8629: loss = 5.4213 (0.507 sec/step)
I0404 21:19:57.985916 47978602034560 learning.py:507] global step 8630: loss = 5.1325 (0.508 sec/step)
I0404 21:19:58.498337 47978602034560 learning.py:507] global step 8631: loss = 7.0184 (0.511 sec/step)
I0404 21:19:59.013757 47978602034560 learning.py:507] global step 8632: loss = 5.3693 (0.514 sec/step)
I0404 21:19:59.522516 47978602034560 learning.py:507] global step 8633: loss = 6.5306 (0.507 sec/step)
I0404 21:20:00.051637 47978602034560 learning.py:507] global step 8634: loss = 4.6612 (0.527 sec/step)
I0404 21:20:00.553528 47978602034560 learning.py:507] global step 8635: loss = 5.6584 (0.500 sec/step)
I0404 21:20:01.068088 47978602034560 learning.py:507] global step 8636: loss = 5.2824 (0.512 sec/step)
I0404 21:20:01.575694 47978602034560 learning.py:507] global step 8637: loss = 6.0898 (0.505 sec/step)
I0404 21:20:02.082378 47978602034560 learning.py:507] global step 8638: loss = 5.9471 (0.504 sec/step)
I0404 21:20:02.626964 47978602034560 learning.py:507] global step 8639: loss = 6.0781 (0.543 sec/step)
I0404 21:20:03.164779 47978602034560 learning.py:507] global step 8640: loss = 5.7734 (0.536 sec/step)
I0404 21:20:03.681284 47978602034560 learning.py:507] global step 8641: loss = 5.0069 (0.515 sec/step)
I0404 21:20:04.184364 47978602034560 learning.py:507] global step 8642: loss = 5.0066 (0.500 sec/step)
I0404 21:20:04.684228 47978602034560 learning.py:507] global step 8643: loss = 5.7998 (0.498 sec/step)
I0404 21:20:05.206404 47978602034560 learning.py:507] global step 8644: loss = 5.9160 (0.519 sec/step)
I0404 21:20:05.728971 47978602034560 learning.py:507] global step 8645: loss = 6.9136 (0.520 sec/step)
I0404 21:20:06.230074 47978602034560 learning.py:507] global step 8646: loss = 6.5186 (0.498 sec/step)
I0404 21:20:06.744891 47978602034560 learning.py:507] global step 8647: loss = 5.7162 (0.513 sec/step)
I0404 21:20:07.275146 47978602034560 learning.py:507] global step 8648: loss = 5.8990 (0.529 sec/step)
I0404 21:20:07.785267 47978602034560 learning.py:507] global step 8649: loss = 5.5961 (0.509 sec/step)
I0404 21:20:08.291647 47978602034560 learning.py:507] global step 8650: loss = 4.9784 (0.505 sec/step)
I0404 21:20:08.828680 47978602034560 learning.py:507] global step 8651: loss = 6.8011 (0.535 sec/step)
I0404 21:20:09.336382 47978602034560 learning.py:507] global step 8652: loss = 6.9670 (0.505 sec/step)
I0404 21:20:09.840278 47978602034560 learning.py:507] global step 8653: loss = 6.2035 (0.501 sec/step)
I0404 21:20:10.361406 47978602034560 learning.py:507] global step 8654: loss = 6.6648 (0.520 sec/step)
I0404 21:20:10.892368 47978602034560 learning.py:507] global step 8655: loss = 6.8284 (0.529 sec/step)
I0404 21:20:11.398306 47978602034560 learning.py:507] global step 8656: loss = 5.5123 (0.504 sec/step)
I0404 21:20:11.904944 47978602034560 learning.py:507] global step 8657: loss = 5.4455 (0.505 sec/step)
I0404 21:20:12.417331 47978602034560 learning.py:507] global step 8658: loss = 5.7223 (0.511 sec/step)
I0404 21:20:12.939697 47978602034560 learning.py:507] global step 8659: loss = 6.0869 (0.521 sec/step)
I0404 21:20:13.448221 47978602034560 learning.py:507] global step 8660: loss = 5.2575 (0.507 sec/step)
I0404 21:20:13.956679 47978602034560 learning.py:507] global step 8661: loss = 5.8160 (0.507 sec/step)
I0404 21:20:14.465670 47978602034560 learning.py:507] global step 8662: loss = 5.7329 (0.507 sec/step)
I0404 21:20:14.968009 47978602034560 learning.py:507] global step 8663: loss = 5.4826 (0.501 sec/step)
I0404 21:20:15.476124 47978602034560 learning.py:507] global step 8664: loss = 6.5659 (0.507 sec/step)
I0404 21:20:16.011667 47978602034560 learning.py:507] global step 8665: loss = 5.8590 (0.533 sec/step)
I0404 21:20:16.535287 47978602034560 learning.py:507] global step 8666: loss = 5.5855 (0.522 sec/step)
I0404 21:20:17.047815 47978602034560 learning.py:507] global step 8667: loss = 4.5959 (0.511 sec/step)
I0404 21:20:17.561112 47978602034560 learning.py:507] global step 8668: loss = 5.9223 (0.510 sec/step)
I0404 21:20:18.089018 47978602034560 learning.py:507] global step 8669: loss = 6.3582 (0.525 sec/step)
I0404 21:20:18.589805 47978602034560 learning.py:507] global step 8670: loss = 5.2977 (0.498 sec/step)
I0404 21:20:19.094620 47978602034560 learning.py:507] global step 8671: loss = 5.9937 (0.502 sec/step)
I0404 21:20:19.608324 47978602034560 learning.py:507] global step 8672: loss = 5.1681 (0.512 sec/step)
I0404 21:20:20.124570 47978602034560 learning.py:507] global step 8673: loss = 6.1537 (0.515 sec/step)
I0404 21:20:20.642442 47978602034560 learning.py:507] global step 8674: loss = 6.1341 (0.515 sec/step)
I0404 21:20:21.150311 47978602034560 learning.py:507] global step 8675: loss = 5.9304 (0.506 sec/step)
I0404 21:20:21.664835 47978602034560 learning.py:507] global step 8676: loss = 6.1790 (0.513 sec/step)
I0404 21:20:22.189510 47978602034560 learning.py:507] global step 8677: loss = 5.2701 (0.523 sec/step)
I0404 21:20:22.703421 47978602034560 learning.py:507] global step 8678: loss = 6.6455 (0.511 sec/step)
I0404 21:20:23.212890 47978602034560 learning.py:507] global step 8679: loss = 5.5794 (0.507 sec/step)
I0404 21:20:23.723923 47978602034560 learning.py:507] global step 8680: loss = 5.6395 (0.508 sec/step)
I0404 21:20:24.241514 47978602034560 learning.py:507] global step 8681: loss = 5.3343 (0.516 sec/step)
I0404 21:20:24.771623 47978602034560 learning.py:507] global step 8682: loss = 6.1601 (0.527 sec/step)
I0404 21:20:25.281696 47978602034560 learning.py:507] global step 8683: loss = 5.5930 (0.507 sec/step)
I0404 21:20:25.821508 47978602034560 learning.py:507] global step 8684: loss = 5.6025 (0.538 sec/step)
I0404 21:20:26.328356 47978602034560 learning.py:507] global step 8685: loss = 4.9980 (0.505 sec/step)
I0404 21:20:26.843559 47978602034560 learning.py:507] global step 8686: loss = 7.1912 (0.512 sec/step)
I0404 21:20:27.364722 47978602034560 learning.py:507] global step 8687: loss = 5.4437 (0.520 sec/step)
I0404 21:20:27.910743 47978602034560 learning.py:507] global step 8688: loss = 6.5066 (0.544 sec/step)
I0404 21:20:28.420523 47978602034560 learning.py:507] global step 8689: loss = 4.9798 (0.507 sec/step)
I0404 21:20:28.922173 47978602034560 learning.py:507] global step 8690: loss = 5.9018 (0.500 sec/step)
I0404 21:20:29.437646 47978602034560 learning.py:507] global step 8691: loss = 6.3625 (0.514 sec/step)
I0404 21:20:29.963940 47978602034560 learning.py:507] global step 8692: loss = 5.7296 (0.525 sec/step)
I0404 21:20:30.470847 47978602034560 learning.py:507] global step 8693: loss = 5.3170 (0.504 sec/step)
I0404 21:20:30.986491 47978602034560 learning.py:507] global step 8694: loss = 5.9043 (0.514 sec/step)
I0404 21:20:31.509014 47978602034560 learning.py:507] global step 8695: loss = 5.8333 (0.520 sec/step)
I0404 21:20:32.027206 47978602034560 learning.py:507] global step 8696: loss = 5.1658 (0.515 sec/step)
I0404 21:20:32.541729 47978602034560 learning.py:507] global step 8697: loss = 7.4457 (0.512 sec/step)
I0404 21:20:33.042961 47978602034560 learning.py:507] global step 8698: loss = 6.4591 (0.499 sec/step)
I0404 21:20:33.557429 47978602034560 learning.py:507] global step 8699: loss = 6.0975 (0.513 sec/step)
I0404 21:20:34.072812 47978602034560 learning.py:507] global step 8700: loss = 5.8900 (0.514 sec/step)
I0404 21:20:34.607929 47978602034560 learning.py:507] global step 8701: loss = 5.5101 (0.533 sec/step)
I0404 21:20:35.117112 47978602034560 learning.py:507] global step 8702: loss = 5.1686 (0.508 sec/step)
I0404 21:20:35.624930 47978602034560 learning.py:507] global step 8703: loss = 5.4984 (0.506 sec/step)
I0404 21:20:36.150293 47978602034560 learning.py:507] global step 8704: loss = 6.2810 (0.524 sec/step)
I0404 21:20:36.656720 47978602034560 learning.py:507] global step 8705: loss = 6.1493 (0.505 sec/step)
I0404 21:20:37.167177 47978602034560 learning.py:507] global step 8706: loss = 5.9108 (0.509 sec/step)
I0404 21:20:37.669143 47978602034560 learning.py:507] global step 8707: loss = 6.7189 (0.500 sec/step)
I0404 21:20:38.175466 47978602034560 learning.py:507] global step 8708: loss = 5.8890 (0.505 sec/step)
I0404 21:20:38.717017 47978602034560 learning.py:507] global step 8709: loss = 5.8488 (0.540 sec/step)
I0404 21:20:39.245959 47978602034560 learning.py:507] global step 8710: loss = 5.3963 (0.527 sec/step)
I0404 21:20:39.758999 47978602034560 learning.py:507] global step 8711: loss = 4.7874 (0.511 sec/step)
I0404 21:20:40.277433 47978602034560 learning.py:507] global step 8712: loss = 7.1602 (0.516 sec/step)
I0404 21:20:40.795707 47978602034560 learning.py:507] global step 8713: loss = 5.7660 (0.517 sec/step)
I0404 21:20:41.312881 47978602034560 learning.py:507] global step 8714: loss = 6.7895 (0.516 sec/step)
I0404 21:20:41.811728 47978602034560 learning.py:507] global step 8715: loss = 6.0902 (0.496 sec/step)
I0404 21:20:42.312321 47978602034560 learning.py:507] global step 8716: loss = 5.7230 (0.499 sec/step)
I0404 21:20:42.817399 47978602034560 learning.py:507] global step 8717: loss = 6.1023 (0.503 sec/step)
I0404 21:20:43.324966 47978602034560 learning.py:507] global step 8718: loss = 5.9194 (0.506 sec/step)
I0404 21:20:43.838445 47978602034560 learning.py:507] global step 8719: loss = 5.4297 (0.512 sec/step)
I0404 21:20:44.369551 47978602034560 learning.py:507] global step 8720: loss = 5.7021 (0.528 sec/step)
I0404 21:20:44.894137 47978602034560 learning.py:507] global step 8721: loss = 6.8764 (0.523 sec/step)
I0404 21:20:45.407516 47978602034560 learning.py:507] global step 8722: loss = 6.2281 (0.512 sec/step)
I0404 21:20:45.920369 47978602034560 learning.py:507] global step 8723: loss = 5.2629 (0.510 sec/step)
I0404 21:20:46.449768 47978602034560 learning.py:507] global step 8724: loss = 5.4655 (0.528 sec/step)
I0404 21:20:46.961740 47978602034560 learning.py:507] global step 8725: loss = 5.6883 (0.510 sec/step)
I0404 21:20:47.466304 47978602034560 learning.py:507] global step 8726: loss = 5.1872 (0.502 sec/step)
I0404 21:20:47.972447 47978602034560 learning.py:507] global step 8727: loss = 5.9684 (0.505 sec/step)
I0404 21:20:48.485302 47978602034560 learning.py:507] global step 8728: loss = 6.0243 (0.510 sec/step)
I0404 21:20:49.009267 47978602034560 learning.py:507] global step 8729: loss = 5.9709 (0.522 sec/step)
I0404 21:20:49.551412 47978602034560 learning.py:507] global step 8730: loss = 5.4810 (0.539 sec/step)
I0404 21:20:50.057755 47978602034560 learning.py:507] global step 8731: loss = 5.7200 (0.503 sec/step)
I0404 21:20:50.567489 47978602034560 learning.py:507] global step 8732: loss = 5.6296 (0.507 sec/step)
I0404 21:20:51.100303 47978602034560 learning.py:507] global step 8733: loss = 6.2560 (0.530 sec/step)
I0404 21:20:51.621544 47978602034560 learning.py:507] global step 8734: loss = 5.2716 (0.520 sec/step)
I0404 21:20:52.132675 47978602034560 learning.py:507] global step 8735: loss = 6.3361 (0.508 sec/step)
I0404 21:20:52.641581 47978602034560 learning.py:507] global step 8736: loss = 6.3339 (0.507 sec/step)
I0404 21:20:53.149560 47978602034560 learning.py:507] global step 8737: loss = 5.2896 (0.506 sec/step)
I0404 21:20:53.674449 47978602034560 learning.py:507] global step 8738: loss = 5.7594 (0.523 sec/step)
I0404 21:20:54.197951 47978602034560 learning.py:507] global step 8739: loss = 5.8602 (0.522 sec/step)
I0404 21:20:54.719094 47978602034560 learning.py:507] global step 8740: loss = 5.4388 (0.520 sec/step)
I0404 21:20:55.236967 47978602034560 learning.py:507] global step 8741: loss = 5.8592 (0.515 sec/step)
I0404 21:20:55.766628 47978602034560 learning.py:507] global step 8742: loss = 5.5191 (0.527 sec/step)
I0404 21:20:56.281431 47978602034560 learning.py:507] global step 8743: loss = 6.0800 (0.513 sec/step)
I0404 21:20:56.796175 47978602034560 learning.py:507] global step 8744: loss = 6.5119 (0.513 sec/step)
I0404 21:20:57.318293 47978602034560 learning.py:507] global step 8745: loss = 5.4521 (0.521 sec/step)
I0404 21:20:57.843359 47978602034560 learning.py:507] global step 8746: loss = 5.4985 (0.524 sec/step)
I0404 21:20:58.351757 47978602034560 learning.py:507] global step 8747: loss = 6.4398 (0.507 sec/step)
I0404 21:20:58.851095 47978602034560 learning.py:507] global step 8748: loss = 4.5469 (0.498 sec/step)
I0404 21:20:59.368617 47978602034560 learning.py:507] global step 8749: loss = 6.0227 (0.516 sec/step)
I0404 21:20:59.905957 47978602034560 learning.py:507] global step 8750: loss = 5.6573 (0.536 sec/step)
I0404 21:21:00.418004 47978602034560 learning.py:507] global step 8751: loss = 6.2764 (0.511 sec/step)
I0404 21:21:00.931620 47978602034560 learning.py:507] global step 8752: loss = 5.7184 (0.511 sec/step)
I0404 21:21:01.461004 47978602034560 learning.py:507] global step 8753: loss = 4.9748 (0.526 sec/step)
I0404 21:21:01.969799 47978602034560 learning.py:507] global step 8754: loss = 6.5984 (0.507 sec/step)
I0404 21:21:02.482188 47978602034560 learning.py:507] global step 8755: loss = 5.0899 (0.511 sec/step)
I0404 21:21:02.991329 47978602034560 learning.py:507] global step 8756: loss = 4.9344 (0.506 sec/step)
I0404 21:21:03.526005 47978602034560 learning.py:507] global step 8757: loss = 6.1556 (0.532 sec/step)
I0404 21:21:04.065213 47978602034560 learning.py:507] global step 8758: loss = 6.5617 (0.538 sec/step)
I0404 21:21:04.579206 47978602034560 learning.py:507] global step 8759: loss = 5.8082 (0.511 sec/step)
I0404 21:21:05.088288 47978602034560 learning.py:507] global step 8760: loss = 4.4818 (0.508 sec/step)
I0404 21:21:05.621921 47978602034560 learning.py:507] global step 8761: loss = 6.4288 (0.532 sec/step)
I0404 21:21:06.134690 47978602034560 learning.py:507] global step 8762: loss = 6.6153 (0.510 sec/step)
I0404 21:21:06.641174 47978602034560 learning.py:507] global step 8763: loss = 5.2849 (0.505 sec/step)
I0404 21:21:07.178708 47978602034560 learning.py:507] global step 8764: loss = 5.7160 (0.536 sec/step)
I0404 21:21:07.697654 47978602034560 learning.py:507] global step 8765: loss = 6.5516 (0.517 sec/step)
I0404 21:21:08.214696 47978602034560 learning.py:507] global step 8766: loss = 5.4220 (0.514 sec/step)
I0404 21:21:08.732622 47978602034560 learning.py:507] global step 8767: loss = 6.0928 (0.516 sec/step)
I0404 21:21:09.245414 47978602034560 learning.py:507] global step 8768: loss = 6.4522 (0.511 sec/step)
I0404 21:21:09.746741 47978602034560 learning.py:507] global step 8769: loss = 5.1447 (0.500 sec/step)
I0404 21:21:10.279792 47978602034560 learning.py:507] global step 8770: loss = 5.6921 (0.531 sec/step)
I0404 21:21:10.783697 47978602034560 learning.py:507] global step 8771: loss = 6.7470 (0.502 sec/step)
I0404 21:21:11.291623 47978602034560 learning.py:507] global step 8772: loss = 6.0229 (0.505 sec/step)
I0404 21:21:11.792562 47978602034560 learning.py:507] global step 8773: loss = 4.3193 (0.499 sec/step)
I0404 21:21:12.303808 47978602034560 learning.py:507] global step 8774: loss = 5.0083 (0.508 sec/step)
I0404 21:21:12.811772 47978602034560 learning.py:507] global step 8775: loss = 5.8700 (0.506 sec/step)
I0404 21:21:13.340073 47978602034560 learning.py:507] global step 8776: loss = 5.9845 (0.527 sec/step)
I0404 21:21:13.881958 47978602034560 learning.py:507] global step 8777: loss = 5.2998 (0.540 sec/step)
I0404 21:21:14.394764 47978602034560 learning.py:507] global step 8778: loss = 5.8717 (0.511 sec/step)
I0404 21:21:14.912829 47978602034560 learning.py:507] global step 8779: loss = 4.3830 (0.516 sec/step)
I0404 21:21:15.418766 47978602034560 learning.py:507] global step 8780: loss = 4.8596 (0.504 sec/step)
I0404 21:21:15.923002 47978602034560 learning.py:507] global step 8781: loss = 5.6568 (0.503 sec/step)
I0404 21:21:16.431047 47978602034560 learning.py:507] global step 8782: loss = 5.0254 (0.507 sec/step)
I0404 21:21:16.942545 47978602034560 learning.py:507] global step 8783: loss = 5.6064 (0.509 sec/step)
I0404 21:21:17.318822 47983661975296 supervisor.py:1050] Recording summary at step 8783.
I0404 21:21:17.644015 47978602034560 learning.py:507] global step 8784: loss = 6.9689 (0.698 sec/step)
I0404 21:21:18.170305 47978602034560 learning.py:507] global step 8785: loss = 6.0836 (0.525 sec/step)
I0404 21:21:18.682739 47978602034560 learning.py:507] global step 8786: loss = 6.7040 (0.511 sec/step)
I0404 21:21:19.183500 47978602034560 learning.py:507] global step 8787: loss = 6.1319 (0.499 sec/step)
I0404 21:21:19.687585 47978602034560 learning.py:507] global step 8788: loss = 6.1520 (0.502 sec/step)
I0404 21:21:20.206176 47978602034560 learning.py:507] global step 8789: loss = 5.9724 (0.517 sec/step)
I0404 21:21:20.708682 47978602034560 learning.py:507] global step 8790: loss = 6.7553 (0.500 sec/step)
I0404 21:21:21.216649 47978602034560 learning.py:507] global step 8791: loss = 6.5197 (0.506 sec/step)
I0404 21:21:21.753116 47978602034560 learning.py:507] global step 8792: loss = 5.2352 (0.534 sec/step)
I0404 21:21:22.284871 47978602034560 learning.py:507] global step 8793: loss = 5.4906 (0.529 sec/step)
I0404 21:21:22.816321 47978602034560 learning.py:507] global step 8794: loss = 5.9251 (0.529 sec/step)
I0404 21:21:23.318830 47978602034560 learning.py:507] global step 8795: loss = 6.1168 (0.500 sec/step)
I0404 21:21:23.832094 47978602034560 learning.py:507] global step 8796: loss = 5.8610 (0.511 sec/step)
I0404 21:21:24.333817 47978602034560 learning.py:507] global step 8797: loss = 7.3824 (0.500 sec/step)
I0404 21:21:24.839413 47978602034560 learning.py:507] global step 8798: loss = 5.4314 (0.504 sec/step)
I0404 21:21:25.375016 47978602034560 learning.py:507] global step 8799: loss = 5.2361 (0.534 sec/step)
I0404 21:21:25.902914 47978602034560 learning.py:507] global step 8800: loss = 6.1791 (0.526 sec/step)
I0404 21:21:26.424691 47978602034560 learning.py:507] global step 8801: loss = 6.9227 (0.519 sec/step)
I0404 21:21:26.946070 47978602034560 learning.py:507] global step 8802: loss = 6.5582 (0.518 sec/step)
I0404 21:21:27.455067 47978602034560 learning.py:507] global step 8803: loss = 5.7597 (0.507 sec/step)
I0404 21:21:27.977514 47978602034560 learning.py:507] global step 8804: loss = 6.0488 (0.521 sec/step)
I0404 21:21:28.507666 47978602034560 learning.py:507] global step 8805: loss = 5.0041 (0.529 sec/step)
I0404 21:21:29.026613 47978602034560 learning.py:507] global step 8806: loss = 5.6647 (0.517 sec/step)
I0404 21:21:29.530334 47978602034560 learning.py:507] global step 8807: loss = 5.4135 (0.502 sec/step)
I0404 21:21:30.043691 47978602034560 learning.py:507] global step 8808: loss = 6.5649 (0.512 sec/step)
I0404 21:21:30.555378 47978602034560 learning.py:507] global step 8809: loss = 4.8462 (0.510 sec/step)
I0404 21:21:31.059239 47978602034560 learning.py:507] global step 8810: loss = 6.7408 (0.501 sec/step)
I0404 21:21:31.576580 47978602034560 learning.py:507] global step 8811: loss = 6.3660 (0.516 sec/step)
I0404 21:21:32.079558 47978602034560 learning.py:507] global step 8812: loss = 6.3114 (0.501 sec/step)
I0404 21:21:32.600110 47978602034560 learning.py:507] global step 8813: loss = 5.8591 (0.519 sec/step)
I0404 21:21:33.108112 47978602034560 learning.py:507] global step 8814: loss = 5.4869 (0.506 sec/step)
I0404 21:21:33.616490 47978602034560 learning.py:507] global step 8815: loss = 5.8216 (0.507 sec/step)
I0404 21:21:34.122039 47978602034560 learning.py:507] global step 8816: loss = 5.8303 (0.504 sec/step)
I0404 21:21:34.639401 47978602034560 learning.py:507] global step 8817: loss = 4.9953 (0.516 sec/step)
I0404 21:21:35.154570 47978602034560 learning.py:507] global step 8818: loss = 6.5100 (0.514 sec/step)
I0404 21:21:35.685302 47978602034560 learning.py:507] global step 8819: loss = 6.2689 (0.529 sec/step)
I0404 21:21:36.191454 47978602034560 learning.py:507] global step 8820: loss = 6.5771 (0.505 sec/step)
I0404 21:21:36.723735 47978602034560 learning.py:507] global step 8821: loss = 6.1829 (0.531 sec/step)
I0404 21:21:37.234520 47978602034560 learning.py:507] global step 8822: loss = 5.9118 (0.509 sec/step)
I0404 21:21:37.739299 47978602034560 learning.py:507] global step 8823: loss = 5.5401 (0.503 sec/step)
I0404 21:21:38.243020 47978602034560 learning.py:507] global step 8824: loss = 4.7092 (0.502 sec/step)
I0404 21:21:38.770893 47978602034560 learning.py:507] global step 8825: loss = 7.1441 (0.526 sec/step)
I0404 21:21:39.276355 47978602034560 learning.py:507] global step 8826: loss = 5.5969 (0.504 sec/step)
I0404 21:21:39.784668 47978602034560 learning.py:507] global step 8827: loss = 6.2931 (0.507 sec/step)
I0404 21:21:40.312111 47978602034560 learning.py:507] global step 8828: loss = 5.1955 (0.526 sec/step)
I0404 21:21:40.819516 47978602034560 learning.py:507] global step 8829: loss = 5.0135 (0.506 sec/step)
I0404 21:21:41.356169 47978602034560 learning.py:507] global step 8830: loss = 6.0947 (0.535 sec/step)
I0404 21:21:41.859502 47978602034560 learning.py:507] global step 8831: loss = 6.1363 (0.502 sec/step)
I0404 21:21:42.363154 47978602034560 learning.py:507] global step 8832: loss = 5.4485 (0.502 sec/step)
I0404 21:21:42.871027 47978602034560 learning.py:507] global step 8833: loss = 6.8747 (0.506 sec/step)
I0404 21:21:43.392494 47978602034560 learning.py:507] global step 8834: loss = 6.3747 (0.520 sec/step)
I0404 21:21:43.892582 47978602034560 learning.py:507] global step 8835: loss = 6.5833 (0.497 sec/step)
I0404 21:21:44.403104 47978602034560 learning.py:507] global step 8836: loss = 6.5700 (0.508 sec/step)
I0404 21:21:44.944207 47978602034560 learning.py:507] global step 8837: loss = 5.5793 (0.540 sec/step)
I0404 21:21:45.466923 47978602034560 learning.py:507] global step 8838: loss = 6.1873 (0.521 sec/step)
I0404 21:21:45.979882 47978602034560 learning.py:507] global step 8839: loss = 6.2374 (0.509 sec/step)
I0404 21:21:46.514756 47978602034560 learning.py:507] global step 8840: loss = 5.5529 (0.533 sec/step)
I0404 21:21:47.029801 47978602034560 learning.py:507] global step 8841: loss = 4.9548 (0.513 sec/step)
I0404 21:21:47.544086 47978602034560 learning.py:507] global step 8842: loss = 6.4475 (0.511 sec/step)
I0404 21:21:48.056953 47978602034560 learning.py:507] global step 8843: loss = 6.0237 (0.510 sec/step)
I0404 21:21:48.575312 47978602034560 learning.py:507] global step 8844: loss = 5.2852 (0.517 sec/step)
I0404 21:21:49.096064 47978602034560 learning.py:507] global step 8845: loss = 5.4936 (0.519 sec/step)
I0404 21:21:49.609577 47978602034560 learning.py:507] global step 8846: loss = 5.8248 (0.512 sec/step)
I0404 21:21:50.113517 47978602034560 learning.py:507] global step 8847: loss = 6.1085 (0.502 sec/step)
I0404 21:21:50.650781 47978602034560 learning.py:507] global step 8848: loss = 5.2921 (0.536 sec/step)
I0404 21:21:51.158886 47978602034560 learning.py:507] global step 8849: loss = 5.3299 (0.507 sec/step)
I0404 21:21:51.662447 47978602034560 learning.py:507] global step 8850: loss = 5.3966 (0.501 sec/step)
I0404 21:21:52.175983 47978602034560 learning.py:507] global step 8851: loss = 6.3646 (0.511 sec/step)
I0404 21:21:52.700611 47978602034560 learning.py:507] global step 8852: loss = 5.4557 (0.523 sec/step)
I0404 21:21:53.218556 47978602034560 learning.py:507] global step 8853: loss = 6.6468 (0.516 sec/step)
I0404 21:21:53.725402 47978602034560 learning.py:507] global step 8854: loss = 6.4614 (0.504 sec/step)
I0404 21:21:54.241679 47978602034560 learning.py:507] global step 8855: loss = 5.2959 (0.515 sec/step)
I0404 21:21:54.755284 47978602034560 learning.py:507] global step 8856: loss = 4.9396 (0.512 sec/step)
I0404 21:21:55.267735 47978602034560 learning.py:507] global step 8857: loss = 4.9862 (0.511 sec/step)
I0404 21:21:55.795823 47978602034560 learning.py:507] global step 8858: loss = 4.4098 (0.527 sec/step)
I0404 21:21:56.311236 47978602034560 learning.py:507] global step 8859: loss = 6.3199 (0.513 sec/step)
I0404 21:21:56.825824 47978602034560 learning.py:507] global step 8860: loss = 5.0415 (0.512 sec/step)
I0404 21:21:57.346484 47978602034560 learning.py:507] global step 8861: loss = 5.0265 (0.518 sec/step)
I0404 21:21:57.860585 47978602034560 learning.py:507] global step 8862: loss = 5.1623 (0.512 sec/step)
I0404 21:21:58.373391 47978602034560 learning.py:507] global step 8863: loss = 5.8538 (0.511 sec/step)
I0404 21:21:58.883292 47978602034560 learning.py:507] global step 8864: loss = 5.9615 (0.508 sec/step)
I0404 21:21:59.394371 47978602034560 learning.py:507] global step 8865: loss = 4.8800 (0.510 sec/step)
I0404 21:21:59.905670 47978602034560 learning.py:507] global step 8866: loss = 6.0030 (0.510 sec/step)
I0404 21:22:00.425295 47978602034560 learning.py:507] global step 8867: loss = 6.5322 (0.518 sec/step)
I0404 21:22:00.936990 47978602034560 learning.py:507] global step 8868: loss = 5.3721 (0.510 sec/step)
I0404 21:22:01.456212 47978602034560 learning.py:507] global step 8869: loss = 6.6960 (0.516 sec/step)
I0404 21:22:01.964490 47978602034560 learning.py:507] global step 8870: loss = 6.7136 (0.507 sec/step)
I0404 21:22:02.475898 47978602034560 learning.py:507] global step 8871: loss = 5.5496 (0.510 sec/step)
I0404 21:22:03.010095 47978602034560 learning.py:507] global step 8872: loss = 6.4916 (0.531 sec/step)
I0404 21:22:03.515287 47978602034560 learning.py:507] global step 8873: loss = 6.4798 (0.504 sec/step)
I0404 21:22:04.035335 47978602034560 learning.py:507] global step 8874: loss = 6.1106 (0.518 sec/step)
I0404 21:22:04.546246 47978602034560 learning.py:507] global step 8875: loss = 7.0621 (0.508 sec/step)
I0404 21:22:05.064152 47978602034560 learning.py:507] global step 8876: loss = 6.4073 (0.516 sec/step)
I0404 21:22:05.571736 47978602034560 learning.py:507] global step 8877: loss = 6.3498 (0.506 sec/step)
I0404 21:22:06.081101 47978602034560 learning.py:507] global step 8878: loss = 6.6663 (0.508 sec/step)
I0404 21:22:06.590005 47978602034560 learning.py:507] global step 8879: loss = 7.6513 (0.507 sec/step)
I0404 21:22:07.111983 47978602034560 learning.py:507] global step 8880: loss = 5.4474 (0.520 sec/step)
I0404 21:22:07.621838 47978602034560 learning.py:507] global step 8881: loss = 5.4108 (0.508 sec/step)
I0404 21:22:08.142854 47978602034560 learning.py:507] global step 8882: loss = 5.9291 (0.519 sec/step)
I0404 21:22:08.659241 47978602034560 learning.py:507] global step 8883: loss = 5.4914 (0.515 sec/step)
I0404 21:22:09.195751 47978602034560 learning.py:507] global step 8884: loss = 5.4803 (0.535 sec/step)
I0404 21:22:09.708113 47978602034560 learning.py:507] global step 8885: loss = 5.3639 (0.511 sec/step)
I0404 21:22:10.242429 47978602034560 learning.py:507] global step 8886: loss = 6.0363 (0.533 sec/step)
I0404 21:22:10.762247 47978602034560 learning.py:507] global step 8887: loss = 7.1258 (0.518 sec/step)
I0404 21:22:11.272661 47978602034560 learning.py:507] global step 8888: loss = 5.2582 (0.509 sec/step)
I0404 21:22:11.804953 47978602034560 learning.py:507] global step 8889: loss = 6.3685 (0.531 sec/step)
I0404 21:22:12.319548 47978602034560 learning.py:507] global step 8890: loss = 4.8650 (0.513 sec/step)
I0404 21:22:12.847249 47978602034560 learning.py:507] global step 8891: loss = 5.6260 (0.525 sec/step)
I0404 21:22:13.369651 47978602034560 learning.py:507] global step 8892: loss = 5.4100 (0.521 sec/step)
I0404 21:22:13.902442 47978602034560 learning.py:507] global step 8893: loss = 5.9821 (0.531 sec/step)
I0404 21:22:14.410822 47978602034560 learning.py:507] global step 8894: loss = 6.3183 (0.506 sec/step)
I0404 21:22:14.925858 47978602034560 learning.py:507] global step 8895: loss = 4.9965 (0.513 sec/step)
I0404 21:22:15.428049 47978602034560 learning.py:507] global step 8896: loss = 4.9212 (0.499 sec/step)
I0404 21:22:15.938183 47978602034560 learning.py:507] global step 8897: loss = 5.4248 (0.509 sec/step)
I0404 21:22:16.483902 47978602034560 learning.py:507] global step 8898: loss = 6.2305 (0.544 sec/step)
I0404 21:22:16.986942 47978602034560 learning.py:507] global step 8899: loss = 4.9418 (0.501 sec/step)
I0404 21:22:17.515577 47978602034560 learning.py:507] global step 8900: loss = 6.5462 (0.527 sec/step)
I0404 21:22:18.025402 47978602034560 learning.py:507] global step 8901: loss = 5.7437 (0.508 sec/step)
I0404 21:22:18.534894 47978602034560 learning.py:507] global step 8902: loss = 5.4986 (0.508 sec/step)
I0404 21:22:19.058370 47978602034560 learning.py:507] global step 8903: loss = 5.0898 (0.522 sec/step)
I0404 21:22:19.574824 47978602034560 learning.py:507] global step 8904: loss = 5.5899 (0.515 sec/step)
I0404 21:22:20.102642 47978602034560 learning.py:507] global step 8905: loss = 5.9658 (0.526 sec/step)
I0404 21:22:20.633259 47978602034560 learning.py:507] global step 8906: loss = 5.3438 (0.528 sec/step)
I0404 21:22:21.142508 47978602034560 learning.py:507] global step 8907: loss = 6.3604 (0.508 sec/step)
I0404 21:22:21.661422 47978602034560 learning.py:507] global step 8908: loss = 5.7052 (0.517 sec/step)
I0404 21:22:22.173404 47978602034560 learning.py:507] global step 8909: loss = 5.8551 (0.509 sec/step)
I0404 21:22:22.707524 47978602034560 learning.py:507] global step 8910: loss = 6.6157 (0.533 sec/step)
I0404 21:22:23.239455 47978602034560 learning.py:507] global step 8911: loss = 6.5908 (0.529 sec/step)
I0404 21:22:23.749762 47978602034560 learning.py:507] global step 8912: loss = 5.0613 (0.509 sec/step)
I0404 21:22:24.258950 47978602034560 learning.py:507] global step 8913: loss = 5.7643 (0.508 sec/step)
I0404 21:22:24.771840 47978602034560 learning.py:507] global step 8914: loss = 5.5329 (0.511 sec/step)
I0404 21:22:25.287770 47978602034560 learning.py:507] global step 8915: loss = 6.4372 (0.514 sec/step)
I0404 21:22:25.818889 47978602034560 learning.py:507] global step 8916: loss = 6.1783 (0.528 sec/step)
I0404 21:22:26.346696 47978602034560 learning.py:507] global step 8917: loss = 7.1597 (0.526 sec/step)
I0404 21:22:26.861560 47978602034560 learning.py:507] global step 8918: loss = 6.2580 (0.513 sec/step)
I0404 21:22:27.381305 47978602034560 learning.py:507] global step 8919: loss = 5.5768 (0.517 sec/step)
I0404 21:22:27.903700 47978602034560 learning.py:507] global step 8920: loss = 5.7653 (0.521 sec/step)
I0404 21:22:28.419170 47978602034560 learning.py:507] global step 8921: loss = 5.4995 (0.514 sec/step)
I0404 21:22:28.929544 47978602034560 learning.py:507] global step 8922: loss = 5.9735 (0.509 sec/step)
I0404 21:22:29.449370 47978602034560 learning.py:507] global step 8923: loss = 5.3204 (0.518 sec/step)
I0404 21:22:29.974185 47978602034560 learning.py:507] global step 8924: loss = 7.2712 (0.523 sec/step)
I0404 21:22:30.485113 47978602034560 learning.py:507] global step 8925: loss = 4.8592 (0.508 sec/step)
I0404 21:22:30.991269 47978602034560 learning.py:507] global step 8926: loss = 5.5183 (0.504 sec/step)
I0404 21:22:31.501914 47978602034560 learning.py:507] global step 8927: loss = 6.2403 (0.509 sec/step)
I0404 21:22:32.012909 47978602034560 learning.py:507] global step 8928: loss = 5.0830 (0.508 sec/step)
I0404 21:22:32.519262 47978602034560 learning.py:507] global step 8929: loss = 4.8299 (0.505 sec/step)
I0404 21:22:33.057446 47978602034560 learning.py:507] global step 8930: loss = 6.2547 (0.535 sec/step)
I0404 21:22:33.579696 47978602034560 learning.py:507] global step 8931: loss = 6.9811 (0.519 sec/step)
I0404 21:22:34.088503 47978602034560 learning.py:507] global step 8932: loss = 5.1216 (0.507 sec/step)
I0404 21:22:34.604992 47978602034560 learning.py:507] global step 8933: loss = 6.0944 (0.515 sec/step)
I0404 21:22:35.140024 47978602034560 learning.py:507] global step 8934: loss = 5.8465 (0.533 sec/step)
I0404 21:22:35.645898 47978602034560 learning.py:507] global step 8935: loss = 5.5865 (0.503 sec/step)
I0404 21:22:36.169975 47978602034560 learning.py:507] global step 8936: loss = 6.4750 (0.521 sec/step)
I0404 21:22:36.685293 47978602034560 learning.py:507] global step 8937: loss = 5.6758 (0.512 sec/step)
I0404 21:22:37.196244 47978602034560 learning.py:507] global step 8938: loss = 5.9631 (0.509 sec/step)
I0404 21:22:37.704678 47978602034560 learning.py:507] global step 8939: loss = 5.6335 (0.507 sec/step)
I0404 21:22:38.212618 47978602034560 learning.py:507] global step 8940: loss = 5.5411 (0.505 sec/step)
I0404 21:22:38.725404 47978602034560 learning.py:507] global step 8941: loss = 6.3599 (0.510 sec/step)
I0404 21:22:39.260496 47978602034560 learning.py:507] global step 8942: loss = 5.7006 (0.533 sec/step)
I0404 21:22:39.764211 47978602034560 learning.py:507] global step 8943: loss = 5.1319 (0.502 sec/step)
I0404 21:22:40.281392 47978602034560 learning.py:507] global step 8944: loss = 5.5361 (0.514 sec/step)
I0404 21:22:40.805091 47978602034560 learning.py:507] global step 8945: loss = 4.6994 (0.522 sec/step)
I0404 21:22:41.348764 47978602034560 learning.py:507] global step 8946: loss = 5.4635 (0.542 sec/step)
I0404 21:22:41.860638 47978602034560 learning.py:507] global step 8947: loss = 4.4285 (0.510 sec/step)
I0404 21:22:42.368899 47978602034560 learning.py:507] global step 8948: loss = 5.0512 (0.505 sec/step)
I0404 21:22:42.880064 47978602034560 learning.py:507] global step 8949: loss = 5.0502 (0.510 sec/step)
I0404 21:22:43.382929 47978602034560 learning.py:507] global step 8950: loss = 6.7885 (0.501 sec/step)
I0404 21:22:43.910023 47978602034560 learning.py:507] global step 8951: loss = 6.5137 (0.525 sec/step)
I0404 21:22:44.437655 47978602034560 learning.py:507] global step 8952: loss = 6.4769 (0.525 sec/step)
I0404 21:22:44.954613 47978602034560 learning.py:507] global step 8953: loss = 5.8416 (0.514 sec/step)
I0404 21:22:45.465090 47978602034560 learning.py:507] global step 8954: loss = 6.0834 (0.509 sec/step)
I0404 21:22:45.976624 47978602034560 learning.py:507] global step 8955: loss = 5.6234 (0.510 sec/step)
I0404 21:22:46.481431 47978602034560 learning.py:507] global step 8956: loss = 4.6877 (0.502 sec/step)
I0404 21:22:46.991430 47978602034560 learning.py:507] global step 8957: loss = 6.1336 (0.508 sec/step)
I0404 21:22:47.523184 47978602034560 learning.py:507] global step 8958: loss = 5.2973 (0.530 sec/step)
I0404 21:22:48.050502 47978602034560 learning.py:507] global step 8959: loss = 6.2636 (0.526 sec/step)
I0404 21:22:48.554871 47978602034560 learning.py:507] global step 8960: loss = 5.8095 (0.503 sec/step)
I0404 21:22:49.064488 47978602034560 learning.py:507] global step 8961: loss = 6.7962 (0.508 sec/step)
I0404 21:22:49.596149 47978602034560 learning.py:507] global step 8962: loss = 6.5299 (0.529 sec/step)
I0404 21:22:50.133326 47978602034560 learning.py:507] global step 8963: loss = 6.1882 (0.534 sec/step)
I0404 21:22:50.643334 47978602034560 learning.py:507] global step 8964: loss = 4.8883 (0.509 sec/step)
I0404 21:22:51.179526 47978602034560 learning.py:507] global step 8965: loss = 6.6923 (0.535 sec/step)
I0404 21:22:51.709692 47978602034560 learning.py:507] global step 8966: loss = 5.9135 (0.529 sec/step)
I0404 21:22:52.222410 47978602034560 learning.py:507] global step 8967: loss = 5.6993 (0.511 sec/step)
I0404 21:22:52.733793 47978602034560 learning.py:507] global step 8968: loss = 5.2504 (0.508 sec/step)
I0404 21:22:53.244692 47978602034560 learning.py:507] global step 8969: loss = 5.9936 (0.509 sec/step)
I0404 21:22:53.750458 47978602034560 learning.py:507] global step 8970: loss = 5.3231 (0.504 sec/step)
I0404 21:22:54.264842 47978602034560 learning.py:507] global step 8971: loss = 5.0584 (0.512 sec/step)
I0404 21:22:54.786335 47978602034560 learning.py:507] global step 8972: loss = 6.5681 (0.520 sec/step)
I0404 21:22:55.315380 47978602034560 learning.py:507] global step 8973: loss = 5.5476 (0.527 sec/step)
I0404 21:22:55.856015 47978602034560 learning.py:507] global step 8974: loss = 7.1810 (0.538 sec/step)
I0404 21:22:56.387302 47978602034560 learning.py:507] global step 8975: loss = 6.3345 (0.530 sec/step)
I0404 21:22:56.892987 47978602034560 learning.py:507] global step 8976: loss = 6.2022 (0.504 sec/step)
I0404 21:22:57.404596 47978602034560 learning.py:507] global step 8977: loss = 4.9710 (0.509 sec/step)
I0404 21:22:57.915747 47978602034560 learning.py:507] global step 8978: loss = 6.3731 (0.510 sec/step)
I0404 21:22:58.442009 47978602034560 learning.py:507] global step 8979: loss = 4.6502 (0.523 sec/step)
I0404 21:22:58.956089 47978602034560 learning.py:507] global step 8980: loss = 5.5191 (0.512 sec/step)
I0404 21:22:59.469735 47978602034560 learning.py:507] global step 8981: loss = 5.9195 (0.512 sec/step)
I0404 21:22:59.997713 47978602034560 learning.py:507] global step 8982: loss = 5.0396 (0.526 sec/step)
I0404 21:23:00.530685 47978602034560 learning.py:507] global step 8983: loss = 5.3580 (0.531 sec/step)
I0404 21:23:01.051980 47978602034560 learning.py:507] global step 8984: loss = 6.3299 (0.520 sec/step)
I0404 21:23:01.580884 47978602034560 learning.py:507] global step 8985: loss = 5.7246 (0.527 sec/step)
I0404 21:23:02.087417 47978602034560 learning.py:507] global step 8986: loss = 5.5992 (0.505 sec/step)
I0404 21:23:02.592528 47978602034560 learning.py:507] global step 8987: loss = 5.0221 (0.503 sec/step)
I0404 21:23:03.098180 47978602034560 learning.py:507] global step 8988: loss = 5.8819 (0.504 sec/step)
I0404 21:23:03.628098 47978602034560 learning.py:507] global step 8989: loss = 6.1473 (0.528 sec/step)
I0404 21:23:04.132988 47978602034560 learning.py:507] global step 8990: loss = 5.5279 (0.503 sec/step)
I0404 21:23:04.650969 47978602034560 learning.py:507] global step 8991: loss = 5.8882 (0.516 sec/step)
I0404 21:23:05.157820 47978602034560 learning.py:507] global step 8992: loss = 5.5255 (0.504 sec/step)
I0404 21:23:05.660419 47978602034560 learning.py:507] global step 8993: loss = 6.0410 (0.500 sec/step)
I0404 21:23:06.170028 47978602034560 learning.py:507] global step 8994: loss = 6.2347 (0.507 sec/step)
I0404 21:23:06.677128 47978602034560 learning.py:507] global step 8995: loss = 6.0512 (0.505 sec/step)
I0404 21:23:07.186213 47978602034560 learning.py:507] global step 8996: loss = 5.9569 (0.506 sec/step)
I0404 21:23:07.699935 47978602034560 learning.py:507] global step 8997: loss = 5.6939 (0.512 sec/step)
I0404 21:23:08.207187 47978602034560 learning.py:507] global step 8998: loss = 5.5910 (0.506 sec/step)
I0404 21:23:08.706159 47978602034560 learning.py:507] global step 8999: loss = 5.6512 (0.497 sec/step)
I0404 21:23:09.214379 47978602034560 learning.py:507] global step 9000: loss = 5.7552 (0.507 sec/step)
I0404 21:23:09.727637 47978602034560 learning.py:507] global step 9001: loss = 5.0303 (0.512 sec/step)
I0404 21:23:10.237042 47978602034560 learning.py:507] global step 9002: loss = 6.6815 (0.508 sec/step)
I0404 21:23:10.752890 47978602034560 learning.py:507] global step 9003: loss = 6.5382 (0.514 sec/step)
I0404 21:23:11.254136 47978602034560 learning.py:507] global step 9004: loss = 5.9705 (0.498 sec/step)
I0404 21:23:11.780420 47978602034560 learning.py:507] global step 9005: loss = 6.2761 (0.525 sec/step)
I0404 21:23:12.297908 47978602034560 learning.py:507] global step 9006: loss = 5.8526 (0.516 sec/step)
I0404 21:23:12.809725 47978602034560 learning.py:507] global step 9007: loss = 5.6441 (0.510 sec/step)
I0404 21:23:13.320000 47978602034560 learning.py:507] global step 9008: loss = 6.3183 (0.509 sec/step)
I0404 21:23:13.837896 47978602034560 learning.py:507] global step 9009: loss = 5.1252 (0.516 sec/step)
I0404 21:23:14.357630 47978602034560 learning.py:507] global step 9010: loss = 5.8585 (0.518 sec/step)
I0404 21:23:14.870329 47978602034560 learning.py:507] global step 9011: loss = 5.3535 (0.511 sec/step)
I0404 21:23:15.385816 47978602034560 learning.py:507] global step 9012: loss = 6.3121 (0.513 sec/step)
I0404 21:23:15.888728 47978602034560 learning.py:507] global step 9013: loss = 6.4028 (0.500 sec/step)
I0404 21:23:16.405489 47978602034560 learning.py:507] global step 9014: loss = 5.5185 (0.514 sec/step)
I0404 21:23:16.916166 47978602034560 learning.py:507] global step 9015: loss = 6.2381 (0.505 sec/step)
I0404 21:23:17.295554 47983661975296 supervisor.py:1050] Recording summary at step 9015.
I0404 21:23:17.625106 47978602034560 learning.py:507] global step 9016: loss = 7.1504 (0.704 sec/step)
I0404 21:23:18.141551 47978602034560 learning.py:507] global step 9017: loss = 6.1679 (0.515 sec/step)
I0404 21:23:18.651674 47978602034560 learning.py:507] global step 9018: loss = 6.6965 (0.507 sec/step)
I0404 21:23:19.183604 47978602034560 learning.py:507] global step 9019: loss = 5.6421 (0.530 sec/step)
I0404 21:23:19.685391 47978602034560 learning.py:507] global step 9020: loss = 5.6377 (0.500 sec/step)
I0404 21:23:20.213410 47978602034560 learning.py:507] global step 9021: loss = 5.5414 (0.526 sec/step)
I0404 21:23:20.720410 47978602034560 learning.py:507] global step 9022: loss = 7.0377 (0.505 sec/step)
I0404 21:23:21.226045 47978602034560 learning.py:507] global step 9023: loss = 7.0063 (0.504 sec/step)
I0404 21:23:21.729932 47978602034560 learning.py:507] global step 9024: loss = 7.4788 (0.501 sec/step)
I0404 21:23:22.273340 47978602034560 learning.py:507] global step 9025: loss = 5.8803 (0.542 sec/step)
I0404 21:23:22.781723 47978602034560 learning.py:507] global step 9026: loss = 6.2416 (0.507 sec/step)
I0404 21:23:23.287935 47978602034560 learning.py:507] global step 9027: loss = 4.9622 (0.503 sec/step)
I0404 21:23:23.805017 47978602034560 learning.py:507] global step 9028: loss = 6.5341 (0.516 sec/step)
I0404 21:23:24.314944 47978602034560 learning.py:507] global step 9029: loss = 6.6090 (0.508 sec/step)
I0404 21:23:24.842206 47978602034560 learning.py:507] global step 9030: loss = 6.3739 (0.526 sec/step)
I0404 21:23:25.354484 47978602034560 learning.py:507] global step 9031: loss = 6.1992 (0.511 sec/step)
I0404 21:23:25.867914 47978602034560 learning.py:507] global step 9032: loss = 6.7889 (0.512 sec/step)
I0404 21:23:26.389346 47978602034560 learning.py:507] global step 9033: loss = 6.1024 (0.520 sec/step)
I0404 21:23:26.907664 47978602034560 learning.py:507] global step 9034: loss = 5.5497 (0.517 sec/step)
I0404 21:23:27.418761 47978602034560 learning.py:507] global step 9035: loss = 6.2349 (0.510 sec/step)
I0404 21:23:27.948068 47978602034560 learning.py:507] global step 9036: loss = 5.6556 (0.526 sec/step)
I0404 21:23:28.461031 47978602034560 learning.py:507] global step 9037: loss = 6.2063 (0.511 sec/step)
I0404 21:23:28.978876 47978602034560 learning.py:507] global step 9038: loss = 5.7754 (0.516 sec/step)
I0404 21:23:29.489509 47978602034560 learning.py:507] global step 9039: loss = 7.7083 (0.509 sec/step)
I0404 21:23:29.998285 47978602034560 learning.py:507] global step 9040: loss = 6.1812 (0.507 sec/step)
I0404 21:23:30.521897 47978602034560 learning.py:507] global step 9041: loss = 5.7619 (0.522 sec/step)
I0404 21:23:31.034718 47978602034560 learning.py:507] global step 9042: loss = 6.5737 (0.511 sec/step)
I0404 21:23:31.539331 47978602034560 learning.py:507] global step 9043: loss = 6.3013 (0.502 sec/step)
I0404 21:23:32.046354 47978602034560 learning.py:507] global step 9044: loss = 5.5721 (0.504 sec/step)
I0404 21:23:32.583594 47978602034560 learning.py:507] global step 9045: loss = 5.6027 (0.534 sec/step)
I0404 21:23:33.121678 47978602034560 learning.py:507] global step 9046: loss = 6.5817 (0.536 sec/step)
I0404 21:23:33.633415 47978602034560 learning.py:507] global step 9047: loss = 6.1273 (0.510 sec/step)
I0404 21:23:34.159058 47978602034560 learning.py:507] global step 9048: loss = 5.5651 (0.524 sec/step)
I0404 21:23:34.667984 47978602034560 learning.py:507] global step 9049: loss = 5.9126 (0.507 sec/step)
I0404 21:23:35.178876 47978602034560 learning.py:507] global step 9050: loss = 6.2254 (0.509 sec/step)
I0404 21:23:35.712884 47978602034560 learning.py:507] global step 9051: loss = 5.3976 (0.532 sec/step)
I0404 21:23:36.223196 47978602034560 learning.py:507] global step 9052: loss = 5.5800 (0.507 sec/step)
I0404 21:23:36.738496 47978602034560 learning.py:507] global step 9053: loss = 6.1734 (0.514 sec/step)
I0404 21:23:37.254616 47978602034560 learning.py:507] global step 9054: loss = 6.3978 (0.514 sec/step)
I0404 21:23:37.785221 47978602034560 learning.py:507] global step 9055: loss = 5.2664 (0.529 sec/step)
I0404 21:23:38.303499 47978602034560 learning.py:507] global step 9056: loss = 6.8857 (0.517 sec/step)
I0404 21:23:38.816382 47978602034560 learning.py:507] global step 9057: loss = 5.4265 (0.511 sec/step)
I0404 21:23:39.335261 47978602034560 learning.py:507] global step 9058: loss = 6.8752 (0.517 sec/step)
I0404 21:23:39.874310 47978602034560 learning.py:507] global step 9059: loss = 5.6954 (0.536 sec/step)
I0404 21:23:40.402082 47978602034560 learning.py:507] global step 9060: loss = 5.3600 (0.525 sec/step)
I0404 21:23:40.910766 47978602034560 learning.py:507] global step 9061: loss = 6.3453 (0.507 sec/step)
I0404 21:23:41.428555 47978602034560 learning.py:507] global step 9062: loss = 5.6281 (0.516 sec/step)
I0404 21:23:41.937194 47978602034560 learning.py:507] global step 9063: loss = 5.8892 (0.506 sec/step)
I0404 21:23:42.458979 47978602034560 learning.py:507] global step 9064: loss = 5.8420 (0.520 sec/step)
I0404 21:23:42.976162 47978602034560 learning.py:507] global step 9065: loss = 6.0261 (0.516 sec/step)
I0404 21:23:43.485327 47978602034560 learning.py:507] global step 9066: loss = 5.9820 (0.508 sec/step)
I0404 21:23:43.991929 47978602034560 learning.py:507] global step 9067: loss = 5.2885 (0.505 sec/step)
I0404 21:23:44.498729 47978602034560 learning.py:507] global step 9068: loss = 5.6144 (0.505 sec/step)
I0404 21:23:45.017959 47978602034560 learning.py:507] global step 9069: loss = 5.8850 (0.518 sec/step)
I0404 21:23:45.531345 47978602034560 learning.py:507] global step 9070: loss = 5.3932 (0.512 sec/step)
I0404 21:23:46.071974 47978602034560 learning.py:507] global step 9071: loss = 5.6477 (0.539 sec/step)
I0404 21:23:46.577357 47978602034560 learning.py:507] global step 9072: loss = 6.1083 (0.504 sec/step)
I0404 21:23:47.091063 47978602034560 learning.py:507] global step 9073: loss = 6.3709 (0.512 sec/step)
I0404 21:23:47.603859 47978602034560 learning.py:507] global step 9074: loss = 5.1649 (0.511 sec/step)
I0404 21:23:48.109506 47978602034560 learning.py:507] global step 9075: loss = 5.5501 (0.504 sec/step)
I0404 21:23:48.616352 47978602034560 learning.py:507] global step 9076: loss = 7.0370 (0.505 sec/step)
I0404 21:23:49.125288 47978602034560 learning.py:507] global step 9077: loss = 6.2355 (0.507 sec/step)
I0404 21:23:49.651877 47978602034560 learning.py:507] global step 9078: loss = 4.7534 (0.525 sec/step)
I0404 21:23:50.161742 47978602034560 learning.py:507] global step 9079: loss = 6.2423 (0.508 sec/step)
I0404 21:23:50.687946 47978602034560 learning.py:507] global step 9080: loss = 6.4126 (0.523 sec/step)
I0404 21:23:51.192855 47978602034560 learning.py:507] global step 9081: loss = 5.0838 (0.503 sec/step)
I0404 21:23:51.700371 47978602034560 learning.py:507] global step 9082: loss = 5.7942 (0.505 sec/step)
I0404 21:23:52.232372 47978602034560 learning.py:507] global step 9083: loss = 5.1621 (0.530 sec/step)
I0404 21:23:52.746138 47978602034560 learning.py:507] global step 9084: loss = 5.1929 (0.512 sec/step)
I0404 21:23:53.254704 47978602034560 learning.py:507] global step 9085: loss = 5.8752 (0.507 sec/step)
I0404 21:23:53.771841 47978602034560 learning.py:507] global step 9086: loss = 4.6511 (0.516 sec/step)
I0404 21:23:54.283108 47978602034560 learning.py:507] global step 9087: loss = 5.7889 (0.510 sec/step)
I0404 21:23:54.810764 47978602034560 learning.py:507] global step 9088: loss = 5.4392 (0.526 sec/step)
I0404 21:23:55.343892 47978602034560 learning.py:507] global step 9089: loss = 5.6601 (0.531 sec/step)
I0404 21:23:55.874968 47978602034560 learning.py:507] global step 9090: loss = 6.6141 (0.529 sec/step)
I0404 21:23:56.415759 47978602034560 learning.py:507] global step 9091: loss = 5.2043 (0.539 sec/step)
I0404 21:23:56.921077 47978602034560 learning.py:507] global step 9092: loss = 5.6920 (0.504 sec/step)
I0404 21:23:57.430681 47978602034560 learning.py:507] global step 9093: loss = 6.1370 (0.508 sec/step)
I0404 21:23:57.938539 47978602034560 learning.py:507] global step 9094: loss = 6.3793 (0.505 sec/step)
I0404 21:23:58.456259 47978602034560 learning.py:507] global step 9095: loss = 6.1269 (0.516 sec/step)
I0404 21:23:58.973431 47978602034560 learning.py:507] global step 9096: loss = 6.3931 (0.516 sec/step)
I0404 21:23:59.490762 47978602034560 learning.py:507] global step 9097: loss = 5.5805 (0.516 sec/step)
I0404 21:24:00.004940 47978602034560 learning.py:507] global step 9098: loss = 5.9505 (0.513 sec/step)
I0404 21:24:00.515656 47978602034560 learning.py:507] global step 9099: loss = 4.9628 (0.509 sec/step)
I0404 21:24:01.053430 47978602034560 learning.py:507] global step 9100: loss = 6.4097 (0.536 sec/step)
I0404 21:24:01.570826 47978602034560 learning.py:507] global step 9101: loss = 5.4060 (0.516 sec/step)
I0404 21:24:02.092254 47978602034560 learning.py:507] global step 9102: loss = 5.0911 (0.520 sec/step)
I0404 21:24:02.596456 47978602034560 learning.py:507] global step 9103: loss = 5.9020 (0.503 sec/step)
I0404 21:24:03.111548 47978602034560 learning.py:507] global step 9104: loss = 5.6808 (0.514 sec/step)
I0404 21:24:03.639116 47978602034560 learning.py:507] global step 9105: loss = 5.3012 (0.525 sec/step)
I0404 21:24:04.150859 47978602034560 learning.py:507] global step 9106: loss = 4.4015 (0.509 sec/step)
I0404 21:24:04.665515 47978602034560 learning.py:507] global step 9107: loss = 5.5035 (0.512 sec/step)
I0404 21:24:05.193678 47978602034560 learning.py:507] global step 9108: loss = 4.9790 (0.525 sec/step)
I0404 21:24:05.707057 47978602034560 learning.py:507] global step 9109: loss = 5.7040 (0.511 sec/step)
I0404 21:24:06.223006 47978602034560 learning.py:507] global step 9110: loss = 6.3124 (0.514 sec/step)
I0404 21:24:06.741130 47978602034560 learning.py:507] global step 9111: loss = 5.8022 (0.517 sec/step)
I0404 21:24:07.258502 47978602034560 learning.py:507] global step 9112: loss = 6.1421 (0.514 sec/step)
I0404 21:24:07.768710 47978602034560 learning.py:507] global step 9113: loss = 6.0234 (0.509 sec/step)
I0404 21:24:08.278066 47978602034560 learning.py:507] global step 9114: loss = 6.8115 (0.508 sec/step)
I0404 21:24:08.790722 47978602034560 learning.py:507] global step 9115: loss = 5.3160 (0.511 sec/step)
I0404 21:24:09.313106 47978602034560 learning.py:507] global step 9116: loss = 7.2440 (0.521 sec/step)
I0404 21:24:09.816693 47978602034560 learning.py:507] global step 9117: loss = 5.7129 (0.502 sec/step)
I0404 21:24:10.329003 47978602034560 learning.py:507] global step 9118: loss = 5.9734 (0.511 sec/step)
I0404 21:24:10.860716 47978602034560 learning.py:507] global step 9119: loss = 5.5089 (0.530 sec/step)
I0404 21:24:11.359881 47978602034560 learning.py:507] global step 9120: loss = 4.4142 (0.498 sec/step)
I0404 21:24:11.863436 47978602034560 learning.py:507] global step 9121: loss = 5.1947 (0.502 sec/step)
I0404 21:24:12.394391 47978602034560 learning.py:507] global step 9122: loss = 6.1943 (0.529 sec/step)
I0404 21:24:12.915419 47978602034560 learning.py:507] global step 9123: loss = 5.4348 (0.519 sec/step)
I0404 21:24:13.455677 47978602034560 learning.py:507] global step 9124: loss = 6.8107 (0.539 sec/step)
I0404 21:24:13.977272 47978602034560 learning.py:507] global step 9125: loss = 6.7099 (0.520 sec/step)
I0404 21:24:14.507489 47978602034560 learning.py:507] global step 9126: loss = 6.1231 (0.527 sec/step)
I0404 21:24:15.015069 47978602034560 learning.py:507] global step 9127: loss = 5.3304 (0.505 sec/step)
I0404 21:24:15.517282 47978602034560 learning.py:507] global step 9128: loss = 4.5983 (0.501 sec/step)
I0404 21:24:16.022674 47978602034560 learning.py:507] global step 9129: loss = 4.7744 (0.502 sec/step)
I0404 21:24:16.536567 47978602034560 learning.py:507] global step 9130: loss = 6.6440 (0.512 sec/step)
I0404 21:24:17.045048 47978602034560 learning.py:507] global step 9131: loss = 5.6192 (0.507 sec/step)
I0404 21:24:17.551354 47978602034560 learning.py:507] global step 9132: loss = 6.3780 (0.505 sec/step)
I0404 21:24:18.083788 47978602034560 learning.py:507] global step 9133: loss = 6.4433 (0.531 sec/step)
I0404 21:24:18.587066 47978602034560 learning.py:507] global step 9134: loss = 5.8127 (0.502 sec/step)
I0404 21:24:19.096615 47978602034560 learning.py:507] global step 9135: loss = 5.6133 (0.507 sec/step)
I0404 21:24:19.607842 47978602034560 learning.py:507] global step 9136: loss = 6.0576 (0.508 sec/step)
I0404 21:24:20.127073 47978602034560 learning.py:507] global step 9137: loss = 6.3574 (0.518 sec/step)
I0404 21:24:20.642858 47978602034560 learning.py:507] global step 9138: loss = 5.5492 (0.513 sec/step)
I0404 21:24:21.152283 47978602034560 learning.py:507] global step 9139: loss = 6.6665 (0.508 sec/step)
I0404 21:24:21.666425 47978602034560 learning.py:507] global step 9140: loss = 6.1916 (0.511 sec/step)
I0404 21:24:22.209970 47978602034560 learning.py:507] global step 9141: loss = 4.8217 (0.541 sec/step)
I0404 21:24:22.727443 47978602034560 learning.py:507] global step 9142: loss = 6.2104 (0.516 sec/step)
I0404 21:24:23.265442 47978602034560 learning.py:507] global step 9143: loss = 5.2976 (0.535 sec/step)
I0404 21:24:23.766346 47978602034560 learning.py:507] global step 9144: loss = 5.2950 (0.499 sec/step)
I0404 21:24:24.272764 47978602034560 learning.py:507] global step 9145: loss = 5.1369 (0.505 sec/step)
I0404 21:24:24.778462 47978602034560 learning.py:507] global step 9146: loss = 6.1765 (0.504 sec/step)
I0404 21:24:25.277868 47978602034560 learning.py:507] global step 9147: loss = 5.5319 (0.498 sec/step)
I0404 21:24:25.784608 47978602034560 learning.py:507] global step 9148: loss = 4.9402 (0.505 sec/step)
I0404 21:24:26.287962 47978602034560 learning.py:507] global step 9149: loss = 5.5534 (0.500 sec/step)
I0404 21:24:26.817432 47978602034560 learning.py:507] global step 9150: loss = 6.5980 (0.528 sec/step)
I0404 21:24:27.325796 47978602034560 learning.py:507] global step 9151: loss = 5.0540 (0.507 sec/step)
I0404 21:24:27.847391 47978602034560 learning.py:507] global step 9152: loss = 5.7185 (0.520 sec/step)
I0404 21:24:28.349539 47978602034560 learning.py:507] global step 9153: loss = 6.4477 (0.501 sec/step)
I0404 21:24:28.864476 47978602034560 learning.py:507] global step 9154: loss = 6.8034 (0.512 sec/step)
I0404 21:24:29.377741 47978602034560 learning.py:507] global step 9155: loss = 5.2647 (0.510 sec/step)
I0404 21:24:29.884140 47978602034560 learning.py:507] global step 9156: loss = 6.4094 (0.504 sec/step)
I0404 21:24:30.400423 47978602034560 learning.py:507] global step 9157: loss = 5.8820 (0.515 sec/step)
I0404 21:24:30.907379 47978602034560 learning.py:507] global step 9158: loss = 5.3117 (0.505 sec/step)
I0404 21:24:31.413903 47978602034560 learning.py:507] global step 9159: loss = 4.6550 (0.505 sec/step)
I0404 21:24:31.926954 47978602034560 learning.py:507] global step 9160: loss = 5.9647 (0.512 sec/step)
I0404 21:24:32.437296 47978602034560 learning.py:507] global step 9161: loss = 6.1804 (0.509 sec/step)
I0404 21:24:32.953423 47978602034560 learning.py:507] global step 9162: loss = 5.9981 (0.515 sec/step)
I0404 21:24:33.460993 47978602034560 learning.py:507] global step 9163: loss = 5.6780 (0.505 sec/step)
I0404 21:24:33.968444 47978602034560 learning.py:507] global step 9164: loss = 5.2049 (0.506 sec/step)
I0404 21:24:34.476609 47978602034560 learning.py:507] global step 9165: loss = 5.5115 (0.507 sec/step)
I0404 21:24:34.985317 47978602034560 learning.py:507] global step 9166: loss = 6.6943 (0.506 sec/step)
I0404 21:24:35.491200 47978602034560 learning.py:507] global step 9167: loss = 6.0795 (0.504 sec/step)
I0404 21:24:35.994336 47978602034560 learning.py:507] global step 9168: loss = 5.6936 (0.501 sec/step)
I0404 21:24:36.509978 47978602034560 learning.py:507] global step 9169: loss = 5.6566 (0.513 sec/step)
I0404 21:24:37.017494 47978602034560 learning.py:507] global step 9170: loss = 6.1902 (0.506 sec/step)
I0404 21:24:37.528961 47978602034560 learning.py:507] global step 9171: loss = 5.5506 (0.510 sec/step)
I0404 21:24:38.033127 47978602034560 learning.py:507] global step 9172: loss = 6.4843 (0.503 sec/step)
I0404 21:24:38.575896 47978602034560 learning.py:507] global step 9173: loss = 5.0242 (0.541 sec/step)
I0404 21:24:39.079264 47978602034560 learning.py:507] global step 9174: loss = 5.3046 (0.500 sec/step)
I0404 21:24:39.586715 47978602034560 learning.py:507] global step 9175: loss = 5.4456 (0.506 sec/step)
I0404 21:24:40.094812 47978602034560 learning.py:507] global step 9176: loss = 6.2424 (0.507 sec/step)
I0404 21:24:40.598360 47978602034560 learning.py:507] global step 9177: loss = 5.8387 (0.502 sec/step)
I0404 21:24:41.140156 47978602034560 learning.py:507] global step 9178: loss = 5.4108 (0.540 sec/step)
I0404 21:24:41.679750 47978602034560 learning.py:507] global step 9179: loss = 6.3537 (0.538 sec/step)
I0404 21:24:42.218840 47978602034560 learning.py:507] global step 9180: loss = 5.9746 (0.536 sec/step)
I0404 21:24:42.736500 47978602034560 learning.py:507] global step 9181: loss = 5.7276 (0.516 sec/step)
I0404 21:24:43.245528 47978602034560 learning.py:507] global step 9182: loss = 5.9791 (0.506 sec/step)
I0404 21:24:43.761655 47978602034560 learning.py:507] global step 9183: loss = 5.8221 (0.513 sec/step)
I0404 21:24:44.286249 47978602034560 learning.py:507] global step 9184: loss = 8.1850 (0.523 sec/step)
I0404 21:24:44.790772 47978602034560 learning.py:507] global step 9185: loss = 5.9572 (0.503 sec/step)
I0404 21:24:45.297720 47978602034560 learning.py:507] global step 9186: loss = 6.1205 (0.505 sec/step)
I0404 21:24:45.809867 47978602034560 learning.py:507] global step 9187: loss = 6.0554 (0.509 sec/step)
I0404 21:24:46.344991 47978602034560 learning.py:507] global step 9188: loss = 6.3924 (0.534 sec/step)
I0404 21:24:46.861120 47978602034560 learning.py:507] global step 9189: loss = 5.4557 (0.515 sec/step)
I0404 21:24:47.401667 47978602034560 learning.py:507] global step 9190: loss = 6.3190 (0.538 sec/step)
I0404 21:24:47.913275 47978602034560 learning.py:507] global step 9191: loss = 5.4778 (0.509 sec/step)
I0404 21:24:48.428715 47978602034560 learning.py:507] global step 9192: loss = 5.7110 (0.514 sec/step)
I0404 21:24:48.932591 47978602034560 learning.py:507] global step 9193: loss = 5.7876 (0.501 sec/step)
I0404 21:24:49.468934 47978602034560 learning.py:507] global step 9194: loss = 5.8975 (0.535 sec/step)
I0404 21:24:49.976371 47978602034560 learning.py:507] global step 9195: loss = 5.6870 (0.506 sec/step)
I0404 21:24:50.482092 47978602034560 learning.py:507] global step 9196: loss = 5.5864 (0.503 sec/step)
I0404 21:24:51.003103 47978602034560 learning.py:507] global step 9197: loss = 6.0855 (0.519 sec/step)
I0404 21:24:51.512401 47978602034560 learning.py:507] global step 9198: loss = 6.1190 (0.508 sec/step)
I0404 21:24:52.025961 47978602034560 learning.py:507] global step 9199: loss = 5.5369 (0.512 sec/step)
I0404 21:24:52.542543 47978602034560 learning.py:507] global step 9200: loss = 5.8071 (0.515 sec/step)
I0404 21:24:53.077780 47978602034560 learning.py:507] global step 9201: loss = 5.7593 (0.532 sec/step)
I0404 21:24:53.583258 47978602034560 learning.py:507] global step 9202: loss = 5.3664 (0.504 sec/step)
I0404 21:24:54.094033 47978602034560 learning.py:507] global step 9203: loss = 6.3647 (0.509 sec/step)
I0404 21:24:54.613022 47978602034560 learning.py:507] global step 9204: loss = 5.7311 (0.517 sec/step)
I0404 21:24:55.118858 47978602034560 learning.py:507] global step 9205: loss = 5.6655 (0.504 sec/step)
I0404 21:24:55.646332 47978602034560 learning.py:507] global step 9206: loss = 5.3503 (0.526 sec/step)
I0404 21:24:56.181702 47978602034560 learning.py:507] global step 9207: loss = 6.2419 (0.532 sec/step)
I0404 21:24:56.688997 47978602034560 learning.py:507] global step 9208: loss = 5.9953 (0.504 sec/step)
I0404 21:24:57.196526 47978602034560 learning.py:507] global step 9209: loss = 5.4395 (0.506 sec/step)
I0404 21:24:57.710937 47978602034560 learning.py:507] global step 9210: loss = 5.1567 (0.513 sec/step)
I0404 21:24:58.216129 47978602034560 learning.py:507] global step 9211: loss = 6.0960 (0.504 sec/step)
I0404 21:24:58.718622 47978602034560 learning.py:507] global step 9212: loss = 5.9596 (0.501 sec/step)
I0404 21:24:59.246284 47978602034560 learning.py:507] global step 9213: loss = 4.8646 (0.526 sec/step)
I0404 21:24:59.754549 47978602034560 learning.py:507] global step 9214: loss = 5.4257 (0.507 sec/step)
I0404 21:25:00.262462 47978602034560 learning.py:507] global step 9215: loss = 5.7932 (0.505 sec/step)
I0404 21:25:00.777046 47978602034560 learning.py:507] global step 9216: loss = 6.2491 (0.513 sec/step)
I0404 21:25:01.298887 47978602034560 learning.py:507] global step 9217: loss = 5.1901 (0.520 sec/step)
I0404 21:25:01.833767 47978602034560 learning.py:507] global step 9218: loss = 5.5458 (0.533 sec/step)
I0404 21:25:02.355534 47978602034560 learning.py:507] global step 9219: loss = 5.5373 (0.520 sec/step)
I0404 21:25:02.893039 47978602034560 learning.py:507] global step 9220: loss = 5.4211 (0.536 sec/step)
I0404 21:25:03.418615 47978602034560 learning.py:507] global step 9221: loss = 5.2296 (0.523 sec/step)
I0404 21:25:03.935634 47978602034560 learning.py:507] global step 9222: loss = 5.7121 (0.514 sec/step)
I0404 21:25:04.444731 47978602034560 learning.py:507] global step 9223: loss = 5.8377 (0.508 sec/step)
I0404 21:25:04.947177 47978602034560 learning.py:507] global step 9224: loss = 6.1386 (0.500 sec/step)
I0404 21:25:05.462837 47978602034560 learning.py:507] global step 9225: loss = 5.9166 (0.514 sec/step)
I0404 21:25:05.973865 47978602034560 learning.py:507] global step 9226: loss = 5.4136 (0.508 sec/step)
I0404 21:25:06.485648 47978602034560 learning.py:507] global step 9227: loss = 5.8154 (0.509 sec/step)
I0404 21:25:07.025206 47978602034560 learning.py:507] global step 9228: loss = 5.9208 (0.538 sec/step)
I0404 21:25:07.542326 47978602034560 learning.py:507] global step 9229: loss = 5.0259 (0.514 sec/step)
I0404 21:25:08.069510 47978602034560 learning.py:507] global step 9230: loss = 5.6393 (0.526 sec/step)
I0404 21:25:08.608101 47978602034560 learning.py:507] global step 9231: loss = 5.7057 (0.537 sec/step)
I0404 21:25:09.113175 47978602034560 learning.py:507] global step 9232: loss = 5.7232 (0.502 sec/step)
I0404 21:25:09.631057 47978602034560 learning.py:507] global step 9233: loss = 6.0339 (0.516 sec/step)
I0404 21:25:10.138632 47978602034560 learning.py:507] global step 9234: loss = 5.5097 (0.505 sec/step)
I0404 21:25:10.651029 47978602034560 learning.py:507] global step 9235: loss = 5.5074 (0.510 sec/step)
I0404 21:25:11.154839 47978602034560 learning.py:507] global step 9236: loss = 5.6050 (0.502 sec/step)
I0404 21:25:11.663647 47978602034560 learning.py:507] global step 9237: loss = 6.1332 (0.507 sec/step)
I0404 21:25:12.181813 47978602034560 learning.py:507] global step 9238: loss = 5.1081 (0.517 sec/step)
I0404 21:25:12.688392 47978602034560 learning.py:507] global step 9239: loss = 5.5222 (0.505 sec/step)
I0404 21:25:13.222176 47978602034560 learning.py:507] global step 9240: loss = 6.1471 (0.532 sec/step)
I0404 21:25:13.753351 47978602034560 learning.py:507] global step 9241: loss = 6.5004 (0.528 sec/step)
I0404 21:25:14.294670 47978602034560 learning.py:507] global step 9242: loss = 4.7993 (0.540 sec/step)
I0404 21:25:14.812070 47978602034560 learning.py:507] global step 9243: loss = 6.5732 (0.515 sec/step)
I0404 21:25:15.343948 47978602034560 learning.py:507] global step 9244: loss = 5.3159 (0.530 sec/step)
I0404 21:25:15.877247 47978602034560 learning.py:507] global step 9245: loss = 5.2901 (0.530 sec/step)
I0404 21:25:16.410339 47978602034560 learning.py:507] global step 9246: loss = 5.4484 (0.531 sec/step)
I0404 21:25:16.636532 47983666177792 supervisor.py:1117] Saving checkpoint to path ../../trainingOutput/model.ckpt
I0404 21:25:16.934574 47978602034560 learning.py:507] global step 9247: loss = 5.3643 (0.522 sec/step)
I0404 21:25:17.620774 47983661975296 supervisor.py:1050] Recording summary at step 9248.
I0404 21:25:17.626310 47978602034560 learning.py:507] global step 9248: loss = 5.2765 (0.678 sec/step)
I0404 21:25:18.317071 47978602034560 learning.py:507] global step 9249: loss = 5.8526 (0.630 sec/step)
I0404 21:25:18.828075 47978602034560 learning.py:507] global step 9250: loss = 5.8681 (0.506 sec/step)
I0404 21:25:19.341068 47978602034560 learning.py:507] global step 9251: loss = 7.3602 (0.511 sec/step)
I0404 21:25:19.869801 47978602034560 learning.py:507] global step 9252: loss = 5.2294 (0.527 sec/step)
I0404 21:25:20.406239 47978602034560 learning.py:507] global step 9253: loss = 5.5147 (0.535 sec/step)
I0404 21:25:20.941999 47978602034560 learning.py:507] global step 9254: loss = 5.6847 (0.534 sec/step)
I0404 21:25:21.453413 47978602034560 learning.py:507] global step 9255: loss = 5.7012 (0.510 sec/step)
I0404 21:25:21.967999 47978602034560 learning.py:507] global step 9256: loss = 5.7686 (0.513 sec/step)
I0404 21:25:22.508272 47978602034560 learning.py:507] global step 9257: loss = 4.8529 (0.539 sec/step)
I0404 21:25:23.044517 47978602034560 learning.py:507] global step 9258: loss = 6.9999 (0.535 sec/step)
I0404 21:25:23.550709 47978602034560 learning.py:507] global step 9259: loss = 6.2249 (0.505 sec/step)
I0404 21:25:24.060760 47978602034560 learning.py:507] global step 9260: loss = 5.1628 (0.508 sec/step)
I0404 21:25:24.571098 47978602034560 learning.py:507] global step 9261: loss = 5.4900 (0.509 sec/step)
I0404 21:25:25.086368 47978602034560 learning.py:507] global step 9262: loss = 5.1750 (0.514 sec/step)
I0404 21:25:25.616949 47978602034560 learning.py:507] global step 9263: loss = 6.1094 (0.529 sec/step)
I0404 21:25:26.117216 47978602034560 learning.py:507] global step 9264: loss = 5.6283 (0.499 sec/step)
I0404 21:25:26.627961 47978602034560 learning.py:507] global step 9265: loss = 6.7428 (0.509 sec/step)
I0404 21:25:27.136736 47978602034560 learning.py:507] global step 9266: loss = 5.1954 (0.507 sec/step)
I0404 21:25:27.663672 47978602034560 learning.py:507] global step 9267: loss = 5.2065 (0.525 sec/step)
I0404 21:25:28.192486 47978602034560 learning.py:507] global step 9268: loss = 5.4808 (0.527 sec/step)
I0404 21:25:28.697793 47978602034560 learning.py:507] global step 9269: loss = 5.4588 (0.502 sec/step)
I0404 21:25:29.207187 47978602034560 learning.py:507] global step 9270: loss = 5.6261 (0.507 sec/step)
I0404 21:25:29.718136 47978602034560 learning.py:507] global step 9271: loss = 5.4331 (0.509 sec/step)
I0404 21:25:30.235095 47978602034560 learning.py:507] global step 9272: loss = 6.0431 (0.515 sec/step)
I0404 21:25:30.746373 47978602034560 learning.py:507] global step 9273: loss = 6.4907 (0.510 sec/step)
I0404 21:25:31.277255 47978602034560 learning.py:507] global step 9274: loss = 5.3821 (0.529 sec/step)
I0404 21:25:31.799859 47978602034560 learning.py:507] global step 9275: loss = 6.5780 (0.520 sec/step)
I0404 21:25:32.313404 47978602034560 learning.py:507] global step 9276: loss = 6.4915 (0.512 sec/step)
I0404 21:25:32.835721 47978602034560 learning.py:507] global step 9277: loss = 6.4944 (0.521 sec/step)
I0404 21:25:33.344572 47978602034560 learning.py:507] global step 9278: loss = 6.8313 (0.506 sec/step)
I0404 21:25:33.853407 47978602034560 learning.py:507] global step 9279: loss = 6.0381 (0.507 sec/step)
I0404 21:25:34.390389 47978602034560 learning.py:507] global step 9280: loss = 5.0914 (0.535 sec/step)
I0404 21:25:34.924378 47978602034560 learning.py:507] global step 9281: loss = 6.0832 (0.532 sec/step)
I0404 21:25:35.430662 47978602034560 learning.py:507] global step 9282: loss = 5.1403 (0.504 sec/step)
I0404 21:25:35.942217 47978602034560 learning.py:507] global step 9283: loss = 5.9540 (0.510 sec/step)
I0404 21:25:36.451099 47978602034560 learning.py:507] global step 9284: loss = 5.4650 (0.507 sec/step)
I0404 21:25:36.965188 47978602034560 learning.py:507] global step 9285: loss = 5.5900 (0.512 sec/step)
I0404 21:25:37.491458 47978602034560 learning.py:507] global step 9286: loss = 5.1541 (0.525 sec/step)
I0404 21:25:38.023495 47978602034560 learning.py:507] global step 9287: loss = 5.0035 (0.529 sec/step)
I0404 21:25:38.531349 47978602034560 learning.py:507] global step 9288: loss = 6.8511 (0.505 sec/step)
I0404 21:25:39.068438 47978602034560 learning.py:507] global step 9289: loss = 5.4742 (0.536 sec/step)
I0404 21:25:39.586900 47978602034560 learning.py:507] global step 9290: loss = 4.7635 (0.517 sec/step)
I0404 21:25:40.094305 47978602034560 learning.py:507] global step 9291: loss = 6.2539 (0.505 sec/step)
I0404 21:25:40.599176 47978602034560 learning.py:507] global step 9292: loss = 5.3506 (0.503 sec/step)
I0404 21:25:41.142311 47978602034560 learning.py:507] global step 9293: loss = 4.3094 (0.542 sec/step)
I0404 21:25:41.646768 47978602034560 learning.py:507] global step 9294: loss = 6.6265 (0.502 sec/step)
I0404 21:25:42.176045 47978602034560 learning.py:507] global step 9295: loss = 6.0434 (0.528 sec/step)
I0404 21:25:42.683110 47978602034560 learning.py:507] global step 9296: loss = 5.7466 (0.505 sec/step)
I0404 21:25:43.189554 47978602034560 learning.py:507] global step 9297: loss = 5.9069 (0.505 sec/step)
I0404 21:25:43.723191 47978602034560 learning.py:507] global step 9298: loss = 6.0392 (0.532 sec/step)
I0404 21:25:44.252804 47978602034560 learning.py:507] global step 9299: loss = 5.6577 (0.527 sec/step)
I0404 21:25:44.766048 47978602034560 learning.py:507] global step 9300: loss = 5.5984 (0.510 sec/step)
I0404 21:25:45.266664 47978602034560 learning.py:507] global step 9301: loss = 6.1290 (0.498 sec/step)
I0404 21:25:45.804761 47978602034560 learning.py:507] global step 9302: loss = 4.7927 (0.537 sec/step)
I0404 21:25:46.342560 47978602034560 learning.py:507] global step 9303: loss = 4.9851 (0.536 sec/step)
I0404 21:25:46.875113 47978602034560 learning.py:507] global step 9304: loss = 6.4545 (0.530 sec/step)
I0404 21:25:47.407879 47978602034560 learning.py:507] global step 9305: loss = 6.1544 (0.531 sec/step)
I0404 21:25:47.915372 47978602034560 learning.py:507] global step 9306: loss = 5.3138 (0.505 sec/step)
I0404 21:25:48.424293 47978602034560 learning.py:507] global step 9307: loss = 5.2068 (0.507 sec/step)
I0404 21:25:48.929229 47978602034560 learning.py:507] global step 9308: loss = 5.7979 (0.502 sec/step)
I0404 21:25:49.450052 47978602034560 learning.py:507] global step 9309: loss = 6.0458 (0.519 sec/step)
I0404 21:25:49.968538 47978602034560 learning.py:507] global step 9310: loss = 5.3838 (0.517 sec/step)
I0404 21:25:50.477867 47978602034560 learning.py:507] global step 9311: loss = 6.6540 (0.506 sec/step)
I0404 21:25:51.010310 47978602034560 learning.py:507] global step 9312: loss = 5.9362 (0.530 sec/step)
I0404 21:25:51.513259 47978602034560 learning.py:507] global step 9313: loss = 6.3683 (0.500 sec/step)
I0404 21:25:52.017942 47978602034560 learning.py:507] global step 9314: loss = 5.9055 (0.503 sec/step)
I0404 21:25:52.527880 47978602034560 learning.py:507] global step 9315: loss = 5.6004 (0.508 sec/step)
I0404 21:25:53.045126 47978602034560 learning.py:507] global step 9316: loss = 6.6387 (0.516 sec/step)
I0404 21:25:53.574622 47978602034560 learning.py:507] global step 9317: loss = 5.4603 (0.528 sec/step)
I0404 21:25:54.098084 47978602034560 learning.py:507] global step 9318: loss = 6.0255 (0.521 sec/step)
I0404 21:25:54.611271 47978602034560 learning.py:507] global step 9319: loss = 5.3154 (0.510 sec/step)
I0404 21:25:55.138748 47978602034560 learning.py:507] global step 9320: loss = 6.1656 (0.526 sec/step)
I0404 21:25:55.649961 47978602034560 learning.py:507] global step 9321: loss = 6.3212 (0.510 sec/step)
I0404 21:25:56.173753 47978602034560 learning.py:507] global step 9322: loss = 5.3328 (0.522 sec/step)
I0404 21:25:56.686906 47978602034560 learning.py:507] global step 9323: loss = 4.9903 (0.510 sec/step)
I0404 21:25:57.192089 47978602034560 learning.py:507] global step 9324: loss = 6.0988 (0.502 sec/step)
I0404 21:25:57.724136 47978602034560 learning.py:507] global step 9325: loss = 4.3428 (0.529 sec/step)
I0404 21:25:58.235389 47978602034560 learning.py:507] global step 9326: loss = 5.3642 (0.510 sec/step)
I0404 21:25:58.770250 47978602034560 learning.py:507] global step 9327: loss = 4.6914 (0.532 sec/step)
I0404 21:25:59.281178 47978602034560 learning.py:507] global step 9328: loss = 5.7389 (0.509 sec/step)
I0404 21:25:59.794305 47978602034560 learning.py:507] global step 9329: loss = 6.8658 (0.512 sec/step)
I0404 21:26:00.310994 47978602034560 learning.py:507] global step 9330: loss = 6.6570 (0.515 sec/step)
I0404 21:26:00.849169 47978602034560 learning.py:507] global step 9331: loss = 5.8377 (0.535 sec/step)
I0404 21:26:01.356596 47978602034560 learning.py:507] global step 9332: loss = 5.3597 (0.505 sec/step)
I0404 21:26:01.871073 47978602034560 learning.py:507] global step 9333: loss = 7.0956 (0.512 sec/step)
I0404 21:26:02.378151 47978602034560 learning.py:507] global step 9334: loss = 4.8946 (0.505 sec/step)
I0404 21:26:02.911085 47978602034560 learning.py:507] global step 9335: loss = 5.9920 (0.531 sec/step)
I0404 21:26:03.447242 47978602034560 learning.py:507] global step 9336: loss = 6.0256 (0.535 sec/step)
I0404 21:26:03.965277 47978602034560 learning.py:507] global step 9337: loss = 5.9137 (0.517 sec/step)
I0404 21:26:04.470996 47978602034560 learning.py:507] global step 9338: loss = 4.8461 (0.504 sec/step)
I0404 21:26:04.973004 47978602034560 learning.py:507] global step 9339: loss = 6.1819 (0.500 sec/step)
I0404 21:26:05.483413 47978602034560 learning.py:507] global step 9340: loss = 6.8327 (0.509 sec/step)
I0404 21:26:06.014495 47978602034560 learning.py:507] global step 9341: loss = 5.1369 (0.529 sec/step)
I0404 21:26:06.553274 47978602034560 learning.py:507] global step 9342: loss = 6.3327 (0.537 sec/step)
I0404 21:26:07.062711 47978602034560 learning.py:507] global step 9343: loss = 5.8799 (0.508 sec/step)
I0404 21:26:07.574609 47978602034560 learning.py:507] global step 9344: loss = 6.3645 (0.510 sec/step)
I0404 21:26:08.091325 47978602034560 learning.py:507] global step 9345: loss = 5.4662 (0.515 sec/step)
I0404 21:26:08.627073 47978602034560 learning.py:507] global step 9346: loss = 5.1340 (0.534 sec/step)
I0404 21:26:09.154978 47978602034560 learning.py:507] global step 9347: loss = 5.9665 (0.526 sec/step)
I0404 21:26:09.683080 47978602034560 learning.py:507] global step 9348: loss = 6.4344 (0.527 sec/step)
I0404 21:26:10.186393 47978602034560 learning.py:507] global step 9349: loss = 4.7703 (0.502 sec/step)
I0404 21:26:10.698705 47978602034560 learning.py:507] global step 9350: loss = 5.0757 (0.511 sec/step)
I0404 21:26:11.229153 47978602034560 learning.py:507] global step 9351: loss = 6.1821 (0.529 sec/step)
I0404 21:26:11.741642 47978602034560 learning.py:507] global step 9352: loss = 5.7807 (0.511 sec/step)
I0404 21:26:12.258299 47978602034560 learning.py:507] global step 9353: loss = 6.0450 (0.514 sec/step)
I0404 21:26:12.766912 47978602034560 learning.py:507] global step 9354: loss = 6.5617 (0.507 sec/step)
I0404 21:26:13.286526 47978602034560 learning.py:507] global step 9355: loss = 7.1978 (0.518 sec/step)
I0404 21:26:13.792459 47978602034560 learning.py:507] global step 9356: loss = 6.6896 (0.504 sec/step)
I0404 21:26:14.295223 47978602034560 learning.py:507] global step 9357: loss = 6.4228 (0.500 sec/step)
I0404 21:26:14.811302 47978602034560 learning.py:507] global step 9358: loss = 5.6751 (0.514 sec/step)
I0404 21:26:15.315679 47978602034560 learning.py:507] global step 9359: loss = 5.9327 (0.503 sec/step)
I0404 21:26:15.843841 47978602034560 learning.py:507] global step 9360: loss = 6.1032 (0.527 sec/step)
I0404 21:26:16.350575 47978602034560 learning.py:507] global step 9361: loss = 5.8091 (0.504 sec/step)
I0404 21:26:16.887439 47978602034560 learning.py:507] global step 9362: loss = 5.8079 (0.535 sec/step)
I0404 21:26:17.393766 47978602034560 learning.py:507] global step 9363: loss = 5.8071 (0.505 sec/step)
I0404 21:26:17.938906 47978602034560 learning.py:507] global step 9364: loss = 5.3284 (0.544 sec/step)
I0404 21:26:18.480486 47978602034560 learning.py:507] global step 9365: loss = 6.3479 (0.540 sec/step)
I0404 21:26:19.007696 47978602034560 learning.py:507] global step 9366: loss = 5.1163 (0.526 sec/step)
I0404 21:26:19.511830 47978602034560 learning.py:507] global step 9367: loss = 4.6803 (0.501 sec/step)
I0404 21:26:20.026807 47978602034560 learning.py:507] global step 9368: loss = 5.7933 (0.512 sec/step)
I0404 21:26:20.535988 47978602034560 learning.py:507] global step 9369: loss = 5.7599 (0.506 sec/step)
I0404 21:26:21.045918 47978602034560 learning.py:507] global step 9370: loss = 5.1409 (0.507 sec/step)
I0404 21:26:21.556710 47978602034560 learning.py:507] global step 9371: loss = 5.3562 (0.509 sec/step)
I0404 21:26:22.059938 47978602034560 learning.py:507] global step 9372: loss = 6.1286 (0.502 sec/step)
I0404 21:26:22.574156 47978602034560 learning.py:507] global step 9373: loss = 6.2582 (0.513 sec/step)
I0404 21:26:23.094061 47978602034560 learning.py:507] global step 9374: loss = 5.0702 (0.518 sec/step)
I0404 21:26:23.611923 47978602034560 learning.py:507] global step 9375: loss = 5.0191 (0.516 sec/step)
I0404 21:26:24.118320 47978602034560 learning.py:507] global step 9376: loss = 5.3234 (0.505 sec/step)
I0404 21:26:24.633665 47978602034560 learning.py:507] global step 9377: loss = 5.1996 (0.514 sec/step)
I0404 21:26:25.158681 47978602034560 learning.py:507] global step 9378: loss = 5.8063 (0.523 sec/step)
I0404 21:26:25.671405 47978602034560 learning.py:507] global step 9379: loss = 4.9755 (0.510 sec/step)
I0404 21:26:26.180379 47978602034560 learning.py:507] global step 9380: loss = 5.5606 (0.507 sec/step)
I0404 21:26:26.693355 47978602034560 learning.py:507] global step 9381: loss = 4.6523 (0.511 sec/step)
I0404 21:26:27.197992 47978602034560 learning.py:507] global step 9382: loss = 6.6627 (0.502 sec/step)
I0404 21:26:27.724486 47978602034560 learning.py:507] global step 9383: loss = 5.0342 (0.525 sec/step)
I0404 21:26:28.234454 47978602034560 learning.py:507] global step 9384: loss = 5.2447 (0.508 sec/step)
I0404 21:26:28.761142 47978602034560 learning.py:507] global step 9385: loss = 6.3200 (0.525 sec/step)
I0404 21:26:29.266563 47978602034560 learning.py:507] global step 9386: loss = 6.0751 (0.504 sec/step)
I0404 21:26:29.803344 47978602034560 learning.py:507] global step 9387: loss = 7.1342 (0.534 sec/step)
I0404 21:26:30.321538 47978602034560 learning.py:507] global step 9388: loss = 5.4654 (0.515 sec/step)
I0404 21:26:30.843788 47978602034560 learning.py:507] global step 9389: loss = 6.7256 (0.521 sec/step)
I0404 21:26:31.350315 47978602034560 learning.py:507] global step 9390: loss = 6.3629 (0.505 sec/step)
I0404 21:26:31.860285 47978602034560 learning.py:507] global step 9391: loss = 5.5216 (0.508 sec/step)
I0404 21:26:32.372569 47978602034560 learning.py:507] global step 9392: loss = 4.7469 (0.511 sec/step)
I0404 21:26:32.886489 47978602034560 learning.py:507] global step 9393: loss = 6.0602 (0.511 sec/step)
I0404 21:26:33.387180 47978602034560 learning.py:507] global step 9394: loss = 4.7571 (0.499 sec/step)
I0404 21:26:33.908588 47978602034560 learning.py:507] global step 9395: loss = 5.2291 (0.520 sec/step)
I0404 21:26:34.419387 47978602034560 learning.py:507] global step 9396: loss = 6.0118 (0.508 sec/step)
I0404 21:26:34.927102 47978602034560 learning.py:507] global step 9397: loss = 5.8550 (0.506 sec/step)
I0404 21:26:35.434925 47978602034560 learning.py:507] global step 9398: loss = 5.4869 (0.506 sec/step)
I0404 21:26:35.940107 47978602034560 learning.py:507] global step 9399: loss = 6.0739 (0.504 sec/step)
I0404 21:26:36.475644 47978602034560 learning.py:507] global step 9400: loss = 5.5657 (0.534 sec/step)
I0404 21:26:36.986619 47978602034560 learning.py:507] global step 9401: loss = 5.1152 (0.509 sec/step)
I0404 21:26:37.492448 47978602034560 learning.py:507] global step 9402: loss = 6.1971 (0.504 sec/step)
I0404 21:26:38.003691 47978602034560 learning.py:507] global step 9403: loss = 6.4002 (0.510 sec/step)
I0404 21:26:38.522277 47978602034560 learning.py:507] global step 9404: loss = 5.4800 (0.517 sec/step)
I0404 21:26:39.049441 47978602034560 learning.py:507] global step 9405: loss = 6.2830 (0.526 sec/step)
I0404 21:26:39.559452 47978602034560 learning.py:507] global step 9406: loss = 5.5782 (0.508 sec/step)
I0404 21:26:40.086742 47978602034560 learning.py:507] global step 9407: loss = 5.8101 (0.526 sec/step)
I0404 21:26:40.599195 47978602034560 learning.py:507] global step 9408: loss = 4.7598 (0.511 sec/step)
I0404 21:26:41.117856 47978602034560 learning.py:507] global step 9409: loss = 6.5594 (0.516 sec/step)
I0404 21:26:41.623776 47978602034560 learning.py:507] global step 9410: loss = 5.3979 (0.503 sec/step)
I0404 21:26:42.128330 47978602034560 learning.py:507] global step 9411: loss = 6.7044 (0.502 sec/step)
I0404 21:26:42.641365 47978602034560 learning.py:507] global step 9412: loss = 5.6004 (0.511 sec/step)
I0404 21:26:43.144665 47978602034560 learning.py:507] global step 9413: loss = 6.8760 (0.502 sec/step)
I0404 21:26:43.663659 47978602034560 learning.py:507] global step 9414: loss = 5.8351 (0.517 sec/step)
I0404 21:26:44.171982 47978602034560 learning.py:507] global step 9415: loss = 5.9985 (0.505 sec/step)
I0404 21:26:44.697945 47978602034560 learning.py:507] global step 9416: loss = 5.5308 (0.524 sec/step)
I0404 21:26:45.206860 47978602034560 learning.py:507] global step 9417: loss = 5.6785 (0.507 sec/step)
I0404 21:26:45.727394 47978602034560 learning.py:507] global step 9418: loss = 6.4370 (0.518 sec/step)
I0404 21:26:46.237105 47978602034560 learning.py:507] global step 9419: loss = 6.7636 (0.508 sec/step)
I0404 21:26:46.750856 47978602034560 learning.py:507] global step 9420: loss = 5.6995 (0.512 sec/step)
I0404 21:26:47.257718 47978602034560 learning.py:507] global step 9421: loss = 6.1339 (0.504 sec/step)
I0404 21:26:47.762019 47978602034560 learning.py:507] global step 9422: loss = 5.2688 (0.501 sec/step)
I0404 21:26:48.290355 47978602034560 learning.py:507] global step 9423: loss = 6.8111 (0.527 sec/step)
I0404 21:26:48.802133 47978602034560 learning.py:507] global step 9424: loss = 5.2234 (0.510 sec/step)
I0404 21:26:49.309195 47978602034560 learning.py:507] global step 9425: loss = 5.8628 (0.504 sec/step)
I0404 21:26:49.808892 47978602034560 learning.py:507] global step 9426: loss = 6.3355 (0.498 sec/step)
I0404 21:26:50.350104 47978602034560 learning.py:507] global step 9427: loss = 5.9615 (0.540 sec/step)
I0404 21:26:50.859997 47978602034560 learning.py:507] global step 9428: loss = 5.5069 (0.508 sec/step)
I0404 21:26:51.386978 47978602034560 learning.py:507] global step 9429: loss = 6.3037 (0.525 sec/step)
I0404 21:26:51.900959 47978602034560 learning.py:507] global step 9430: loss = 4.7901 (0.511 sec/step)
I0404 21:26:52.420578 47978602034560 learning.py:507] global step 9431: loss = 6.9019 (0.517 sec/step)
I0404 21:26:52.925552 47978602034560 learning.py:507] global step 9432: loss = 5.9123 (0.503 sec/step)
I0404 21:26:53.441394 47978602034560 learning.py:507] global step 9433: loss = 5.1313 (0.514 sec/step)
I0404 21:26:53.970509 47978602034560 learning.py:507] global step 9434: loss = 7.0454 (0.528 sec/step)
I0404 21:26:54.476971 47978602034560 learning.py:507] global step 9435: loss = 5.6056 (0.505 sec/step)
I0404 21:26:54.990113 47978602034560 learning.py:507] global step 9436: loss = 4.7052 (0.511 sec/step)
I0404 21:26:55.501128 47978602034560 learning.py:507] global step 9437: loss = 5.2569 (0.509 sec/step)
I0404 21:26:56.041126 47978602034560 learning.py:507] global step 9438: loss = 6.1865 (0.538 sec/step)
I0404 21:26:56.547641 47978602034560 learning.py:507] global step 9439: loss = 5.7220 (0.504 sec/step)
I0404 21:26:57.054455 47978602034560 learning.py:507] global step 9440: loss = 5.5879 (0.505 sec/step)
I0404 21:26:57.565177 47978602034560 learning.py:507] global step 9441: loss = 4.8066 (0.509 sec/step)
I0404 21:26:58.096773 47978602034560 learning.py:507] global step 9442: loss = 5.9860 (0.529 sec/step)
I0404 21:26:58.601602 47978602034560 learning.py:507] global step 9443: loss = 5.5365 (0.502 sec/step)
I0404 21:26:59.111681 47978602034560 learning.py:507] global step 9444: loss = 5.7732 (0.509 sec/step)
I0404 21:26:59.620573 47978602034560 learning.py:507] global step 9445: loss = 5.5358 (0.507 sec/step)
I0404 21:27:00.131503 47978602034560 learning.py:507] global step 9446: loss = 5.8677 (0.509 sec/step)
I0404 21:27:00.634990 47978602034560 learning.py:507] global step 9447: loss = 5.6253 (0.502 sec/step)
I0404 21:27:01.143673 47978602034560 learning.py:507] global step 9448: loss = 5.7639 (0.507 sec/step)
I0404 21:27:01.665296 47978602034560 learning.py:507] global step 9449: loss = 7.7449 (0.520 sec/step)
I0404 21:27:02.174789 47978602034560 learning.py:507] global step 9450: loss = 5.0795 (0.508 sec/step)
I0404 21:27:02.693686 47978602034560 learning.py:507] global step 9451: loss = 5.7694 (0.517 sec/step)
I0404 21:27:03.207291 47978602034560 learning.py:507] global step 9452: loss = 5.6297 (0.511 sec/step)
I0404 21:27:03.728373 47978602034560 learning.py:507] global step 9453: loss = 6.1984 (0.520 sec/step)
I0404 21:27:04.264868 47978602034560 learning.py:507] global step 9454: loss = 5.6556 (0.535 sec/step)
I0404 21:27:04.785955 47978602034560 learning.py:507] global step 9455: loss = 5.3673 (0.518 sec/step)
I0404 21:27:05.299127 47978602034560 learning.py:507] global step 9456: loss = 5.1346 (0.512 sec/step)
I0404 21:27:05.807703 47978602034560 learning.py:507] global step 9457: loss = 6.4537 (0.507 sec/step)
I0404 21:27:06.329825 47978602034560 learning.py:507] global step 9458: loss = 6.1955 (0.519 sec/step)
I0404 21:27:06.832602 47978602034560 learning.py:507] global step 9459: loss = 5.4438 (0.501 sec/step)
I0404 21:27:07.341505 47978602034560 learning.py:507] global step 9460: loss = 4.9749 (0.507 sec/step)
I0404 21:27:07.863589 47978602034560 learning.py:507] global step 9461: loss = 5.8711 (0.521 sec/step)
I0404 21:27:08.373047 47978602034560 learning.py:507] global step 9462: loss = 6.1463 (0.508 sec/step)
I0404 21:27:08.915535 47978602034560 learning.py:507] global step 9463: loss = 4.9069 (0.541 sec/step)
I0404 21:27:09.425315 47978602034560 learning.py:507] global step 9464: loss = 6.0999 (0.508 sec/step)
I0404 21:27:09.931676 47978602034560 learning.py:507] global step 9465: loss = 5.4103 (0.503 sec/step)
I0404 21:27:10.439617 47978602034560 learning.py:507] global step 9466: loss = 6.1990 (0.505 sec/step)
I0404 21:27:10.948610 47978602034560 learning.py:507] global step 9467: loss = 4.9383 (0.507 sec/step)
I0404 21:27:11.458560 47978602034560 learning.py:507] global step 9468: loss = 5.5614 (0.508 sec/step)
I0404 21:27:11.977231 47978602034560 learning.py:507] global step 9469: loss = 4.5924 (0.517 sec/step)
I0404 21:27:12.486629 47978602034560 learning.py:507] global step 9470: loss = 5.1344 (0.508 sec/step)
I0404 21:27:13.002922 47978602034560 learning.py:507] global step 9471: loss = 6.2422 (0.515 sec/step)
I0404 21:27:13.527932 47978602034560 learning.py:507] global step 9472: loss = 6.5961 (0.523 sec/step)
I0404 21:27:14.038369 47978602034560 learning.py:507] global step 9473: loss = 4.6602 (0.509 sec/step)
I0404 21:27:14.550497 47978602034560 learning.py:507] global step 9474: loss = 5.8888 (0.510 sec/step)
I0404 21:27:15.063862 47978602034560 learning.py:507] global step 9475: loss = 6.1746 (0.512 sec/step)
I0404 21:27:15.575372 47978602034560 learning.py:507] global step 9476: loss = 6.0004 (0.510 sec/step)
I0404 21:27:16.092399 47978602034560 learning.py:507] global step 9477: loss = 6.3238 (0.515 sec/step)
I0404 21:27:16.623000 47978602034560 learning.py:507] global step 9478: loss = 5.9103 (0.528 sec/step)
I0404 21:27:17.349079 47978602034560 learning.py:507] global step 9479: loss = 5.6483 (0.723 sec/step)
I0404 21:27:17.350264 47983661975296 supervisor.py:1050] Recording summary at step 9479.
I0404 21:27:17.866977 47978602034560 learning.py:507] global step 9480: loss = 6.6001 (0.512 sec/step)
I0404 21:27:18.390465 47978602034560 learning.py:507] global step 9481: loss = 5.7675 (0.522 sec/step)
I0404 21:27:18.907229 47978602034560 learning.py:507] global step 9482: loss = 6.0194 (0.515 sec/step)
I0404 21:27:19.410551 47978602034560 learning.py:507] global step 9483: loss = 5.4030 (0.502 sec/step)
I0404 21:27:19.928842 47978602034560 learning.py:507] global step 9484: loss = 6.2407 (0.515 sec/step)
I0404 21:27:20.455595 47978602034560 learning.py:507] global step 9485: loss = 6.2599 (0.525 sec/step)
I0404 21:27:20.971111 47978602034560 learning.py:507] global step 9486: loss = 6.0583 (0.513 sec/step)
I0404 21:27:21.478547 47978602034560 learning.py:507] global step 9487: loss = 5.9771 (0.505 sec/step)
I0404 21:27:21.985406 47978602034560 learning.py:507] global step 9488: loss = 5.6621 (0.505 sec/step)
I0404 21:27:22.510545 47978602034560 learning.py:507] global step 9489: loss = 4.7277 (0.524 sec/step)
I0404 21:27:23.048512 47978602034560 learning.py:507] global step 9490: loss = 5.6420 (0.536 sec/step)
I0404 21:27:23.561776 47978602034560 learning.py:507] global step 9491: loss = 5.1509 (0.512 sec/step)
I0404 21:27:24.073281 47978602034560 learning.py:507] global step 9492: loss = 5.8296 (0.510 sec/step)
I0404 21:27:24.579447 47978602034560 learning.py:507] global step 9493: loss = 6.4638 (0.503 sec/step)
I0404 21:27:25.095287 47978602034560 learning.py:507] global step 9494: loss = 5.4750 (0.513 sec/step)
I0404 21:27:25.612945 47978602034560 learning.py:507] global step 9495: loss = 5.7861 (0.514 sec/step)
I0404 21:27:26.132423 47978602034560 learning.py:507] global step 9496: loss = 5.8971 (0.517 sec/step)
I0404 21:27:26.648313 47978602034560 learning.py:507] global step 9497: loss = 4.6501 (0.514 sec/step)
I0404 21:27:27.156818 47978602034560 learning.py:507] global step 9498: loss = 5.6724 (0.507 sec/step)
I0404 21:27:27.695247 47978602034560 learning.py:507] global step 9499: loss = 6.0269 (0.537 sec/step)
I0404 21:27:28.206602 47978602034560 learning.py:507] global step 9500: loss = 5.5279 (0.510 sec/step)
I0404 21:27:28.712413 47978602034560 learning.py:507] global step 9501: loss = 4.9044 (0.503 sec/step)
I0404 21:27:29.236122 47978602034560 learning.py:507] global step 9502: loss = 4.9611 (0.522 sec/step)
I0404 21:27:29.742707 47978602034560 learning.py:507] global step 9503: loss = 4.8079 (0.505 sec/step)
I0404 21:27:30.252037 47978602034560 learning.py:507] global step 9504: loss = 5.4425 (0.508 sec/step)
I0404 21:27:30.750477 47978602034560 learning.py:507] global step 9505: loss = 5.1905 (0.496 sec/step)
I0404 21:27:31.279244 47978602034560 learning.py:507] global step 9506: loss = 5.4583 (0.527 sec/step)
I0404 21:27:31.787129 47978602034560 learning.py:507] global step 9507: loss = 6.5951 (0.505 sec/step)
I0404 21:27:32.301132 47978602034560 learning.py:507] global step 9508: loss = 6.6465 (0.512 sec/step)
I0404 21:27:32.837838 47978602034560 learning.py:507] global step 9509: loss = 5.8787 (0.535 sec/step)
I0404 21:27:33.352314 47978602034560 learning.py:507] global step 9510: loss = 5.8069 (0.513 sec/step)
I0404 21:27:33.867111 47978602034560 learning.py:507] global step 9511: loss = 5.2487 (0.513 sec/step)
I0404 21:27:34.392149 47978602034560 learning.py:507] global step 9512: loss = 5.4458 (0.523 sec/step)
I0404 21:27:34.905336 47978602034560 learning.py:507] global step 9513: loss = 5.9042 (0.510 sec/step)
I0404 21:27:35.437691 47978602034560 learning.py:507] global step 9514: loss = 6.4060 (0.530 sec/step)
I0404 21:27:35.955542 47978602034560 learning.py:507] global step 9515: loss = 5.1812 (0.516 sec/step)
I0404 21:27:36.493263 47978602034560 learning.py:507] global step 9516: loss = 7.1690 (0.536 sec/step)
I0404 21:27:36.998332 47978602034560 learning.py:507] global step 9517: loss = 5.7257 (0.503 sec/step)
I0404 21:27:37.510929 47978602034560 learning.py:507] global step 9518: loss = 5.2016 (0.511 sec/step)
I0404 21:27:38.024591 47978602034560 learning.py:507] global step 9519: loss = 6.1135 (0.511 sec/step)
I0404 21:27:38.535785 47978602034560 learning.py:507] global step 9520: loss = 5.7093 (0.510 sec/step)
I0404 21:27:39.058127 47978602034560 learning.py:507] global step 9521: loss = 6.2042 (0.521 sec/step)
I0404 21:27:39.597758 47978602034560 learning.py:507] global step 9522: loss = 5.5713 (0.538 sec/step)
I0404 21:27:40.112010 47978602034560 learning.py:507] global step 9523: loss = 6.7071 (0.513 sec/step)
I0404 21:27:40.620611 47978602034560 learning.py:507] global step 9524: loss = 5.9854 (0.507 sec/step)
I0404 21:27:41.128376 47978602034560 learning.py:507] global step 9525: loss = 6.1591 (0.506 sec/step)
I0404 21:27:41.642943 47978602034560 learning.py:507] global step 9526: loss = 5.6712 (0.513 sec/step)
I0404 21:27:42.154996 47978602034560 learning.py:507] global step 9527: loss = 5.8035 (0.511 sec/step)
I0404 21:27:42.662499 47978602034560 learning.py:507] global step 9528: loss = 6.0561 (0.506 sec/step)
I0404 21:27:43.167372 47978602034560 learning.py:507] global step 9529: loss = 7.1279 (0.502 sec/step)
I0404 21:27:43.682701 47978602034560 learning.py:507] global step 9530: loss = 4.6468 (0.512 sec/step)
I0404 21:27:44.198905 47978602034560 learning.py:507] global step 9531: loss = 5.0498 (0.515 sec/step)
I0404 21:27:44.726778 47978602034560 learning.py:507] global step 9532: loss = 5.1393 (0.526 sec/step)
I0404 21:27:45.240386 47978602034560 learning.py:507] global step 9533: loss = 6.1069 (0.512 sec/step)
I0404 21:27:45.775138 47978602034560 learning.py:507] global step 9534: loss = 6.5269 (0.533 sec/step)
I0404 21:27:46.290981 47978602034560 learning.py:507] global step 9535: loss = 5.0550 (0.514 sec/step)
I0404 21:27:46.802790 47978602034560 learning.py:507] global step 9536: loss = 5.0428 (0.510 sec/step)
I0404 21:27:47.317194 47978602034560 learning.py:507] global step 9537: loss = 5.8426 (0.512 sec/step)
I0404 21:27:47.824345 47978602034560 learning.py:507] global step 9538: loss = 5.6663 (0.506 sec/step)
I0404 21:27:48.362535 47978602034560 learning.py:507] global step 9539: loss = 5.1220 (0.537 sec/step)
I0404 21:27:48.873180 47978602034560 learning.py:507] global step 9540: loss = 5.2990 (0.509 sec/step)
I0404 21:27:49.407344 47978602034560 learning.py:507] global step 9541: loss = 4.9557 (0.533 sec/step)
I0404 21:27:49.921892 47978602034560 learning.py:507] global step 9542: loss = 6.4248 (0.513 sec/step)
I0404 21:27:50.432318 47978602034560 learning.py:507] global step 9543: loss = 6.0127 (0.509 sec/step)
I0404 21:27:50.954033 47978602034560 learning.py:507] global step 9544: loss = 4.9220 (0.520 sec/step)
I0404 21:27:51.472122 47978602034560 learning.py:507] global step 9545: loss = 6.2308 (0.515 sec/step)
I0404 21:27:51.989233 47978602034560 learning.py:507] global step 9546: loss = 5.2940 (0.516 sec/step)
I0404 21:27:52.513042 47978602034560 learning.py:507] global step 9547: loss = 7.0997 (0.522 sec/step)
I0404 21:27:53.046722 47978602034560 learning.py:507] global step 9548: loss = 6.0557 (0.532 sec/step)
I0404 21:27:53.556157 47978602034560 learning.py:507] global step 9549: loss = 6.5729 (0.508 sec/step)
I0404 21:27:54.095878 47978602034560 learning.py:507] global step 9550: loss = 5.2044 (0.538 sec/step)
I0404 21:27:54.619955 47978602034560 learning.py:507] global step 9551: loss = 5.2887 (0.521 sec/step)
I0404 21:27:55.135380 47978602034560 learning.py:507] global step 9552: loss = 4.9965 (0.514 sec/step)
I0404 21:27:55.642311 47978602034560 learning.py:507] global step 9553: loss = 5.6921 (0.505 sec/step)
I0404 21:27:56.177698 47978602034560 learning.py:507] global step 9554: loss = 4.8011 (0.534 sec/step)
I0404 21:27:56.695293 47978602034560 learning.py:507] global step 9555: loss = 6.6902 (0.516 sec/step)
I0404 21:27:57.207170 47978602034560 learning.py:507] global step 9556: loss = 6.3023 (0.510 sec/step)
I0404 21:27:57.713705 47978602034560 learning.py:507] global step 9557: loss = 5.8606 (0.505 sec/step)
I0404 21:27:58.229028 47978602034560 learning.py:507] global step 9558: loss = 6.0477 (0.514 sec/step)
I0404 21:27:58.753644 47978602034560 learning.py:507] global step 9559: loss = 6.3081 (0.523 sec/step)
I0404 21:27:59.262595 47978602034560 learning.py:507] global step 9560: loss = 5.5754 (0.506 sec/step)
I0404 21:27:59.776764 47978602034560 learning.py:507] global step 9561: loss = 6.9949 (0.513 sec/step)
I0404 21:28:00.286116 47978602034560 learning.py:507] global step 9562: loss = 5.7743 (0.508 sec/step)
I0404 21:28:00.798017 47978602034560 learning.py:507] global step 9563: loss = 5.5912 (0.510 sec/step)
I0404 21:28:01.309305 47978602034560 learning.py:507] global step 9564: loss = 5.5281 (0.510 sec/step)
I0404 21:28:01.836314 47978602034560 learning.py:507] global step 9565: loss = 6.3687 (0.524 sec/step)
I0404 21:28:02.375909 47978602034560 learning.py:507] global step 9566: loss = 5.9159 (0.537 sec/step)
I0404 21:28:02.889051 47978602034560 learning.py:507] global step 9567: loss = 6.2157 (0.510 sec/step)
I0404 21:28:03.395263 47978602034560 learning.py:507] global step 9568: loss = 6.1537 (0.503 sec/step)
I0404 21:28:03.928770 47978602034560 learning.py:507] global step 9569: loss = 5.9998 (0.532 sec/step)
I0404 21:28:04.438542 47978602034560 learning.py:507] global step 9570: loss = 6.4397 (0.508 sec/step)
I0404 21:28:04.949083 47978602034560 learning.py:507] global step 9571: loss = 5.4311 (0.509 sec/step)
I0404 21:28:05.456150 47978602034560 learning.py:507] global step 9572: loss = 6.5031 (0.505 sec/step)
I0404 21:28:05.960488 47978602034560 learning.py:507] global step 9573: loss = 5.7232 (0.503 sec/step)
I0404 21:28:06.498056 47978602034560 learning.py:507] global step 9574: loss = 5.2896 (0.536 sec/step)
I0404 21:28:07.010584 47978602034560 learning.py:507] global step 9575: loss = 5.5104 (0.510 sec/step)
I0404 21:28:07.523119 47978602034560 learning.py:507] global step 9576: loss = 5.9519 (0.510 sec/step)
I0404 21:28:08.040676 47978602034560 learning.py:507] global step 9577: loss = 5.6748 (0.516 sec/step)
I0404 21:28:08.575592 47978602034560 learning.py:507] global step 9578: loss = 6.2367 (0.533 sec/step)
I0404 21:28:09.080690 47978602034560 learning.py:507] global step 9579: loss = 5.5933 (0.504 sec/step)
I0404 21:28:09.592838 47978602034560 learning.py:507] global step 9580: loss = 5.5300 (0.510 sec/step)
I0404 21:28:10.096288 47978602034560 learning.py:507] global step 9581: loss = 5.8941 (0.502 sec/step)
I0404 21:28:10.634161 47978602034560 learning.py:507] global step 9582: loss = 6.6436 (0.536 sec/step)
I0404 21:28:11.145263 47978602034560 learning.py:507] global step 9583: loss = 5.1791 (0.510 sec/step)
I0404 21:28:11.681180 47978602034560 learning.py:507] global step 9584: loss = 7.2844 (0.534 sec/step)
I0404 21:28:12.212646 47978602034560 learning.py:507] global step 9585: loss = 5.7666 (0.529 sec/step)
I0404 21:28:12.716028 47978602034560 learning.py:507] global step 9586: loss = 5.9913 (0.502 sec/step)
I0404 21:28:13.232495 47978602034560 learning.py:507] global step 9587: loss = 5.6063 (0.515 sec/step)
I0404 21:28:13.741176 47978602034560 learning.py:507] global step 9588: loss = 4.7284 (0.506 sec/step)
I0404 21:28:14.247300 47978602034560 learning.py:507] global step 9589: loss = 5.3026 (0.503 sec/step)
I0404 21:28:14.752444 47978602034560 learning.py:507] global step 9590: loss = 6.1874 (0.504 sec/step)
I0404 21:28:15.259450 47978602034560 learning.py:507] global step 9591: loss = 6.2093 (0.505 sec/step)
I0404 21:28:15.766717 47978602034560 learning.py:507] global step 9592: loss = 6.1791 (0.506 sec/step)
I0404 21:28:16.273379 47978602034560 learning.py:507] global step 9593: loss = 5.6085 (0.505 sec/step)
I0404 21:28:16.799155 47978602034560 learning.py:507] global step 9594: loss = 5.9993 (0.524 sec/step)
I0404 21:28:17.320262 47978602034560 learning.py:507] global step 9595: loss = 4.7459 (0.520 sec/step)
I0404 21:28:17.828847 47978602034560 learning.py:507] global step 9596: loss = 6.0778 (0.507 sec/step)
I0404 21:28:18.355956 47978602034560 learning.py:507] global step 9597: loss = 4.9621 (0.525 sec/step)
I0404 21:28:18.884091 47978602034560 learning.py:507] global step 9598: loss = 5.1499 (0.527 sec/step)
I0404 21:28:19.389018 47978602034560 learning.py:507] global step 9599: loss = 7.5141 (0.503 sec/step)
I0404 21:28:19.889357 47978602034560 learning.py:507] global step 9600: loss = 6.0251 (0.499 sec/step)
I0404 21:28:20.398648 47978602034560 learning.py:507] global step 9601: loss = 5.3720 (0.506 sec/step)
I0404 21:28:20.907940 47978602034560 learning.py:507] global step 9602: loss = 6.0545 (0.508 sec/step)
I0404 21:28:21.432709 47978602034560 learning.py:507] global step 9603: loss = 5.6979 (0.522 sec/step)
I0404 21:28:21.937622 47978602034560 learning.py:507] global step 9604: loss = 6.4386 (0.502 sec/step)
I0404 21:28:22.476304 47978602034560 learning.py:507] global step 9605: loss = 5.0360 (0.537 sec/step)
I0404 21:28:22.991080 47978602034560 learning.py:507] global step 9606: loss = 6.0764 (0.513 sec/step)
I0404 21:28:23.493042 47978602034560 learning.py:507] global step 9607: loss = 5.6025 (0.500 sec/step)
I0404 21:28:24.012231 47978602034560 learning.py:507] global step 9608: loss = 4.9724 (0.518 sec/step)
I0404 21:28:24.534834 47978602034560 learning.py:507] global step 9609: loss = 6.3206 (0.521 sec/step)
I0404 21:28:25.069267 47978602034560 learning.py:507] global step 9610: loss = 5.5830 (0.532 sec/step)
I0404 21:28:25.581099 47978602034560 learning.py:507] global step 9611: loss = 6.8794 (0.510 sec/step)
I0404 21:28:26.088385 47978602034560 learning.py:507] global step 9612: loss = 6.5089 (0.504 sec/step)
I0404 21:28:26.606331 47978602034560 learning.py:507] global step 9613: loss = 6.3583 (0.516 sec/step)
I0404 21:28:27.133141 47978602034560 learning.py:507] global step 9614: loss = 5.7870 (0.525 sec/step)
I0404 21:28:27.665745 47978602034560 learning.py:507] global step 9615: loss = 6.4335 (0.531 sec/step)
I0404 21:28:28.200725 47978602034560 learning.py:507] global step 9616: loss = 4.9410 (0.533 sec/step)
I0404 21:28:28.730866 47978602034560 learning.py:507] global step 9617: loss = 6.1092 (0.529 sec/step)
I0404 21:28:29.265806 47978602034560 learning.py:507] global step 9618: loss = 6.6775 (0.533 sec/step)
I0404 21:28:29.771856 47978602034560 learning.py:507] global step 9619: loss = 6.3822 (0.504 sec/step)
I0404 21:28:30.299396 47978602034560 learning.py:507] global step 9620: loss = 5.2812 (0.526 sec/step)
I0404 21:28:30.805581 47978602034560 learning.py:507] global step 9621: loss = 5.7068 (0.503 sec/step)
I0404 21:28:31.316003 47978602034560 learning.py:507] global step 9622: loss = 6.1978 (0.508 sec/step)
I0404 21:28:31.826391 47978602034560 learning.py:507] global step 9623: loss = 5.9536 (0.509 sec/step)
I0404 21:28:32.336790 47978602034560 learning.py:507] global step 9624: loss = 5.7296 (0.508 sec/step)
I0404 21:28:32.866885 47978602034560 learning.py:507] global step 9625: loss = 5.4921 (0.529 sec/step)
I0404 21:28:33.398519 47978602034560 learning.py:507] global step 9626: loss = 6.0803 (0.530 sec/step)
I0404 21:28:33.907395 47978602034560 learning.py:507] global step 9627: loss = 5.9307 (0.506 sec/step)
I0404 21:28:34.411501 47978602034560 learning.py:507] global step 9628: loss = 6.5361 (0.503 sec/step)
I0404 21:28:34.912961 47978602034560 learning.py:507] global step 9629: loss = 6.4390 (0.500 sec/step)
I0404 21:28:35.434711 47978602034560 learning.py:507] global step 9630: loss = 6.0856 (0.519 sec/step)
I0404 21:28:35.942185 47978602034560 learning.py:507] global step 9631: loss = 5.4629 (0.505 sec/step)
I0404 21:28:36.467759 47978602034560 learning.py:507] global step 9632: loss = 5.0700 (0.524 sec/step)
I0404 21:28:36.984548 47978602034560 learning.py:507] global step 9633: loss = 5.8469 (0.515 sec/step)
I0404 21:28:37.492848 47978602034560 learning.py:507] global step 9634: loss = 5.3970 (0.507 sec/step)
I0404 21:28:38.009912 47978602034560 learning.py:507] global step 9635: loss = 5.7581 (0.516 sec/step)
I0404 21:28:38.532156 47978602034560 learning.py:507] global step 9636: loss = 5.7564 (0.521 sec/step)
I0404 21:28:39.041353 47978602034560 learning.py:507] global step 9637: loss = 5.0473 (0.508 sec/step)
I0404 21:28:39.544542 47978602034560 learning.py:507] global step 9638: loss = 5.8453 (0.500 sec/step)
I0404 21:28:40.064167 47978602034560 learning.py:507] global step 9639: loss = 6.5823 (0.517 sec/step)
I0404 21:28:40.581714 47978602034560 learning.py:507] global step 9640: loss = 5.8375 (0.516 sec/step)
I0404 21:28:41.090454 47978602034560 learning.py:507] global step 9641: loss = 5.6967 (0.507 sec/step)
I0404 21:28:41.612112 47978602034560 learning.py:507] global step 9642: loss = 6.0261 (0.520 sec/step)
I0404 21:28:42.120255 47978602034560 learning.py:507] global step 9643: loss = 5.1840 (0.507 sec/step)
I0404 21:28:42.626681 47978602034560 learning.py:507] global step 9644: loss = 5.6542 (0.505 sec/step)
I0404 21:28:43.146834 47978602034560 learning.py:507] global step 9645: loss = 5.1521 (0.517 sec/step)
I0404 21:28:43.660459 47978602034560 learning.py:507] global step 9646: loss = 5.3199 (0.512 sec/step)
I0404 21:28:44.181686 47978602034560 learning.py:507] global step 9647: loss = 5.6888 (0.520 sec/step)
I0404 21:28:44.712088 47978602034560 learning.py:507] global step 9648: loss = 6.6812 (0.529 sec/step)
I0404 21:28:45.220611 47978602034560 learning.py:507] global step 9649: loss = 7.5565 (0.507 sec/step)
I0404 21:28:45.729520 47978602034560 learning.py:507] global step 9650: loss = 5.0811 (0.507 sec/step)
I0404 21:28:46.234144 47978602034560 learning.py:507] global step 9651: loss = 6.0342 (0.503 sec/step)
I0404 21:28:46.744904 47978602034560 learning.py:507] global step 9652: loss = 5.7320 (0.509 sec/step)
I0404 21:28:47.255868 47978602034560 learning.py:507] global step 9653: loss = 5.5096 (0.508 sec/step)
I0404 21:28:47.765636 47978602034560 learning.py:507] global step 9654: loss = 5.4603 (0.507 sec/step)
I0404 21:28:48.285841 47978602034560 learning.py:507] global step 9655: loss = 5.7230 (0.519 sec/step)
I0404 21:28:48.788098 47978602034560 learning.py:507] global step 9656: loss = 4.4749 (0.501 sec/step)
I0404 21:28:49.291807 47978602034560 learning.py:507] global step 9657: loss = 5.7203 (0.501 sec/step)
I0404 21:28:49.820510 47978602034560 learning.py:507] global step 9658: loss = 4.8228 (0.527 sec/step)
I0404 21:28:50.338424 47978602034560 learning.py:507] global step 9659: loss = 5.2412 (0.515 sec/step)
I0404 21:28:50.858998 47978602034560 learning.py:507] global step 9660: loss = 5.1261 (0.519 sec/step)
I0404 21:28:51.385003 47978602034560 learning.py:507] global step 9661: loss = 4.1566 (0.524 sec/step)
I0404 21:28:51.889305 47978602034560 learning.py:507] global step 9662: loss = 6.8202 (0.503 sec/step)
I0404 21:28:52.411367 47978602034560 learning.py:507] global step 9663: loss = 4.9668 (0.519 sec/step)
I0404 21:28:52.917771 47978602034560 learning.py:507] global step 9664: loss = 5.1828 (0.505 sec/step)
I0404 21:28:53.427612 47978602034560 learning.py:507] global step 9665: loss = 6.4623 (0.508 sec/step)
I0404 21:28:53.951037 47978602034560 learning.py:507] global step 9666: loss = 5.8700 (0.522 sec/step)
I0404 21:28:54.454770 47978602034560 learning.py:507] global step 9667: loss = 5.3988 (0.502 sec/step)
I0404 21:28:54.968059 47978602034560 learning.py:507] global step 9668: loss = 5.8473 (0.512 sec/step)
I0404 21:28:55.479808 47978602034560 learning.py:507] global step 9669: loss = 5.2646 (0.510 sec/step)
I0404 21:28:55.986343 47978602034560 learning.py:507] global step 9670: loss = 5.4607 (0.504 sec/step)
I0404 21:28:56.500062 47978602034560 learning.py:507] global step 9671: loss = 5.4396 (0.512 sec/step)
I0404 21:28:57.006219 47978602034560 learning.py:507] global step 9672: loss = 5.5452 (0.503 sec/step)
I0404 21:28:57.523834 47978602034560 learning.py:507] global step 9673: loss = 5.4095 (0.515 sec/step)
I0404 21:28:58.057138 47978602034560 learning.py:507] global step 9674: loss = 5.5534 (0.532 sec/step)
I0404 21:28:58.563547 47978602034560 learning.py:507] global step 9675: loss = 5.6046 (0.505 sec/step)
I0404 21:28:59.100052 47978602034560 learning.py:507] global step 9676: loss = 5.9736 (0.534 sec/step)
I0404 21:28:59.606766 47978602034560 learning.py:507] global step 9677: loss = 5.9729 (0.505 sec/step)
I0404 21:29:00.112606 47978602034560 learning.py:507] global step 9678: loss = 4.5451 (0.504 sec/step)
I0404 21:29:00.640606 47978602034560 learning.py:507] global step 9679: loss = 5.1350 (0.526 sec/step)
I0404 21:29:01.166777 47978602034560 learning.py:507] global step 9680: loss = 4.6617 (0.525 sec/step)
I0404 21:29:01.684295 47978602034560 learning.py:507] global step 9681: loss = 5.8205 (0.516 sec/step)
I0404 21:29:02.192317 47978602034560 learning.py:507] global step 9682: loss = 5.2548 (0.506 sec/step)
I0404 21:29:02.694221 47978602034560 learning.py:507] global step 9683: loss = 6.0028 (0.499 sec/step)
I0404 21:29:03.203419 47978602034560 learning.py:507] global step 9684: loss = 5.3401 (0.508 sec/step)
I0404 21:29:03.751314 47978602034560 learning.py:507] global step 9685: loss = 5.8897 (0.546 sec/step)
I0404 21:29:04.260432 47978602034560 learning.py:507] global step 9686: loss = 5.0562 (0.507 sec/step)
I0404 21:29:04.777199 47978602034560 learning.py:507] global step 9687: loss = 4.9857 (0.515 sec/step)
I0404 21:29:05.311012 47978602034560 learning.py:507] global step 9688: loss = 5.6252 (0.532 sec/step)
I0404 21:29:05.816732 47978602034560 learning.py:507] global step 9689: loss = 4.9791 (0.503 sec/step)
I0404 21:29:06.323977 47978602034560 learning.py:507] global step 9690: loss = 6.3986 (0.504 sec/step)
I0404 21:29:06.828141 47978602034560 learning.py:507] global step 9691: loss = 6.1464 (0.503 sec/step)
I0404 21:29:07.339282 47978602034560 learning.py:507] global step 9692: loss = 5.5545 (0.508 sec/step)
I0404 21:29:07.854299 47978602034560 learning.py:507] global step 9693: loss = 5.8121 (0.514 sec/step)
I0404 21:29:08.388802 47978602034560 learning.py:507] global step 9694: loss = 5.3207 (0.532 sec/step)
I0404 21:29:08.892222 47978602034560 learning.py:507] global step 9695: loss = 6.2024 (0.502 sec/step)
I0404 21:29:09.402983 47978602034560 learning.py:507] global step 9696: loss = 4.9997 (0.509 sec/step)
I0404 21:29:09.905299 47978602034560 learning.py:507] global step 9697: loss = 6.3737 (0.501 sec/step)
I0404 21:29:10.419485 47978602034560 learning.py:507] global step 9698: loss = 5.1211 (0.513 sec/step)
I0404 21:29:10.929630 47978602034560 learning.py:507] global step 9699: loss = 5.6934 (0.507 sec/step)
I0404 21:29:11.442123 47978602034560 learning.py:507] global step 9700: loss = 5.2067 (0.511 sec/step)
I0404 21:29:11.947953 47978602034560 learning.py:507] global step 9701: loss = 5.7950 (0.504 sec/step)
I0404 21:29:12.477114 47978602034560 learning.py:507] global step 9702: loss = 5.0720 (0.528 sec/step)
I0404 21:29:13.012314 47978602034560 learning.py:507] global step 9703: loss = 5.4024 (0.534 sec/step)
I0404 21:29:13.514321 47978602034560 learning.py:507] global step 9704: loss = 6.2788 (0.500 sec/step)
I0404 21:29:14.031644 47978602034560 learning.py:507] global step 9705: loss = 5.6948 (0.516 sec/step)
I0404 21:29:14.566564 47978602034560 learning.py:507] global step 9706: loss = 6.2089 (0.533 sec/step)
I0404 21:29:15.077555 47978602034560 learning.py:507] global step 9707: loss = 5.8612 (0.509 sec/step)
I0404 21:29:15.585611 47978602034560 learning.py:507] global step 9708: loss = 7.0307 (0.506 sec/step)
I0404 21:29:16.095511 47978602034560 learning.py:507] global step 9709: loss = 5.3966 (0.508 sec/step)
I0404 21:29:16.604097 47978602034560 learning.py:507] global step 9710: loss = 5.8761 (0.506 sec/step)
I0404 21:29:17.313962 47978602034560 learning.py:507] global step 9711: loss = 5.3072 (0.708 sec/step)
I0404 21:29:17.315711 47983661975296 supervisor.py:1050] Recording summary at step 9711.
I0404 21:29:17.824393 47978602034560 learning.py:507] global step 9712: loss = 5.6251 (0.509 sec/step)
I0404 21:29:18.351328 47978602034560 learning.py:507] global step 9713: loss = 6.0381 (0.525 sec/step)
I0404 21:29:18.863016 47978602034560 learning.py:507] global step 9714: loss = 5.1420 (0.510 sec/step)
I0404 21:29:19.393652 47978602034560 learning.py:507] global step 9715: loss = 5.4663 (0.529 sec/step)
I0404 21:29:19.907206 47978602034560 learning.py:507] global step 9716: loss = 6.4069 (0.512 sec/step)
I0404 21:29:20.446337 47978602034560 learning.py:507] global step 9717: loss = 5.1094 (0.538 sec/step)
I0404 21:29:20.954257 47978602034560 learning.py:507] global step 9718: loss = 6.2357 (0.505 sec/step)
I0404 21:29:21.473392 47978602034560 learning.py:507] global step 9719: loss = 5.3324 (0.518 sec/step)
I0404 21:29:21.984908 47978602034560 learning.py:507] global step 9720: loss = 5.2643 (0.510 sec/step)
I0404 21:29:22.522526 47978602034560 learning.py:507] global step 9721: loss = 5.4962 (0.536 sec/step)
I0404 21:29:23.041663 47978602034560 learning.py:507] global step 9722: loss = 6.6616 (0.518 sec/step)
I0404 21:29:23.547355 47978602034560 learning.py:507] global step 9723: loss = 5.6043 (0.504 sec/step)
I0404 21:29:24.064505 47978602034560 learning.py:507] global step 9724: loss = 6.0742 (0.516 sec/step)
I0404 21:29:24.564009 47978602034560 learning.py:507] global step 9725: loss = 7.0735 (0.498 sec/step)
I0404 21:29:25.074513 47978602034560 learning.py:507] global step 9726: loss = 5.6560 (0.509 sec/step)
I0404 21:29:25.584733 47978602034560 learning.py:507] global step 9727: loss = 4.7648 (0.509 sec/step)
I0404 21:29:26.100514 47978602034560 learning.py:507] global step 9728: loss = 5.9887 (0.514 sec/step)
I0404 21:29:26.635416 47978602034560 learning.py:507] global step 9729: loss = 5.9469 (0.533 sec/step)
I0404 21:29:27.181222 47978602034560 learning.py:507] global step 9730: loss = 6.8338 (0.543 sec/step)
I0404 21:29:27.697395 47978602034560 learning.py:507] global step 9731: loss = 5.3765 (0.513 sec/step)
I0404 21:29:28.206438 47978602034560 learning.py:507] global step 9732: loss = 6.9893 (0.507 sec/step)
I0404 21:29:28.742605 47978602034560 learning.py:507] global step 9733: loss = 7.1642 (0.535 sec/step)
I0404 21:29:29.254450 47978602034560 learning.py:507] global step 9734: loss = 6.9579 (0.510 sec/step)
I0404 21:29:29.765934 47978602034560 learning.py:507] global step 9735: loss = 5.6790 (0.510 sec/step)
I0404 21:29:30.288074 47978602034560 learning.py:507] global step 9736: loss = 5.2179 (0.519 sec/step)
I0404 21:29:30.804621 47978602034560 learning.py:507] global step 9737: loss = 6.7196 (0.515 sec/step)
I0404 21:29:31.349575 47978602034560 learning.py:507] global step 9738: loss = 6.2684 (0.543 sec/step)
I0404 21:29:31.857013 47978602034560 learning.py:507] global step 9739: loss = 7.0949 (0.506 sec/step)
I0404 21:29:32.369606 47978602034560 learning.py:507] global step 9740: loss = 4.9147 (0.511 sec/step)
I0404 21:29:32.883848 47978602034560 learning.py:507] global step 9741: loss = 5.9608 (0.511 sec/step)
I0404 21:29:33.414656 47978602034560 learning.py:507] global step 9742: loss = 6.3257 (0.528 sec/step)
I0404 21:29:33.931826 47978602034560 learning.py:507] global step 9743: loss = 6.0998 (0.514 sec/step)
I0404 21:29:34.450889 47978602034560 learning.py:507] global step 9744: loss = 6.5111 (0.517 sec/step)
I0404 21:29:34.954485 47978602034560 learning.py:507] global step 9745: loss = 5.0787 (0.501 sec/step)
I0404 21:29:35.465717 47978602034560 learning.py:507] global step 9746: loss = 5.3997 (0.510 sec/step)
I0404 21:29:35.984525 47978602034560 learning.py:507] global step 9747: loss = 6.2912 (0.517 sec/step)
I0404 21:29:36.517279 47978602034560 learning.py:507] global step 9748: loss = 6.1192 (0.530 sec/step)
I0404 21:29:37.023000 47978602034560 learning.py:507] global step 9749: loss = 5.9240 (0.503 sec/step)
I0404 21:29:37.562273 47978602034560 learning.py:507] global step 9750: loss = 4.6669 (0.538 sec/step)
I0404 21:29:38.073434 47978602034560 learning.py:507] global step 9751: loss = 5.5946 (0.510 sec/step)
I0404 21:29:38.591052 47978602034560 learning.py:507] global step 9752: loss = 5.5757 (0.515 sec/step)
I0404 21:29:39.104632 47978602034560 learning.py:507] global step 9753: loss = 6.2954 (0.512 sec/step)
I0404 21:29:39.618492 47978602034560 learning.py:507] global step 9754: loss = 5.1092 (0.512 sec/step)
I0404 21:29:40.123842 47978602034560 learning.py:507] global step 9755: loss = 5.4392 (0.504 sec/step)
I0404 21:29:40.656246 47978602034560 learning.py:507] global step 9756: loss = 5.8773 (0.530 sec/step)
I0404 21:29:41.182157 47978602034560 learning.py:507] global step 9757: loss = 5.9744 (0.524 sec/step)
I0404 21:29:41.704507 47978602034560 learning.py:507] global step 9758: loss = 5.4313 (0.521 sec/step)
I0404 21:29:42.240389 47978602034560 learning.py:507] global step 9759: loss = 5.0723 (0.533 sec/step)
I0404 21:29:42.751164 47978602034560 learning.py:507] global step 9760: loss = 5.1005 (0.509 sec/step)
I0404 21:29:43.256454 47978602034560 learning.py:507] global step 9761: loss = 5.6479 (0.504 sec/step)
I0404 21:29:43.759459 47978602034560 learning.py:507] global step 9762: loss = 6.5255 (0.500 sec/step)
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyboardInterrupt</span>                         Traceback (most recent call last)
<span class="ansi-green-fg">/home-net/home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/legacy/train.py</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-intense-fg ansi-bold">    183</span> 
<span class="ansi-green-intense-fg ansi-bold">    184</span> <span class="ansi-green-fg">if</span> __name__ <span class="ansi-blue-fg">==</span> <span class="ansi-blue-fg">&#39;__main__&#39;</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 185</span><span class="ansi-red-fg">   </span>tf<span class="ansi-blue-fg">.</span>app<span class="ansi-blue-fg">.</span>run<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/.conda/envs/LPEnvironment/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py</span> in <span class="ansi-cyan-fg">run</span><span class="ansi-blue-fg">(main, argv)</span>
<span class="ansi-green-intense-fg ansi-bold">     38</span>   main <span class="ansi-blue-fg">=</span> main <span class="ansi-green-fg">or</span> _sys<span class="ansi-blue-fg">.</span>modules<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">&#39;__main__&#39;</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">.</span>main
<span class="ansi-green-intense-fg ansi-bold">     39</span> 
<span class="ansi-green-fg">---&gt; 40</span><span class="ansi-red-fg">   </span>_run<span class="ansi-blue-fg">(</span>main<span class="ansi-blue-fg">=</span>main<span class="ansi-blue-fg">,</span> argv<span class="ansi-blue-fg">=</span>argv<span class="ansi-blue-fg">,</span> flags_parser<span class="ansi-blue-fg">=</span>_parse_flags_tolerate_undef<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/.conda/envs/LPEnvironment/lib/python3.7/site-packages/absl/app.py</span> in <span class="ansi-cyan-fg">run</span><span class="ansi-blue-fg">(main, argv, flags_parser)</span>
<span class="ansi-green-intense-fg ansi-bold">    297</span>       callback<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    298</span>     <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 299</span><span class="ansi-red-fg">       </span>_run_main<span class="ansi-blue-fg">(</span>main<span class="ansi-blue-fg">,</span> args<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    300</span>     <span class="ansi-green-fg">except</span> UsageError <span class="ansi-green-fg">as</span> error<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    301</span>       usage<span class="ansi-blue-fg">(</span>shorthelp<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">True</span><span class="ansi-blue-fg">,</span> detailed_error<span class="ansi-blue-fg">=</span>error<span class="ansi-blue-fg">,</span> exitcode<span class="ansi-blue-fg">=</span>error<span class="ansi-blue-fg">.</span>exitcode<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/.conda/envs/LPEnvironment/lib/python3.7/site-packages/absl/app.py</span> in <span class="ansi-cyan-fg">_run_main</span><span class="ansi-blue-fg">(main, argv)</span>
<span class="ansi-green-intense-fg ansi-bold">    248</span>     sys<span class="ansi-blue-fg">.</span>exit<span class="ansi-blue-fg">(</span>retval<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    249</span>   <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 250</span><span class="ansi-red-fg">     </span>sys<span class="ansi-blue-fg">.</span>exit<span class="ansi-blue-fg">(</span>main<span class="ansi-blue-fg">(</span>argv<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    251</span> 
<span class="ansi-green-intense-fg ansi-bold">    252</span> 

<span class="ansi-green-fg">~/.conda/envs/LPEnvironment/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py</span> in <span class="ansi-cyan-fg">new_func</span><span class="ansi-blue-fg">(*args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    322</span>               <span class="ansi-blue-fg">&#39;in a future version&#39;</span> <span class="ansi-green-fg">if</span> date <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">None</span> <span class="ansi-green-fg">else</span> <span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#39;after %s&#39;</span> <span class="ansi-blue-fg">%</span> date<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    323</span>               instructions)
<span class="ansi-green-fg">--&gt; 324</span><span class="ansi-red-fg">       </span><span class="ansi-green-fg">return</span> func<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    325</span>     return tf_decorator.make_decorator(
<span class="ansi-green-intense-fg ansi-bold">    326</span>         func<span class="ansi-blue-fg">,</span> new_func<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">&#39;deprecated&#39;</span><span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">/home-net/home-1/cpaolic1@jhu.edu/code/AutomaticLP/models/research/object_detection/legacy/train.py</span> in <span class="ansi-cyan-fg">main</span><span class="ansi-blue-fg">(_)</span>
<span class="ansi-green-intense-fg ansi-bold">    179</span>       is_chief<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    180</span>       FLAGS<span class="ansi-blue-fg">.</span>train_dir<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">--&gt; 181</span><span class="ansi-red-fg">       graph_hook_fn=graph_rewriter_fn)
</span><span class="ansi-green-intense-fg ansi-bold">    182</span> 
<span class="ansi-green-intense-fg ansi-bold">    183</span> 

<span class="ansi-green-fg">~/code/AutomaticLP/models/research/object_detection/legacy/trainer.py</span> in <span class="ansi-cyan-fg">train</span><span class="ansi-blue-fg">(create_tensor_dict_fn, create_model_fn, train_config, master, task, num_clones, worker_replicas, clone_on_cpu, ps_tasks, worker_job_name, is_chief, train_dir, graph_hook_fn)</span>
<span class="ansi-green-intense-fg ansi-bold">    415</span>         save_summaries_secs<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">120</span><span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    416</span>         sync_optimizer<span class="ansi-blue-fg">=</span>sync_optimizer<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">--&gt; 417</span><span class="ansi-red-fg">         saver=saver)
</span>
<span class="ansi-green-fg">~/.conda/envs/LPEnvironment/lib/python3.7/site-packages/tensorflow_core/contrib/slim/python/slim/learning.py</span> in <span class="ansi-cyan-fg">train</span><span class="ansi-blue-fg">(train_op, logdir, train_step_fn, train_step_kwargs, log_every_n_steps, graph, master, is_chief, global_step, number_of_steps, init_op, init_feed_dict, local_init_op, init_fn, ready_op, summary_op, save_summaries_secs, summary_writer, startup_delay_steps, saver, save_interval_secs, sync_optimizer, session_config, session_wrapper, trace_every_n_steps, ignore_live_threads)</span>
<span class="ansi-green-intense-fg ansi-bold">    773</span>           <span class="ansi-green-fg">while</span> <span class="ansi-green-fg">not</span> sv<span class="ansi-blue-fg">.</span>should_stop<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    774</span>             total_loss, should_stop = train_step_fn(sess, train_op, global_step,
<span class="ansi-green-fg">--&gt; 775</span><span class="ansi-red-fg">                                                     train_step_kwargs)
</span><span class="ansi-green-intense-fg ansi-bold">    776</span>             <span class="ansi-green-fg">if</span> should_stop<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    777</span>               logging<span class="ansi-blue-fg">.</span>info<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#39;Stopping Training.&#39;</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/.conda/envs/LPEnvironment/lib/python3.7/site-packages/tensorflow_core/contrib/slim/python/slim/learning.py</span> in <span class="ansi-cyan-fg">train_step</span><span class="ansi-blue-fg">(sess, train_op, global_step, train_step_kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    488</span>   total_loss, np_global_step = sess.run([train_op, global_step],
<span class="ansi-green-intense-fg ansi-bold">    489</span>                                         options<span class="ansi-blue-fg">=</span>trace_run_options<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">--&gt; 490</span><span class="ansi-red-fg">                                         run_metadata=run_metadata)
</span><span class="ansi-green-intense-fg ansi-bold">    491</span>   time_elapsed <span class="ansi-blue-fg">=</span> time<span class="ansi-blue-fg">.</span>time<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">-</span> start_time
<span class="ansi-green-intense-fg ansi-bold">    492</span> 

<span class="ansi-green-fg">~/.conda/envs/LPEnvironment/lib/python3.7/site-packages/tensorflow_core/python/client/session.py</span> in <span class="ansi-cyan-fg">run</span><span class="ansi-blue-fg">(self, fetches, feed_dict, options, run_metadata)</span>
<span class="ansi-green-intense-fg ansi-bold">    954</span>     <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    955</span>       result = self._run(None, fetches, feed_dict, options_ptr,
<span class="ansi-green-fg">--&gt; 956</span><span class="ansi-red-fg">                          run_metadata_ptr)
</span><span class="ansi-green-intense-fg ansi-bold">    957</span>       <span class="ansi-green-fg">if</span> run_metadata<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    958</span>         proto_data <span class="ansi-blue-fg">=</span> tf_session<span class="ansi-blue-fg">.</span>TF_GetBuffer<span class="ansi-blue-fg">(</span>run_metadata_ptr<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/.conda/envs/LPEnvironment/lib/python3.7/site-packages/tensorflow_core/python/client/session.py</span> in <span class="ansi-cyan-fg">_run</span><span class="ansi-blue-fg">(self, handle, fetches, feed_dict, options, run_metadata)</span>
<span class="ansi-green-intense-fg ansi-bold">   1178</span>     <span class="ansi-green-fg">if</span> final_fetches <span class="ansi-green-fg">or</span> final_targets <span class="ansi-green-fg">or</span> <span class="ansi-blue-fg">(</span>handle <span class="ansi-green-fg">and</span> feed_dict_tensor<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   1179</span>       results = self._do_run(handle, final_targets, final_fetches,
<span class="ansi-green-fg">-&gt; 1180</span><span class="ansi-red-fg">                              feed_dict_tensor, options, run_metadata)
</span><span class="ansi-green-intense-fg ansi-bold">   1181</span>     <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   1182</span>       results <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">]</span>

<span class="ansi-green-fg">~/.conda/envs/LPEnvironment/lib/python3.7/site-packages/tensorflow_core/python/client/session.py</span> in <span class="ansi-cyan-fg">_do_run</span><span class="ansi-blue-fg">(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)</span>
<span class="ansi-green-intense-fg ansi-bold">   1357</span>     <span class="ansi-green-fg">if</span> handle <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   1358</span>       return self._do_call(_run_fn, feeds, fetches, targets, options,
<span class="ansi-green-fg">-&gt; 1359</span><span class="ansi-red-fg">                            run_metadata)
</span><span class="ansi-green-intense-fg ansi-bold">   1360</span>     <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   1361</span>       <span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>_do_call<span class="ansi-blue-fg">(</span>_prun_fn<span class="ansi-blue-fg">,</span> handle<span class="ansi-blue-fg">,</span> feeds<span class="ansi-blue-fg">,</span> fetches<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/.conda/envs/LPEnvironment/lib/python3.7/site-packages/tensorflow_core/python/client/session.py</span> in <span class="ansi-cyan-fg">_do_call</span><span class="ansi-blue-fg">(self, fn, *args)</span>
<span class="ansi-green-intense-fg ansi-bold">   1363</span>   <span class="ansi-green-fg">def</span> _do_call<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> fn<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   1364</span>     <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">-&gt; 1365</span><span class="ansi-red-fg">       </span><span class="ansi-green-fg">return</span> fn<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1366</span>     <span class="ansi-green-fg">except</span> errors<span class="ansi-blue-fg">.</span>OpError <span class="ansi-green-fg">as</span> e<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   1367</span>       message <span class="ansi-blue-fg">=</span> compat<span class="ansi-blue-fg">.</span>as_text<span class="ansi-blue-fg">(</span>e<span class="ansi-blue-fg">.</span>message<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/.conda/envs/LPEnvironment/lib/python3.7/site-packages/tensorflow_core/python/client/session.py</span> in <span class="ansi-cyan-fg">_run_fn</span><span class="ansi-blue-fg">(feed_dict, fetch_list, target_list, options, run_metadata)</span>
<span class="ansi-green-intense-fg ansi-bold">   1348</span>       self<span class="ansi-blue-fg">.</span>_extend_graph<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1349</span>       return self._call_tf_sessionrun(options, feed_dict, fetch_list,
<span class="ansi-green-fg">-&gt; 1350</span><span class="ansi-red-fg">                                       target_list, run_metadata)
</span><span class="ansi-green-intense-fg ansi-bold">   1351</span> 
<span class="ansi-green-intense-fg ansi-bold">   1352</span>     <span class="ansi-green-fg">def</span> _prun_fn<span class="ansi-blue-fg">(</span>handle<span class="ansi-blue-fg">,</span> feed_dict<span class="ansi-blue-fg">,</span> fetch_list<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">~/.conda/envs/LPEnvironment/lib/python3.7/site-packages/tensorflow_core/python/client/session.py</span> in <span class="ansi-cyan-fg">_call_tf_sessionrun</span><span class="ansi-blue-fg">(self, options, feed_dict, fetch_list, target_list, run_metadata)</span>
<span class="ansi-green-intense-fg ansi-bold">   1441</span>     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,
<span class="ansi-green-intense-fg ansi-bold">   1442</span>                                             fetch_list<span class="ansi-blue-fg">,</span> target_list<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">-&gt; 1443</span><span class="ansi-red-fg">                                             run_metadata)
</span><span class="ansi-green-intense-fg ansi-bold">   1444</span> 
<span class="ansi-green-intense-fg ansi-bold">   1445</span>   <span class="ansi-green-fg">def</span> _call_tf_sessionprun<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> handle<span class="ansi-blue-fg">,</span> feed_dict<span class="ansi-blue-fg">,</span> fetch_list<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-red-fg">KeyboardInterrupt</span>: </pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Put the cell output back to normal</span>
<span class="n">sys</span><span class="o">.</span><span class="n">stdout</span> <span class="o">=</span> <span class="n">old_stdout</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">run</span> viewTraining.py
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Evaluation">Evaluation<a class="anchor-link" href="#Evaluation">&#182;</a></h2><p>Both Evaluation and Training outputs can be looked at in Tensorboard for extra details</p>
<p><strong>TODO: update checkpoint number based on number of steps trained to</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">cd</span> models/research
<span class="o">!</span>python object_detection/export_inference_graph.py --input_type image_tensor --pipeline_config_path ../../FromScratch/models/model/ssd_mobilenet_v1_coco.config --trained_checkpoint_prefix ../../trainingOutput/model.ckpt-10 --output_directory ../../inference_graph
<span class="o">%</span><span class="k">cd</span> ../..
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">run</span> customEvaluation.py
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">cd</span> models/research
<span class="o">!</span>python object_detection/legacy/eval.py --logtostderr --pipeline_config_path<span class="o">=</span>../../FromScratch/models/model/ssd_mobilenet_v1_coco.config --checkpoint_dir<span class="o">=</span>../../trainingOutput --eval_dir<span class="o">=</span>../../evalOutput
<span class="o">%</span><span class="k">cd</span> ../..
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    </div>
  </div>
</body>

 


</html>
